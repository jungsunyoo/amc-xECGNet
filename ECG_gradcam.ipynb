{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/numba/errors.py:137: UserWarning: Insufficiently recent colorama version found. Numba requires colorama >= 0.3.9\n",
      "  warnings.warn(msg)\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import keras\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras.applications.densenet import DenseNet121, DenseNet169\n",
    "#from keras.applications.nasnet import NASNetLarge\n",
    "# from keras_efficientnets import EfficientNetB7\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras import initializers, regularizers, constraints\n",
    "from keras.layers.normalization import BatchNormalization \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from keras import backend as K\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, 2880, 12)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)              (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_20 (Lambda)              (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)              (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)              (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_23 (Lambda)              (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_24 (Lambda)              (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_13 (GaussianNois (None, 2880, 1)      0           lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_14 (GaussianNois (None, 2880, 1)      0           lambda_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_15 (GaussianNois (None, 2880, 1)      0           lambda_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_16 (GaussianNois (None, 2880, 1)      0           lambda_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_17 (GaussianNois (None, 2880, 1)      0           lambda_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_18 (GaussianNois (None, 2880, 1)      0           lambda_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_19 (GaussianNois (None, 2880, 1)      0           lambda_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_20 (GaussianNois (None, 2880, 1)      0           lambda_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_21 (GaussianNois (None, 2880, 1)      0           lambda_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_22 (GaussianNois (None, 2880, 1)      0           lambda_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_23 (GaussianNois (None, 2880, 1)      0           lambda_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_24 (GaussianNois (None, 2880, 1)      0           lambda_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_109 (Conv1D)             (None, 2880, 32)     352         gaussian_noise_13[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_118 (Conv1D)             (None, 2880, 32)     352         gaussian_noise_14[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_127 (Conv1D)             (None, 2880, 32)     352         gaussian_noise_15[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_136 (Conv1D)             (None, 2880, 32)     352         gaussian_noise_16[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_145 (Conv1D)             (None, 2880, 32)     352         gaussian_noise_17[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_154 (Conv1D)             (None, 2880, 32)     352         gaussian_noise_18[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_163 (Conv1D)             (None, 2880, 32)     352         gaussian_noise_19[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_172 (Conv1D)             (None, 2880, 32)     352         gaussian_noise_20[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_181 (Conv1D)             (None, 2880, 32)     352         gaussian_noise_21[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_190 (Conv1D)             (None, 2880, 32)     352         gaussian_noise_22[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_199 (Conv1D)             (None, 2880, 32)     352         gaussian_noise_23[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_208 (Conv1D)             (None, 2880, 32)     352         gaussian_noise_24[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 2880, 32)     128         conv1d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 2880, 32)     128         conv1d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 2880, 32)     128         conv1d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 2880, 32)     128         conv1d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 2880, 32)     128         conv1d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 2880, 32)     128         conv1d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 2880, 32)     128         conv1d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 2880, 32)     128         conv1d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 2880, 32)     128         conv1d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 2880, 32)     128         conv1d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 2880, 32)     128         conv1d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 2880, 32)     128         conv1d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_97 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_105 (LeakyReLU)     (None, 2880, 32)     0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_113 (LeakyReLU)     (None, 2880, 32)     0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_121 (LeakyReLU)     (None, 2880, 32)     0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_129 (LeakyReLU)     (None, 2880, 32)     0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_137 (LeakyReLU)     (None, 2880, 32)     0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_145 (LeakyReLU)     (None, 2880, 32)     0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_153 (LeakyReLU)     (None, 2880, 32)     0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_161 (LeakyReLU)     (None, 2880, 32)     0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_169 (LeakyReLU)     (None, 2880, 32)     0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_177 (LeakyReLU)     (None, 2880, 32)     0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_185 (LeakyReLU)     (None, 2880, 32)     0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_110 (Conv1D)             (None, 2880, 32)     10272       leaky_re_lu_97[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_119 (Conv1D)             (None, 2880, 32)     10272       leaky_re_lu_105[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_128 (Conv1D)             (None, 2880, 32)     10272       leaky_re_lu_113[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_137 (Conv1D)             (None, 2880, 32)     10272       leaky_re_lu_121[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_146 (Conv1D)             (None, 2880, 32)     10272       leaky_re_lu_129[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_155 (Conv1D)             (None, 2880, 32)     10272       leaky_re_lu_137[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_164 (Conv1D)             (None, 2880, 32)     10272       leaky_re_lu_145[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_173 (Conv1D)             (None, 2880, 32)     10272       leaky_re_lu_153[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_182 (Conv1D)             (None, 2880, 32)     10272       leaky_re_lu_161[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_191 (Conv1D)             (None, 2880, 32)     10272       leaky_re_lu_169[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_200 (Conv1D)             (None, 2880, 32)     10272       leaky_re_lu_177[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_209 (Conv1D)             (None, 2880, 32)     10272       leaky_re_lu_185[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_37 (Add)                    (None, 2880, 32)     0           conv1d_110[0][0]                 \n",
      "                                                                 leaky_re_lu_97[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_40 (Add)                    (None, 2880, 32)     0           conv1d_119[0][0]                 \n",
      "                                                                 leaky_re_lu_105[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_43 (Add)                    (None, 2880, 32)     0           conv1d_128[0][0]                 \n",
      "                                                                 leaky_re_lu_113[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_46 (Add)                    (None, 2880, 32)     0           conv1d_137[0][0]                 \n",
      "                                                                 leaky_re_lu_121[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_49 (Add)                    (None, 2880, 32)     0           conv1d_146[0][0]                 \n",
      "                                                                 leaky_re_lu_129[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_52 (Add)                    (None, 2880, 32)     0           conv1d_155[0][0]                 \n",
      "                                                                 leaky_re_lu_137[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_55 (Add)                    (None, 2880, 32)     0           conv1d_164[0][0]                 \n",
      "                                                                 leaky_re_lu_145[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_58 (Add)                    (None, 2880, 32)     0           conv1d_173[0][0]                 \n",
      "                                                                 leaky_re_lu_153[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_61 (Add)                    (None, 2880, 32)     0           conv1d_182[0][0]                 \n",
      "                                                                 leaky_re_lu_161[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_64 (Add)                    (None, 2880, 32)     0           conv1d_191[0][0]                 \n",
      "                                                                 leaky_re_lu_169[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_67 (Add)                    (None, 2880, 32)     0           conv1d_200[0][0]                 \n",
      "                                                                 leaky_re_lu_177[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_70 (Add)                    (None, 2880, 32)     0           conv1d_209[0][0]                 \n",
      "                                                                 leaky_re_lu_185[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 2880, 32)     128         add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 2880, 32)     128         add_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 2880, 32)     128         add_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 2880, 32)     128         add_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 2880, 32)     128         add_49[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 2880, 32)     128         add_52[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 2880, 32)     128         add_55[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 2880, 32)     128         add_58[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 2880, 32)     128         add_61[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 2880, 32)     128         add_64[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 2880, 32)     128         add_67[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 2880, 32)     128         add_70[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_98 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_106 (LeakyReLU)     (None, 2880, 32)     0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_114 (LeakyReLU)     (None, 2880, 32)     0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_122 (LeakyReLU)     (None, 2880, 32)     0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_130 (LeakyReLU)     (None, 2880, 32)     0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_138 (LeakyReLU)     (None, 2880, 32)     0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_146 (LeakyReLU)     (None, 2880, 32)     0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_154 (LeakyReLU)     (None, 2880, 32)     0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_162 (LeakyReLU)     (None, 2880, 32)     0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_170 (LeakyReLU)     (None, 2880, 32)     0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_178 (LeakyReLU)     (None, 2880, 32)     0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_186 (LeakyReLU)     (None, 2880, 32)     0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_111 (Conv1D)             (None, 1440, 32)     20512       leaky_re_lu_98[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_120 (Conv1D)             (None, 1440, 32)     20512       leaky_re_lu_106[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_129 (Conv1D)             (None, 1440, 32)     20512       leaky_re_lu_114[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_138 (Conv1D)             (None, 1440, 32)     20512       leaky_re_lu_122[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_147 (Conv1D)             (None, 1440, 32)     20512       leaky_re_lu_130[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_156 (Conv1D)             (None, 1440, 32)     20512       leaky_re_lu_138[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_165 (Conv1D)             (None, 1440, 32)     20512       leaky_re_lu_146[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_174 (Conv1D)             (None, 1440, 32)     20512       leaky_re_lu_154[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_183 (Conv1D)             (None, 1440, 32)     20512       leaky_re_lu_162[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_192 (Conv1D)             (None, 1440, 32)     20512       leaky_re_lu_170[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_201 (Conv1D)             (None, 1440, 32)     20512       leaky_re_lu_178[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_210 (Conv1D)             (None, 1440, 32)     20512       leaky_re_lu_186[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_112 (Conv1D)             (None, 1440, 64)     20544       conv1d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_121 (Conv1D)             (None, 1440, 64)     20544       conv1d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_130 (Conv1D)             (None, 1440, 64)     20544       conv1d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_139 (Conv1D)             (None, 1440, 64)     20544       conv1d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_148 (Conv1D)             (None, 1440, 64)     20544       conv1d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_157 (Conv1D)             (None, 1440, 64)     20544       conv1d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_166 (Conv1D)             (None, 1440, 64)     20544       conv1d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_175 (Conv1D)             (None, 1440, 64)     20544       conv1d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_184 (Conv1D)             (None, 1440, 64)     20544       conv1d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_193 (Conv1D)             (None, 1440, 64)     20544       conv1d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_202 (Conv1D)             (None, 1440, 64)     20544       conv1d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_211 (Conv1D)             (None, 1440, 64)     20544       conv1d_210[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 1440, 64)     256         conv1d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 1440, 64)     256         conv1d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 1440, 64)     256         conv1d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 1440, 64)     256         conv1d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 1440, 64)     256         conv1d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 1440, 64)     256         conv1d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 1440, 64)     256         conv1d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 1440, 64)     256         conv1d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 1440, 64)     256         conv1d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 1440, 64)     256         conv1d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 1440, 64)     256         conv1d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 1440, 64)     256         conv1d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_99 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_107 (LeakyReLU)     (None, 1440, 64)     0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_115 (LeakyReLU)     (None, 1440, 64)     0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_123 (LeakyReLU)     (None, 1440, 64)     0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_131 (LeakyReLU)     (None, 1440, 64)     0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_139 (LeakyReLU)     (None, 1440, 64)     0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_147 (LeakyReLU)     (None, 1440, 64)     0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_155 (LeakyReLU)     (None, 1440, 64)     0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_163 (LeakyReLU)     (None, 1440, 64)     0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_171 (LeakyReLU)     (None, 1440, 64)     0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_179 (LeakyReLU)     (None, 1440, 64)     0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_187 (LeakyReLU)     (None, 1440, 64)     0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_113 (Conv1D)             (None, 1440, 64)     41024       leaky_re_lu_99[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_122 (Conv1D)             (None, 1440, 64)     41024       leaky_re_lu_107[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_131 (Conv1D)             (None, 1440, 64)     41024       leaky_re_lu_115[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_140 (Conv1D)             (None, 1440, 64)     41024       leaky_re_lu_123[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_149 (Conv1D)             (None, 1440, 64)     41024       leaky_re_lu_131[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_158 (Conv1D)             (None, 1440, 64)     41024       leaky_re_lu_139[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_167 (Conv1D)             (None, 1440, 64)     41024       leaky_re_lu_147[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_176 (Conv1D)             (None, 1440, 64)     41024       leaky_re_lu_155[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_185 (Conv1D)             (None, 1440, 64)     41024       leaky_re_lu_163[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_194 (Conv1D)             (None, 1440, 64)     41024       leaky_re_lu_171[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_203 (Conv1D)             (None, 1440, 64)     41024       leaky_re_lu_179[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_212 (Conv1D)             (None, 1440, 64)     41024       leaky_re_lu_187[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_38 (Add)                    (None, 1440, 64)     0           conv1d_113[0][0]                 \n",
      "                                                                 leaky_re_lu_99[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_41 (Add)                    (None, 1440, 64)     0           conv1d_122[0][0]                 \n",
      "                                                                 leaky_re_lu_107[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_44 (Add)                    (None, 1440, 64)     0           conv1d_131[0][0]                 \n",
      "                                                                 leaky_re_lu_115[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_47 (Add)                    (None, 1440, 64)     0           conv1d_140[0][0]                 \n",
      "                                                                 leaky_re_lu_123[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_50 (Add)                    (None, 1440, 64)     0           conv1d_149[0][0]                 \n",
      "                                                                 leaky_re_lu_131[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_53 (Add)                    (None, 1440, 64)     0           conv1d_158[0][0]                 \n",
      "                                                                 leaky_re_lu_139[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_56 (Add)                    (None, 1440, 64)     0           conv1d_167[0][0]                 \n",
      "                                                                 leaky_re_lu_147[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_59 (Add)                    (None, 1440, 64)     0           conv1d_176[0][0]                 \n",
      "                                                                 leaky_re_lu_155[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_62 (Add)                    (None, 1440, 64)     0           conv1d_185[0][0]                 \n",
      "                                                                 leaky_re_lu_163[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_65 (Add)                    (None, 1440, 64)     0           conv1d_194[0][0]                 \n",
      "                                                                 leaky_re_lu_171[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_68 (Add)                    (None, 1440, 64)     0           conv1d_203[0][0]                 \n",
      "                                                                 leaky_re_lu_179[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_71 (Add)                    (None, 1440, 64)     0           conv1d_212[0][0]                 \n",
      "                                                                 leaky_re_lu_187[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 1440, 64)     256         add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 1440, 64)     256         add_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 1440, 64)     256         add_44[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 1440, 64)     256         add_47[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 1440, 64)     256         add_50[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 1440, 64)     256         add_53[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 1440, 64)     256         add_56[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 1440, 64)     256         add_59[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 1440, 64)     256         add_62[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 1440, 64)     256         add_65[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 1440, 64)     256         add_68[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 1440, 64)     256         add_71[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_100 (LeakyReLU)     (None, 1440, 64)     0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_108 (LeakyReLU)     (None, 1440, 64)     0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_116 (LeakyReLU)     (None, 1440, 64)     0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_124 (LeakyReLU)     (None, 1440, 64)     0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_132 (LeakyReLU)     (None, 1440, 64)     0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_140 (LeakyReLU)     (None, 1440, 64)     0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_148 (LeakyReLU)     (None, 1440, 64)     0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_156 (LeakyReLU)     (None, 1440, 64)     0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_164 (LeakyReLU)     (None, 1440, 64)     0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_172 (LeakyReLU)     (None, 1440, 64)     0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_180 (LeakyReLU)     (None, 1440, 64)     0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_188 (LeakyReLU)     (None, 1440, 64)     0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_114 (Conv1D)             (None, 720, 32)      40992       leaky_re_lu_100[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_123 (Conv1D)             (None, 720, 32)      40992       leaky_re_lu_108[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_132 (Conv1D)             (None, 720, 32)      40992       leaky_re_lu_116[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_141 (Conv1D)             (None, 720, 32)      40992       leaky_re_lu_124[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_150 (Conv1D)             (None, 720, 32)      40992       leaky_re_lu_132[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_159 (Conv1D)             (None, 720, 32)      40992       leaky_re_lu_140[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_168 (Conv1D)             (None, 720, 32)      40992       leaky_re_lu_148[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_177 (Conv1D)             (None, 720, 32)      40992       leaky_re_lu_156[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_186 (Conv1D)             (None, 720, 32)      40992       leaky_re_lu_164[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_195 (Conv1D)             (None, 720, 32)      40992       leaky_re_lu_172[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_204 (Conv1D)             (None, 720, 32)      40992       leaky_re_lu_180[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_213 (Conv1D)             (None, 720, 32)      40992       leaky_re_lu_188[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_115 (Conv1D)             (None, 720, 128)     41088       conv1d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_124 (Conv1D)             (None, 720, 128)     41088       conv1d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_133 (Conv1D)             (None, 720, 128)     41088       conv1d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_142 (Conv1D)             (None, 720, 128)     41088       conv1d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_151 (Conv1D)             (None, 720, 128)     41088       conv1d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_160 (Conv1D)             (None, 720, 128)     41088       conv1d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_169 (Conv1D)             (None, 720, 128)     41088       conv1d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_178 (Conv1D)             (None, 720, 128)     41088       conv1d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_187 (Conv1D)             (None, 720, 128)     41088       conv1d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_196 (Conv1D)             (None, 720, 128)     41088       conv1d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_205 (Conv1D)             (None, 720, 128)     41088       conv1d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_214 (Conv1D)             (None, 720, 128)     41088       conv1d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 720, 128)     512         conv1d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 720, 128)     512         conv1d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 720, 128)     512         conv1d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 720, 128)     512         conv1d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 720, 128)     512         conv1d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 720, 128)     512         conv1d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 720, 128)     512         conv1d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 720, 128)     512         conv1d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 720, 128)     512         conv1d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 720, 128)     512         conv1d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 720, 128)     512         conv1d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 720, 128)     512         conv1d_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_101 (LeakyReLU)     (None, 720, 128)     0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_109 (LeakyReLU)     (None, 720, 128)     0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_117 (LeakyReLU)     (None, 720, 128)     0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_125 (LeakyReLU)     (None, 720, 128)     0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_133 (LeakyReLU)     (None, 720, 128)     0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_141 (LeakyReLU)     (None, 720, 128)     0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_149 (LeakyReLU)     (None, 720, 128)     0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_157 (LeakyReLU)     (None, 720, 128)     0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_165 (LeakyReLU)     (None, 720, 128)     0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_173 (LeakyReLU)     (None, 720, 128)     0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_181 (LeakyReLU)     (None, 720, 128)     0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_189 (LeakyReLU)     (None, 720, 128)     0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_116 (Conv1D)             (None, 720, 128)     163968      leaky_re_lu_101[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_125 (Conv1D)             (None, 720, 128)     163968      leaky_re_lu_109[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_134 (Conv1D)             (None, 720, 128)     163968      leaky_re_lu_117[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_143 (Conv1D)             (None, 720, 128)     163968      leaky_re_lu_125[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_152 (Conv1D)             (None, 720, 128)     163968      leaky_re_lu_133[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_161 (Conv1D)             (None, 720, 128)     163968      leaky_re_lu_141[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_170 (Conv1D)             (None, 720, 128)     163968      leaky_re_lu_149[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_179 (Conv1D)             (None, 720, 128)     163968      leaky_re_lu_157[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_188 (Conv1D)             (None, 720, 128)     163968      leaky_re_lu_165[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_197 (Conv1D)             (None, 720, 128)     163968      leaky_re_lu_173[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_206 (Conv1D)             (None, 720, 128)     163968      leaky_re_lu_181[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_215 (Conv1D)             (None, 720, 128)     163968      leaky_re_lu_189[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_39 (Add)                    (None, 720, 128)     0           conv1d_116[0][0]                 \n",
      "                                                                 leaky_re_lu_101[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_42 (Add)                    (None, 720, 128)     0           conv1d_125[0][0]                 \n",
      "                                                                 leaky_re_lu_109[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_45 (Add)                    (None, 720, 128)     0           conv1d_134[0][0]                 \n",
      "                                                                 leaky_re_lu_117[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_48 (Add)                    (None, 720, 128)     0           conv1d_143[0][0]                 \n",
      "                                                                 leaky_re_lu_125[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_51 (Add)                    (None, 720, 128)     0           conv1d_152[0][0]                 \n",
      "                                                                 leaky_re_lu_133[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_54 (Add)                    (None, 720, 128)     0           conv1d_161[0][0]                 \n",
      "                                                                 leaky_re_lu_141[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_57 (Add)                    (None, 720, 128)     0           conv1d_170[0][0]                 \n",
      "                                                                 leaky_re_lu_149[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_60 (Add)                    (None, 720, 128)     0           conv1d_179[0][0]                 \n",
      "                                                                 leaky_re_lu_157[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_63 (Add)                    (None, 720, 128)     0           conv1d_188[0][0]                 \n",
      "                                                                 leaky_re_lu_165[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_66 (Add)                    (None, 720, 128)     0           conv1d_197[0][0]                 \n",
      "                                                                 leaky_re_lu_173[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_69 (Add)                    (None, 720, 128)     0           conv1d_206[0][0]                 \n",
      "                                                                 leaky_re_lu_181[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_72 (Add)                    (None, 720, 128)     0           conv1d_215[0][0]                 \n",
      "                                                                 leaky_re_lu_189[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 720, 128)     512         add_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 720, 128)     512         add_42[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 720, 128)     512         add_45[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 720, 128)     512         add_48[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 720, 128)     512         add_51[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 720, 128)     512         add_54[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 720, 128)     512         add_57[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 720, 128)     512         add_60[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 720, 128)     512         add_63[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 720, 128)     512         add_66[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 720, 128)     512         add_69[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 720, 128)     512         add_72[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_102 (LeakyReLU)     (None, 720, 128)     0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_110 (LeakyReLU)     (None, 720, 128)     0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_118 (LeakyReLU)     (None, 720, 128)     0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_126 (LeakyReLU)     (None, 720, 128)     0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_134 (LeakyReLU)     (None, 720, 128)     0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_142 (LeakyReLU)     (None, 720, 128)     0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_150 (LeakyReLU)     (None, 720, 128)     0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_158 (LeakyReLU)     (None, 720, 128)     0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_166 (LeakyReLU)     (None, 720, 128)     0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_174 (LeakyReLU)     (None, 720, 128)     0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_182 (LeakyReLU)     (None, 720, 128)     0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_190 (LeakyReLU)     (None, 720, 128)     0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_117 (Conv1D)             (None, 360, 64)      163904      leaky_re_lu_102[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_126 (Conv1D)             (None, 360, 64)      163904      leaky_re_lu_110[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_135 (Conv1D)             (None, 360, 64)      163904      leaky_re_lu_118[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_144 (Conv1D)             (None, 360, 64)      163904      leaky_re_lu_126[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_153 (Conv1D)             (None, 360, 64)      163904      leaky_re_lu_134[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_162 (Conv1D)             (None, 360, 64)      163904      leaky_re_lu_142[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_171 (Conv1D)             (None, 360, 64)      163904      leaky_re_lu_150[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_180 (Conv1D)             (None, 360, 64)      163904      leaky_re_lu_158[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_189 (Conv1D)             (None, 360, 64)      163904      leaky_re_lu_166[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_198 (Conv1D)             (None, 360, 64)      163904      leaky_re_lu_174[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_207 (Conv1D)             (None, 360, 64)      163904      leaky_re_lu_182[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_216 (Conv1D)             (None, 360, 64)      163904      leaky_re_lu_190[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_13 (Bidirectional (None, 360, 256)     148992      conv1d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_14 (Bidirectional (None, 360, 256)     148992      conv1d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_15 (Bidirectional (None, 360, 256)     148992      conv1d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_16 (Bidirectional (None, 360, 256)     148992      conv1d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_17 (Bidirectional (None, 360, 256)     148992      conv1d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_18 (Bidirectional (None, 360, 256)     148992      conv1d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_19 (Bidirectional (None, 360, 256)     148992      conv1d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_20 (Bidirectional (None, 360, 256)     148992      conv1d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_21 (Bidirectional (None, 360, 256)     148992      conv1d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_22 (Bidirectional (None, 360, 256)     148992      conv1d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_23 (Bidirectional (None, 360, 256)     148992      conv1d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_24 (Bidirectional (None, 360, 256)     148992      conv1d_216[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_103 (LeakyReLU)     (None, 360, 256)     0           bidirectional_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_111 (LeakyReLU)     (None, 360, 256)     0           bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_119 (LeakyReLU)     (None, 360, 256)     0           bidirectional_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_127 (LeakyReLU)     (None, 360, 256)     0           bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_135 (LeakyReLU)     (None, 360, 256)     0           bidirectional_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_143 (LeakyReLU)     (None, 360, 256)     0           bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_151 (LeakyReLU)     (None, 360, 256)     0           bidirectional_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_159 (LeakyReLU)     (None, 360, 256)     0           bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_167 (LeakyReLU)     (None, 360, 256)     0           bidirectional_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_175 (LeakyReLU)     (None, 360, 256)     0           bidirectional_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_183 (LeakyReLU)     (None, 360, 256)     0           bidirectional_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_191 (LeakyReLU)     (None, 360, 256)     0           bidirectional_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_13 (Atte (None, 256)          66048       leaky_re_lu_103[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_14 (Atte (None, 256)          66048       leaky_re_lu_111[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_15 (Atte (None, 256)          66048       leaky_re_lu_119[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_16 (Atte (None, 256)          66048       leaky_re_lu_127[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_17 (Atte (None, 256)          66048       leaky_re_lu_135[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_18 (Atte (None, 256)          66048       leaky_re_lu_143[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_19 (Atte (None, 256)          66048       leaky_re_lu_151[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_20 (Atte (None, 256)          66048       leaky_re_lu_159[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_21 (Atte (None, 256)          66048       leaky_re_lu_167[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_22 (Atte (None, 256)          66048       leaky_re_lu_175[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_23 (Atte (None, 256)          66048       leaky_re_lu_183[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_24 (Atte (None, 256)          66048       leaky_re_lu_191[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 256)          1024        attention_with_context_13[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 256)          1024        attention_with_context_14[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 256)          1024        attention_with_context_15[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 256)          1024        attention_with_context_16[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 256)          1024        attention_with_context_17[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 256)          1024        attention_with_context_18[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 256)          1024        attention_with_context_19[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 256)          1024        attention_with_context_20[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 256)          1024        attention_with_context_21[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 256)          1024        attention_with_context_22[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 256)          1024        attention_with_context_23[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 256)          1024        attention_with_context_24[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_104 (LeakyReLU)     (None, 256)          0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_112 (LeakyReLU)     (None, 256)          0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_120 (LeakyReLU)     (None, 256)          0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_128 (LeakyReLU)     (None, 256)          0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_136 (LeakyReLU)     (None, 256)          0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_144 (LeakyReLU)     (None, 256)          0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_152 (LeakyReLU)     (None, 256)          0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_160 (LeakyReLU)     (None, 256)          0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_168 (LeakyReLU)     (None, 256)          0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_176 (LeakyReLU)     (None, 256)          0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_184 (LeakyReLU)     (None, 256)          0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_192 (LeakyReLU)     (None, 256)          0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 9)            2313        leaky_re_lu_104[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 9)            2313        leaky_re_lu_112[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 9)            2313        leaky_re_lu_120[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 9)            2313        leaky_re_lu_128[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 9)            2313        leaky_re_lu_136[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 9)            2313        leaky_re_lu_144[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 9)            2313        leaky_re_lu_152[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 9)            2313        leaky_re_lu_160[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 9)            2313        leaky_re_lu_168[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 9)            2313        leaky_re_lu_176[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 9)            2313        leaky_re_lu_184[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 9)            2313        leaky_re_lu_192[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 9)            0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 9)            0           dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 9)            0           dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 9)            0           dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 9)            0           dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 9)            0           dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 9)            0           dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 9)            0           dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 9)            0           dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 9)            0           dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 9)            0           dense_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 9)            0           dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "average_2 (Average)             (None, 9)            0           activation_13[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "                                                                 activation_20[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_22[0][0]              \n",
      "                                                                 activation_23[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 8,673,900\n",
      "Trainable params: 8,657,004\n",
      "Non-trainable params: 16,896\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "minimum_len=2880\n",
    "def score_f1(y_true, y_pred): #taken from old keras source code\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val\n",
    "\n",
    "def dot_product(x, kernel):\n",
    "    if K.backend() == 'tensorflow':\n",
    "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
    "    else:\n",
    "        return K.dot(x, kernel)\n",
    "    \n",
    "class AttentionWithContext(Layer):\n",
    "    def __init__(self,\n",
    "                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, u_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.u_regularizer = regularizers.get(u_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.u_constraint = constraints.get(u_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "        self.bias = bias\n",
    "        super(AttentionWithContext, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "        self.W = self.add_weight((input_shape[-1], input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight((input_shape[-1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "            self.u = self.add_weight((input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_u'.format(self.name),\n",
    "                                 regularizer=self.u_regularizer,\n",
    "                                 constraint=self.u_constraint)\n",
    "        super(AttentionWithContext, self).build(input_shape)\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        uit = dot_product(x, self.W)\n",
    "        if self.bias:\n",
    "            uit += self.b\n",
    "        uit = K.tanh(uit)\n",
    "        ait = dot_product(uit, self.u)\n",
    "        a = K.exp(ait)\n",
    "        if mask is not None:\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], input_shape[-1]\n",
    "\n",
    "    \n",
    "def cce_f1_loss(y_true, y_pred):\n",
    "    return 1 + 0.1*keras.losses.categorical_crossentropy(y_true, y_pred) - keras.metrics.categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "main_input = Input(shape=(minimum_len,12), dtype='float32', name='main_input')\n",
    "\n",
    "branch_pred = []\n",
    "for i in range(12):\n",
    "    # Slicing the ith channel:\n",
    "    input_sl = Lambda(lambda x: x[:, :, i:i+1])(main_input)\n",
    "    #print(input_sl)\n",
    "    x1 = GaussianNoise(0.01 ,input_shape=(minimum_len, 1))(input_sl)\n",
    "    x1 = Conv1D(32, 10, dilation_rate=3, padding='same')(x1)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = LeakyReLU(alpha=0.3)(x1)\n",
    "    x2 = Conv1D(32, 10, dilation_rate=3, padding='same')(x1)\n",
    "    x2 = add([x2, x1])\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = LeakyReLU(alpha=0.3)(x2)\n",
    "    #x2 = MaxPooling1D(pool_size=2)(x2)\n",
    "    x2 = Convolution1D(32, 20, strides = 2, padding='same')(x2)\n",
    "    #x2 = Dropout(0.25)(x2)\n",
    "\n",
    "    x3 = Conv1D(64, 10, dilation_rate=2, padding='same')(x2)\n",
    "    x3 = BatchNormalization()(x3)\n",
    "    x3 = LeakyReLU(alpha=0.3)(x3)\n",
    "    x4 = Conv1D(64, 10, dilation_rate=2, padding='same')(x3)\n",
    "    x4 = add([x4, x3])\n",
    "    x4 = BatchNormalization()(x4)\n",
    "    x4 = LeakyReLU(alpha=0.3)(x4)\n",
    "    #x4 = MaxPooling1D(pool_size=2)(x4)\n",
    "    x4 = Convolution1D(32, 20, strides = 2, padding='same')(x4)\n",
    "    #x4 = Dropout(0.25)(x4)\n",
    "\n",
    "    x5 = Conv1D(128, 10, dilation_rate=1, padding='same')(x4)\n",
    "    x5 = BatchNormalization()(x5)\n",
    "    x5 = LeakyReLU(alpha=0.3)(x5)\n",
    "    x6 = Conv1D(128, 10, dilation_rate=1, padding='same')(x5)\n",
    "    x6 = add([x6, x5])\n",
    "    x6 = BatchNormalization()(x6)\n",
    "    x6 = LeakyReLU(alpha=0.3)(x6)\n",
    "    #x6 = MaxPooling1D(pool_size=2)(x6)\n",
    "    x6 = Convolution1D(64, 20, strides = 2, padding='same')(x6)\n",
    "    #x6 = Dropout(0.25)(x6)\n",
    "    '''\n",
    "    x7 = Conv1D(64, 10, dilation_rate=1, padding='same')(x6)\n",
    "    x7 = BatchNormalization()(x7)\n",
    "    x7 = LeakyReLU(alpha=0.3)(x7)\n",
    "    x8 = Conv1D(64, 10, dilation_rate=1, padding='same')(x7)\n",
    "    x8 = add([x8, x7])\n",
    "    x8 = BatchNormalization()(x8)\n",
    "    x8 = LeakyReLU(alpha=0.3)(x8)\n",
    "    #x8 = MaxPooling1D(pool_size=2)(x8)\n",
    "    x8 = Convolution1D(64, 20, strides = 2, padding='same')(x8)\n",
    "    #cnnout = GlobalAveragePooling1D()(x8)\n",
    "    #x8 = Dropout(0.25)(x8)\n",
    "    '''\n",
    "    x = Bidirectional(CuDNNGRU(128, input_shape=(360,128),return_sequences=True,return_state=False))(x6)\n",
    "    x = LeakyReLU(alpha=0.3)(x)\n",
    "    x = AttentionWithContext()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.3)(x)\n",
    "    \n",
    "    #x = GlobalAveragePooling1D()(x8)\n",
    "    #x = Flatten()(x8)\n",
    "    #x = Dense(512)(x)\n",
    "    #x = BatchNormalization()(x)\n",
    "    #x = Activation('relu')(x)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    x = Dense(9)(x)\n",
    "    pred  = Activation('softmax')(x)\n",
    "    branch_pred.append(pred)\n",
    "    \n",
    "out = Average()(branch_pred)\n",
    "#print(out)\n",
    "\n",
    "model = Model(inputs=main_input, outputs=out)\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=loss_function,\n",
    "              optimizer=optimizers.Adam(lr=1e-5),\n",
    "              metrics=['acc', score_f1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_dir = '/home/taejoon/PhysioNetChallenge/results_20200424_0'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "modelname = 'ecg_mel_E395L0.35'\n",
    "\n",
    "# model=load_model(os.path.join(model_dir, modelname), custom_objects={'AttentionWithContext':AttentionWithContext()})\n",
    "\n",
    "\n",
    "\n",
    "model.load_weights(os.path.join(model_dir, modelname))\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.24290386e-03 -4.58280585e-05  4.31697309e-03 -3.00174693e-03\n",
      " -2.36609229e-04  1.28997408e-03  2.17347589e-04 -7.99152384e-04\n",
      " -3.42993744e-03 -1.69711686e-03  1.27138164e-03  1.94670545e-03]\n",
      "(3840,) (1280,) (1281,)\n"
     ]
    }
   ],
   "source": [
    "def get_unique_classes(input_directory,files):\n",
    "\n",
    "    unique_classes=set()\n",
    "    for f in files:\n",
    "        g = f.replace('.mat','.hea')\n",
    "        input_file = os.path.join(input_directory,g)\n",
    "        with open(input_file,'r') as f:\n",
    "            for lines in f:\n",
    "                if lines.startswith('#Dx'):\n",
    "                    tmp = lines.split(': ')[1].split(',')\n",
    "                    for c in tmp:\n",
    "                        unique_classes.add(c.strip())\n",
    "    return sorted(unique_classes)\n",
    "\n",
    "def one_hot_encoding(one_hot_vector,y, class2index):\n",
    "    ind=class2index[y]\n",
    "    one_hot_vector[ind]=1\n",
    "    return one_hot_vector\n",
    "\n",
    "# Search for multi-label subjects\n",
    "def searching_overlap(input_directory,class2index, input_file_names):\n",
    "    multiclasses=[]\n",
    "    multisubjects=[]\n",
    "    number = []\n",
    "    for file in input_file_names:\n",
    "        f=file\n",
    "        g = f.replace('.mat','.hea')\n",
    "        input_file = os.path.join(input_directory,g)\n",
    "        with open(input_file,'r') as f:\n",
    "            for lines in f:\n",
    "                if lines.startswith('#Dx'):\n",
    "                    tmp = lines.split(': ')[1].split(',')\n",
    "                    if len(tmp)>1:\n",
    "                        one_hot_vector = [0]*(len(class2index))\n",
    "                        for c in tmp:\n",
    "                            one_hot_vector = one_hot_encoding(one_hot_vector, c.strip(), class2index)\n",
    "                        multiclasses.append(one_hot_vector)\n",
    "                        multisubjects.append(g)\n",
    "                        number.append(len(tmp))\n",
    "    return multisubjects, multiclasses, number\n",
    "\n",
    "def block_feature(sequence_en, minimum_len): \n",
    "    new_en = []\n",
    "    if len(sequence_en) > minimum_len:  # 길이가 minimum보다 긴 경우\n",
    "        start = random.randint(0,len(sequence_en)-minimum_len)\n",
    "        #print(start)\n",
    "        new_en = sequence_en[start:start+minimum_len]\n",
    "    elif len(sequence_en) == minimum_len: # 길이가 minimum\n",
    "        new_en = sequence_en\n",
    "    else: \n",
    "        assert len(sequence_en) <= minimum_len\n",
    "    return new_en\n",
    "\n",
    "def exploratory_look(input_directory,file, class2index):\n",
    "    classes = []\n",
    "    f = file\n",
    "    g = f.replace('.mat','.hea')\n",
    "    input_file = os.path.join(input_directory,g)\n",
    "    with open(input_file,'r') as f:\n",
    "        for lines in f:\n",
    "            if lines.startswith('#Dx'):\n",
    "                tmp = lines.split(': ')[1].split(',')\n",
    "                print(tmp, len(tmp))\n",
    "    return tmp     \n",
    "\n",
    "# Get classes of sorted file names\n",
    "def get_labels(input_directory,file, class2index):\n",
    "    f = file\n",
    "    g = f.replace('.mat','.hea')\n",
    "    input_file = os.path.join(input_directory,g)\n",
    "    with open(input_file,'r') as f:\n",
    "        for lines in f:\n",
    "            if lines.startswith('#Dx'):\n",
    "                tmp = lines.split(': ')[1].split(',')\n",
    "                one_hot_vector = [0]*(len(class2index))\n",
    "                for c in tmp:\n",
    "                    one_hot_vector = one_hot_encoding(one_hot_vector, c.strip(), class2index)\n",
    "                \n",
    "    return one_hot_vector\n",
    "\n",
    "def randextract_mels(curr_step, batch_size, data, mel_directory, class2index, minimum_len, x_mean_final, x_std_final):\n",
    "    mel_files = []\n",
    "    classes = []\n",
    "    start = batch_size*curr_step\n",
    "    end = batch_size*(curr_step+1)\n",
    "    curr_file_indices = data[start:end]\n",
    "    for file in curr_file_indices:\n",
    "        tmp_file = np.load(mel_directory + '/' + file.replace('.mat', '.npy'))\n",
    "        clip_file = block_feature(tmp_file, minimum_len)\n",
    "        #print(clip_file.shape)\n",
    "        #clip_file = tmp_file[:minimum_len]\n",
    "        clip_file -= x_mean_final\n",
    "        clip_file /= x_std_final\n",
    "        mel_files.append(clip_file)\n",
    "        label = get_labels(input_directory, file, class2index)\n",
    "        classes.append(label)\n",
    "    concat = list(zip(mel_files, classes))\n",
    "    random.shuffle(concat)\n",
    "    mel_files, classes = zip(*concat)\n",
    "    return mel_files, classes\n",
    "\n",
    "def train(data_train, mel_directory, batch_size, class2index, minimum_len, x_mean_final, x_std_final): \n",
    "    loss=[]\n",
    "    acc = []\n",
    "    f1 = []\n",
    "\n",
    "    total_steps = int(np.ceil(len(data_train)/batch_size))\n",
    "    for curr_step in range(total_steps):\n",
    "        batch_mels, batch_labels = randextract_mels(curr_step, batch_size, data_train, mel_directory, class2index, minimum_len, x_mean_final, x_std_final)\n",
    "        batch_mels = np.asarray(batch_mels)\n",
    "        batch_labels = np.asarray(np.squeeze(batch_labels))\n",
    "        train_tmp = model.train_on_batch(batch_mels, batch_labels)\n",
    "        loss.append(train_tmp[0])\n",
    "        acc.append(train_tmp[1])\n",
    "        f1.append(train_tmp[2])\n",
    "\n",
    "    loss = np.mean(np.array(loss))\n",
    "    acc = np.mean(np.array(acc))\n",
    "    f1 = np.mean(np.array(f1))\n",
    "    return loss, acc, f1\n",
    "\n",
    "def test(data, mel_directory, input_directory, class2index, minimum_len, model, x_mean_final, x_std_final):\n",
    "    scores = []\n",
    "    predicted_labels=[]\n",
    "    accuracy=np.zeros(len(data))\n",
    "    #total_loss=[]\n",
    "    total_acc = 0\n",
    "    total_f1 = 0\n",
    "    \n",
    "    mel_files = []\n",
    "    classes = []\n",
    "    for i, file in enumerate(data):\n",
    "        tmp_file = np.load(mel_directory + '/' + file.replace('.mat', '.npy'))\n",
    "        steps = int(np.floor(tmp_file.shape[0]/minimum_len))\n",
    "        mel_files = []\n",
    "        for block in range(steps): # 128개씩 쪼갠 블럭 단위로 predict\n",
    "            start = block*minimum_len\n",
    "            end = (block+1)*minimum_len\n",
    "            clip_file = tmp_file[start:end]\n",
    "            clip_file -= x_mean_final\n",
    "            clip_file /= x_std_final\n",
    "            mel_files.append(clip_file)\n",
    "        mel_files = np.asarray(mel_files)\n",
    "        logit = model.predict(mel_files)\n",
    "        logit = np.mean(logit, axis=0)\n",
    "        pred = np.argmax(logit)\n",
    "        label = np.argmax(get_labels(input_directory, file, class2index))\n",
    "        #f1 = f1_score(label, logit)\n",
    "        #print(pred, label)\n",
    "        if pred == label:\n",
    "            acc = 1\n",
    "        else:\n",
    "            acc = 0\n",
    "        total_acc += acc\n",
    "        #total_f1 += f1\n",
    "    final_acc = total_acc / i\n",
    "    #final_f1 = total_f1 / i\n",
    "    return final_acc#, final_f1\n",
    "\n",
    "batch_size = 32\n",
    "minimum_len = 2880\n",
    "\n",
    "epochs = 1000\n",
    "loss_function = 'categorical_crossentropy'\n",
    "activation_function = 'softmax'\n",
    "rootdir = '../'\n",
    "date = datetime.today().strftime(\"%Y%m%d\")\n",
    "input_directory = os.path.join(rootdir, 'Training_WFDB')\n",
    "mel_name = 'Raw_data_20200424' \n",
    "mel_directory = os.path.join(rootdir, mel_name)\n",
    "results_directory = os.path.join(rootdir, 'results_'+date+'_0')\n",
    "if not os.path.isdir(input_directory):\n",
    "    os.mkdir(input_directory)\n",
    "if not os.path.isdir(mel_directory):\n",
    "    os.mkdir(mel_directory)\n",
    "if not os.path.isdir(results_directory):\n",
    "    os.mkdir(results_directory)\n",
    "        \n",
    "input_files = []\n",
    "for f in os.listdir(input_directory):\n",
    "    if os.path.isfile(os.path.join(input_directory, f)) and not f.lower().startswith('.') and f.lower().endswith('mat'):\n",
    "        input_files.append(f)\n",
    "input_file_names = sorted(input_files)\n",
    "\n",
    "unique_classes = get_unique_classes(input_directory, input_files)\n",
    "class2index = {}\n",
    "for a, b in enumerate(unique_classes):\n",
    "    class2index[b] = a\n",
    "index2class = {y:x for x,y in class2index.items()}    \n",
    "classes_orig= [x.replace('.mat', '.hea') for x in input_file_names] # total subjects\n",
    "classes_multi, _, _ = searching_overlap(input_directory,class2index, input_file_names)\n",
    "classes_single = [x for x in classes_orig if x not in classes_multi]\n",
    "classes_single = [x.replace('.hea', '.mat') for x in classes_single]\n",
    "\n",
    "# double-checking if classes_single have single-label\n",
    "a, b, c  = searching_overlap(input_directory,class2index,classes_single)\n",
    "\n",
    "# we can safely use classes_single as input_file_names\n",
    "input_file_names = classes_single\n",
    "random.shuffle(input_file_names)\n",
    "np.shape(input_file_names)\n",
    "\n",
    "x_mean_all = []\n",
    "x_std_all = []\n",
    "for file in input_file_names:\n",
    "    x = np.load(mel_directory + '/' + file.replace('.mat', '.npy'))\n",
    "    x_mean = [np.mean(x[:,0]), np.mean(x[:,1]), np.mean(x[:,2]), np.mean(x[:,3]), np.mean(x[:,4]), np.mean(x[:,5]),\n",
    "             np.mean(x[:,6]), np.mean(x[:,7]), np.mean(x[:,8]), np.mean(x[:,9]), np.mean(x[:,10]), np.mean(x[:,11])]\n",
    "    \n",
    "    x_std = [np.std(x[:,0]), np.std(x[:,1]), np.std(x[:,2]), np.std(x[:,3]), np.std(x[:,4]), np.std(x[:,5]),\n",
    "             np.std(x[:,6]), np.std(x[:,7]), np.std(x[:,8]), np.std(x[:,9]), np.std(x[:,10]), np.std(x[:,11])]\n",
    "    #print(x_mean)\n",
    "    x_mean_all.append(x_mean)\n",
    "    x_std_all.append(x_mean)\n",
    "x_mean_final = np.mean(x_mean_all, axis=0)\n",
    "x_std_final = np.mean(x_std_all, axis=0)\n",
    "print(x_mean_final)\n",
    "\n",
    "data, data_test = train_test_split(input_file_names, test_size = 0.2, train_size = 0.8, shuffle=True)\n",
    "data_train, data_val = train_test_split(data, test_size = 0.25, train_size = 0.75, shuffle=True)\n",
    "print(np.shape(data_train), np.shape(data_val), np.shape(data_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2880, 12)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file=data_train[0]\n",
    "tmp_file = np.load(mel_directory + '/' + file.replace('.mat', '.npy'))\n",
    "clip_file = block_feature(tmp_file, minimum_len)\n",
    "clip_file -= x_mean_final\n",
    "clip_file /= x_std_final\n",
    "clip_file.shape\n",
    "\n",
    "preprocessed_input=clip_file\n",
    "\n",
    "preprocessed_input.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`decode_predictions` expects a batch of predictions (i.e. a 2D array of shape (samples, 1000)). Found array with shape: (1, 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d53fe0531521>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocessed_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m \u001b[0mtop_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Predicted class:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s (%s) with probability %.2f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtop_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/applications/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'models'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'utils'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbase_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/applications/vgg16.py\u001b[0m in \u001b[0;36mdecode_predictions\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mkeras_modules_injection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdecode_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mvgg16\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_applications/imagenet_utils.py\u001b[0m in \u001b[0;36mdecode_predictions\u001b[0;34m(preds, top, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m                          \u001b[0;34m'a batch of predictions '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                          \u001b[0;34m'(i.e. a 2D array of shape (samples, 1000)). '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m                          'Found array with shape: ' + str(preds.shape))\n\u001b[0m\u001b[1;32m    223\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mCLASS_INDEX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         fpath = keras_utils.get_file(\n",
      "\u001b[0;31mValueError\u001b[0m: `decode_predictions` expects a batch of predictions (i.e. a 2D array of shape (samples, 1000)). Found array with shape: (1, 9)"
     ]
    }
   ],
   "source": [
    "# from keras.applications.vgg16 import (\n",
    "#     VGG16, preprocess_input, decode_predictions)\n",
    "from keras.preprocessing import image\n",
    "from keras.layers.core import Lambda\n",
    "from keras.models import Sequential\n",
    "from tensorflow.python.framework import ops\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "import sys\n",
    "import cv2\n",
    "\n",
    "def target_category_loss(x, category_index, nb_classes):\n",
    "    return tf.multiply(x, K.one_hot([category_index], nb_classes))\n",
    "\n",
    "def target_category_loss_output_shape(input_shape):\n",
    "    return input_shape\n",
    "\n",
    "def normalize(x):\n",
    "    # utility function to normalize a tensor by its L2 norm\n",
    "    return x / (K.sqrt(K.mean(K.square(x))) + 1e-5)\n",
    "\n",
    "def load_image(path):\n",
    "    img_path = sys.argv[1]\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    return x\n",
    "\n",
    "def register_gradient():\n",
    "    if \"GuidedBackProp\" not in ops._gradient_registry._registry:\n",
    "        @ops.RegisterGradient(\"GuidedBackProp\")\n",
    "        def _GuidedBackProp(op, grad):\n",
    "            dtype = op.inputs[0].dtype\n",
    "            return grad * tf.cast(grad > 0., dtype) * \\\n",
    "                tf.cast(op.inputs[0] > 0., dtype)\n",
    "\n",
    "def compile_saliency_function(model, activation_layer='block5_conv3'):\n",
    "    input_img = model.input\n",
    "    layer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])\n",
    "    layer_output = layer_dict[activation_layer].output\n",
    "    max_output = K.max(layer_output, axis=3)\n",
    "    saliency = K.gradients(K.sum(max_output), input_img)[0]\n",
    "    return K.function([input_img, K.learning_phase()], [saliency])\n",
    "\n",
    "def modify_backprop(model, name):\n",
    "    g = tf.get_default_graph()\n",
    "    with g.gradient_override_map({'Relu': name}):\n",
    "\n",
    "        # get layers that have an activation\n",
    "        layer_dict = [layer for layer in model.layers[1:]\n",
    "                      if hasattr(layer, 'activation')]\n",
    "\n",
    "        # replace relu activation\n",
    "        for layer in layer_dict:\n",
    "            if layer.activation == keras.activations.relu:\n",
    "                layer.activation = tf.nn.relu\n",
    "\n",
    "        # re-instanciate a new model\n",
    "        new_model = VGG16(weights='imagenet')\n",
    "    return new_model\n",
    "\n",
    "def deprocess_image(x):\n",
    "    '''\n",
    "    Same normalization as in:\n",
    "    https://github.com/fchollet/keras/blob/master/examples/conv_filter_visualization.py\n",
    "    '''\n",
    "    if np.ndim(x) > 3:\n",
    "        x = np.squeeze(x)\n",
    "    # normalize tensor: center on 0., ensure std is 0.1\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + 1e-5)\n",
    "    x *= 0.1\n",
    "\n",
    "    # clip to [0, 1]\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "\n",
    "    # convert to RGB array\n",
    "    x *= 255\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        x = x.transpose((1, 2, 0))\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x\n",
    "\n",
    "def grad_cam(input_model, image, category_index, layer_name):\n",
    "    model = Sequential()\n",
    "    model.add(input_model)\n",
    "\n",
    "    nb_classes = 9#1000\n",
    "    target_layer = lambda x: target_category_loss(x, category_index, nb_classes)\n",
    "    model.add(Lambda(target_layer,\n",
    "                     output_shape = target_category_loss_output_shape))\n",
    "\n",
    "    loss = K.sum(model.layers[-1].output)\n",
    "    conv_output =  [l for l in model.layers[0].layers if l.name is layer_name][0].output\n",
    "    grads = normalize(K.gradients(loss, conv_output)[0])\n",
    "    gradient_function = K.function([model.layers[0].input], [conv_output, grads])\n",
    "\n",
    "    output, grads_val = gradient_function([image])\n",
    "    output, grads_val = output[0, :], grads_val[0, :, :, :]\n",
    "\n",
    "    weights = np.mean(grads_val, axis = (0, 1))\n",
    "    cam = np.ones(output.shape[0 : 2], dtype = np.float32)\n",
    "\n",
    "    for i, w in enumerate(weights):\n",
    "        cam += w * output[:, :, i]\n",
    "\n",
    "    cam = cv2.resize(cam, (224, 224))\n",
    "    cam = np.maximum(cam, 0)\n",
    "    heatmap = cam / np.max(cam)\n",
    "\n",
    "    #Return to BGR [0..255] from the preprocessed image\n",
    "    image = image[0, :]\n",
    "    image -= np.min(image)\n",
    "    image = np.minimum(image, 255)\n",
    "\n",
    "    cam = cv2.applyColorMap(np.uint8(255*heatmap), cv2.COLORMAP_JET)\n",
    "    cam = np.float32(cam) + np.float32(image)\n",
    "    cam = 255 * cam / np.max(cam)\n",
    "    return np.uint8(cam), heatmap\n",
    "\n",
    "# preprocessed_input = load_image(sys.argv[1])\n",
    "\n",
    "# model = VGG16(weights='imagenet')\n",
    "preprocessed_input = np.reshape(preprocessed_input, (1,minimum_len,12))\n",
    "\n",
    "\n",
    "predictions = model.predict(preprocessed_input)\n",
    "predicted_class = np.argmax(predictions)\n",
    "# top_1 = decode_predictions(predictions)[0][0]\n",
    "print('Predicted class:')\n",
    "print('%s with probability %.2f' % (index2class[predicted_class], np.max(predictions)))\n",
    "\n",
    "\n",
    "cam, heatmap = grad_cam(model, preprocessed_input, predicted_class, \"conv5_block16_2_conv\")\n",
    "\n",
    "\n",
    "cv2.imwrite(\"gradcam.jpg\", cam)\n",
    "\n",
    "register_gradient()\n",
    "guided_model = modify_backprop(model, 'GuidedBackProp')\n",
    "saliency_fn = compile_saliency_function(guided_model)\n",
    "saliency = saliency_fn([preprocessed_input, 0])\n",
    "gradcam = saliency[0] * heatmap[..., np.newaxis]\n",
    "cv2.imwrite(\"guided_gradcam.jpg\", deprocess_image(gradcam))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.10575937, 0.07610711, 0.13565929, 0.12985349, 0.13307458,\n",
       "        0.09876314, 0.11559706, 0.10243087, 0.10275507]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(preprocessed_input)\n",
    "predictions\n",
    "print(np.argmax(predictions))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "np.max(predictions)\n",
    "\n",
    "predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'AF',\n",
       " 1: 'I-AVB',\n",
       " 2: 'LBBB',\n",
       " 3: 'Normal',\n",
       " 4: 'PAC',\n",
       " 5: 'PVC',\n",
       " 6: 'RBBB',\n",
       " 7: 'STD',\n",
       " 8: 'STE'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class2index2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 273.891818,
   "position": {
    "height": "40px",
    "left": "1408.41px",
    "right": "20px",
    "top": "127.972px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
