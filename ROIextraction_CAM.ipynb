{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "# tf.enable_eager_execution()\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import keras\n",
    "# import datetime as dt\n",
    "from datetime import datetime\n",
    "\n",
    "import time\n",
    "# import datetime.datetime\n",
    "\n",
    "\n",
    "\n",
    "from keras import layers\n",
    "from keras import models\n",
    "# from keras import optimizers\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "from keras.applications.densenet import DenseNet121, DenseNet169\n",
    "#from keras.applications.nasnet import NASNetLarge\n",
    "# from keras_efficientnets import EfficientNetB7\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras import initializers, regularizers, constraints\n",
    "from keras.layers.normalization import BatchNormalization \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from keras import backend as K\n",
    "\n",
    "tf.set_random_seed(1234)\n",
    "random.seed(100)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from ABNmodules import *\n",
    "\n",
    "loss_function = 'categorical_crossentropy'\n",
    "activation_function = 'softmax'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.24290386e-03 -4.58280585e-05  4.31697309e-03 -3.00174693e-03\n",
      " -2.36609229e-04  1.28997408e-03  2.17347589e-04 -7.99152384e-04\n",
      " -3.42993744e-03 -1.69711686e-03  1.27138164e-03  1.94670545e-03]\n",
      "(3840,) (1280,) (1281,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 2880, 12)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_unique_classes(input_directory,files):\n",
    "\n",
    "    unique_classes=set()\n",
    "    for f in files:\n",
    "        g = f.replace('.mat','.hea')\n",
    "        input_file = os.path.join(input_directory,g)\n",
    "        with open(input_file,'r') as f:\n",
    "            for lines in f:\n",
    "                if lines.startswith('#Dx'):\n",
    "                    tmp = lines.split(': ')[1].split(',')\n",
    "                    for c in tmp:\n",
    "                        unique_classes.add(c.strip())\n",
    "    return sorted(unique_classes)\n",
    "\n",
    "def one_hot_encoding(one_hot_vector,y, class2index):\n",
    "    ind=class2index[y]\n",
    "    one_hot_vector[ind]=1\n",
    "    return one_hot_vector\n",
    "\n",
    "# Search for multi-label subjects\n",
    "def searching_overlap(input_directory,class2index, input_file_names):\n",
    "    multiclasses=[]\n",
    "    multisubjects=[]\n",
    "    number = []\n",
    "    for file in input_file_names:\n",
    "        f=file\n",
    "        g = f.replace('.mat','.hea')\n",
    "        input_file = os.path.join(input_directory,g)\n",
    "        with open(input_file,'r') as f:\n",
    "            for lines in f:\n",
    "                if lines.startswith('#Dx'):\n",
    "                    tmp = lines.split(': ')[1].split(',')\n",
    "                    if len(tmp)>1:\n",
    "                        one_hot_vector = [0]*(len(class2index))\n",
    "                        for c in tmp:\n",
    "                            one_hot_vector = one_hot_encoding(one_hot_vector, c.strip(), class2index)\n",
    "                        multiclasses.append(one_hot_vector)\n",
    "                        multisubjects.append(g)\n",
    "                        number.append(len(tmp))\n",
    "    return multisubjects, multiclasses, number\n",
    "\n",
    "def block_feature(sequence_en, minimum_len): \n",
    "    new_en = []\n",
    "    if len(sequence_en) > minimum_len:  # 길이가 minimum보다 긴 경우\n",
    "        start = random.randint(0,len(sequence_en)-minimum_len)\n",
    "        #print(start)\n",
    "        new_en = sequence_en[start:start+minimum_len]\n",
    "    elif len(sequence_en) == minimum_len: # 길이가 minimum\n",
    "        new_en = sequence_en\n",
    "    else: \n",
    "        assert len(sequence_en) <= minimum_len\n",
    "    return new_en\n",
    "\n",
    "def exploratory_look(input_directory,file, class2index):\n",
    "    classes = []\n",
    "    f = file\n",
    "    g = f.replace('.mat','.hea')\n",
    "    input_file = os.path.join(input_directory,g)\n",
    "    with open(input_file,'r') as f:\n",
    "        for lines in f:\n",
    "            if lines.startswith('#Dx'):\n",
    "                tmp = lines.split(': ')[1].split(',')\n",
    "                print(tmp, len(tmp))\n",
    "    return tmp     \n",
    "\n",
    "# Get classes of sorted file names\n",
    "def get_labels(input_directory,file, class2index):\n",
    "    f = file\n",
    "    g = f.replace('.mat','.hea')\n",
    "    input_file = os.path.join(input_directory,g)\n",
    "    with open(input_file,'r') as f:\n",
    "        for lines in f:\n",
    "            if lines.startswith('#Dx'):\n",
    "                tmp = lines.split(': ')[1].split(',')\n",
    "                one_hot_vector = [0]*(len(class2index))\n",
    "                for c in tmp:\n",
    "                    one_hot_vector = one_hot_encoding(one_hot_vector, c.strip(), class2index)\n",
    "                \n",
    "    return one_hot_vector\n",
    "\n",
    "def randextract_mels(curr_step, batch_size, data, mel_directory, class2index, minimum_len, x_mean_final, x_std_final):\n",
    "    mel_files = []\n",
    "    classes = []\n",
    "    start = batch_size*curr_step\n",
    "    end = batch_size*(curr_step+1)\n",
    "    curr_file_indices = data[start:end]\n",
    "    for file in curr_file_indices:\n",
    "        tmp_file = np.load(mel_directory + '/' + file.replace('.mat', '.npy'))\n",
    "        clip_file = block_feature(tmp_file, minimum_len)\n",
    "        #print(clip_file.shape)\n",
    "        #clip_file = tmp_file[:minimum_len]\n",
    "        clip_file -= x_mean_final\n",
    "        clip_file /= x_std_final\n",
    "        mel_files.append(clip_file)\n",
    "        label = get_labels(input_directory, file, class2index)\n",
    "        classes.append(label)\n",
    "    concat = list(zip(mel_files, classes))\n",
    "    random.shuffle(concat)\n",
    "    mel_files, classes = zip(*concat)\n",
    "    return mel_files, classes\n",
    "\n",
    "def train(data_train, mel_directory, batch_size, class2index, minimum_len, x_mean_final, x_std_final): \n",
    "    loss=[]\n",
    "    acc = []\n",
    "    f1 = []\n",
    "\n",
    "    total_steps = int(np.ceil(len(data_train)/batch_size))\n",
    "    for curr_step in range(total_steps):\n",
    "        batch_mels, batch_labels = randextract_mels(curr_step, batch_size, data_train, mel_directory, class2index, minimum_len, x_mean_final, x_std_final)\n",
    "        batch_mels = np.asarray(batch_mels)\n",
    "        batch_labels = np.asarray(np.squeeze(batch_labels))\n",
    "        train_tmp = model.train_on_batch(batch_mels, batch_labels)\n",
    "        loss.append(train_tmp[0])\n",
    "        acc.append(train_tmp[1])\n",
    "        f1.append(train_tmp[2])\n",
    "\n",
    "    loss = np.mean(np.array(loss))\n",
    "    acc = np.mean(np.array(acc))\n",
    "    f1 = np.mean(np.array(f1))\n",
    "    return loss, acc, f1\n",
    "\n",
    "def test(data, mel_directory, input_directory, class2index, minimum_len, model, x_mean_final, x_std_final):\n",
    "    scores = []\n",
    "    predicted_labels=[]\n",
    "    accuracy=np.zeros(len(data))\n",
    "    #total_loss=[]\n",
    "    total_acc = 0\n",
    "    total_f1 = 0\n",
    "    \n",
    "    mel_files = []\n",
    "    classes = []\n",
    "    for i, file in enumerate(data):\n",
    "        tmp_file = np.load(mel_directory + '/' + file.replace('.mat', '.npy'))\n",
    "        steps = int(np.floor(tmp_file.shape[0]/minimum_len))\n",
    "        mel_files = []\n",
    "        for block in range(steps): # 128개씩 쪼갠 블럭 단위로 predict\n",
    "            start = block*minimum_len\n",
    "            end = (block+1)*minimum_len\n",
    "            clip_file = tmp_file[start:end]\n",
    "            clip_file -= x_mean_final\n",
    "            clip_file /= x_std_final\n",
    "            mel_files.append(clip_file)\n",
    "        mel_files = np.asarray(mel_files)\n",
    "        logit = model.predict(mel_files)\n",
    "        logit = np.mean(logit, axis=0)\n",
    "        pred = np.argmax(logit)\n",
    "        label = np.argmax(get_labels(input_directory, file, class2index))\n",
    "        #f1 = f1_score(label, logit)\n",
    "        #print(pred, label)\n",
    "        if pred == label:\n",
    "            acc = 1\n",
    "        else:\n",
    "            acc = 0\n",
    "        total_acc += acc\n",
    "        #total_f1 += f1\n",
    "    final_acc = total_acc / i\n",
    "    #final_f1 = total_f1 / i\n",
    "    return final_acc#, final_f1\n",
    "\n",
    "batch_size = 32\n",
    "minimum_len = 2880\n",
    "\n",
    "epochs = 1000\n",
    "loss_function = 'categorical_crossentropy'\n",
    "activation_function = 'softmax'\n",
    "rootdir = '../'\n",
    "date = datetime.today().strftime(\"%Y%m%d\")\n",
    "input_directory = os.path.join(rootdir, 'Training_WFDB')\n",
    "mel_name = 'Raw_data_20200424' \n",
    "mel_directory = os.path.join(rootdir, mel_name)\n",
    "results_directory = os.path.join(rootdir, 'results_'+date+'_0')\n",
    "if not os.path.isdir(input_directory):\n",
    "    os.mkdir(input_directory)\n",
    "if not os.path.isdir(mel_directory):\n",
    "    os.mkdir(mel_directory)\n",
    "if not os.path.isdir(results_directory):\n",
    "    os.mkdir(results_directory)\n",
    "        \n",
    "input_files = []\n",
    "for f in os.listdir(input_directory):\n",
    "    if os.path.isfile(os.path.join(input_directory, f)) and not f.lower().startswith('.') and f.lower().endswith('mat'):\n",
    "        input_files.append(f)\n",
    "input_file_names = sorted(input_files)\n",
    "\n",
    "unique_classes = get_unique_classes(input_directory, input_files)\n",
    "class2index = {}\n",
    "for a, b in enumerate(unique_classes):\n",
    "    class2index[b] = a\n",
    "index2class = {y:x for x,y in class2index.items()}    \n",
    "classes_orig= [x.replace('.mat', '.hea') for x in input_file_names] # total subjects\n",
    "classes_multi, _, _ = searching_overlap(input_directory,class2index, input_file_names)\n",
    "classes_single = [x for x in classes_orig if x not in classes_multi]\n",
    "classes_single = [x.replace('.hea', '.mat') for x in classes_single]\n",
    "\n",
    "# double-checking if classes_single have single-label\n",
    "a, b, c  = searching_overlap(input_directory,class2index,classes_single)\n",
    "\n",
    "# we can safely use classes_single as input_file_names\n",
    "input_file_names = classes_single\n",
    "random.shuffle(input_file_names)\n",
    "np.shape(input_file_names)\n",
    "\n",
    "x_mean_all = []\n",
    "x_std_all = []\n",
    "\n",
    "for file in input_file_names:\n",
    "    x = np.load(mel_directory + '/' + file.replace('.mat', '.npy'))\n",
    "    x_mean = [np.mean(x[:,0]), np.mean(x[:,1]), np.mean(x[:,2]), np.mean(x[:,3]), np.mean(x[:,4]), np.mean(x[:,5]),\n",
    "             np.mean(x[:,6]), np.mean(x[:,7]), np.mean(x[:,8]), np.mean(x[:,9]), np.mean(x[:,10]), np.mean(x[:,11])]\n",
    "    \n",
    "    x_std = [np.std(x[:,0]), np.std(x[:,1]), np.std(x[:,2]), np.std(x[:,3]), np.std(x[:,4]), np.std(x[:,5]),\n",
    "             np.std(x[:,6]), np.std(x[:,7]), np.std(x[:,8]), np.std(x[:,9]), np.std(x[:,10]), np.std(x[:,11])]\n",
    "    #print(x_mean)\n",
    "    x_mean_all.append(x_mean)\n",
    "    x_std_all.append(x_std)\n",
    "x_mean_final = np.mean(x_mean_all, axis=0)\n",
    "x_std_final = np.mean(x_std_all, axis=0)\n",
    "print(x_mean_final)\n",
    "\n",
    "data, data_test = train_test_split(input_file_names, test_size = 0.2, train_size = 0.8, shuffle=True)\n",
    "data_train, data_val = train_test_split(data, test_size = 0.25, train_size = 0.75, shuffle=True)\n",
    "print(np.shape(data_train), np.shape(data_val), np.shape(data_test))\n",
    "\n",
    "\n",
    "file=data_train[0]\n",
    "tmp_file = np.load(mel_directory + '/' + file.replace('.mat', '.npy'))\n",
    "clip_file = block_feature(tmp_file, minimum_len)\n",
    "\n",
    "clip_file -= x_mean_final\n",
    "clip_file /= x_std_final\n",
    "clip_file.shape\n",
    "\n",
    "preprocessed_input=clip_file\n",
    "\n",
    "preprocessed_input.shape\n",
    "\n",
    "preprocessed_input = np.reshape(preprocessed_input, (1,minimum_len,12))\n",
    "\n",
    "preprocessed_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_f1(y_true, y_pred): #taken from old keras source code\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '/home/taejoon/PhysioNetChallenge/results_20200601_1_CAM_primitive_model'\n",
    "minimum_len = 2880\n",
    "\n",
    "bestmodel = 'ECG_ABN_E87L0.33'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model = load_model(os.path.join(model_dir, bestmodel), custom_objects={'score_f1' : score_f1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_image (InputLayer)     [(None, None, 12)]        0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 64)          2368      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, None, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, None, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, None, 128)         24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, None, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, None, 128)         49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, None, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, None, 256)         98560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, None, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, None, 256)         196864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, None, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, None, 256)         196864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, None, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, None, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, None, 512)         393728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, None, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, None, 512)         786944    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, None, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, None, 512)         786944    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, None, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, None, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, None, 512)         786944    \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, None, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, None, 256)         393472    \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, None, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, None, 128)         98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, None, 128)         512       \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_final (Dense)          (None, 9)                 1161      \n",
      "_________________________________________________________________\n",
      "output (Softmax)             (None, 9)                 0         \n",
      "=================================================================\n",
      "Total params: 3,842,953\n",
      "Trainable params: 3,835,785\n",
      "Non-trainable params: 7,168\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_out = model.get_layer('batch_normalization_12')\n",
    "softmax_weights = model.get_layer('dense_final').get_weights()[0]\n",
    "# len(softmax_weights[0][0]) # size of softmax_weights = (2, 128, 9) -> 첫 번쨰 2는 weight, bias인듯 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_cam_conv1D(model, layer_nm, x, save_dir, x_mean_final, x_std_final, minimum_len, n_channels, n_classes,sample_weight=1,  keras_phase=0):\n",
    "    \n",
    "    #레이어 이름에 해당되는 레이어 정보를 가져옴 \n",
    "    layers_wt = model.get_layer(layer_nm).weights\n",
    "    layers = model.get_layer(layer_nm)\n",
    "    layers_weights = model.get_layer(layer_nm).get_weights()\n",
    "    \n",
    "    conv_out = model.get_layer('batch_normalization_12')\n",
    "    softmax_weights = model.get_layer('dense_final').get_weights()[0]\n",
    "    \n",
    "    # preprocessing x\n",
    "    tmp_file = np.load(mel_directory + '/' + file.replace('.mat', '.npy'))\n",
    "    clip_file = block_feature(tmp_file, minimum_len)\n",
    "    clip_file -= x_mean_final\n",
    "    clip_file /= x_std_final    \n",
    "    clip_file = clip_file.reshape(1,minimum_len, n_channels)\n",
    "    \n",
    "    classes=[]\n",
    "    for label in range(n_classes):\n",
    "        \n",
    "        savepath = os.path.join(save_dir, file.replace('.mat', '.npy'))\n",
    "    \n",
    "        #긍정 클래스를 설명할 수 있게 컨볼루션 필터 가중치의 gradient를 구함  \n",
    "        grads = K.gradients(model.output[:,label], layers_wt)[0]\n",
    "\n",
    "        #필터별로 가중치를 구함 \n",
    "        pooled_grads = K.mean(grads, axis=(0,1))\n",
    "        get_pooled_grads = K.function(model.input, \n",
    "                             [pooled_grads, layers.output[0]])\n",
    "        \n",
    "        pooled_grads_value, conv_layer_output_value = get_pooled_grads(clip_file)\n",
    "\n",
    "        #다시한번 이야기 하지만 loss를 줄이기 위한 학습과정이 아니다... \n",
    "        for i in range(conv_layer_output_value.shape[-1]):\n",
    "            conv_layer_output_value[:, i] *= pooled_grads_value[i]\n",
    "\n",
    "        heatmap = np.mean(conv_layer_output_value, axis=-1)\n",
    "    #     heatmap = np.maximum(heatmap, 0)\n",
    "    #     heatmap = heatmap/np.max(heatmap)\n",
    "#         hm = cv2.resize(heatmap, (1,2880)) # 속도가 넘 느린데.. 얘를 resize 안하면 나아지려나?\n",
    "#         classes.append(hm)\n",
    "        classes.append(heatmap)\n",
    "#     np.save(savepath, classes)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((1,37))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_file.shape\n",
    "clip_file=clip_file.reshape(1,2880,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_nm = 'batch_normalization_12'\n",
    "conv_out = model.get_layer(layer_nm)\n",
    "softmax_out = model.get_layer('dense_final')\n",
    "softmax_weights = softmax_out.weights\n",
    "# softmax_weights = model.get_layer('dense_final').get_weights()[0]\n",
    "get_conv_out = K.function(model.input, [conv_out.output, softmax_weights[0]])\n",
    "conv_out, softmax_weights = get_conv_out(clip_file)\n",
    "\n",
    "curr_weights = softmax_weights[:,curr_class]\n",
    "weighted_conv = conv_out*curr_weights\n",
    "\n",
    "\n",
    "# len(conv_out) # 1, 1, 36, 128\n",
    "# len(softmax_weights[0][0][0]) # 2, 128, 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120.0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3840/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128,)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_class = 8\n",
    "curr_weights = softmax_weights[:,curr_class]\n",
    "curr_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 36, 128)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = conv_out*curr_weights\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 36)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b =a.sum(axis=2)\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5e8db28278>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAAsCAYAAABi69O0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAITUlEQVR4nO2dbawUZxXHf/+7903upVCQFloKLY0Bm6q0ULG2Nli1olHaJoiSaOqHBppKxPhF0QSRhBSNbzGaGhpbS6LFxqIS06gYMNgYay8FSnmVWmqL9EIvrfbycuFyjx/mubLd7u4zsCs7455fstmZ2bNz/jk7c3bmzPMiM8NxHMdpHloaLcBxHMe5sHjidxzHaTI88TuO4zQZnvgdx3GaDE/8juM4TYYnfsdxnCajpsQvaYykDZL+Ft4vrmB3RtK28Fpfi0/HcRynNlRLO35J3wSOmtkqSV8GLjazL5Wx6zez7hp0Oo7jOHWi1sS/F5htZockTQD+aGZTy9h54nccx8kItdb4LzWzQ2H5ZeDSCnadknok/UXSHTX6dBzHcWqgNWYg6Q/A+DIffbV4xcxMUqXbh8lmdlDSFGCjpB1m9lwZXwuBhQAFCjNGcFF1bW1R+QCcvKw9anNJ97+jNt0tA6n8dUlRmxM2FLXZ3z8ulb80tLTE7+yGThWiNjqTzl/ribjN6RFxm8LpdP4sHnLaRp2K2gyciB8rFFLeJVc8HYoYjF97taSMQevxuL/TXfFAWbrTCrXFj+HRnfED4fXTHan8DQ7Gj09IEfOheAyU8jeunPLOYidT6O6IxxKguz2eg/r29L1iZlWTR11KPcC7gB8Ak4BlZraqxK4DWAPMAEYFm/ur7fsijbFZ+kBV/63jK91gvJFdKyZFbZbctCFq874R+1L5m9ERTx47T8VPiLlP3Bt3lvLn6xwRT3on/zEyatN6LEWGBcbuiAs7cl18X13/TOdvKEWyuuxjL0Rt9u2cGLWxrnT/foWOuJ0diSe9zt50N+aXbI3/Q/Te0Ba1GRibLgkVxh+P2tw59ZmozeaXr07lr/fIqKhNS2tc+5nj8YOlfWT8fAFobx+M2gzsievWlGOp/L138vNRmzWzHtpiZjOr2dRa6lkPfBb4IbAO+D6wQNI1wwahpc8i4FXgPcAgMLdGv47jOM55kvKmriKrgN+SlIKuB+YDfcC9kjrN7G7g7cBKkmcANwHLgPskyXxoUMdxnAtOTVf8ZtYHfAN4xMw+aGZHgZfCZ3eH9z8DLwDvN7N3mNkDwL+AsaX7k7QwPATuOU26errjOI5zbtR6xT/MxFDvLwBbgCMln48Gtkt6MayXLSab2WpgNSQ1/jppcxzHcYqox5ANh4BbgI8A14Tl0qdMrwKbzGw6MDP47auDb8dxHOccqUfiH252Ue0KfSswLSzPAzZ6fd9xHKcx1KPUMx7YDPyOpNTzBNAmaQXQY2brgT8Bn5A0ABwDPl4Hv47jOM55UFM7fgBJ84A5ww9zJX0GmGVmi4tsxgL9ZjYgaRHwSTO7tcy+/tuBC5gK7C0xeSvwSk2CG0detedVN+RXe151Q36151U3vFn75P9pBy4ASTcCy83sw2F9KYCZ3VfBvkAysFu8V8Obv9sT65iQVfKqPa+6Ib/a86ob8qs9r7rh/LTXo8b/FPA2SVdJagc+RdKxq1jYhKLVucDuOvh1HMdxzoOaa/xmNihpMWdr/A+a2c6SGv/nJc0l6bV7lKS3r+M4jtMA6tKO38weBx4v2basaHkpsLQOrlbXYR+NIq/a86ob8qs9r7ohv9rzqhvOQ3vNNX7HcRwnX/icu47jOE1GbhK/pDmS9kraH6Z5zAWSDkjaEeYb7mm0nmpIelDSYUnPFm1LNa9yI6mge7mkg0VzPX+0kRorIekKSZsk7ZK0U9KSsD3Tca+iO/Nxl9Qp6a+StgftXw/br5L0ZMgxPw+NVTJDFd0/kfR8UcynR/eVh1JPaAK6D/gQySBwTwELzGxXQ4WlQNIBYKaZZb6NsKRbgH5gjZldG7almle5kVTQvZyk78i3GqktRmjxNsHMnpY0kmSsqztIGkBkNu5VdM8n43GXJKDLzPoltZF0Ol0CfBFYZ2ZrJf0I2B6bN+RCUkX3PcBvzOwXafeVlyv+dwP7zezvZnYKWAvc3mBN/3eY2WaSVlfF3A48HJYfJjm5M0UF3bnAzA6Z2dNh+XWSps6Xk/G4V9GdeSyhP6y2hZcBtwLDyTOLMa+k+5zJS+K/HHixaP0lcnKQkfwwv5e0JfRMzhtp51XOIoslPRNKQZkqlZRD0pXAdcCT5CjuJbohB3GXVJC0DTgMbACeA14zs+EptTKZY0p1m9lwzFeGmH9XyYyHVclL4s8zN5vZ9SSjl34ulCVySRhYL/u1wYT7gauB6SQjyH67sXKqI6kbeAz4gpm9YQLoLMe9jO5cxN3MzoTRgieSVBSmRb6SCUp1S7qWpKn8NOAGYAwQLQnmJfEfBK4oWp8YtmUeMzsY3g8DvyQ5yPJE73DP6/B+uMF6UmFmveEkGQIeIMNxD/Xax4Cfmtm6sDnzcS+nO09xBzCz14BNwI3AaEnDfZsynWOKdM8JZTczswHgIVLEPC+JPzosRBaR1BUefCGpC7gNeLb6tzLHeuCusHwX8OsGaklNyTAhd5LRuIcHdj8GdpvZd4o+ynTcK+nOQ9wljZM0Oiy/haTRyG6SRDovmGUx5uV07ym6QBDJc4lozHPRqgcgNAv7HmeHhVjZYElRJE0hucqHpJf0z7KsW9IjwGyS0f56ga8BvwIeBSaRTKE5P0yxmRkq6J5NUm4w4ACwqKhmnhkk3UwybPkOYChs/gpJvTyzca+iewEZj7ukd5I8vC2QXPw+amYrwvm6lqRcshX4dLiKzgRVdG8ExpHMjbINuKfoIXD5feUl8TuO4zj1IS+lHsdxHKdOeOJ3HMdpMjzxO47jNBme+B3HcZoMT/yO4zhNhid+x3GcJsMTv+M4TpPhid9xHKfJ+A/5wVDvceZP1gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb=np.resize(b,(1,2880))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5e618de588>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAAjCAYAAACXSLFcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAFN0lEQVR4nO3cW6hUVRzH8e9PLYOUOmaYmaCGLz6VmPggFhjeKE69+VAdKvDFqB6CDB/ysYJ6ECooEiwiiS4kpJSGJEFaFt5NPalQelLUsBt4O/8e1hoaxpk5jpPOzJ7fBzaz9tpb9/6x9vkzs/fMUkRgZmbFN6zVJ2BmZteGC76ZWZdwwTcz6xIu+GZmXcIF38ysS7jgm5l1iaYKvqQxkjZIOilpUNJ5Seur7DdYtlyQ9HwzxzUzs8Y1+w5/GbAJuAl4G1gJ3CfpwYr9LgJ7I2IY8AgwvcnjmplZg5ot+L3AOeAMsAJ4APgaWFrlOD/l9kfAXElq8thmZtaAZgv+OOA24CTwW14/Atxe5Ti9kv4GNgN/Abc0eWwzM2vAiKF2kLSRVNQrLS9fiYiQVGuehoPAgtz+DhhV41hbgHvy6mBeLgx1jgUwAucsEucslk7L+U9E3Fptw5AFPyLur7VN0nHSO/uxksYDJ4BJwLGKXQ8D4yLiW0nrgEeBU1WONavi/98WETOGOsdO55zF4pzFUqSczd7SWQvcQHpo+yLwOXAv8EZpB0k9wDdAn6SxpPv8Z8KztpmZXVNDvsMfwkvAh6SHtktI38bZBByTNAC8A6wDngbG5H3OApXf4jEzs6usqYIfEaeAuTU2jy9rV72fdBneusJ/12mcs1ics1gKk1O+s2Jm1h08tYKZWZdoy4IvaYGk/ZL6JS1r9fk0S9IRSbskbZe0LfeVpqU4mF97cr8krczZd0pq218lS1ol6YSk3WV9DeeS1Jf3PyiprxVZ6qmRc4Wko3lMt0taVLbthZxzv6T5Zf1tfV1Lmihpk6S9kvZIeib3F2pM6+Qs3JheIiLaagGGAz8DU4DrgR3AtFafV5OZjgBjK/peAZbl9jLg5dxeBKwHBMwCtrb6/OvkmkOaJmP3leYiPcw/lF97crun1dkuI+cK4Lkq+07L1+xIYHK+lod3wnVNeu42PbdHAwdynkKNaZ2chRvTyqUd3+HPBPoj4lBEnAPWkKZwKJpeYHVurwYeKut/N5ItwM35Nw5tJyI2A6cruhvNNR/YEBGnI+J3YAP//UivLdTIWUsvsCYizkbEYaCfdE23/XUdEQMR8WNu/wnsAyZQsDGtk7OWjh3TSu1Y8CcAv5St/0r9wegEAXwp6QdJS3LfuIgYyO3StBTQ+fkbzdXJeZ/KtzJWlW5zUJCckiYBdwNbKfCYVuSEAo8ptGfBL6LZETEdWAgslTSnfGOkz42F+7pUUXNlbwJ3AncBA8CrrT2d/4+kUcDHwLMR8Uf5tiKNaZWchR3TknYs+EeBiWXrd+S+jhURR/PrCeBT0kfB46VbNWXTUkDn5280V0fmjYjjEXExIgZJU4PPzJs6Oqek60hF8P2I+CR3F25Mq+Us6piWa8eC/z0wVdJkSdcDi0lTOHQkSTdKGl1qA/OA3aRMpW8v9AGf5fZa4LH8DYhZpGkoBugcjeb6ApgnqSd/hJ6X+9paxXOVh0ljCinnYkkjJU0GppImDGz761qSSL+O3xcRr5VtKtSY1spZxDG9RKufGldbSE//D5CegC9v9fk0mWUK6en9DmBPKQ9peuivSDOJbgTG5H4Br+fsu4AZrc5QJ9sHpI++50n3L5+8klzAE6QHYf3A463OdZk538s5dpL+yMeX7b8859wPLCzrb+vrGphNul2zE9iel0VFG9M6OQs3ppWLf2lrZtYl2vGWjpmZXQUu+GZmXcIF38ysS7jgm5l1CRd8M7Mu4YJvZtYlXPDNzLqEC76ZWZf4FwwNFnzQ4MffAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f5e61957438>]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "c = clip_file[:,:,curr_class]\n",
    "plt.plot(c.reshape(2880,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = os.path.join(model_dir, \"GradCAM_ROI_2\")\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "n_channels=12\n",
    "n_classes = 9\n",
    "import cv2\n",
    "# for i,file in enumerate(data_train):\n",
    "for file in data_train:\n",
    "    grad_cam_conv1D(model, 'conv1d_12',  file, save_dir, x_mean_final, x_std_final,  minimum_len, n_channels, n_classes)\n",
    "    print(\"finished {}\".format(file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(heatmap.reshape(36,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm = cv2.resize(heatmap, (1,2880))\n",
    "plt.plot(hm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot2 = hm * x\n",
    "dot2.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(12):\n",
    "    plt.subplot(12,1,i+1)\n",
    "    plt.pcolor(np.reshape(dot2[:,:,i], (1,2880)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(12):\n",
    "    plt.subplot(12,1,i+1)\n",
    "    plt.plot(np.reshape(clip_file[:,i], (2880,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "hm = cv2.resize(heatmap, (1,2880))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.resize(x[:,:,0], (1,2880))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm = np.uint8(255 * hm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm = cv2.applyColorMap(hm, cv2.COLORMAP_JET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "superimposed_img = hm*0.4 + img\n",
    "superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_file.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa = clip_file[:,0]\n",
    "\n",
    "\n",
    "aaa.reshape(1,2880)\n",
    "aaa.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clip_file[:,0]\n",
    "plt.imshow(np.transpose(clip_file))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(hm)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(aaa.reshape(1,2880))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"elephant_cam.jpg\"\n",
    "superimposed_img.save(save_path)\n",
    "display(Image(save_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(superimposed_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm = np.mean(conv_layer_output_value, axis=-1)\n",
    "graded = pooled_grads_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm_tbl = pd.DataFrame({'heat':hm, 'kw':[keyword_rev_dict[i] for i in test_x[idx] ]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(conv_layer_output_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = conv_layer_output_value.resize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.sample_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_layer_names = [ \"global_average_pooling1d\",\n",
    "    \"dense\", \"batch_normalization_13\", \"activation\", \"dense_1\", \"batch_normalization_14\", \"activation_1\", \"dense_final\"\n",
    "    , \"output\"\n",
    "]\n",
    "\n",
    "last_conv_layer = model2.get_layer('max_pooling1d_4') # 암튼 GAP 직전 layer 불러오기 \n",
    "last_conv_layer_model = Model(model2.inputs, last_conv_layer.output)\n",
    "\n",
    "classifier_input = Input(shape=last_conv_layer.output.shape[1:])\n",
    "x = classifier_input\n",
    "for layer_name in classifier_layer_names:\n",
    "    print(layer_name)\n",
    "    x = model.get_layer(layer_name)(x)\n",
    "classifier_model = Model(classifier_input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_conv_layer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "        # Compute activations of the last conv layer and make the tape watch it\n",
    "        p = tf.convert_to_tensor(preprocessed_input, dtype=\"float32\")\n",
    "#         if dtype(p) == 'float64':\n",
    "#             p = tf.cast(p, 'float32')\n",
    "        last_conv_layer_output = last_conv_layer_model(p)\n",
    "        tape.watch(last_conv_layer_output)\n",
    "        # Compute class predictions\n",
    "        preds = classifier_model(last_conv_layer_output)\n",
    "        top_pred_index = tf.argmax(preds[0])\n",
    "        top_class_channel = preds[:, top_pred_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = tf.gradients(top_class_channel, last_conv_layer_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_grads = tf.reduce_mean(grads, axis=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_grads = K.eval(pooled_grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_grads.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_conv_layer_output =K.eval(last_conv_layer_output)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_conv_layer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_conv_layer_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_grads.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(pooled_grads.shape[-1]):\n",
    "    last_conv_layer_output[i] *= pooled_grads[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_cam_conv1D(model, layer_nm, x, sample_weight=1, keras_phase=0):\n",
    "    # 레이어 이름에 해당하는 레이어 정보를 가져옴\n",
    "    layers_wt = model.get_layer(layer_nm).weights\n",
    "    layers = model.get_layer(layer_nm)\n",
    "    layers_weights = model.get_layer(layer_nm).get_weights()\n",
    "    \n",
    "    # 긍정 클래스를 설명할 수 있게 컨볼루션 필터 가중치의 gradient를 구함\n",
    "    grads = K.gradients(model.output[:,0], layers_wt)[0]\n",
    "    \n",
    "    # 필터별로 가중치를 구함\n",
    "    pooled_grads = K.mean(grads, axis=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_wrt_class = model2.output[:,1] # [:,i] : i가 관심있는 class\n",
    "output_wrt_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = K.gradients(output_wrt_class, last_conv_layer.output)[0]\n",
    "pooled_grads = K.mean(grads, axis=(0,1)) # tf.reduce_sum이랑 비슷한듯; 여긴 1d이니까 0,1,2가 아니라 0,1만?\n",
    "iterate = K.function([model2.input],[pooled_grads, last_conv_layer.output[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=preprocessed_input\n",
    "pooled_grads_value, conv_layer_output_value = iterate([x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_grads_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_grads_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer_output_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer_output_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(128):\n",
    "        conv_layer_output_value[:,i] *= pooled_grads_value[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer_output_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap = np.mean(conv_layer_output_value, axis=-1)\n",
    "heatmap = np.maximum(heatmap, 0)\n",
    "heatmap = heatmap/np.max(heatmap)\n",
    "print(heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "571.719px",
    "left": "1441.43px",
    "right": "20px",
    "top": "127.991px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
