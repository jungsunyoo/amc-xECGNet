{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/numba/errors.py:137: UserWarning: Insufficiently recent colorama version found. Numba requires colorama >= 0.3.9\n",
      "  warnings.warn(msg)\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import datetime as dt\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set TF random seed to improve reproducibility\n",
    "tf.set_random_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters\n",
    "batch_size = 32\n",
    "minimum_len = 128\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#currdir= os.getcwd()\n",
    "rootdir = '/home/taejoon/PhysioNetChallenge'\n",
    "input_directory = os.path.join(rootdir, 'Training_WFDB')\n",
    "mel_name = 'Mel_data_20200402_128' \n",
    "mel_directory = os.path.join(rootdir, mel_name)\n",
    "#save_directory = os.path.join(currdir, '')\n",
    "if not os.path.isdir(input_directory):\n",
    "        os.mkdir(input_directory)\n",
    "if not os.path.isdir(mel_directory):\n",
    "        os.mkdir(mel_directory)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find files\n",
    "input_files = []\n",
    "for f in os.listdir(input_directory):\n",
    "    if os.path.isfile(os.path.join(input_directory, f)) and not f.lower().startswith('.') and f.lower().endswith('mat'):\n",
    "        input_files.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A0001.mat',\n",
       " 'A0002.mat',\n",
       " 'A0003.mat',\n",
       " 'A0004.mat',\n",
       " 'A0005.mat',\n",
       " 'A0006.mat',\n",
       " 'A0007.mat',\n",
       " 'A0008.mat',\n",
       " 'A0009.mat',\n",
       " 'A0010.mat',\n",
       " 'A0011.mat',\n",
       " 'A0012.mat',\n",
       " 'A0013.mat',\n",
       " 'A0014.mat',\n",
       " 'A0015.mat',\n",
       " 'A0016.mat',\n",
       " 'A0017.mat',\n",
       " 'A0018.mat',\n",
       " 'A0019.mat',\n",
       " 'A0020.mat',\n",
       " 'A0021.mat',\n",
       " 'A0022.mat',\n",
       " 'A0023.mat',\n",
       " 'A0024.mat',\n",
       " 'A0025.mat',\n",
       " 'A0026.mat',\n",
       " 'A0027.mat',\n",
       " 'A0028.mat',\n",
       " 'A0029.mat',\n",
       " 'A0030.mat',\n",
       " 'A0031.mat',\n",
       " 'A0032.mat',\n",
       " 'A0033.mat',\n",
       " 'A0034.mat',\n",
       " 'A0035.mat',\n",
       " 'A0036.mat',\n",
       " 'A0037.mat',\n",
       " 'A0038.mat',\n",
       " 'A0039.mat',\n",
       " 'A0040.mat',\n",
       " 'A0041.mat',\n",
       " 'A0042.mat',\n",
       " 'A0043.mat',\n",
       " 'A0044.mat',\n",
       " 'A0045.mat',\n",
       " 'A0046.mat',\n",
       " 'A0047.mat',\n",
       " 'A0048.mat',\n",
       " 'A0049.mat',\n",
       " 'A0050.mat',\n",
       " 'A0051.mat',\n",
       " 'A0052.mat',\n",
       " 'A0053.mat',\n",
       " 'A0054.mat',\n",
       " 'A0055.mat',\n",
       " 'A0056.mat',\n",
       " 'A0057.mat',\n",
       " 'A0058.mat',\n",
       " 'A0059.mat',\n",
       " 'A0060.mat',\n",
       " 'A0061.mat',\n",
       " 'A0062.mat',\n",
       " 'A0063.mat',\n",
       " 'A0064.mat',\n",
       " 'A0065.mat',\n",
       " 'A0066.mat',\n",
       " 'A0067.mat',\n",
       " 'A0068.mat',\n",
       " 'A0069.mat',\n",
       " 'A0070.mat',\n",
       " 'A0071.mat',\n",
       " 'A0072.mat',\n",
       " 'A0073.mat',\n",
       " 'A0074.mat',\n",
       " 'A0075.mat',\n",
       " 'A0076.mat',\n",
       " 'A0077.mat',\n",
       " 'A0078.mat',\n",
       " 'A0079.mat',\n",
       " 'A0080.mat',\n",
       " 'A0081.mat',\n",
       " 'A0082.mat',\n",
       " 'A0083.mat',\n",
       " 'A0084.mat',\n",
       " 'A0085.mat',\n",
       " 'A0086.mat',\n",
       " 'A0087.mat',\n",
       " 'A0088.mat',\n",
       " 'A0089.mat',\n",
       " 'A0090.mat',\n",
       " 'A0091.mat',\n",
       " 'A0092.mat',\n",
       " 'A0093.mat',\n",
       " 'A0094.mat',\n",
       " 'A0095.mat',\n",
       " 'A0096.mat',\n",
       " 'A0097.mat',\n",
       " 'A0098.mat',\n",
       " 'A0099.mat',\n",
       " 'A0100.mat',\n",
       " 'A0101.mat',\n",
       " 'A0102.mat',\n",
       " 'A0103.mat',\n",
       " 'A0104.mat',\n",
       " 'A0105.mat',\n",
       " 'A0106.mat',\n",
       " 'A0107.mat',\n",
       " 'A0108.mat',\n",
       " 'A0109.mat',\n",
       " 'A0110.mat',\n",
       " 'A0111.mat',\n",
       " 'A0112.mat',\n",
       " 'A0113.mat',\n",
       " 'A0114.mat',\n",
       " 'A0115.mat',\n",
       " 'A0116.mat',\n",
       " 'A0117.mat',\n",
       " 'A0118.mat',\n",
       " 'A0119.mat',\n",
       " 'A0120.mat',\n",
       " 'A0121.mat',\n",
       " 'A0122.mat',\n",
       " 'A0123.mat',\n",
       " 'A0124.mat',\n",
       " 'A0125.mat',\n",
       " 'A0126.mat',\n",
       " 'A0127.mat',\n",
       " 'A0128.mat',\n",
       " 'A0129.mat',\n",
       " 'A0130.mat',\n",
       " 'A0131.mat',\n",
       " 'A0132.mat',\n",
       " 'A0133.mat',\n",
       " 'A0134.mat',\n",
       " 'A0135.mat',\n",
       " 'A0136.mat',\n",
       " 'A0137.mat',\n",
       " 'A0138.mat',\n",
       " 'A0139.mat',\n",
       " 'A0140.mat',\n",
       " 'A0141.mat',\n",
       " 'A0142.mat',\n",
       " 'A0143.mat',\n",
       " 'A0144.mat',\n",
       " 'A0145.mat',\n",
       " 'A0146.mat',\n",
       " 'A0147.mat',\n",
       " 'A0148.mat',\n",
       " 'A0149.mat',\n",
       " 'A0150.mat',\n",
       " 'A0151.mat',\n",
       " 'A0152.mat',\n",
       " 'A0153.mat',\n",
       " 'A0154.mat',\n",
       " 'A0155.mat',\n",
       " 'A0156.mat',\n",
       " 'A0157.mat',\n",
       " 'A0158.mat',\n",
       " 'A0159.mat',\n",
       " 'A0160.mat',\n",
       " 'A0161.mat',\n",
       " 'A0162.mat',\n",
       " 'A0163.mat',\n",
       " 'A0164.mat',\n",
       " 'A0165.mat',\n",
       " 'A0166.mat',\n",
       " 'A0167.mat',\n",
       " 'A0168.mat',\n",
       " 'A0169.mat',\n",
       " 'A0170.mat',\n",
       " 'A0171.mat',\n",
       " 'A0172.mat',\n",
       " 'A0173.mat',\n",
       " 'A0174.mat',\n",
       " 'A0175.mat',\n",
       " 'A0176.mat',\n",
       " 'A0177.mat',\n",
       " 'A0178.mat',\n",
       " 'A0179.mat',\n",
       " 'A0180.mat',\n",
       " 'A0181.mat',\n",
       " 'A0182.mat',\n",
       " 'A0183.mat',\n",
       " 'A0184.mat',\n",
       " 'A0185.mat',\n",
       " 'A0186.mat',\n",
       " 'A0187.mat',\n",
       " 'A0188.mat',\n",
       " 'A0189.mat',\n",
       " 'A0190.mat',\n",
       " 'A0191.mat',\n",
       " 'A0192.mat',\n",
       " 'A0193.mat',\n",
       " 'A0194.mat',\n",
       " 'A0195.mat',\n",
       " 'A0196.mat',\n",
       " 'A0197.mat',\n",
       " 'A0198.mat',\n",
       " 'A0199.mat',\n",
       " 'A0200.mat',\n",
       " 'A0201.mat',\n",
       " 'A0202.mat',\n",
       " 'A0203.mat',\n",
       " 'A0204.mat',\n",
       " 'A0205.mat',\n",
       " 'A0206.mat',\n",
       " 'A0207.mat',\n",
       " 'A0208.mat',\n",
       " 'A0209.mat',\n",
       " 'A0210.mat',\n",
       " 'A0211.mat',\n",
       " 'A0212.mat',\n",
       " 'A0213.mat',\n",
       " 'A0214.mat',\n",
       " 'A0215.mat',\n",
       " 'A0216.mat',\n",
       " 'A0217.mat',\n",
       " 'A0218.mat',\n",
       " 'A0219.mat',\n",
       " 'A0220.mat',\n",
       " 'A0221.mat',\n",
       " 'A0222.mat',\n",
       " 'A0223.mat',\n",
       " 'A0224.mat',\n",
       " 'A0225.mat',\n",
       " 'A0226.mat',\n",
       " 'A0227.mat',\n",
       " 'A0228.mat',\n",
       " 'A0229.mat',\n",
       " 'A0230.mat',\n",
       " 'A0231.mat',\n",
       " 'A0232.mat',\n",
       " 'A0233.mat',\n",
       " 'A0234.mat',\n",
       " 'A0235.mat',\n",
       " 'A0236.mat',\n",
       " 'A0237.mat',\n",
       " 'A0238.mat',\n",
       " 'A0239.mat',\n",
       " 'A0240.mat',\n",
       " 'A0241.mat',\n",
       " 'A0242.mat',\n",
       " 'A0243.mat',\n",
       " 'A0244.mat',\n",
       " 'A0245.mat',\n",
       " 'A0246.mat',\n",
       " 'A0247.mat',\n",
       " 'A0248.mat',\n",
       " 'A0249.mat',\n",
       " 'A0250.mat',\n",
       " 'A0251.mat',\n",
       " 'A0252.mat',\n",
       " 'A0253.mat',\n",
       " 'A0254.mat',\n",
       " 'A0255.mat',\n",
       " 'A0256.mat',\n",
       " 'A0257.mat',\n",
       " 'A0258.mat',\n",
       " 'A0259.mat',\n",
       " 'A0260.mat',\n",
       " 'A0261.mat',\n",
       " 'A0262.mat',\n",
       " 'A0263.mat',\n",
       " 'A0264.mat',\n",
       " 'A0265.mat',\n",
       " 'A0266.mat',\n",
       " 'A0267.mat',\n",
       " 'A0268.mat',\n",
       " 'A0269.mat',\n",
       " 'A0270.mat',\n",
       " 'A0271.mat',\n",
       " 'A0272.mat',\n",
       " 'A0273.mat',\n",
       " 'A0274.mat',\n",
       " 'A0275.mat',\n",
       " 'A0276.mat',\n",
       " 'A0277.mat',\n",
       " 'A0278.mat',\n",
       " 'A0279.mat',\n",
       " 'A0280.mat',\n",
       " 'A0281.mat',\n",
       " 'A0282.mat',\n",
       " 'A0283.mat',\n",
       " 'A0284.mat',\n",
       " 'A0285.mat',\n",
       " 'A0286.mat',\n",
       " 'A0287.mat',\n",
       " 'A0288.mat',\n",
       " 'A0289.mat',\n",
       " 'A0290.mat',\n",
       " 'A0291.mat',\n",
       " 'A0292.mat',\n",
       " 'A0293.mat',\n",
       " 'A0294.mat',\n",
       " 'A0295.mat',\n",
       " 'A0296.mat',\n",
       " 'A0297.mat',\n",
       " 'A0298.mat',\n",
       " 'A0299.mat',\n",
       " 'A0300.mat',\n",
       " 'A0301.mat',\n",
       " 'A0302.mat',\n",
       " 'A0303.mat',\n",
       " 'A0304.mat',\n",
       " 'A0305.mat',\n",
       " 'A0306.mat',\n",
       " 'A0307.mat',\n",
       " 'A0308.mat',\n",
       " 'A0309.mat',\n",
       " 'A0310.mat',\n",
       " 'A0311.mat',\n",
       " 'A0312.mat',\n",
       " 'A0313.mat',\n",
       " 'A0314.mat',\n",
       " 'A0315.mat',\n",
       " 'A0316.mat',\n",
       " 'A0317.mat',\n",
       " 'A0318.mat',\n",
       " 'A0319.mat',\n",
       " 'A0320.mat',\n",
       " 'A0321.mat',\n",
       " 'A0322.mat',\n",
       " 'A0323.mat',\n",
       " 'A0324.mat',\n",
       " 'A0325.mat',\n",
       " 'A0326.mat',\n",
       " 'A0327.mat',\n",
       " 'A0328.mat',\n",
       " 'A0329.mat',\n",
       " 'A0330.mat',\n",
       " 'A0331.mat',\n",
       " 'A0332.mat',\n",
       " 'A0333.mat',\n",
       " 'A0334.mat',\n",
       " 'A0335.mat',\n",
       " 'A0336.mat',\n",
       " 'A0337.mat',\n",
       " 'A0338.mat',\n",
       " 'A0339.mat',\n",
       " 'A0340.mat',\n",
       " 'A0341.mat',\n",
       " 'A0342.mat',\n",
       " 'A0343.mat',\n",
       " 'A0344.mat',\n",
       " 'A0345.mat',\n",
       " 'A0346.mat',\n",
       " 'A0347.mat',\n",
       " 'A0348.mat',\n",
       " 'A0349.mat',\n",
       " 'A0350.mat',\n",
       " 'A0351.mat',\n",
       " 'A0352.mat',\n",
       " 'A0353.mat',\n",
       " 'A0354.mat',\n",
       " 'A0355.mat',\n",
       " 'A0356.mat',\n",
       " 'A0357.mat',\n",
       " 'A0358.mat',\n",
       " 'A0359.mat',\n",
       " 'A0360.mat',\n",
       " 'A0361.mat',\n",
       " 'A0362.mat',\n",
       " 'A0363.mat',\n",
       " 'A0364.mat',\n",
       " 'A0365.mat',\n",
       " 'A0366.mat',\n",
       " 'A0367.mat',\n",
       " 'A0368.mat',\n",
       " 'A0369.mat',\n",
       " 'A0370.mat',\n",
       " 'A0371.mat',\n",
       " 'A0372.mat',\n",
       " 'A0373.mat',\n",
       " 'A0374.mat',\n",
       " 'A0375.mat',\n",
       " 'A0376.mat',\n",
       " 'A0377.mat',\n",
       " 'A0378.mat',\n",
       " 'A0379.mat',\n",
       " 'A0380.mat',\n",
       " 'A0381.mat',\n",
       " 'A0382.mat',\n",
       " 'A0383.mat',\n",
       " 'A0384.mat',\n",
       " 'A0385.mat',\n",
       " 'A0386.mat',\n",
       " 'A0387.mat',\n",
       " 'A0388.mat',\n",
       " 'A0389.mat',\n",
       " 'A0390.mat',\n",
       " 'A0391.mat',\n",
       " 'A0392.mat',\n",
       " 'A0393.mat',\n",
       " 'A0394.mat',\n",
       " 'A0395.mat',\n",
       " 'A0396.mat',\n",
       " 'A0397.mat',\n",
       " 'A0398.mat',\n",
       " 'A0399.mat',\n",
       " 'A0400.mat',\n",
       " 'A0401.mat',\n",
       " 'A0402.mat',\n",
       " 'A0403.mat',\n",
       " 'A0404.mat',\n",
       " 'A0405.mat',\n",
       " 'A0406.mat',\n",
       " 'A0407.mat',\n",
       " 'A0408.mat',\n",
       " 'A0409.mat',\n",
       " 'A0410.mat',\n",
       " 'A0411.mat',\n",
       " 'A0412.mat',\n",
       " 'A0413.mat',\n",
       " 'A0414.mat',\n",
       " 'A0415.mat',\n",
       " 'A0416.mat',\n",
       " 'A0417.mat',\n",
       " 'A0418.mat',\n",
       " 'A0419.mat',\n",
       " 'A0420.mat',\n",
       " 'A0421.mat',\n",
       " 'A0422.mat',\n",
       " 'A0423.mat',\n",
       " 'A0424.mat',\n",
       " 'A0425.mat',\n",
       " 'A0426.mat',\n",
       " 'A0427.mat',\n",
       " 'A0428.mat',\n",
       " 'A0429.mat',\n",
       " 'A0430.mat',\n",
       " 'A0431.mat',\n",
       " 'A0432.mat',\n",
       " 'A0433.mat',\n",
       " 'A0434.mat',\n",
       " 'A0435.mat',\n",
       " 'A0436.mat',\n",
       " 'A0437.mat',\n",
       " 'A0438.mat',\n",
       " 'A0439.mat',\n",
       " 'A0440.mat',\n",
       " 'A0441.mat',\n",
       " 'A0442.mat',\n",
       " 'A0443.mat',\n",
       " 'A0444.mat',\n",
       " 'A0445.mat',\n",
       " 'A0446.mat',\n",
       " 'A0447.mat',\n",
       " 'A0448.mat',\n",
       " 'A0449.mat',\n",
       " 'A0450.mat',\n",
       " 'A0451.mat',\n",
       " 'A0452.mat',\n",
       " 'A0453.mat',\n",
       " 'A0454.mat',\n",
       " 'A0455.mat',\n",
       " 'A0456.mat',\n",
       " 'A0457.mat',\n",
       " 'A0458.mat',\n",
       " 'A0459.mat',\n",
       " 'A0460.mat',\n",
       " 'A0461.mat',\n",
       " 'A0462.mat',\n",
       " 'A0463.mat',\n",
       " 'A0464.mat',\n",
       " 'A0465.mat',\n",
       " 'A0466.mat',\n",
       " 'A0467.mat',\n",
       " 'A0468.mat',\n",
       " 'A0469.mat',\n",
       " 'A0470.mat',\n",
       " 'A0471.mat',\n",
       " 'A0472.mat',\n",
       " 'A0473.mat',\n",
       " 'A0474.mat',\n",
       " 'A0475.mat',\n",
       " 'A0476.mat',\n",
       " 'A0477.mat',\n",
       " 'A0478.mat',\n",
       " 'A0479.mat',\n",
       " 'A0480.mat',\n",
       " 'A0481.mat',\n",
       " 'A0482.mat',\n",
       " 'A0483.mat',\n",
       " 'A0484.mat',\n",
       " 'A0485.mat',\n",
       " 'A0486.mat',\n",
       " 'A0487.mat',\n",
       " 'A0488.mat',\n",
       " 'A0489.mat',\n",
       " 'A0490.mat',\n",
       " 'A0491.mat',\n",
       " 'A0492.mat',\n",
       " 'A0493.mat',\n",
       " 'A0494.mat',\n",
       " 'A0495.mat',\n",
       " 'A0496.mat',\n",
       " 'A0497.mat',\n",
       " 'A0498.mat',\n",
       " 'A0499.mat',\n",
       " 'A0500.mat',\n",
       " 'A0501.mat',\n",
       " 'A0502.mat',\n",
       " 'A0503.mat',\n",
       " 'A0504.mat',\n",
       " 'A0505.mat',\n",
       " 'A0506.mat',\n",
       " 'A0507.mat',\n",
       " 'A0508.mat',\n",
       " 'A0509.mat',\n",
       " 'A0510.mat',\n",
       " 'A0511.mat',\n",
       " 'A0512.mat',\n",
       " 'A0513.mat',\n",
       " 'A0514.mat',\n",
       " 'A0515.mat',\n",
       " 'A0516.mat',\n",
       " 'A0517.mat',\n",
       " 'A0518.mat',\n",
       " 'A0519.mat',\n",
       " 'A0520.mat',\n",
       " 'A0521.mat',\n",
       " 'A0522.mat',\n",
       " 'A0523.mat',\n",
       " 'A0524.mat',\n",
       " 'A0525.mat',\n",
       " 'A0526.mat',\n",
       " 'A0527.mat',\n",
       " 'A0528.mat',\n",
       " 'A0529.mat',\n",
       " 'A0530.mat',\n",
       " 'A0531.mat',\n",
       " 'A0532.mat',\n",
       " 'A0533.mat',\n",
       " 'A0534.mat',\n",
       " 'A0535.mat',\n",
       " 'A0536.mat',\n",
       " 'A0537.mat',\n",
       " 'A0538.mat',\n",
       " 'A0539.mat',\n",
       " 'A0540.mat',\n",
       " 'A0541.mat',\n",
       " 'A0542.mat',\n",
       " 'A0543.mat',\n",
       " 'A0544.mat',\n",
       " 'A0545.mat',\n",
       " 'A0546.mat',\n",
       " 'A0547.mat',\n",
       " 'A0548.mat',\n",
       " 'A0549.mat',\n",
       " 'A0550.mat',\n",
       " 'A0551.mat',\n",
       " 'A0552.mat',\n",
       " 'A0553.mat',\n",
       " 'A0554.mat',\n",
       " 'A0555.mat',\n",
       " 'A0556.mat',\n",
       " 'A0557.mat',\n",
       " 'A0558.mat',\n",
       " 'A0559.mat',\n",
       " 'A0560.mat',\n",
       " 'A0561.mat',\n",
       " 'A0562.mat',\n",
       " 'A0563.mat',\n",
       " 'A0564.mat',\n",
       " 'A0565.mat',\n",
       " 'A0566.mat',\n",
       " 'A0567.mat',\n",
       " 'A0568.mat',\n",
       " 'A0569.mat',\n",
       " 'A0570.mat',\n",
       " 'A0571.mat',\n",
       " 'A0572.mat',\n",
       " 'A0573.mat',\n",
       " 'A0574.mat',\n",
       " 'A0575.mat',\n",
       " 'A0576.mat',\n",
       " 'A0577.mat',\n",
       " 'A0578.mat',\n",
       " 'A0579.mat',\n",
       " 'A0580.mat',\n",
       " 'A0581.mat',\n",
       " 'A0582.mat',\n",
       " 'A0583.mat',\n",
       " 'A0584.mat',\n",
       " 'A0585.mat',\n",
       " 'A0586.mat',\n",
       " 'A0587.mat',\n",
       " 'A0588.mat',\n",
       " 'A0589.mat',\n",
       " 'A0590.mat',\n",
       " 'A0591.mat',\n",
       " 'A0592.mat',\n",
       " 'A0593.mat',\n",
       " 'A0594.mat',\n",
       " 'A0595.mat',\n",
       " 'A0596.mat',\n",
       " 'A0597.mat',\n",
       " 'A0598.mat',\n",
       " 'A0599.mat',\n",
       " 'A0600.mat',\n",
       " 'A0601.mat',\n",
       " 'A0602.mat',\n",
       " 'A0603.mat',\n",
       " 'A0604.mat',\n",
       " 'A0605.mat',\n",
       " 'A0606.mat',\n",
       " 'A0607.mat',\n",
       " 'A0608.mat',\n",
       " 'A0609.mat',\n",
       " 'A0610.mat',\n",
       " 'A0611.mat',\n",
       " 'A0612.mat',\n",
       " 'A0613.mat',\n",
       " 'A0614.mat',\n",
       " 'A0615.mat',\n",
       " 'A0616.mat',\n",
       " 'A0617.mat',\n",
       " 'A0618.mat',\n",
       " 'A0619.mat',\n",
       " 'A0620.mat',\n",
       " 'A0621.mat',\n",
       " 'A0622.mat',\n",
       " 'A0623.mat',\n",
       " 'A0624.mat',\n",
       " 'A0625.mat',\n",
       " 'A0626.mat',\n",
       " 'A0627.mat',\n",
       " 'A0628.mat',\n",
       " 'A0629.mat',\n",
       " 'A0630.mat',\n",
       " 'A0631.mat',\n",
       " 'A0632.mat',\n",
       " 'A0633.mat',\n",
       " 'A0634.mat',\n",
       " 'A0635.mat',\n",
       " 'A0636.mat',\n",
       " 'A0637.mat',\n",
       " 'A0638.mat',\n",
       " 'A0639.mat',\n",
       " 'A0640.mat',\n",
       " 'A0641.mat',\n",
       " 'A0642.mat',\n",
       " 'A0643.mat',\n",
       " 'A0644.mat',\n",
       " 'A0645.mat',\n",
       " 'A0646.mat',\n",
       " 'A0647.mat',\n",
       " 'A0648.mat',\n",
       " 'A0649.mat',\n",
       " 'A0650.mat',\n",
       " 'A0651.mat',\n",
       " 'A0652.mat',\n",
       " 'A0653.mat',\n",
       " 'A0654.mat',\n",
       " 'A0655.mat',\n",
       " 'A0656.mat',\n",
       " 'A0657.mat',\n",
       " 'A0658.mat',\n",
       " 'A0659.mat',\n",
       " 'A0660.mat',\n",
       " 'A0661.mat',\n",
       " 'A0662.mat',\n",
       " 'A0663.mat',\n",
       " 'A0664.mat',\n",
       " 'A0665.mat',\n",
       " 'A0666.mat',\n",
       " 'A0667.mat',\n",
       " 'A0668.mat',\n",
       " 'A0669.mat',\n",
       " 'A0670.mat',\n",
       " 'A0671.mat',\n",
       " 'A0672.mat',\n",
       " 'A0673.mat',\n",
       " 'A0674.mat',\n",
       " 'A0675.mat',\n",
       " 'A0676.mat',\n",
       " 'A0677.mat',\n",
       " 'A0678.mat',\n",
       " 'A0679.mat',\n",
       " 'A0680.mat',\n",
       " 'A0681.mat',\n",
       " 'A0682.mat',\n",
       " 'A0683.mat',\n",
       " 'A0684.mat',\n",
       " 'A0685.mat',\n",
       " 'A0686.mat',\n",
       " 'A0687.mat',\n",
       " 'A0688.mat',\n",
       " 'A0689.mat',\n",
       " 'A0690.mat',\n",
       " 'A0691.mat',\n",
       " 'A0692.mat',\n",
       " 'A0693.mat',\n",
       " 'A0694.mat',\n",
       " 'A0695.mat',\n",
       " 'A0696.mat',\n",
       " 'A0697.mat',\n",
       " 'A0698.mat',\n",
       " 'A0699.mat',\n",
       " 'A0700.mat',\n",
       " 'A0701.mat',\n",
       " 'A0702.mat',\n",
       " 'A0703.mat',\n",
       " 'A0704.mat',\n",
       " 'A0705.mat',\n",
       " 'A0706.mat',\n",
       " 'A0707.mat',\n",
       " 'A0708.mat',\n",
       " 'A0709.mat',\n",
       " 'A0710.mat',\n",
       " 'A0711.mat',\n",
       " 'A0712.mat',\n",
       " 'A0713.mat',\n",
       " 'A0714.mat',\n",
       " 'A0715.mat',\n",
       " 'A0716.mat',\n",
       " 'A0717.mat',\n",
       " 'A0718.mat',\n",
       " 'A0719.mat',\n",
       " 'A0720.mat',\n",
       " 'A0721.mat',\n",
       " 'A0722.mat',\n",
       " 'A0723.mat',\n",
       " 'A0724.mat',\n",
       " 'A0725.mat',\n",
       " 'A0726.mat',\n",
       " 'A0727.mat',\n",
       " 'A0728.mat',\n",
       " 'A0729.mat',\n",
       " 'A0730.mat',\n",
       " 'A0731.mat',\n",
       " 'A0732.mat',\n",
       " 'A0733.mat',\n",
       " 'A0734.mat',\n",
       " 'A0735.mat',\n",
       " 'A0736.mat',\n",
       " 'A0737.mat',\n",
       " 'A0738.mat',\n",
       " 'A0739.mat',\n",
       " 'A0740.mat',\n",
       " 'A0741.mat',\n",
       " 'A0742.mat',\n",
       " 'A0743.mat',\n",
       " 'A0744.mat',\n",
       " 'A0745.mat',\n",
       " 'A0746.mat',\n",
       " 'A0747.mat',\n",
       " 'A0748.mat',\n",
       " 'A0749.mat',\n",
       " 'A0750.mat',\n",
       " 'A0751.mat',\n",
       " 'A0752.mat',\n",
       " 'A0753.mat',\n",
       " 'A0754.mat',\n",
       " 'A0755.mat',\n",
       " 'A0756.mat',\n",
       " 'A0757.mat',\n",
       " 'A0758.mat',\n",
       " 'A0759.mat',\n",
       " 'A0760.mat',\n",
       " 'A0761.mat',\n",
       " 'A0762.mat',\n",
       " 'A0763.mat',\n",
       " 'A0764.mat',\n",
       " 'A0765.mat',\n",
       " 'A0766.mat',\n",
       " 'A0767.mat',\n",
       " 'A0768.mat',\n",
       " 'A0769.mat',\n",
       " 'A0770.mat',\n",
       " 'A0771.mat',\n",
       " 'A0772.mat',\n",
       " 'A0773.mat',\n",
       " 'A0774.mat',\n",
       " 'A0775.mat',\n",
       " 'A0776.mat',\n",
       " 'A0777.mat',\n",
       " 'A0778.mat',\n",
       " 'A0779.mat',\n",
       " 'A0780.mat',\n",
       " 'A0781.mat',\n",
       " 'A0782.mat',\n",
       " 'A0783.mat',\n",
       " 'A0784.mat',\n",
       " 'A0785.mat',\n",
       " 'A0786.mat',\n",
       " 'A0787.mat',\n",
       " 'A0788.mat',\n",
       " 'A0789.mat',\n",
       " 'A0790.mat',\n",
       " 'A0791.mat',\n",
       " 'A0792.mat',\n",
       " 'A0793.mat',\n",
       " 'A0794.mat',\n",
       " 'A0795.mat',\n",
       " 'A0796.mat',\n",
       " 'A0797.mat',\n",
       " 'A0798.mat',\n",
       " 'A0799.mat',\n",
       " 'A0800.mat',\n",
       " 'A0801.mat',\n",
       " 'A0802.mat',\n",
       " 'A0803.mat',\n",
       " 'A0804.mat',\n",
       " 'A0805.mat',\n",
       " 'A0806.mat',\n",
       " 'A0807.mat',\n",
       " 'A0808.mat',\n",
       " 'A0809.mat',\n",
       " 'A0810.mat',\n",
       " 'A0811.mat',\n",
       " 'A0812.mat',\n",
       " 'A0813.mat',\n",
       " 'A0814.mat',\n",
       " 'A0815.mat',\n",
       " 'A0816.mat',\n",
       " 'A0817.mat',\n",
       " 'A0818.mat',\n",
       " 'A0819.mat',\n",
       " 'A0820.mat',\n",
       " 'A0821.mat',\n",
       " 'A0822.mat',\n",
       " 'A0823.mat',\n",
       " 'A0824.mat',\n",
       " 'A0825.mat',\n",
       " 'A0826.mat',\n",
       " 'A0827.mat',\n",
       " 'A0828.mat',\n",
       " 'A0829.mat',\n",
       " 'A0830.mat',\n",
       " 'A0831.mat',\n",
       " 'A0832.mat',\n",
       " 'A0833.mat',\n",
       " 'A0834.mat',\n",
       " 'A0835.mat',\n",
       " 'A0836.mat',\n",
       " 'A0837.mat',\n",
       " 'A0838.mat',\n",
       " 'A0839.mat',\n",
       " 'A0840.mat',\n",
       " 'A0841.mat',\n",
       " 'A0842.mat',\n",
       " 'A0843.mat',\n",
       " 'A0844.mat',\n",
       " 'A0845.mat',\n",
       " 'A0846.mat',\n",
       " 'A0847.mat',\n",
       " 'A0848.mat',\n",
       " 'A0849.mat',\n",
       " 'A0850.mat',\n",
       " 'A0851.mat',\n",
       " 'A0852.mat',\n",
       " 'A0853.mat',\n",
       " 'A0854.mat',\n",
       " 'A0855.mat',\n",
       " 'A0856.mat',\n",
       " 'A0857.mat',\n",
       " 'A0858.mat',\n",
       " 'A0859.mat',\n",
       " 'A0860.mat',\n",
       " 'A0861.mat',\n",
       " 'A0862.mat',\n",
       " 'A0863.mat',\n",
       " 'A0864.mat',\n",
       " 'A0865.mat',\n",
       " 'A0866.mat',\n",
       " 'A0867.mat',\n",
       " 'A0868.mat',\n",
       " 'A0869.mat',\n",
       " 'A0870.mat',\n",
       " 'A0871.mat',\n",
       " 'A0872.mat',\n",
       " 'A0873.mat',\n",
       " 'A0874.mat',\n",
       " 'A0875.mat',\n",
       " 'A0876.mat',\n",
       " 'A0877.mat',\n",
       " 'A0878.mat',\n",
       " 'A0879.mat',\n",
       " 'A0880.mat',\n",
       " 'A0881.mat',\n",
       " 'A0882.mat',\n",
       " 'A0883.mat',\n",
       " 'A0884.mat',\n",
       " 'A0885.mat',\n",
       " 'A0886.mat',\n",
       " 'A0887.mat',\n",
       " 'A0888.mat',\n",
       " 'A0889.mat',\n",
       " 'A0890.mat',\n",
       " 'A0891.mat',\n",
       " 'A0892.mat',\n",
       " 'A0893.mat',\n",
       " 'A0894.mat',\n",
       " 'A0895.mat',\n",
       " 'A0896.mat',\n",
       " 'A0897.mat',\n",
       " 'A0898.mat',\n",
       " 'A0899.mat',\n",
       " 'A0900.mat',\n",
       " 'A0901.mat',\n",
       " 'A0902.mat',\n",
       " 'A0903.mat',\n",
       " 'A0904.mat',\n",
       " 'A0905.mat',\n",
       " 'A0906.mat',\n",
       " 'A0907.mat',\n",
       " 'A0908.mat',\n",
       " 'A0909.mat',\n",
       " 'A0910.mat',\n",
       " 'A0911.mat',\n",
       " 'A0912.mat',\n",
       " 'A0913.mat',\n",
       " 'A0914.mat',\n",
       " 'A0915.mat',\n",
       " 'A0916.mat',\n",
       " 'A0917.mat',\n",
       " 'A0918.mat',\n",
       " 'A0919.mat',\n",
       " 'A0920.mat',\n",
       " 'A0921.mat',\n",
       " 'A0922.mat',\n",
       " 'A0923.mat',\n",
       " 'A0924.mat',\n",
       " 'A0925.mat',\n",
       " 'A0926.mat',\n",
       " 'A0927.mat',\n",
       " 'A0928.mat',\n",
       " 'A0929.mat',\n",
       " 'A0930.mat',\n",
       " 'A0931.mat',\n",
       " 'A0932.mat',\n",
       " 'A0933.mat',\n",
       " 'A0934.mat',\n",
       " 'A0935.mat',\n",
       " 'A0936.mat',\n",
       " 'A0937.mat',\n",
       " 'A0938.mat',\n",
       " 'A0939.mat',\n",
       " 'A0940.mat',\n",
       " 'A0941.mat',\n",
       " 'A0942.mat',\n",
       " 'A0943.mat',\n",
       " 'A0944.mat',\n",
       " 'A0945.mat',\n",
       " 'A0946.mat',\n",
       " 'A0947.mat',\n",
       " 'A0948.mat',\n",
       " 'A0949.mat',\n",
       " 'A0950.mat',\n",
       " 'A0951.mat',\n",
       " 'A0952.mat',\n",
       " 'A0953.mat',\n",
       " 'A0954.mat',\n",
       " 'A0955.mat',\n",
       " 'A0956.mat',\n",
       " 'A0957.mat',\n",
       " 'A0958.mat',\n",
       " 'A0959.mat',\n",
       " 'A0960.mat',\n",
       " 'A0961.mat',\n",
       " 'A0962.mat',\n",
       " 'A0963.mat',\n",
       " 'A0964.mat',\n",
       " 'A0965.mat',\n",
       " 'A0966.mat',\n",
       " 'A0967.mat',\n",
       " 'A0968.mat',\n",
       " 'A0969.mat',\n",
       " 'A0970.mat',\n",
       " 'A0971.mat',\n",
       " 'A0972.mat',\n",
       " 'A0973.mat',\n",
       " 'A0974.mat',\n",
       " 'A0975.mat',\n",
       " 'A0976.mat',\n",
       " 'A0977.mat',\n",
       " 'A0978.mat',\n",
       " 'A0979.mat',\n",
       " 'A0980.mat',\n",
       " 'A0981.mat',\n",
       " 'A0982.mat',\n",
       " 'A0983.mat',\n",
       " 'A0984.mat',\n",
       " 'A0985.mat',\n",
       " 'A0986.mat',\n",
       " 'A0987.mat',\n",
       " 'A0988.mat',\n",
       " 'A0989.mat',\n",
       " 'A0990.mat',\n",
       " 'A0991.mat',\n",
       " 'A0992.mat',\n",
       " 'A0993.mat',\n",
       " 'A0994.mat',\n",
       " 'A0995.mat',\n",
       " 'A0996.mat',\n",
       " 'A0997.mat',\n",
       " 'A0998.mat',\n",
       " 'A0999.mat',\n",
       " 'A1000.mat',\n",
       " ...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_file_names = sorted(input_files)\n",
    "input_file_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle and divide files into train/eval/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, data_test = train_test_split(input_file_names, test_size = 0.2, train_size = 0.8, shuffle=True)\n",
    "data_train, data_val = train_test_split(data, test_size = 0.25, train_size = 0.75, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4125,) (1376,) (1376,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(data_train), np.shape(data_val), np.shape(data_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess labels (one-hot encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find unique number of classes  \n",
    "def get_unique_classes(input_directory,files):\n",
    "\n",
    "    unique_classes=set()\n",
    "    for f in files:\n",
    "        g = f.replace('.mat','.hea')\n",
    "        input_file = os.path.join(input_directory,g)\n",
    "        with open(input_file,'r') as f:\n",
    "            for lines in f:\n",
    "                if lines.startswith('#Dx'):\n",
    "                    tmp = lines.split(': ')[1].split(',')\n",
    "                    for c in tmp:\n",
    "                        unique_classes.add(c.strip())\n",
    "\n",
    "    return sorted(unique_classes)\n",
    "\n",
    "unique_classes = get_unique_classes(input_directory, input_files)\n",
    "# Creating one-hot vector for Y\n",
    "# num = np.unique(classes, axis=0)\n",
    "class2index = {}\n",
    "for a, b in enumerate(unique_classes):\n",
    "    class2index[b] = a\n",
    "#class2index\n",
    "\n",
    "def one_hot_encoding(one_hot_vector,y, class2index):\n",
    "\n",
    "       ind=class2index[y]\n",
    "       one_hot_vector[ind]=1\n",
    "       return one_hot_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AF': 0,\n",
       " 'I-AVB': 1,\n",
       " 'LBBB': 2,\n",
       " 'Normal': 3,\n",
       " 'PAC': 4,\n",
       " 'PVC': 5,\n",
       " 'RBBB': 6,\n",
       " 'STD': 7,\n",
       " 'STE': 8}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Checkinc which x is minimum\n",
    "# minimum = 300\n",
    "# for file in input_file_names:\n",
    "#     tmp_file = np.load(mel_directory + '/' + file.replace('.mat', '.npy'))\n",
    "#     print(np.shape(tmp_file))\n",
    "#     if len(tmp_file) < minimum:\n",
    "#         minimum = tmp_file.shape[0]\n",
    "# #print(minimum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes= np.asarray(classes)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mel_files = np.asarray(mel_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# dataset = dataset.batch(batch_size)\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, x_test, y, y_test  = train_test_split(mel_files, classes, test_size=0.2, train_size = 0.8)\n",
    "# x_train, x_val, y_train, y_val = train_test_split(x, y, test_size = 0.25, train_size = 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(np.shape(x_train), np.shape(x_val), np.shape(x_test), np.shape(y_train), np.shape(y_val), np.shape(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.densenet import DenseNet169\n",
    "from keras.layers import Input, GlobalAveragePooling2D, Dense\n",
    "from keras.models import Model \n",
    "\n",
    "input_tensor = Input(shape=(128, 128, 12))\n",
    "base_model = DenseNet169(input_tensor=input_tensor, weights=None, include_top=False)\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "pred = Dense(9, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 128, 128, 12) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 134, 134, 12) 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1/conv (Conv2D)             (None, 64, 64, 64)   37632       zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1/bn (BatchNormalization)   (None, 64, 64, 64)   256         conv1/conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1/relu (Activation)         (None, 64, 64, 64)   0           conv1/bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 66, 66, 64)   0           conv1/relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 32, 32, 64)   0           zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 32, 32, 64)   256         pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_relu (Activation (None, 32, 32, 64)   0           conv2_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 32, 32, 128)  8192        conv2_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 32, 32, 128)  512         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 32, 32, 128)  0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_concat (Concatenat (None, 32, 32, 96)   0           pool1[0][0]                      \n",
      "                                                                 conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_bn (BatchNormali (None, 32, 32, 96)   384         conv2_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_relu (Activation (None, 32, 32, 96)   0           conv2_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 32, 32, 128)  12288       conv2_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 32, 32, 128)  512         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 32, 32, 128)  0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_concat (Concatenat (None, 32, 32, 128)  0           conv2_block1_concat[0][0]        \n",
      "                                                                 conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_bn (BatchNormali (None, 32, 32, 128)  512         conv2_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_relu (Activation (None, 32, 32, 128)  0           conv2_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 32, 32, 128)  16384       conv2_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 32, 32, 128)  512         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 32, 32, 128)  0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_concat (Concatenat (None, 32, 32, 160)  0           conv2_block2_concat[0][0]        \n",
      "                                                                 conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_bn (BatchNormali (None, 32, 32, 160)  640         conv2_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_relu (Activation (None, 32, 32, 160)  0           conv2_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_conv (Conv2D)    (None, 32, 32, 128)  20480       conv2_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_bn (BatchNormali (None, 32, 32, 128)  512         conv2_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_relu (Activation (None, 32, 32, 128)  0           conv2_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv2_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_concat (Concatenat (None, 32, 32, 192)  0           conv2_block3_concat[0][0]        \n",
      "                                                                 conv2_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_bn (BatchNormali (None, 32, 32, 192)  768         conv2_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_relu (Activation (None, 32, 32, 192)  0           conv2_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_conv (Conv2D)    (None, 32, 32, 128)  24576       conv2_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_bn (BatchNormali (None, 32, 32, 128)  512         conv2_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_relu (Activation (None, 32, 32, 128)  0           conv2_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv2_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_concat (Concatenat (None, 32, 32, 224)  0           conv2_block4_concat[0][0]        \n",
      "                                                                 conv2_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_bn (BatchNormali (None, 32, 32, 224)  896         conv2_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_relu (Activation (None, 32, 32, 224)  0           conv2_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_conv (Conv2D)    (None, 32, 32, 128)  28672       conv2_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_bn (BatchNormali (None, 32, 32, 128)  512         conv2_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_relu (Activation (None, 32, 32, 128)  0           conv2_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv2_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_concat (Concatenat (None, 32, 32, 256)  0           conv2_block5_concat[0][0]        \n",
      "                                                                 conv2_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_bn (BatchNormalization)   (None, 32, 32, 256)  1024        conv2_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_relu (Activation)         (None, 32, 32, 256)  0           pool2_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool2_conv (Conv2D)             (None, 32, 32, 128)  32768       pool2_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool2_pool (AveragePooling2D)   (None, 16, 16, 128)  0           pool2_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 16, 16, 128)  512         pool2_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_relu (Activation (None, 16, 16, 128)  0           conv3_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 16, 16, 128)  16384       conv3_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 16, 16, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_concat (Concatenat (None, 16, 16, 160)  0           pool2_pool[0][0]                 \n",
      "                                                                 conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_bn (BatchNormali (None, 16, 16, 160)  640         conv3_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_relu (Activation (None, 16, 16, 160)  0           conv3_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 16, 16, 128)  20480       conv3_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 16, 16, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_concat (Concatenat (None, 16, 16, 192)  0           conv3_block1_concat[0][0]        \n",
      "                                                                 conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_bn (BatchNormali (None, 16, 16, 192)  768         conv3_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_relu (Activation (None, 16, 16, 192)  0           conv3_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 16, 16, 128)  24576       conv3_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 16, 16, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_concat (Concatenat (None, 16, 16, 224)  0           conv3_block2_concat[0][0]        \n",
      "                                                                 conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_bn (BatchNormali (None, 16, 16, 224)  896         conv3_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_relu (Activation (None, 16, 16, 224)  0           conv3_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 16, 16, 128)  28672       conv3_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 16, 16, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_concat (Concatenat (None, 16, 16, 256)  0           conv3_block3_concat[0][0]        \n",
      "                                                                 conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_bn (BatchNormali (None, 16, 16, 256)  1024        conv3_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_relu (Activation (None, 16, 16, 256)  0           conv3_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_conv (Conv2D)    (None, 16, 16, 128)  32768       conv3_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_relu (Activation (None, 16, 16, 128)  0           conv3_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_concat (Concatenat (None, 16, 16, 288)  0           conv3_block4_concat[0][0]        \n",
      "                                                                 conv3_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_bn (BatchNormali (None, 16, 16, 288)  1152        conv3_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_relu (Activation (None, 16, 16, 288)  0           conv3_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_conv (Conv2D)    (None, 16, 16, 128)  36864       conv3_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_relu (Activation (None, 16, 16, 128)  0           conv3_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_concat (Concatenat (None, 16, 16, 320)  0           conv3_block5_concat[0][0]        \n",
      "                                                                 conv3_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_bn (BatchNormali (None, 16, 16, 320)  1280        conv3_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_relu (Activation (None, 16, 16, 320)  0           conv3_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_conv (Conv2D)    (None, 16, 16, 128)  40960       conv3_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_relu (Activation (None, 16, 16, 128)  0           conv3_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_concat (Concatenat (None, 16, 16, 352)  0           conv3_block6_concat[0][0]        \n",
      "                                                                 conv3_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_bn (BatchNormali (None, 16, 16, 352)  1408        conv3_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_relu (Activation (None, 16, 16, 352)  0           conv3_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_conv (Conv2D)    (None, 16, 16, 128)  45056       conv3_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_relu (Activation (None, 16, 16, 128)  0           conv3_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_concat (Concatenat (None, 16, 16, 384)  0           conv3_block7_concat[0][0]        \n",
      "                                                                 conv3_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_bn (BatchNormali (None, 16, 16, 384)  1536        conv3_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_relu (Activation (None, 16, 16, 384)  0           conv3_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_conv (Conv2D)    (None, 16, 16, 128)  49152       conv3_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_relu (Activation (None, 16, 16, 128)  0           conv3_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_concat (Concatenat (None, 16, 16, 416)  0           conv3_block8_concat[0][0]        \n",
      "                                                                 conv3_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_bn (BatchNormal (None, 16, 16, 416)  1664        conv3_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_relu (Activatio (None, 16, 16, 416)  0           conv3_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_conv (Conv2D)   (None, 16, 16, 128)  53248       conv3_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_bn (BatchNormal (None, 16, 16, 128)  512         conv3_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_relu (Activatio (None, 16, 16, 128)  0           conv3_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv3_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_concat (Concatena (None, 16, 16, 448)  0           conv3_block9_concat[0][0]        \n",
      "                                                                 conv3_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_bn (BatchNormal (None, 16, 16, 448)  1792        conv3_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_relu (Activatio (None, 16, 16, 448)  0           conv3_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_conv (Conv2D)   (None, 16, 16, 128)  57344       conv3_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_bn (BatchNormal (None, 16, 16, 128)  512         conv3_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_relu (Activatio (None, 16, 16, 128)  0           conv3_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv3_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_concat (Concatena (None, 16, 16, 480)  0           conv3_block10_concat[0][0]       \n",
      "                                                                 conv3_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_bn (BatchNormal (None, 16, 16, 480)  1920        conv3_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_relu (Activatio (None, 16, 16, 480)  0           conv3_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_conv (Conv2D)   (None, 16, 16, 128)  61440       conv3_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_bn (BatchNormal (None, 16, 16, 128)  512         conv3_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_relu (Activatio (None, 16, 16, 128)  0           conv3_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv3_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_concat (Concatena (None, 16, 16, 512)  0           conv3_block11_concat[0][0]       \n",
      "                                                                 conv3_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_bn (BatchNormalization)   (None, 16, 16, 512)  2048        conv3_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_relu (Activation)         (None, 16, 16, 512)  0           pool3_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool3_conv (Conv2D)             (None, 16, 16, 256)  131072      pool3_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool3_pool (AveragePooling2D)   (None, 8, 8, 256)    0           pool3_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        pool3_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_relu (Activation (None, 8, 8, 256)    0           conv4_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 8, 8, 128)    32768       conv4_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 8, 8, 128)    0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_concat (Concatenat (None, 8, 8, 288)    0           pool3_pool[0][0]                 \n",
      "                                                                 conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_bn (BatchNormali (None, 8, 8, 288)    1152        conv4_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_relu (Activation (None, 8, 8, 288)    0           conv4_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 8, 8, 128)    36864       conv4_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 8, 8, 128)    0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_concat (Concatenat (None, 8, 8, 320)    0           conv4_block1_concat[0][0]        \n",
      "                                                                 conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_bn (BatchNormali (None, 8, 8, 320)    1280        conv4_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_relu (Activation (None, 8, 8, 320)    0           conv4_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 8, 8, 128)    40960       conv4_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 8, 8, 128)    0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_concat (Concatenat (None, 8, 8, 352)    0           conv4_block2_concat[0][0]        \n",
      "                                                                 conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_bn (BatchNormali (None, 8, 8, 352)    1408        conv4_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_relu (Activation (None, 8, 8, 352)    0           conv4_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 8, 8, 128)    45056       conv4_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 8, 8, 128)    0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_concat (Concatenat (None, 8, 8, 384)    0           conv4_block3_concat[0][0]        \n",
      "                                                                 conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_bn (BatchNormali (None, 8, 8, 384)    1536        conv4_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_relu (Activation (None, 8, 8, 384)    0           conv4_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 8, 8, 128)    49152       conv4_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 8, 8, 128)    0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_concat (Concatenat (None, 8, 8, 416)    0           conv4_block4_concat[0][0]        \n",
      "                                                                 conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_bn (BatchNormali (None, 8, 8, 416)    1664        conv4_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_relu (Activation (None, 8, 8, 416)    0           conv4_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 8, 8, 128)    53248       conv4_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 8, 8, 128)    0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_concat (Concatenat (None, 8, 8, 448)    0           conv4_block5_concat[0][0]        \n",
      "                                                                 conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_bn (BatchNormali (None, 8, 8, 448)    1792        conv4_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_relu (Activation (None, 8, 8, 448)    0           conv4_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 8, 8, 128)    57344       conv4_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 8, 8, 128)    0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_concat (Concatenat (None, 8, 8, 480)    0           conv4_block6_concat[0][0]        \n",
      "                                                                 conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_bn (BatchNormali (None, 8, 8, 480)    1920        conv4_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_relu (Activation (None, 8, 8, 480)    0           conv4_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 8, 8, 128)    61440       conv4_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 8, 8, 128)    0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_concat (Concatenat (None, 8, 8, 512)    0           conv4_block7_concat[0][0]        \n",
      "                                                                 conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_bn (BatchNormali (None, 8, 8, 512)    2048        conv4_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_relu (Activation (None, 8, 8, 512)    0           conv4_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 8, 8, 128)    65536       conv4_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 8, 8, 128)    0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_concat (Concatenat (None, 8, 8, 544)    0           conv4_block8_concat[0][0]        \n",
      "                                                                 conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_bn (BatchNormal (None, 8, 8, 544)    2176        conv4_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_relu (Activatio (None, 8, 8, 544)    0           conv4_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 8, 8, 128)    69632       conv4_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_concat (Concatena (None, 8, 8, 576)    0           conv4_block9_concat[0][0]        \n",
      "                                                                 conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_bn (BatchNormal (None, 8, 8, 576)    2304        conv4_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_relu (Activatio (None, 8, 8, 576)    0           conv4_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 8, 8, 128)    73728       conv4_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_concat (Concatena (None, 8, 8, 608)    0           conv4_block10_concat[0][0]       \n",
      "                                                                 conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_bn (BatchNormal (None, 8, 8, 608)    2432        conv4_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_relu (Activatio (None, 8, 8, 608)    0           conv4_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 8, 8, 128)    77824       conv4_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_concat (Concatena (None, 8, 8, 640)    0           conv4_block11_concat[0][0]       \n",
      "                                                                 conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_bn (BatchNormal (None, 8, 8, 640)    2560        conv4_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_relu (Activatio (None, 8, 8, 640)    0           conv4_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 8, 8, 128)    81920       conv4_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_concat (Concatena (None, 8, 8, 672)    0           conv4_block12_concat[0][0]       \n",
      "                                                                 conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_bn (BatchNormal (None, 8, 8, 672)    2688        conv4_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_relu (Activatio (None, 8, 8, 672)    0           conv4_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 8, 8, 128)    86016       conv4_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_concat (Concatena (None, 8, 8, 704)    0           conv4_block13_concat[0][0]       \n",
      "                                                                 conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_bn (BatchNormal (None, 8, 8, 704)    2816        conv4_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_relu (Activatio (None, 8, 8, 704)    0           conv4_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 8, 8, 128)    90112       conv4_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_concat (Concatena (None, 8, 8, 736)    0           conv4_block14_concat[0][0]       \n",
      "                                                                 conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_bn (BatchNormal (None, 8, 8, 736)    2944        conv4_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_relu (Activatio (None, 8, 8, 736)    0           conv4_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 8, 8, 128)    94208       conv4_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_concat (Concatena (None, 8, 8, 768)    0           conv4_block15_concat[0][0]       \n",
      "                                                                 conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_bn (BatchNormal (None, 8, 8, 768)    3072        conv4_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_relu (Activatio (None, 8, 8, 768)    0           conv4_block17_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 8, 8, 128)    98304       conv4_block17_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_concat (Concatena (None, 8, 8, 800)    0           conv4_block16_concat[0][0]       \n",
      "                                                                 conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_bn (BatchNormal (None, 8, 8, 800)    3200        conv4_block17_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_relu (Activatio (None, 8, 8, 800)    0           conv4_block18_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 8, 8, 128)    102400      conv4_block18_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_concat (Concatena (None, 8, 8, 832)    0           conv4_block17_concat[0][0]       \n",
      "                                                                 conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_bn (BatchNormal (None, 8, 8, 832)    3328        conv4_block18_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_relu (Activatio (None, 8, 8, 832)    0           conv4_block19_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 8, 8, 128)    106496      conv4_block19_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_concat (Concatena (None, 8, 8, 864)    0           conv4_block18_concat[0][0]       \n",
      "                                                                 conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_bn (BatchNormal (None, 8, 8, 864)    3456        conv4_block19_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_relu (Activatio (None, 8, 8, 864)    0           conv4_block20_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 8, 8, 128)    110592      conv4_block20_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_concat (Concatena (None, 8, 8, 896)    0           conv4_block19_concat[0][0]       \n",
      "                                                                 conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_bn (BatchNormal (None, 8, 8, 896)    3584        conv4_block20_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_relu (Activatio (None, 8, 8, 896)    0           conv4_block21_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 8, 8, 128)    114688      conv4_block21_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_concat (Concatena (None, 8, 8, 928)    0           conv4_block20_concat[0][0]       \n",
      "                                                                 conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_bn (BatchNormal (None, 8, 8, 928)    3712        conv4_block21_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_relu (Activatio (None, 8, 8, 928)    0           conv4_block22_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 8, 8, 128)    118784      conv4_block22_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_concat (Concatena (None, 8, 8, 960)    0           conv4_block21_concat[0][0]       \n",
      "                                                                 conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_bn (BatchNormal (None, 8, 8, 960)    3840        conv4_block22_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_relu (Activatio (None, 8, 8, 960)    0           conv4_block23_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 8, 8, 128)    122880      conv4_block23_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_concat (Concatena (None, 8, 8, 992)    0           conv4_block22_concat[0][0]       \n",
      "                                                                 conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_bn (BatchNormal (None, 8, 8, 992)    3968        conv4_block23_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_relu (Activatio (None, 8, 8, 992)    0           conv4_block24_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_conv (Conv2D)   (None, 8, 8, 128)    126976      conv4_block24_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_concat (Concatena (None, 8, 8, 1024)   0           conv4_block23_concat[0][0]       \n",
      "                                                                 conv4_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_0_bn (BatchNormal (None, 8, 8, 1024)   4096        conv4_block24_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_0_relu (Activatio (None, 8, 8, 1024)   0           conv4_block25_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_1_conv (Conv2D)   (None, 8, 8, 128)    131072      conv4_block25_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block25_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block25_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block25_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_concat (Concatena (None, 8, 8, 1056)   0           conv4_block24_concat[0][0]       \n",
      "                                                                 conv4_block25_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_0_bn (BatchNormal (None, 8, 8, 1056)   4224        conv4_block25_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_0_relu (Activatio (None, 8, 8, 1056)   0           conv4_block26_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_1_conv (Conv2D)   (None, 8, 8, 128)    135168      conv4_block26_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block26_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block26_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block26_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_concat (Concatena (None, 8, 8, 1088)   0           conv4_block25_concat[0][0]       \n",
      "                                                                 conv4_block26_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_0_bn (BatchNormal (None, 8, 8, 1088)   4352        conv4_block26_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_0_relu (Activatio (None, 8, 8, 1088)   0           conv4_block27_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_1_conv (Conv2D)   (None, 8, 8, 128)    139264      conv4_block27_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block27_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block27_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block27_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_concat (Concatena (None, 8, 8, 1120)   0           conv4_block26_concat[0][0]       \n",
      "                                                                 conv4_block27_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_0_bn (BatchNormal (None, 8, 8, 1120)   4480        conv4_block27_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_0_relu (Activatio (None, 8, 8, 1120)   0           conv4_block28_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_1_conv (Conv2D)   (None, 8, 8, 128)    143360      conv4_block28_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block28_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block28_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block28_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_concat (Concatena (None, 8, 8, 1152)   0           conv4_block27_concat[0][0]       \n",
      "                                                                 conv4_block28_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_0_bn (BatchNormal (None, 8, 8, 1152)   4608        conv4_block28_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_0_relu (Activatio (None, 8, 8, 1152)   0           conv4_block29_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_1_conv (Conv2D)   (None, 8, 8, 128)    147456      conv4_block29_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block29_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block29_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block29_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_concat (Concatena (None, 8, 8, 1184)   0           conv4_block28_concat[0][0]       \n",
      "                                                                 conv4_block29_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_0_bn (BatchNormal (None, 8, 8, 1184)   4736        conv4_block29_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_0_relu (Activatio (None, 8, 8, 1184)   0           conv4_block30_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_1_conv (Conv2D)   (None, 8, 8, 128)    151552      conv4_block30_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block30_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block30_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block30_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_concat (Concatena (None, 8, 8, 1216)   0           conv4_block29_concat[0][0]       \n",
      "                                                                 conv4_block30_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_0_bn (BatchNormal (None, 8, 8, 1216)   4864        conv4_block30_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_0_relu (Activatio (None, 8, 8, 1216)   0           conv4_block31_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_1_conv (Conv2D)   (None, 8, 8, 128)    155648      conv4_block31_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block31_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block31_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block31_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_concat (Concatena (None, 8, 8, 1248)   0           conv4_block30_concat[0][0]       \n",
      "                                                                 conv4_block31_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_0_bn (BatchNormal (None, 8, 8, 1248)   4992        conv4_block31_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_0_relu (Activatio (None, 8, 8, 1248)   0           conv4_block32_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_1_conv (Conv2D)   (None, 8, 8, 128)    159744      conv4_block32_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block32_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block32_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block32_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_concat (Concatena (None, 8, 8, 1280)   0           conv4_block31_concat[0][0]       \n",
      "                                                                 conv4_block32_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_bn (BatchNormalization)   (None, 8, 8, 1280)   5120        conv4_block32_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_relu (Activation)         (None, 8, 8, 1280)   0           pool4_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool4_conv (Conv2D)             (None, 8, 8, 640)    819200      pool4_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool4_pool (AveragePooling2D)   (None, 4, 4, 640)    0           pool4_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 4, 4, 640)    2560        pool4_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_relu (Activation (None, 4, 4, 640)    0           conv5_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 4, 4, 128)    81920       conv5_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 4, 4, 128)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_concat (Concatenat (None, 4, 4, 672)    0           pool4_pool[0][0]                 \n",
      "                                                                 conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_bn (BatchNormali (None, 4, 4, 672)    2688        conv5_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_relu (Activation (None, 4, 4, 672)    0           conv5_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 4, 4, 128)    86016       conv5_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 4, 4, 128)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_concat (Concatenat (None, 4, 4, 704)    0           conv5_block1_concat[0][0]        \n",
      "                                                                 conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_bn (BatchNormali (None, 4, 4, 704)    2816        conv5_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_relu (Activation (None, 4, 4, 704)    0           conv5_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 4, 4, 128)    90112       conv5_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 4, 4, 128)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_concat (Concatenat (None, 4, 4, 736)    0           conv5_block2_concat[0][0]        \n",
      "                                                                 conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_bn (BatchNormali (None, 4, 4, 736)    2944        conv5_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_relu (Activation (None, 4, 4, 736)    0           conv5_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_conv (Conv2D)    (None, 4, 4, 128)    94208       conv5_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_relu (Activation (None, 4, 4, 128)    0           conv5_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_concat (Concatenat (None, 4, 4, 768)    0           conv5_block3_concat[0][0]        \n",
      "                                                                 conv5_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_bn (BatchNormali (None, 4, 4, 768)    3072        conv5_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_relu (Activation (None, 4, 4, 768)    0           conv5_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_conv (Conv2D)    (None, 4, 4, 128)    98304       conv5_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_relu (Activation (None, 4, 4, 128)    0           conv5_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_concat (Concatenat (None, 4, 4, 800)    0           conv5_block4_concat[0][0]        \n",
      "                                                                 conv5_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_bn (BatchNormali (None, 4, 4, 800)    3200        conv5_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_relu (Activation (None, 4, 4, 800)    0           conv5_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_conv (Conv2D)    (None, 4, 4, 128)    102400      conv5_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_relu (Activation (None, 4, 4, 128)    0           conv5_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_concat (Concatenat (None, 4, 4, 832)    0           conv5_block5_concat[0][0]        \n",
      "                                                                 conv5_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_bn (BatchNormali (None, 4, 4, 832)    3328        conv5_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_relu (Activation (None, 4, 4, 832)    0           conv5_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_conv (Conv2D)    (None, 4, 4, 128)    106496      conv5_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_relu (Activation (None, 4, 4, 128)    0           conv5_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_concat (Concatenat (None, 4, 4, 864)    0           conv5_block6_concat[0][0]        \n",
      "                                                                 conv5_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_bn (BatchNormali (None, 4, 4, 864)    3456        conv5_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_relu (Activation (None, 4, 4, 864)    0           conv5_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_conv (Conv2D)    (None, 4, 4, 128)    110592      conv5_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_relu (Activation (None, 4, 4, 128)    0           conv5_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_concat (Concatenat (None, 4, 4, 896)    0           conv5_block7_concat[0][0]        \n",
      "                                                                 conv5_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_bn (BatchNormali (None, 4, 4, 896)    3584        conv5_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_relu (Activation (None, 4, 4, 896)    0           conv5_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_conv (Conv2D)    (None, 4, 4, 128)    114688      conv5_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_relu (Activation (None, 4, 4, 128)    0           conv5_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_concat (Concatenat (None, 4, 4, 928)    0           conv5_block8_concat[0][0]        \n",
      "                                                                 conv5_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_bn (BatchNormal (None, 4, 4, 928)    3712        conv5_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_relu (Activatio (None, 4, 4, 928)    0           conv5_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_conv (Conv2D)   (None, 4, 4, 128)    118784      conv5_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_concat (Concatena (None, 4, 4, 960)    0           conv5_block9_concat[0][0]        \n",
      "                                                                 conv5_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_bn (BatchNormal (None, 4, 4, 960)    3840        conv5_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_relu (Activatio (None, 4, 4, 960)    0           conv5_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_conv (Conv2D)   (None, 4, 4, 128)    122880      conv5_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_concat (Concatena (None, 4, 4, 992)    0           conv5_block10_concat[0][0]       \n",
      "                                                                 conv5_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_bn (BatchNormal (None, 4, 4, 992)    3968        conv5_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_relu (Activatio (None, 4, 4, 992)    0           conv5_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_conv (Conv2D)   (None, 4, 4, 128)    126976      conv5_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_concat (Concatena (None, 4, 4, 1024)   0           conv5_block11_concat[0][0]       \n",
      "                                                                 conv5_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_bn (BatchNormal (None, 4, 4, 1024)   4096        conv5_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_relu (Activatio (None, 4, 4, 1024)   0           conv5_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_conv (Conv2D)   (None, 4, 4, 128)    131072      conv5_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_concat (Concatena (None, 4, 4, 1056)   0           conv5_block12_concat[0][0]       \n",
      "                                                                 conv5_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_bn (BatchNormal (None, 4, 4, 1056)   4224        conv5_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_relu (Activatio (None, 4, 4, 1056)   0           conv5_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_conv (Conv2D)   (None, 4, 4, 128)    135168      conv5_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_concat (Concatena (None, 4, 4, 1088)   0           conv5_block13_concat[0][0]       \n",
      "                                                                 conv5_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_bn (BatchNormal (None, 4, 4, 1088)   4352        conv5_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_relu (Activatio (None, 4, 4, 1088)   0           conv5_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_conv (Conv2D)   (None, 4, 4, 128)    139264      conv5_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_concat (Concatena (None, 4, 4, 1120)   0           conv5_block14_concat[0][0]       \n",
      "                                                                 conv5_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_bn (BatchNormal (None, 4, 4, 1120)   4480        conv5_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_relu (Activatio (None, 4, 4, 1120)   0           conv5_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_conv (Conv2D)   (None, 4, 4, 128)    143360      conv5_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_concat (Concatena (None, 4, 4, 1152)   0           conv5_block15_concat[0][0]       \n",
      "                                                                 conv5_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_0_bn (BatchNormal (None, 4, 4, 1152)   4608        conv5_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_0_relu (Activatio (None, 4, 4, 1152)   0           conv5_block17_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_1_conv (Conv2D)   (None, 4, 4, 128)    147456      conv5_block17_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_concat (Concatena (None, 4, 4, 1184)   0           conv5_block16_concat[0][0]       \n",
      "                                                                 conv5_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_0_bn (BatchNormal (None, 4, 4, 1184)   4736        conv5_block17_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_0_relu (Activatio (None, 4, 4, 1184)   0           conv5_block18_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_1_conv (Conv2D)   (None, 4, 4, 128)    151552      conv5_block18_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_concat (Concatena (None, 4, 4, 1216)   0           conv5_block17_concat[0][0]       \n",
      "                                                                 conv5_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_0_bn (BatchNormal (None, 4, 4, 1216)   4864        conv5_block18_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_0_relu (Activatio (None, 4, 4, 1216)   0           conv5_block19_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_1_conv (Conv2D)   (None, 4, 4, 128)    155648      conv5_block19_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_concat (Concatena (None, 4, 4, 1248)   0           conv5_block18_concat[0][0]       \n",
      "                                                                 conv5_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_0_bn (BatchNormal (None, 4, 4, 1248)   4992        conv5_block19_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_0_relu (Activatio (None, 4, 4, 1248)   0           conv5_block20_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_1_conv (Conv2D)   (None, 4, 4, 128)    159744      conv5_block20_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_concat (Concatena (None, 4, 4, 1280)   0           conv5_block19_concat[0][0]       \n",
      "                                                                 conv5_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_0_bn (BatchNormal (None, 4, 4, 1280)   5120        conv5_block20_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_0_relu (Activatio (None, 4, 4, 1280)   0           conv5_block21_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_1_conv (Conv2D)   (None, 4, 4, 128)    163840      conv5_block21_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_concat (Concatena (None, 4, 4, 1312)   0           conv5_block20_concat[0][0]       \n",
      "                                                                 conv5_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_0_bn (BatchNormal (None, 4, 4, 1312)   5248        conv5_block21_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_0_relu (Activatio (None, 4, 4, 1312)   0           conv5_block22_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_1_conv (Conv2D)   (None, 4, 4, 128)    167936      conv5_block22_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_concat (Concatena (None, 4, 4, 1344)   0           conv5_block21_concat[0][0]       \n",
      "                                                                 conv5_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_0_bn (BatchNormal (None, 4, 4, 1344)   5376        conv5_block22_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_0_relu (Activatio (None, 4, 4, 1344)   0           conv5_block23_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_1_conv (Conv2D)   (None, 4, 4, 128)    172032      conv5_block23_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_concat (Concatena (None, 4, 4, 1376)   0           conv5_block22_concat[0][0]       \n",
      "                                                                 conv5_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_0_bn (BatchNormal (None, 4, 4, 1376)   5504        conv5_block23_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_0_relu (Activatio (None, 4, 4, 1376)   0           conv5_block24_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_1_conv (Conv2D)   (None, 4, 4, 128)    176128      conv5_block24_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_concat (Concatena (None, 4, 4, 1408)   0           conv5_block23_concat[0][0]       \n",
      "                                                                 conv5_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_0_bn (BatchNormal (None, 4, 4, 1408)   5632        conv5_block24_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_0_relu (Activatio (None, 4, 4, 1408)   0           conv5_block25_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_1_conv (Conv2D)   (None, 4, 4, 128)    180224      conv5_block25_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block25_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block25_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block25_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_concat (Concatena (None, 4, 4, 1440)   0           conv5_block24_concat[0][0]       \n",
      "                                                                 conv5_block25_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_0_bn (BatchNormal (None, 4, 4, 1440)   5760        conv5_block25_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_0_relu (Activatio (None, 4, 4, 1440)   0           conv5_block26_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_1_conv (Conv2D)   (None, 4, 4, 128)    184320      conv5_block26_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block26_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block26_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block26_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_concat (Concatena (None, 4, 4, 1472)   0           conv5_block25_concat[0][0]       \n",
      "                                                                 conv5_block26_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_0_bn (BatchNormal (None, 4, 4, 1472)   5888        conv5_block26_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_0_relu (Activatio (None, 4, 4, 1472)   0           conv5_block27_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_1_conv (Conv2D)   (None, 4, 4, 128)    188416      conv5_block27_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block27_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block27_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block27_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_concat (Concatena (None, 4, 4, 1504)   0           conv5_block26_concat[0][0]       \n",
      "                                                                 conv5_block27_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_0_bn (BatchNormal (None, 4, 4, 1504)   6016        conv5_block27_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_0_relu (Activatio (None, 4, 4, 1504)   0           conv5_block28_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_1_conv (Conv2D)   (None, 4, 4, 128)    192512      conv5_block28_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block28_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block28_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block28_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_concat (Concatena (None, 4, 4, 1536)   0           conv5_block27_concat[0][0]       \n",
      "                                                                 conv5_block28_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_0_bn (BatchNormal (None, 4, 4, 1536)   6144        conv5_block28_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_0_relu (Activatio (None, 4, 4, 1536)   0           conv5_block29_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_1_conv (Conv2D)   (None, 4, 4, 128)    196608      conv5_block29_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block29_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block29_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block29_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_concat (Concatena (None, 4, 4, 1568)   0           conv5_block28_concat[0][0]       \n",
      "                                                                 conv5_block29_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_0_bn (BatchNormal (None, 4, 4, 1568)   6272        conv5_block29_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_0_relu (Activatio (None, 4, 4, 1568)   0           conv5_block30_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_1_conv (Conv2D)   (None, 4, 4, 128)    200704      conv5_block30_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block30_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block30_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block30_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_concat (Concatena (None, 4, 4, 1600)   0           conv5_block29_concat[0][0]       \n",
      "                                                                 conv5_block30_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_0_bn (BatchNormal (None, 4, 4, 1600)   6400        conv5_block30_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_0_relu (Activatio (None, 4, 4, 1600)   0           conv5_block31_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_1_conv (Conv2D)   (None, 4, 4, 128)    204800      conv5_block31_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block31_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block31_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block31_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_concat (Concatena (None, 4, 4, 1632)   0           conv5_block30_concat[0][0]       \n",
      "                                                                 conv5_block31_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_0_bn (BatchNormal (None, 4, 4, 1632)   6528        conv5_block31_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_0_relu (Activatio (None, 4, 4, 1632)   0           conv5_block32_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_1_conv (Conv2D)   (None, 4, 4, 128)    208896      conv5_block32_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block32_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block32_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block32_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_concat (Concatena (None, 4, 4, 1664)   0           conv5_block31_concat[0][0]       \n",
      "                                                                 conv5_block32_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn (BatchNormalization)         (None, 4, 4, 1664)   6656        conv5_block32_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "relu (Activation)               (None, 4, 4, 1664)   0           bn[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 1664)         0           relu[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         1704960     global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 9)            9225        dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 14,385,289\n",
      "Trainable params: 14,226,889\n",
      "Non-trainable params: 158,400\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = models.Sequential()\n",
    "# model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "#                         input_shape=(minimum_len, minimum_len, 12)))\n",
    "# model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "# model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "# model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "# model.add(layers.Flatten())\n",
    "# model.add(layers.Dense(512, activation='relu'))\n",
    "# model.add(layers.Dense(9, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block_feature(sequence_en, minimum_len): \n",
    "    new_en = []\n",
    "    if len(sequence_en) > minimum_len:  #  minimum  \n",
    "        start = random.randint(0,len(sequence_en)-minimum_len)    \n",
    "        new_en = sequence_en[start:start+minimum_len]\n",
    "    elif len(sequence_en) == minimum_len: #  minimum\n",
    "        new_en = sequence_en\n",
    "    else: \n",
    "        assert len(sequence_en) <= minimum_len\n",
    "    return new_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exploratory_look(input_directory,file, class2index):\n",
    "    \n",
    "    classes = []\n",
    "\n",
    "    f = file\n",
    "    g = f.replace('.mat','.hea')\n",
    "    input_file = os.path.join(input_directory,g)\n",
    "    with open(input_file,'r') as f:\n",
    "        for lines in f:\n",
    "            if lines.startswith('#Dx'):\n",
    "                tmp = lines.split(': ')[1].split(',')\n",
    "                print(tmp, len(tmp))\n",
    "    return tmp            \n",
    "\n",
    "for file in input_file_names:\n",
    "    tmp = exploratory_look(input_directory, file, class2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for multi-label subjects\n",
    "def searching_overlap(input_directory,class2index, input_file_names):\n",
    "    multiclasses=[]\n",
    "    multisubjects=[]\n",
    "    number = []\n",
    "    for file in input_file_names:\n",
    "        f=file\n",
    "        g = f.replace('.mat','.hea')\n",
    "        input_file = os.path.join(input_directory,g)\n",
    "        with open(input_file,'r') as f:\n",
    "            for lines in f:\n",
    "                if lines.startswith('#Dx'):\n",
    "                    tmp = lines.split(': ')[1].split(',')\n",
    "                    if len(tmp)>1:\n",
    "                        one_hot_vector = [0]*(len(class2index))\n",
    "                        for c in tmp:\n",
    "                            one_hot_vector = one_hot_encoding(one_hot_vector, c.strip(), class2index)\n",
    "                        multiclasses.append(one_hot_vector)\n",
    "                        multisubjects.append(g)\n",
    "                        number.append(len(tmp))\n",
    "    return multisubjects, multiclasses, number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sub, cls, num = get_labels2(input_directory, class2index, input_file_names)\n",
    "print(len(num)) # number of subjects who have more than two diagnoses\n",
    "print(num.count(2)) # number of subjects who have two diagnoses\n",
    "print(num.count(3)) # number of subjects who have three diagnoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get classes of sorted file names\n",
    "def get_labels(input_directory,file, class2index):\n",
    "    f = file\n",
    "    g = f.replace('.mat','.hea')\n",
    "    input_file = os.path.join(input_directory,g)\n",
    "    with open(input_file,'r') as f:\n",
    "        for lines in f:\n",
    "            if lines.startswith('#Dx'):\n",
    "                tmp = lines.split(': ')[1].split(',')\n",
    "                one_hot_vector = [0]*(len(class2index))\n",
    "                for c in tmp:\n",
    "                    one_hot_vector = one_hot_encoding(one_hot_vector, c.strip(), class2index)\n",
    "                \n",
    "    return one_hot_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 0, 0, 0, 1, 0, 0]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes2=[]\n",
    "for file in input_file_names:\n",
    "    classes = get_labels(input_directory, file, class2index)\n",
    "    classes2.append(classes)\n",
    "classes2[42] # 43th subject has multi-diagnoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randextract_mels(curr_step, batch_size, data_train, mel_directory, class2index, minimum_len): # step = 0, 1, 2, 3....\n",
    "    mel_files = []\n",
    "    classes = []\n",
    "    start = batch_size*curr_step\n",
    "    end = batch_size*(curr_step+1)\n",
    "    curr_file_indices = data_train[start:end]\n",
    "    for file in curr_file_indices:\n",
    "        tmp_file = np.load(mel_directory + '/' + file.replace('.mat', '.npy'))\n",
    "        clip_file = block_feature(tmp_file, minimum_len)\n",
    "        mel_files.append(clip_file)\n",
    "        \n",
    "        label = get_labels(input_directory, file, class2index)\n",
    "        classes.append(label)\n",
    "    return mel_files, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randextract_mels_val(curr_range_start, curr_range_end, data_val, mel_directory, class2index, minimum_len): # step = 0, 1, 2, 3....\n",
    "    mel_files = []\n",
    "    classes = []\n",
    "    curr_file_indices = data_val[int(curr_range_start):int(curr_range_end)]\n",
    "    for file in curr_file_indices:\n",
    "        tmp_file = np.load(mel_directory + '/' + file.replace('.mat', '.npy'))\n",
    "        clip_file = block_feature(tmp_file, minimum_len)\n",
    "        mel_files.append(clip_file)\n",
    "        \n",
    "        label = get_labels(input_directory, file, class2index)\n",
    "        classes.append(label)\n",
    "    return mel_files, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_train, mel_directory, batch_size, class2index, minimum_len): \n",
    "    \n",
    "    loss=[]\n",
    "    acc = []\n",
    "\n",
    "    total_steps = int(np.ceil(len(data_train)/batch_size))\n",
    "    for curr_step in range(total_steps):\n",
    "        batch_mels, batch_labels = randextract_mels(curr_step, batch_size, data_train, mel_directory, class2index, minimum_len)\n",
    "        batch_mels = np.asarray(batch_mels)\n",
    "        batch_labels = np.asarray(np.squeeze(batch_labels))\n",
    "        train_loss_tmp = model.train_on_batch(batch_mels, batch_labels)\n",
    "        loss.append(train_loss_tmp[0])\n",
    "        acc.append(train_loss_tmp[1])\n",
    "\n",
    "    loss = np.mean(np.array(loss))\n",
    "    acc = np.mean(np.array(acc))\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def voting(data, epochs, minimum_len,flag='val', ct=None): # valid     ct  \n",
    "    # 1.  \n",
    "    #2. 128  ( -> np.floor)\n",
    "    #3. model.predict -> logit  (thresholding)\n",
    "    #4.   return (   label )\n",
    "    if flag=='val':\n",
    "        per_epoch = epochs/20 # how many validation sets we need: divide total epochs (1000) by 20\n",
    "        per_val = np.floor(len(data)/per_epoch)\n",
    "        curr_range_start = (ct-1)*per_val\n",
    "        curr_range_end = ct*per_val\n",
    "    elif flag=='test':\n",
    "        curr_range_start = 0\n",
    "        curr_range_end = len(data)\n",
    "    curr_file_indices = data[curr_range_start:curr_range_end]\n",
    "    \n",
    "    for file in curr_file_indices:\n",
    "        tmp_file = np.load(mel_directory + '/' + file.replace('.mat', '.npy'))\n",
    "        steps = np.floor(tmp_file.shape[1]/minimum_len)\n",
    "        for block in range(steps): # 128    predict\n",
    "            start = blocks*minimum_len\n",
    "            end = (blocks+1)*minimum_len - 1\n",
    "            curr_block = tmp_file(start:end)\n",
    "            logit = model.predict(curr_block)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = data_test[1]\n",
    "tmp_file = np.load(mel_directory + '/' + file.replace('.mat', '.npy'))\n",
    "block=0\n",
    "curr_block = tmp_file[0:128]\n",
    "np.shape(curr_block)\n",
    "curr_block = np.expand_dims(curr_block,0)\n",
    "# np.shape(curr_block)\n",
    "logit = model.predict(curr_block)\n",
    "logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans=get_labels(input_directory, file.replace('.mat', '.hea'), class2index)\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(ct, data_val, mel_directory, class2index, minimum_len, epochs): \n",
    "    loss = []\n",
    "    acc = []\n",
    "    \n",
    "    per_epoch = epochs/20 # how many validation sets we need: divide total epochs by 20\n",
    "    per_val = np.floor(len(data_val)/per_epoch)\n",
    "    curr_range_start = (ct-1)*per_val\n",
    "    curr_range_end = ct*per_val\n",
    "    batch_mels, batch_labels = randextract_mels_val(curr_range_start, curr_range_end, data_val, mel_directory, class2index, minimum_len)\n",
    "    batch_mels = np.asarray(batch_mels)\n",
    "    batch_labels = np.asarray(np.squeeze(batch_labels))\n",
    "    val_loss_tmp = model.test_on_batch(batch_mels, batch_labels)\n",
    "    loss.append(val_loss_tmp[0])\n",
    "    acc.append(val_loss_tmp[1])\n",
    "    loss = np.mean(np.array(loss))\n",
    "    acc = np.mean(np.array(acc))\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 train_loss: 0.318 train_acc: 0.884 \t 2020-04-07 05:27:34.298034\n",
      "\n",
      "Epoch 2 train_loss: 0.258 train_acc: 0.906 \t 2020-04-07 05:29:19.679848\n",
      "\n",
      "Epoch 3 train_loss: 0.232 train_acc: 0.915 \t 2020-04-07 05:29:40.668645\n",
      "\n",
      "Epoch 4 train_loss: 0.218 train_acc: 0.920 \t 2020-04-07 05:30:01.654437\n",
      "\n",
      "Epoch 5 train_loss: 0.212 train_acc: 0.922 \t 2020-04-07 05:30:22.671964\n",
      "\n",
      "Epoch 6 train_loss: 0.198 train_acc: 0.926 \t 2020-04-07 05:30:43.734834\n",
      "\n",
      "Epoch 7 train_loss: 0.186 train_acc: 0.931 \t 2020-04-07 05:31:04.813313\n",
      "\n",
      "Epoch 8 train_loss: 0.179 train_acc: 0.932 \t 2020-04-07 05:31:25.876970\n",
      "\n",
      "Epoch 9 train_loss: 0.172 train_acc: 0.936 \t 2020-04-07 05:31:46.960671\n",
      "\n",
      "Epoch 10 train_loss: 0.165 train_acc: 0.938 \t 2020-04-07 05:32:08.077234\n",
      "\n",
      "Epoch 11 train_loss: 0.156 train_acc: 0.942 \t 2020-04-07 05:32:29.141042\n",
      "\n",
      "Epoch 12 train_loss: 0.153 train_acc: 0.943 \t 2020-04-07 05:32:50.226549\n",
      "\n",
      "Epoch 13 train_loss: 0.149 train_acc: 0.945 \t 2020-04-07 05:33:11.332319\n",
      "\n",
      "Epoch 14 train_loss: 0.144 train_acc: 0.945 \t 2020-04-07 05:33:32.427615\n",
      "\n",
      "Epoch 15 train_loss: 0.136 train_acc: 0.948 \t 2020-04-07 05:33:53.532714\n",
      "\n",
      "Epoch 16 train_loss: 0.132 train_acc: 0.950 \t 2020-04-07 05:34:14.635762\n",
      "\n",
      "Epoch 17 train_loss: 0.132 train_acc: 0.951 \t 2020-04-07 05:34:35.774102\n",
      "\n",
      "Epoch 18 train_loss: 0.124 train_acc: 0.953 \t 2020-04-07 05:34:56.847046\n",
      "\n",
      "Epoch 19 train_loss: 0.124 train_acc: 0.954 \t 2020-04-07 05:35:17.962383\n",
      "\n",
      "Validation 1 valid_loss: 0.572 valid_acc: 0.882 \t 2020-04-07 05:35:21.929343\n",
      "\n",
      "Epoch 21 train_loss: 0.112 train_acc: 0.957 \t 2020-04-07 05:35:42.959482\n",
      "\n",
      "Epoch 22 train_loss: 0.112 train_acc: 0.958 \t 2020-04-07 05:36:04.022002\n",
      "\n",
      "Epoch 23 train_loss: 0.106 train_acc: 0.960 \t 2020-04-07 05:36:25.103525\n",
      "\n",
      "Epoch 24 train_loss: 0.100 train_acc: 0.961 \t 2020-04-07 05:36:46.159068\n",
      "\n",
      "Epoch 25 train_loss: 0.098 train_acc: 0.962 \t 2020-04-07 05:37:07.239855\n",
      "\n",
      "Epoch 26 train_loss: 0.092 train_acc: 0.964 \t 2020-04-07 05:37:28.306554\n",
      "\n",
      "Epoch 27 train_loss: 0.087 train_acc: 0.966 \t 2020-04-07 05:37:49.369665\n",
      "\n",
      "Epoch 28 train_loss: 0.091 train_acc: 0.966 \t 2020-04-07 05:38:10.401004\n",
      "\n",
      "Epoch 29 train_loss: 0.084 train_acc: 0.969 \t 2020-04-07 05:38:31.443281\n",
      "\n",
      "Epoch 30 train_loss: 0.080 train_acc: 0.968 \t 2020-04-07 05:38:52.514604\n",
      "\n",
      "Epoch 31 train_loss: 0.077 train_acc: 0.971 \t 2020-04-07 05:39:13.543907\n",
      "\n",
      "Epoch 32 train_loss: 0.070 train_acc: 0.972 \t 2020-04-07 05:39:34.622073\n",
      "\n",
      "Epoch 33 train_loss: 0.068 train_acc: 0.973 \t 2020-04-07 05:39:55.649352\n",
      "\n",
      "Epoch 34 train_loss: 0.067 train_acc: 0.974 \t 2020-04-07 05:40:16.970174\n",
      "\n",
      "Epoch 35 train_loss: 0.062 train_acc: 0.977 \t 2020-04-07 05:40:37.995191\n",
      "\n",
      "Epoch 36 train_loss: 0.061 train_acc: 0.977 \t 2020-04-07 05:40:59.061961\n",
      "\n",
      "Epoch 37 train_loss: 0.059 train_acc: 0.977 \t 2020-04-07 05:41:20.136334\n",
      "\n",
      "Epoch 38 train_loss: 0.056 train_acc: 0.979 \t 2020-04-07 05:41:41.217112\n",
      "\n",
      "Epoch 39 train_loss: 0.052 train_acc: 0.980 \t 2020-04-07 05:42:02.262421\n",
      "\n",
      "Validation 2 valid_loss: 1.117 valid_acc: 0.782 \t 2020-04-07 05:42:03.695581\n",
      "\n",
      "Epoch 41 train_loss: 0.054 train_acc: 0.980 \t 2020-04-07 05:42:24.754897\n",
      "\n",
      "Epoch 42 train_loss: 0.050 train_acc: 0.981 \t 2020-04-07 05:42:45.820264\n",
      "\n",
      "Epoch 43 train_loss: 0.051 train_acc: 0.980 \t 2020-04-07 05:43:06.870552\n",
      "\n",
      "Epoch 44 train_loss: 0.050 train_acc: 0.982 \t 2020-04-07 05:43:27.932899\n",
      "\n",
      "Epoch 45 train_loss: 0.050 train_acc: 0.981 \t 2020-04-07 05:43:49.016022\n",
      "\n",
      "Epoch 46 train_loss: 0.044 train_acc: 0.983 \t 2020-04-07 05:44:10.066129\n",
      "\n",
      "Epoch 47 train_loss: 0.040 train_acc: 0.985 \t 2020-04-07 05:44:31.160711\n",
      "\n",
      "Epoch 48 train_loss: 0.043 train_acc: 0.983 \t 2020-04-07 05:44:52.218069\n",
      "\n",
      "Epoch 49 train_loss: 0.043 train_acc: 0.984 \t 2020-04-07 05:45:13.292863\n",
      "\n",
      "Epoch 50 train_loss: 0.040 train_acc: 0.985 \t 2020-04-07 05:45:34.352900\n",
      "\n",
      "Epoch 51 train_loss: 0.038 train_acc: 0.986 \t 2020-04-07 05:45:55.437208\n",
      "\n",
      "Epoch 52 train_loss: 0.037 train_acc: 0.986 \t 2020-04-07 05:46:16.499563\n",
      "\n",
      "Epoch 53 train_loss: 0.035 train_acc: 0.987 \t 2020-04-07 05:46:37.542284\n",
      "\n",
      "Epoch 54 train_loss: 0.038 train_acc: 0.986 \t 2020-04-07 05:46:58.627385\n",
      "\n",
      "Epoch 55 train_loss: 0.037 train_acc: 0.987 \t 2020-04-07 05:47:19.699178\n",
      "\n",
      "Epoch 56 train_loss: 0.035 train_acc: 0.988 \t 2020-04-07 05:47:40.755338\n",
      "\n",
      "Epoch 57 train_loss: 0.035 train_acc: 0.987 \t 2020-04-07 05:48:01.817654\n",
      "\n",
      "Epoch 58 train_loss: 0.030 train_acc: 0.989 \t 2020-04-07 05:48:22.907144\n",
      "\n",
      "Epoch 59 train_loss: 0.031 train_acc: 0.988 \t 2020-04-07 05:48:43.997730\n",
      "\n",
      "Validation 3 valid_loss: 2.013 valid_acc: 0.788 \t 2020-04-07 05:48:45.343564\n",
      "\n",
      "Epoch 61 train_loss: 0.033 train_acc: 0.988 \t 2020-04-07 05:49:06.405963\n",
      "\n",
      "Epoch 62 train_loss: 0.029 train_acc: 0.989 \t 2020-04-07 05:49:27.499571\n",
      "\n",
      "Epoch 63 train_loss: 0.031 train_acc: 0.989 \t 2020-04-07 05:49:48.536118\n",
      "\n",
      "Epoch 64 train_loss: 0.032 train_acc: 0.989 \t 2020-04-07 05:50:09.597404\n",
      "\n",
      "Epoch 65 train_loss: 0.030 train_acc: 0.989 \t 2020-04-07 05:50:30.673549\n",
      "\n",
      "Epoch 66 train_loss: 0.028 train_acc: 0.989 \t 2020-04-07 05:50:51.727810\n",
      "\n",
      "Epoch 67 train_loss: 0.031 train_acc: 0.989 \t 2020-04-07 05:51:12.815215\n",
      "\n",
      "Epoch 68 train_loss: 0.027 train_acc: 0.990 \t 2020-04-07 05:51:33.869750\n",
      "\n",
      "Epoch 69 train_loss: 0.030 train_acc: 0.990 \t 2020-04-07 05:51:54.938742\n",
      "\n",
      "Epoch 70 train_loss: 0.025 train_acc: 0.991 \t 2020-04-07 05:52:15.986383\n",
      "\n",
      "Epoch 71 train_loss: 0.026 train_acc: 0.991 \t 2020-04-07 05:52:37.068763\n",
      "\n",
      "Epoch 72 train_loss: 0.027 train_acc: 0.990 \t 2020-04-07 05:52:58.172488\n",
      "\n",
      "Epoch 73 train_loss: 0.028 train_acc: 0.990 \t 2020-04-07 05:53:19.279596\n",
      "\n",
      "Epoch 74 train_loss: 0.024 train_acc: 0.991 \t 2020-04-07 05:53:40.365572\n",
      "\n",
      "Epoch 75 train_loss: 0.023 train_acc: 0.992 \t 2020-04-07 05:54:01.456793\n",
      "\n",
      "Epoch 76 train_loss: 0.024 train_acc: 0.992 \t 2020-04-07 05:54:22.541900\n",
      "\n",
      "Epoch 77 train_loss: 0.023 train_acc: 0.992 \t 2020-04-07 05:54:43.603811\n",
      "\n",
      "Epoch 78 train_loss: 0.025 train_acc: 0.992 \t 2020-04-07 05:55:04.673418\n",
      "\n",
      "Epoch 79 train_loss: 0.025 train_acc: 0.992 \t 2020-04-07 05:55:25.759827\n",
      "\n",
      "Validation 4 valid_loss: 1.969 valid_acc: 0.797 \t 2020-04-07 05:55:27.082545\n",
      "\n",
      "Epoch 81 train_loss: 0.023 train_acc: 0.992 \t 2020-04-07 05:55:48.166594\n",
      "\n",
      "Epoch 82 train_loss: 0.024 train_acc: 0.992 \t 2020-04-07 05:56:09.253369\n",
      "\n",
      "Epoch 83 train_loss: 0.023 train_acc: 0.992 \t 2020-04-07 05:56:30.343288\n",
      "\n",
      "Epoch 84 train_loss: 0.022 train_acc: 0.992 \t 2020-04-07 05:56:51.428994\n",
      "\n",
      "Epoch 85 train_loss: 0.022 train_acc: 0.992 \t 2020-04-07 05:57:12.511938\n",
      "\n",
      "Epoch 86 train_loss: 0.019 train_acc: 0.994 \t 2020-04-07 05:57:33.589138\n",
      "\n",
      "Epoch 87 train_loss: 0.022 train_acc: 0.992 \t 2020-04-07 05:57:54.668079\n",
      "\n",
      "Epoch 88 train_loss: 0.020 train_acc: 0.993 \t 2020-04-07 05:58:15.737746\n",
      "\n",
      "Epoch 89 train_loss: 0.022 train_acc: 0.992 \t 2020-04-07 05:58:36.806126\n",
      "\n",
      "Epoch 90 train_loss: 0.024 train_acc: 0.992 \t 2020-04-07 05:58:57.897902\n",
      "\n",
      "Epoch 91 train_loss: 0.022 train_acc: 0.992 \t 2020-04-07 05:59:18.988540\n",
      "\n",
      "Epoch 92 train_loss: 0.023 train_acc: 0.992 \t 2020-04-07 05:59:40.063069\n",
      "\n",
      "Epoch 93 train_loss: 0.020 train_acc: 0.994 \t 2020-04-07 06:00:01.164415\n",
      "\n",
      "Epoch 94 train_loss: 0.019 train_acc: 0.994 \t 2020-04-07 06:00:22.260190\n",
      "\n",
      "Epoch 95 train_loss: 0.024 train_acc: 0.992 \t 2020-04-07 06:00:43.365538\n",
      "\n",
      "Epoch 96 train_loss: 0.017 train_acc: 0.995 \t 2020-04-07 06:01:04.438742\n",
      "\n",
      "Epoch 97 train_loss: 0.021 train_acc: 0.993 \t 2020-04-07 06:01:25.547342\n",
      "\n",
      "Epoch 98 train_loss: 0.022 train_acc: 0.993 \t 2020-04-07 06:01:46.632368\n",
      "\n",
      "Epoch 99 train_loss: 0.017 train_acc: 0.994 \t 2020-04-07 06:02:07.733028\n",
      "\n",
      "Validation 5 valid_loss: 1.250 valid_acc: 0.783 \t 2020-04-07 06:02:09.115118\n",
      "\n",
      "Epoch 101 train_loss: 0.017 train_acc: 0.994 \t 2020-04-07 06:02:30.204522\n",
      "\n",
      "Epoch 102 train_loss: 0.016 train_acc: 0.995 \t 2020-04-07 06:02:51.296465\n",
      "\n",
      "Epoch 103 train_loss: 0.022 train_acc: 0.993 \t 2020-04-07 06:03:12.374640\n",
      "\n",
      "Epoch 104 train_loss: 0.020 train_acc: 0.993 \t 2020-04-07 06:03:33.458152\n",
      "\n",
      "Epoch 105 train_loss: 0.016 train_acc: 0.994 \t 2020-04-07 06:03:54.549825\n",
      "\n",
      "Epoch 106 train_loss: 0.021 train_acc: 0.993 \t 2020-04-07 06:04:15.623447\n",
      "\n",
      "Epoch 107 train_loss: 0.016 train_acc: 0.995 \t 2020-04-07 06:04:36.726215\n",
      "\n",
      "Epoch 108 train_loss: 0.016 train_acc: 0.995 \t 2020-04-07 06:04:57.822772\n",
      "\n",
      "Epoch 109 train_loss: 0.017 train_acc: 0.994 \t 2020-04-07 06:05:18.901233\n",
      "\n",
      "Epoch 110 train_loss: 0.016 train_acc: 0.995 \t 2020-04-07 06:05:39.977522\n",
      "\n",
      "Epoch 111 train_loss: 0.020 train_acc: 0.993 \t 2020-04-07 06:06:01.077113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 112 train_loss: 0.017 train_acc: 0.995 \t 2020-04-07 06:06:22.156086\n",
      "\n",
      "Epoch 113 train_loss: 0.017 train_acc: 0.994 \t 2020-04-07 06:06:43.226129\n",
      "\n",
      "Epoch 114 train_loss: 0.018 train_acc: 0.994 \t 2020-04-07 06:07:04.357867\n",
      "\n",
      "Epoch 115 train_loss: 0.016 train_acc: 0.994 \t 2020-04-07 06:07:25.447972\n",
      "\n",
      "Epoch 116 train_loss: 0.017 train_acc: 0.994 \t 2020-04-07 06:07:46.567486\n",
      "\n",
      "Epoch 117 train_loss: 0.020 train_acc: 0.993 \t 2020-04-07 06:08:07.642720\n",
      "\n",
      "Epoch 118 train_loss: 0.015 train_acc: 0.995 \t 2020-04-07 06:08:28.724114\n",
      "\n",
      "Epoch 119 train_loss: 0.016 train_acc: 0.995 \t 2020-04-07 06:08:49.794143\n",
      "\n",
      "Validation 6 valid_loss: 1.050 valid_acc: 0.875 \t 2020-04-07 06:08:51.206145\n",
      "\n",
      "Epoch 121 train_loss: 0.015 train_acc: 0.995 \t 2020-04-07 06:09:12.266997\n",
      "\n",
      "Epoch 122 train_loss: 0.014 train_acc: 0.995 \t 2020-04-07 06:09:33.338591\n",
      "\n",
      "Epoch 123 train_loss: 0.015 train_acc: 0.995 \t 2020-04-07 06:09:54.416872\n",
      "\n",
      "Epoch 124 train_loss: 0.015 train_acc: 0.995 \t 2020-04-07 06:10:15.470977\n",
      "\n",
      "Epoch 125 train_loss: 0.018 train_acc: 0.994 \t 2020-04-07 06:10:36.586305\n",
      "\n",
      "Epoch 126 train_loss: 0.013 train_acc: 0.996 \t 2020-04-07 06:10:57.663956\n",
      "\n",
      "Epoch 127 train_loss: 0.014 train_acc: 0.995 \t 2020-04-07 06:11:18.773142\n",
      "\n",
      "Epoch 128 train_loss: 0.014 train_acc: 0.996 \t 2020-04-07 06:11:39.858825\n",
      "\n",
      "Epoch 129 train_loss: 0.015 train_acc: 0.995 \t 2020-04-07 06:12:00.930988\n",
      "\n",
      "Epoch 130 train_loss: 0.015 train_acc: 0.995 \t 2020-04-07 06:12:22.055274\n",
      "\n",
      "Epoch 131 train_loss: 0.014 train_acc: 0.996 \t 2020-04-07 06:12:43.141314\n",
      "\n",
      "Epoch 132 train_loss: 0.015 train_acc: 0.995 \t 2020-04-07 06:13:04.224884\n",
      "\n",
      "Epoch 133 train_loss: 0.018 train_acc: 0.994 \t 2020-04-07 06:13:25.299168\n",
      "\n",
      "Epoch 134 train_loss: 0.014 train_acc: 0.995 \t 2020-04-07 06:13:46.364526\n",
      "\n",
      "Epoch 135 train_loss: 0.017 train_acc: 0.995 \t 2020-04-07 06:14:07.478447\n",
      "\n",
      "Epoch 136 train_loss: 0.014 train_acc: 0.996 \t 2020-04-07 06:14:30.093611\n",
      "\n",
      "Epoch 137 train_loss: 0.016 train_acc: 0.995 \t 2020-04-07 06:14:53.448005\n",
      "\n",
      "Epoch 138 train_loss: 0.016 train_acc: 0.995 \t 2020-04-07 06:15:14.627389\n",
      "\n",
      "Epoch 139 train_loss: 0.015 train_acc: 0.995 \t 2020-04-07 06:15:35.790597\n",
      "\n",
      "Validation 7 valid_loss: 0.928 valid_acc: 0.877 \t 2020-04-07 06:15:37.153605\n",
      "\n",
      "Epoch 141 train_loss: 0.013 train_acc: 0.996 \t 2020-04-07 06:15:58.328367\n",
      "\n",
      "Epoch 142 train_loss: 0.012 train_acc: 0.996 \t 2020-04-07 06:16:19.504767\n",
      "\n",
      "Epoch 143 train_loss: 0.016 train_acc: 0.994 \t 2020-04-07 06:16:40.676748\n",
      "\n",
      "Epoch 144 train_loss: 0.018 train_acc: 0.995 \t 2020-04-07 06:17:01.859485\n",
      "\n",
      "Epoch 145 train_loss: 0.012 train_acc: 0.996 \t 2020-04-07 06:17:23.014800\n",
      "\n",
      "Epoch 146 train_loss: 0.010 train_acc: 0.997 \t 2020-04-07 06:17:44.169354\n",
      "\n",
      "Epoch 147 train_loss: 0.014 train_acc: 0.996 \t 2020-04-07 06:18:05.375562\n",
      "\n",
      "Epoch 148 train_loss: 0.012 train_acc: 0.996 \t 2020-04-07 06:18:26.564269\n",
      "\n",
      "Epoch 149 train_loss: 0.016 train_acc: 0.995 \t 2020-04-07 06:18:47.742307\n",
      "\n",
      "Epoch 150 train_loss: 0.011 train_acc: 0.996 \t 2020-04-07 06:19:08.942218\n",
      "\n",
      "Epoch 151 train_loss: 0.011 train_acc: 0.996 \t 2020-04-07 06:19:30.107210\n",
      "\n",
      "Epoch 152 train_loss: 0.014 train_acc: 0.996 \t 2020-04-07 06:19:51.330405\n",
      "\n",
      "Epoch 153 train_loss: 0.012 train_acc: 0.996 \t 2020-04-07 06:20:12.488666\n",
      "\n",
      "Epoch 154 train_loss: 0.010 train_acc: 0.996 \t 2020-04-07 06:20:33.638574\n",
      "\n",
      "Epoch 155 train_loss: 0.013 train_acc: 0.996 \t 2020-04-07 06:20:54.785779\n",
      "\n",
      "Epoch 156 train_loss: 0.012 train_acc: 0.996 \t 2020-04-07 06:21:15.957964\n",
      "\n",
      "Epoch 157 train_loss: 0.011 train_acc: 0.997 \t 2020-04-07 06:21:37.151518\n",
      "\n",
      "Epoch 158 train_loss: 0.011 train_acc: 0.997 \t 2020-04-07 06:21:58.340716\n",
      "\n",
      "Epoch 159 train_loss: 0.009 train_acc: 0.997 \t 2020-04-07 06:22:19.508246\n",
      "\n",
      "Validation 8 valid_loss: 0.649 valid_acc: 0.874 \t 2020-04-07 06:22:20.894782\n",
      "\n",
      "Epoch 161 train_loss: 0.011 train_acc: 0.996 \t 2020-04-07 06:22:42.072291\n",
      "\n",
      "Epoch 162 train_loss: 0.015 train_acc: 0.996 \t 2020-04-07 06:23:03.234406\n",
      "\n",
      "Epoch 163 train_loss: 0.013 train_acc: 0.996 \t 2020-04-07 06:23:24.417971\n",
      "\n",
      "Epoch 164 train_loss: 0.011 train_acc: 0.996 \t 2020-04-07 06:23:45.557292\n",
      "\n",
      "Epoch 165 train_loss: 0.011 train_acc: 0.997 \t 2020-04-07 06:24:06.710053\n",
      "\n",
      "Epoch 166 train_loss: 0.008 train_acc: 0.997 \t 2020-04-07 06:24:27.831128\n",
      "\n",
      "Epoch 167 train_loss: 0.012 train_acc: 0.996 \t 2020-04-07 06:24:48.991533\n",
      "\n",
      "Epoch 168 train_loss: 0.012 train_acc: 0.996 \t 2020-04-07 06:25:10.113613\n",
      "\n",
      "Epoch 169 train_loss: 0.009 train_acc: 0.997 \t 2020-04-07 06:25:31.196154\n",
      "\n",
      "Epoch 170 train_loss: 0.015 train_acc: 0.996 \t 2020-04-07 06:25:52.295404\n",
      "\n",
      "Epoch 171 train_loss: 0.011 train_acc: 0.996 \t 2020-04-07 06:26:13.382989\n",
      "\n",
      "Epoch 172 train_loss: 0.009 train_acc: 0.997 \t 2020-04-07 06:26:34.475639\n",
      "\n",
      "Epoch 173 train_loss: 0.014 train_acc: 0.996 \t 2020-04-07 06:26:55.540053\n",
      "\n",
      "Epoch 174 train_loss: 0.011 train_acc: 0.996 \t 2020-04-07 06:27:16.634213\n",
      "\n",
      "Epoch 175 train_loss: 0.010 train_acc: 0.997 \t 2020-04-07 06:27:37.687310\n",
      "\n",
      "Epoch 176 train_loss: 0.012 train_acc: 0.996 \t 2020-04-07 06:27:58.775170\n",
      "\n",
      "Epoch 177 train_loss: 0.013 train_acc: 0.996 \t 2020-04-07 06:28:19.879596\n",
      "\n",
      "Epoch 178 train_loss: 0.008 train_acc: 0.997 \t 2020-04-07 06:28:40.950029\n",
      "\n",
      "Epoch 179 train_loss: 0.013 train_acc: 0.996 \t 2020-04-07 06:29:02.065448\n",
      "\n",
      "Validation 9 valid_loss: 1.357 valid_acc: 0.882 \t 2020-04-07 06:29:03.419211\n",
      "\n",
      "Epoch 181 train_loss: 0.014 train_acc: 0.995 \t 2020-04-07 06:29:24.743137\n",
      "\n",
      "Epoch 182 train_loss: 0.010 train_acc: 0.997 \t 2020-04-07 06:29:45.799257\n",
      "\n",
      "Epoch 183 train_loss: 0.008 train_acc: 0.997 \t 2020-04-07 06:30:06.872318\n",
      "\n",
      "Epoch 184 train_loss: 0.014 train_acc: 0.996 \t 2020-04-07 06:30:27.987664\n",
      "\n",
      "Epoch 185 train_loss: 0.013 train_acc: 0.996 \t 2020-04-07 06:30:49.079290\n",
      "\n",
      "Epoch 186 train_loss: 0.009 train_acc: 0.997 \t 2020-04-07 06:31:10.120653\n",
      "\n",
      "Epoch 187 train_loss: 0.008 train_acc: 0.998 \t 2020-04-07 06:31:31.193838\n",
      "\n",
      "Epoch 188 train_loss: 0.014 train_acc: 0.995 \t 2020-04-07 06:31:52.306064\n",
      "\n",
      "Epoch 189 train_loss: 0.008 train_acc: 0.998 \t 2020-04-07 06:32:13.380142\n",
      "\n",
      "Epoch 190 train_loss: 0.009 train_acc: 0.997 \t 2020-04-07 06:32:34.463229\n",
      "\n",
      "Epoch 191 train_loss: 0.009 train_acc: 0.997 \t 2020-04-07 06:32:55.539226\n",
      "\n",
      "Epoch 192 train_loss: 0.008 train_acc: 0.998 \t 2020-04-07 06:33:16.632622\n",
      "\n",
      "Epoch 193 train_loss: 0.009 train_acc: 0.997 \t 2020-04-07 06:33:37.724093\n",
      "\n",
      "Epoch 194 train_loss: 0.008 train_acc: 0.998 \t 2020-04-07 06:33:58.796207\n",
      "\n",
      "Epoch 195 train_loss: 0.011 train_acc: 0.997 \t 2020-04-07 06:34:19.890272\n",
      "\n",
      "Epoch 196 train_loss: 0.012 train_acc: 0.996 \t 2020-04-07 06:34:40.992651\n",
      "\n",
      "Epoch 197 train_loss: 0.011 train_acc: 0.997 \t 2020-04-07 06:35:02.055200\n",
      "\n",
      "Epoch 198 train_loss: 0.009 train_acc: 0.997 \t 2020-04-07 06:35:23.148548\n",
      "\n",
      "Epoch 199 train_loss: 0.006 train_acc: 0.998 \t 2020-04-07 06:35:44.234267\n",
      "\n",
      "Validation 10 valid_loss: 1.851 valid_acc: 0.783 \t 2020-04-07 06:35:45.617162\n"
     ]
    }
   ],
   "source": [
    "ct = 0\n",
    "val_loss_sum = []\n",
    "val_acc_sum=[]\n",
    "train_loss_sum=[]\n",
    "train_acc_sum=[]\n",
    "for num_epoch in range(epochs):\n",
    "    if (num_epoch+1)%20 == 0: # Validation for every 20 epochs\n",
    "        ct += 1\n",
    "        val_loss, val_acc = validation(ct,data_val, mel_directory, class2index, minimum_len, epochs)\n",
    "        print('\\nValidation', int((num_epoch+1)/20),'valid_loss:',f'{val_loss:.3f}', 'valid_acc:',f'{val_acc:.3f}',\"\\t\", dt.datetime.now())\n",
    "        val_loss_sum.append(val_loss)\n",
    "        val_acc_sum.append(val_acc)\n",
    "    else: \n",
    "        train_loss, train_acc = train(data_train, mel_directory, batch_size, class2index, minimum_len)\n",
    "        print('\\nEpoch',num_epoch+1,'train_loss:',f'{train_loss:.3f}','train_acc:',f'{train_acc:.3f}',\"\\t\", dt.datetime.now())\n",
    "        train_loss_sum.append(train_loss)\n",
    "        train_acc_sum.append(train_acc)\n",
    "    model.save('MEL.h5')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(int((num_epoch+1)/20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, test with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(data_test, mel_directory, class2index, minimum_len): \n",
    "    \n",
    "    metrics = []\n",
    "    batch_mels, batch_labels = randextract_mels_val(0, len(data_test)-1, data_val, mel_directory, class2index, minimum_len)\n",
    "    # although rendextract_mels_val, you can use the same function fpr test\n",
    "    batch_mels = np.asarray(batch_mels)\n",
    "    batch_labels = np.asarray(np.squeeze(batch_labels))\n",
    "    test_loss_tmp = model.test_on_batch(batch_mels, batch_labels)\n",
    "    loss = test_loss_tmp[0]\n",
    "    acc = test_loss_tmp[1]\n",
    "#     metrics.append(test_loss_tmp)\n",
    "\n",
    "#     metrics = np.mean(np.array(metrics))\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = test(data_test, mel_directory, class2index, minimum_len)\n",
    "print('\\nTest result: loss:',f'{test_metrics[0]:.3f}','accuracy:', f'{test_metrics[1]:.3f}',\"\\t\", dt.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(\n",
    "#       mel_files, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras import optimizers\n",
    "# model.compile(loss='categorical_crossentropy',\n",
    "#               optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "#               metrics=['acc'])\n",
    "# nepochs=1000\n",
    "# model.fit(x_train, y_train, batch_size=batch_size, epochs=nepochs, validation_data=(x_val, y_val), verbose=2)\n",
    "# model.save('ECG1.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 481,
   "position": {
    "height": "503px",
    "left": "1534px",
    "right": "20px",
    "top": "258px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
