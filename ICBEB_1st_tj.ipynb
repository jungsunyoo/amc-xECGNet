{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.24290386e-03 -4.58280585e-05  4.31697309e-03 -3.00174693e-03\n",
      " -2.36609229e-04  1.28997408e-03  2.17347589e-04 -7.99152384e-04\n",
      " -3.42993744e-03 -1.69711686e-03  1.27138164e-03  1.94670545e-03]\n",
      "(3840,) (1280,) (1281,)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, 2880, 12)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_1 (GaussianNoise (None, 2880, 1)      0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_2 (GaussianNoise (None, 2880, 1)      0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_3 (GaussianNoise (None, 2880, 1)      0           lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_4 (GaussianNoise (None, 2880, 1)      0           lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_5 (GaussianNoise (None, 2880, 1)      0           lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_6 (GaussianNoise (None, 2880, 1)      0           lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_7 (GaussianNoise (None, 2880, 1)      0           lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_8 (GaussianNoise (None, 2880, 1)      0           lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_9 (GaussianNoise (None, 2880, 1)      0           lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_10 (GaussianNois (None, 2880, 1)      0           lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_11 (GaussianNois (None, 2880, 1)      0           lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_12 (GaussianNois (None, 2880, 1)      0           lambda_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 2880, 32)     352         gaussian_noise_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 2880, 32)     352         gaussian_noise_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 2880, 32)     352         gaussian_noise_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 2880, 32)     352         gaussian_noise_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 2880, 32)     352         gaussian_noise_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_46 (Conv1D)              (None, 2880, 32)     352         gaussian_noise_6[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_55 (Conv1D)              (None, 2880, 32)     352         gaussian_noise_7[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_64 (Conv1D)              (None, 2880, 32)     352         gaussian_noise_8[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_73 (Conv1D)              (None, 2880, 32)     352         gaussian_noise_9[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_82 (Conv1D)              (None, 2880, 32)     352         gaussian_noise_10[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_91 (Conv1D)              (None, 2880, 32)     352         gaussian_noise_11[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_100 (Conv1D)             (None, 2880, 32)     352         gaussian_noise_12[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 2880, 32)     128         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 2880, 32)     128         conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 2880, 32)     128         conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 2880, 32)     128         conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 2880, 32)     128         conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 2880, 32)     128         conv1d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 2880, 32)     128         conv1d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 2880, 32)     128         conv1d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 2880, 32)     128         conv1d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 2880, 32)     128         conv1d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 2880, 32)     128         conv1d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 2880, 32)     128         conv1d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 2880, 32)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 2880, 32)     0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_33 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_41 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_49 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_57 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_65 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_73 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_81 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_89 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 2880, 32)     10272       leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 2880, 32)     10272       leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 2880, 32)     10272       leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 2880, 32)     10272       leaky_re_lu_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, 2880, 32)     10272       leaky_re_lu_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_47 (Conv1D)              (None, 2880, 32)     10272       leaky_re_lu_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_56 (Conv1D)              (None, 2880, 32)     10272       leaky_re_lu_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_65 (Conv1D)              (None, 2880, 32)     10272       leaky_re_lu_57[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_74 (Conv1D)              (None, 2880, 32)     10272       leaky_re_lu_65[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_83 (Conv1D)              (None, 2880, 32)     10272       leaky_re_lu_73[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_92 (Conv1D)              (None, 2880, 32)     10272       leaky_re_lu_81[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_101 (Conv1D)             (None, 2880, 32)     10272       leaky_re_lu_89[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 2880, 32)     0           conv1d_2[0][0]                   \n",
      "                                                                 leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 2880, 32)     0           conv1d_11[0][0]                  \n",
      "                                                                 leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 2880, 32)     0           conv1d_20[0][0]                  \n",
      "                                                                 leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 2880, 32)     0           conv1d_29[0][0]                  \n",
      "                                                                 leaky_re_lu_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 2880, 32)     0           conv1d_38[0][0]                  \n",
      "                                                                 leaky_re_lu_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 2880, 32)     0           conv1d_47[0][0]                  \n",
      "                                                                 leaky_re_lu_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 2880, 32)     0           conv1d_56[0][0]                  \n",
      "                                                                 leaky_re_lu_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 2880, 32)     0           conv1d_65[0][0]                  \n",
      "                                                                 leaky_re_lu_57[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 2880, 32)     0           conv1d_74[0][0]                  \n",
      "                                                                 leaky_re_lu_65[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 2880, 32)     0           conv1d_83[0][0]                  \n",
      "                                                                 leaky_re_lu_73[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 2880, 32)     0           conv1d_92[0][0]                  \n",
      "                                                                 leaky_re_lu_81[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_34 (Add)                    (None, 2880, 32)     0           conv1d_101[0][0]                 \n",
      "                                                                 leaky_re_lu_89[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 2880, 32)     128         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 2880, 32)     128         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 2880, 32)     128         add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 2880, 32)     128         add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 2880, 32)     128         add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 2880, 32)     128         add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 2880, 32)     128         add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 2880, 32)     128         add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 2880, 32)     128         add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 2880, 32)     128         add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 2880, 32)     128         add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 2880, 32)     128         add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 2880, 32)     0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_26 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_34 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_42 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_50 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_58 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_66 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_74 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_82 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_90 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 1440, 32)     20512       leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 1440, 32)     20512       leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 1440, 32)     20512       leaky_re_lu_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 1440, 32)     20512       leaky_re_lu_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_39 (Conv1D)              (None, 1440, 32)     20512       leaky_re_lu_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_48 (Conv1D)              (None, 1440, 32)     20512       leaky_re_lu_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_57 (Conv1D)              (None, 1440, 32)     20512       leaky_re_lu_50[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_66 (Conv1D)              (None, 1440, 32)     20512       leaky_re_lu_58[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_75 (Conv1D)              (None, 1440, 32)     20512       leaky_re_lu_66[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_84 (Conv1D)              (None, 1440, 32)     20512       leaky_re_lu_74[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_93 (Conv1D)              (None, 1440, 32)     20512       leaky_re_lu_82[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_102 (Conv1D)             (None, 1440, 32)     20512       leaky_re_lu_90[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 1440, 64)     20544       conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 1440, 64)     20544       conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 1440, 64)     20544       conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, 1440, 64)     20544       conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_40 (Conv1D)              (None, 1440, 64)     20544       conv1d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_49 (Conv1D)              (None, 1440, 64)     20544       conv1d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_58 (Conv1D)              (None, 1440, 64)     20544       conv1d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_67 (Conv1D)              (None, 1440, 64)     20544       conv1d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_76 (Conv1D)              (None, 1440, 64)     20544       conv1d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_85 (Conv1D)              (None, 1440, 64)     20544       conv1d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_94 (Conv1D)              (None, 1440, 64)     20544       conv1d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_103 (Conv1D)             (None, 1440, 64)     20544       conv1d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1440, 64)     256         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 1440, 64)     256         conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 1440, 64)     256         conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 1440, 64)     256         conv1d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 1440, 64)     256         conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 1440, 64)     256         conv1d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 1440, 64)     256         conv1d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 1440, 64)     256         conv1d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 1440, 64)     256         conv1d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 1440, 64)     256         conv1d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 1440, 64)     256         conv1d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 1440, 64)     256         conv1d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 1440, 64)     0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_27 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_35 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_43 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_51 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_59 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_67 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_75 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_83 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_91 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 1440, 64)     41024       leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 1440, 64)     41024       leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 1440, 64)     41024       leaky_re_lu_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 1440, 64)     41024       leaky_re_lu_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_41 (Conv1D)              (None, 1440, 64)     41024       leaky_re_lu_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_50 (Conv1D)              (None, 1440, 64)     41024       leaky_re_lu_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_59 (Conv1D)              (None, 1440, 64)     41024       leaky_re_lu_51[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_68 (Conv1D)              (None, 1440, 64)     41024       leaky_re_lu_59[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_77 (Conv1D)              (None, 1440, 64)     41024       leaky_re_lu_67[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_86 (Conv1D)              (None, 1440, 64)     41024       leaky_re_lu_75[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_95 (Conv1D)              (None, 1440, 64)     41024       leaky_re_lu_83[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_104 (Conv1D)             (None, 1440, 64)     41024       leaky_re_lu_91[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 1440, 64)     0           conv1d_5[0][0]                   \n",
      "                                                                 leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 1440, 64)     0           conv1d_14[0][0]                  \n",
      "                                                                 leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 1440, 64)     0           conv1d_23[0][0]                  \n",
      "                                                                 leaky_re_lu_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 1440, 64)     0           conv1d_32[0][0]                  \n",
      "                                                                 leaky_re_lu_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 1440, 64)     0           conv1d_41[0][0]                  \n",
      "                                                                 leaky_re_lu_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 1440, 64)     0           conv1d_50[0][0]                  \n",
      "                                                                 leaky_re_lu_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 1440, 64)     0           conv1d_59[0][0]                  \n",
      "                                                                 leaky_re_lu_51[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 1440, 64)     0           conv1d_68[0][0]                  \n",
      "                                                                 leaky_re_lu_59[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 1440, 64)     0           conv1d_77[0][0]                  \n",
      "                                                                 leaky_re_lu_67[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 1440, 64)     0           conv1d_86[0][0]                  \n",
      "                                                                 leaky_re_lu_75[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 1440, 64)     0           conv1d_95[0][0]                  \n",
      "                                                                 leaky_re_lu_83[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_35 (Add)                    (None, 1440, 64)     0           conv1d_104[0][0]                 \n",
      "                                                                 leaky_re_lu_91[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 1440, 64)     256         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 1440, 64)     256         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 1440, 64)     256         add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 1440, 64)     256         add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 1440, 64)     256         add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 1440, 64)     256         add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 1440, 64)     256         add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 1440, 64)     256         add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 1440, 64)     256         add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 1440, 64)     256         add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 1440, 64)     256         add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 1440, 64)     256         add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 1440, 64)     0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_28 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_36 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_44 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_52 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_60 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_68 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_76 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_84 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_92 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 720, 32)      40992       leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 720, 32)      40992       leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 720, 32)      40992       leaky_re_lu_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 720, 32)      40992       leaky_re_lu_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_42 (Conv1D)              (None, 720, 32)      40992       leaky_re_lu_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_51 (Conv1D)              (None, 720, 32)      40992       leaky_re_lu_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_60 (Conv1D)              (None, 720, 32)      40992       leaky_re_lu_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_69 (Conv1D)              (None, 720, 32)      40992       leaky_re_lu_60[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_78 (Conv1D)              (None, 720, 32)      40992       leaky_re_lu_68[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_87 (Conv1D)              (None, 720, 32)      40992       leaky_re_lu_76[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_96 (Conv1D)              (None, 720, 32)      40992       leaky_re_lu_84[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_105 (Conv1D)             (None, 720, 32)      40992       leaky_re_lu_92[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 720, 128)     41088       conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 720, 128)     41088       conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 720, 128)     41088       conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 720, 128)     41088       conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_43 (Conv1D)              (None, 720, 128)     41088       conv1d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_52 (Conv1D)              (None, 720, 128)     41088       conv1d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_61 (Conv1D)              (None, 720, 128)     41088       conv1d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_70 (Conv1D)              (None, 720, 128)     41088       conv1d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_79 (Conv1D)              (None, 720, 128)     41088       conv1d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_88 (Conv1D)              (None, 720, 128)     41088       conv1d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_97 (Conv1D)              (None, 720, 128)     41088       conv1d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_106 (Conv1D)             (None, 720, 128)     41088       conv1d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 720, 128)     512         conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 720, 128)     512         conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 720, 128)     512         conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 720, 128)     512         conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 720, 128)     512         conv1d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 720, 128)     512         conv1d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 720, 128)     512         conv1d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 720, 128)     512         conv1d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 720, 128)     512         conv1d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 720, 128)     512         conv1d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 720, 128)     512         conv1d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 720, 128)     512         conv1d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 720, 128)     0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_29 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_37 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_45 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_53 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_61 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_69 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_77 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_85 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_93 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 720, 128)     163968      leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 720, 128)     163968      leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 720, 128)     163968      leaky_re_lu_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 720, 128)     163968      leaky_re_lu_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_44 (Conv1D)              (None, 720, 128)     163968      leaky_re_lu_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_53 (Conv1D)              (None, 720, 128)     163968      leaky_re_lu_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_62 (Conv1D)              (None, 720, 128)     163968      leaky_re_lu_53[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_71 (Conv1D)              (None, 720, 128)     163968      leaky_re_lu_61[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_80 (Conv1D)              (None, 720, 128)     163968      leaky_re_lu_69[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_89 (Conv1D)              (None, 720, 128)     163968      leaky_re_lu_77[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_98 (Conv1D)              (None, 720, 128)     163968      leaky_re_lu_85[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_107 (Conv1D)             (None, 720, 128)     163968      leaky_re_lu_93[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 720, 128)     0           conv1d_8[0][0]                   \n",
      "                                                                 leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 720, 128)     0           conv1d_17[0][0]                  \n",
      "                                                                 leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 720, 128)     0           conv1d_26[0][0]                  \n",
      "                                                                 leaky_re_lu_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 720, 128)     0           conv1d_35[0][0]                  \n",
      "                                                                 leaky_re_lu_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 720, 128)     0           conv1d_44[0][0]                  \n",
      "                                                                 leaky_re_lu_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 720, 128)     0           conv1d_53[0][0]                  \n",
      "                                                                 leaky_re_lu_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 720, 128)     0           conv1d_62[0][0]                  \n",
      "                                                                 leaky_re_lu_53[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 720, 128)     0           conv1d_71[0][0]                  \n",
      "                                                                 leaky_re_lu_61[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 720, 128)     0           conv1d_80[0][0]                  \n",
      "                                                                 leaky_re_lu_69[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 720, 128)     0           conv1d_89[0][0]                  \n",
      "                                                                 leaky_re_lu_77[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_33 (Add)                    (None, 720, 128)     0           conv1d_98[0][0]                  \n",
      "                                                                 leaky_re_lu_85[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_36 (Add)                    (None, 720, 128)     0           conv1d_107[0][0]                 \n",
      "                                                                 leaky_re_lu_93[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 720, 128)     512         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 720, 128)     512         add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 720, 128)     512         add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 720, 128)     512         add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 720, 128)     512         add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 720, 128)     512         add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 720, 128)     512         add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 720, 128)     512         add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 720, 128)     512         add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 720, 128)     512         add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 720, 128)     512         add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 720, 128)     512         add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 720, 128)     0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_30 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_38 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_46 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_54 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_62 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_70 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_78 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_86 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_94 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 360, 64)      163904      leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 360, 64)      163904      leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 360, 64)      163904      leaky_re_lu_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, 360, 64)      163904      leaky_re_lu_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_45 (Conv1D)              (None, 360, 64)      163904      leaky_re_lu_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_54 (Conv1D)              (None, 360, 64)      163904      leaky_re_lu_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_63 (Conv1D)              (None, 360, 64)      163904      leaky_re_lu_54[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_72 (Conv1D)              (None, 360, 64)      163904      leaky_re_lu_62[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_81 (Conv1D)              (None, 360, 64)      163904      leaky_re_lu_70[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_90 (Conv1D)              (None, 360, 64)      163904      leaky_re_lu_78[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_99 (Conv1D)              (None, 360, 64)      163904      leaky_re_lu_86[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_108 (Conv1D)             (None, 360, 64)      163904      leaky_re_lu_94[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 360, 256)     148992      conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 360, 256)     148992      conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 360, 256)     148992      conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 360, 256)     148992      conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 360, 256)     148992      conv1d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, 360, 256)     148992      conv1d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, 360, 256)     148992      conv1d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, 360, 256)     148992      conv1d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, 360, 256)     148992      conv1d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, 360, 256)     148992      conv1d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional (None, 360, 256)     148992      conv1d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional (None, 360, 256)     148992      conv1d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 360, 256)     0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, 360, 256)     0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)      (None, 360, 256)     0           bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_31 (LeakyReLU)      (None, 360, 256)     0           bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_39 (LeakyReLU)      (None, 360, 256)     0           bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_47 (LeakyReLU)      (None, 360, 256)     0           bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_55 (LeakyReLU)      (None, 360, 256)     0           bidirectional_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_63 (LeakyReLU)      (None, 360, 256)     0           bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_71 (LeakyReLU)      (None, 360, 256)     0           bidirectional_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_79 (LeakyReLU)      (None, 360, 256)     0           bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_87 (LeakyReLU)      (None, 360, 256)     0           bidirectional_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_95 (LeakyReLU)      (None, 360, 256)     0           bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_1 (Atten (None, 256)          66048       leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_2 (Atten (None, 256)          66048       leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_3 (Atten (None, 256)          66048       leaky_re_lu_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_4 (Atten (None, 256)          66048       leaky_re_lu_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_5 (Atten (None, 256)          66048       leaky_re_lu_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_6 (Atten (None, 256)          66048       leaky_re_lu_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_7 (Atten (None, 256)          66048       leaky_re_lu_55[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_8 (Atten (None, 256)          66048       leaky_re_lu_63[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_9 (Atten (None, 256)          66048       leaky_re_lu_71[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_10 (Atte (None, 256)          66048       leaky_re_lu_79[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_11 (Atte (None, 256)          66048       leaky_re_lu_87[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_12 (Atte (None, 256)          66048       leaky_re_lu_95[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 256)          1024        attention_with_context_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 256)          1024        attention_with_context_2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 256)          1024        attention_with_context_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 256)          1024        attention_with_context_4[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 256)          1024        attention_with_context_5[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 256)          1024        attention_with_context_6[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 256)          1024        attention_with_context_7[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 256)          1024        attention_with_context_8[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 256)          1024        attention_with_context_9[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 256)          1024        attention_with_context_10[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 256)          1024        attention_with_context_11[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 256)          1024        attention_with_context_12[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 256)          0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, 256)          0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)      (None, 256)          0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_32 (LeakyReLU)      (None, 256)          0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_40 (LeakyReLU)      (None, 256)          0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_48 (LeakyReLU)      (None, 256)          0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_56 (LeakyReLU)      (None, 256)          0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_64 (LeakyReLU)      (None, 256)          0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_72 (LeakyReLU)      (None, 256)          0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_80 (LeakyReLU)      (None, 256)          0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_88 (LeakyReLU)      (None, 256)          0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_96 (LeakyReLU)      (None, 256)          0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 9)            2313        leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 9)            2313        leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 9)            2313        leaky_re_lu_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 9)            2313        leaky_re_lu_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 9)            2313        leaky_re_lu_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 9)            2313        leaky_re_lu_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 9)            2313        leaky_re_lu_56[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 9)            2313        leaky_re_lu_64[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 9)            2313        leaky_re_lu_72[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 9)            2313        leaky_re_lu_80[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 9)            2313        leaky_re_lu_88[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 9)            2313        leaky_re_lu_96[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 9)            0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 9)            0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 9)            0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 9)            0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 9)            0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 9)            0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 9)            0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 9)            0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 9)            0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 9)            0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 9)            0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 9)            0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "average_1 (Average)             (None, 9)            0           activation_1[0][0]               \n",
      "                                                                 activation_2[0][0]               \n",
      "                                                                 activation_3[0][0]               \n",
      "                                                                 activation_4[0][0]               \n",
      "                                                                 activation_5[0][0]               \n",
      "                                                                 activation_6[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_9[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 8,673,900\n",
      "Trainable params: 8,657,004\n",
      "Non-trainable params: 16,896\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "\n",
      "Epoch 1 train_loss: 1.765 train_acc: 0.469 train_f1: 0.066 \t\n",
      "\n",
      "Validation 1 valid_acc: 0.536 best_acc: 0.536 \t\n",
      "\n",
      "Epoch 2 train_loss: 1.499 train_acc: 0.579 train_f1: 0.216 \t\n",
      "\n",
      "Validation 2 valid_acc: 0.575 best_acc: 0.575 \t\n",
      "\n",
      "Epoch 3 train_loss: 1.388 train_acc: 0.622 train_f1: 0.268 \t\n",
      "\n",
      "Validation 3 valid_acc: 0.607 best_acc: 0.607 \t\n",
      "\n",
      "Epoch 4 train_loss: 1.309 train_acc: 0.658 train_f1: 0.304 \t\n",
      "\n",
      "Validation 4 valid_acc: 0.626 best_acc: 0.626 \t\n",
      "\n",
      "Epoch 5 train_loss: 1.255 train_acc: 0.672 train_f1: 0.347 \t\n",
      "\n",
      "Validation 5 valid_acc: 0.633 best_acc: 0.633 \t\n",
      "\n",
      "Epoch 6 train_loss: 1.229 train_acc: 0.672 train_f1: 0.372 \t\n",
      "\n",
      "Validation 6 valid_acc: 0.629 best_acc: 0.633 \t\n",
      "\n",
      "Epoch 7 train_loss: 1.188 train_acc: 0.689 train_f1: 0.389 \t\n",
      "\n",
      "Validation 7 valid_acc: 0.646 best_acc: 0.646 \t\n",
      "\n",
      "Epoch 8 train_loss: 1.161 train_acc: 0.693 train_f1: 0.419 \t\n",
      "\n",
      "Validation 8 valid_acc: 0.646 best_acc: 0.646 \t\n",
      "\n",
      "Epoch 9 train_loss: 1.122 train_acc: 0.707 train_f1: 0.436 \t\n",
      "\n",
      "Validation 9 valid_acc: 0.658 best_acc: 0.658 \t\n",
      "\n",
      "Epoch 10 train_loss: 1.106 train_acc: 0.713 train_f1: 0.456 \t\n",
      "\n",
      "Validation 10 valid_acc: 0.668 best_acc: 0.668 \t\n",
      "\n",
      "Epoch 11 train_loss: 1.083 train_acc: 0.718 train_f1: 0.485 \t\n",
      "\n",
      "Validation 11 valid_acc: 0.697 best_acc: 0.697 \t\n",
      "\n",
      "Epoch 12 train_loss: 1.054 train_acc: 0.726 train_f1: 0.502 \t\n",
      "\n",
      "Validation 12 valid_acc: 0.694 best_acc: 0.697 \t\n",
      "\n",
      "Epoch 13 train_loss: 1.042 train_acc: 0.728 train_f1: 0.510 \t\n",
      "\n",
      "Validation 13 valid_acc: 0.697 best_acc: 0.697 \t\n",
      "\n",
      "Epoch 14 train_loss: 1.025 train_acc: 0.733 train_f1: 0.530 \t\n",
      "\n",
      "Validation 14 valid_acc: 0.704 best_acc: 0.704 \t\n",
      "\n",
      "Epoch 15 train_loss: 1.007 train_acc: 0.736 train_f1: 0.535 \t\n",
      "\n",
      "Validation 15 valid_acc: 0.694 best_acc: 0.704 \t\n",
      "\n",
      "Epoch 16 train_loss: 0.997 train_acc: 0.737 train_f1: 0.545 \t\n",
      "\n",
      "Validation 16 valid_acc: 0.688 best_acc: 0.704 \t\n",
      "\n",
      "Epoch 17 train_loss: 0.973 train_acc: 0.744 train_f1: 0.569 \t\n",
      "\n",
      "Validation 17 valid_acc: 0.716 best_acc: 0.716 \t\n",
      "\n",
      "Epoch 18 train_loss: 0.979 train_acc: 0.739 train_f1: 0.571 \t\n",
      "\n",
      "Validation 18 valid_acc: 0.712 best_acc: 0.716 \t\n",
      "\n",
      "Epoch 19 train_loss: 0.956 train_acc: 0.748 train_f1: 0.578 \t\n",
      "\n",
      "Validation 19 valid_acc: 0.717 best_acc: 0.717 \t\n",
      "\n",
      "Epoch 20 train_loss: 0.947 train_acc: 0.743 train_f1: 0.594 \t\n",
      "\n",
      "Validation 20 valid_acc: 0.727 best_acc: 0.727 \t\n",
      "\n",
      "Epoch 21 train_loss: 0.941 train_acc: 0.743 train_f1: 0.602 \t\n",
      "\n",
      "Validation 21 valid_acc: 0.709 best_acc: 0.727 \t\n",
      "\n",
      "Epoch 22 train_loss: 0.932 train_acc: 0.748 train_f1: 0.610 \t\n",
      "\n",
      "Validation 22 valid_acc: 0.719 best_acc: 0.727 \t\n",
      "\n",
      "Epoch 23 train_loss: 0.919 train_acc: 0.756 train_f1: 0.614 \t\n",
      "\n",
      "Validation 23 valid_acc: 0.729 best_acc: 0.729 \t\n",
      "\n",
      "Epoch 24 train_loss: 0.918 train_acc: 0.754 train_f1: 0.614 \t\n",
      "\n",
      "Validation 24 valid_acc: 0.724 best_acc: 0.729 \t\n",
      "\n",
      "Epoch 25 train_loss: 0.914 train_acc: 0.748 train_f1: 0.622 \t\n",
      "\n",
      "Validation 25 valid_acc: 0.722 best_acc: 0.729 \t\n",
      "\n",
      "Epoch 26 train_loss: 0.900 train_acc: 0.760 train_f1: 0.632 \t\n",
      "\n",
      "Validation 26 valid_acc: 0.740 best_acc: 0.740 \t\n",
      "\n",
      "Epoch 27 train_loss: 0.892 train_acc: 0.765 train_f1: 0.631 \t\n",
      "\n",
      "Validation 27 valid_acc: 0.721 best_acc: 0.740 \t\n",
      "\n",
      "Epoch 28 train_loss: 0.884 train_acc: 0.764 train_f1: 0.641 \t\n",
      "\n",
      "Validation 28 valid_acc: 0.732 best_acc: 0.740 \t\n",
      "\n",
      "Epoch 29 train_loss: 0.874 train_acc: 0.757 train_f1: 0.644 \t\n",
      "\n",
      "Validation 29 valid_acc: 0.715 best_acc: 0.740 \t\n",
      "\n",
      "Epoch 30 train_loss: 0.863 train_acc: 0.766 train_f1: 0.654 \t\n",
      "\n",
      "Validation 30 valid_acc: 0.738 best_acc: 0.740 \t\n",
      "\n",
      "Epoch 31 train_loss: 0.868 train_acc: 0.767 train_f1: 0.648 \t\n",
      "\n",
      "Validation 31 valid_acc: 0.733 best_acc: 0.740 \t\n",
      "\n",
      "Epoch 32 train_loss: 0.865 train_acc: 0.769 train_f1: 0.648 \t\n",
      "\n",
      "Validation 32 valid_acc: 0.730 best_acc: 0.740 \t\n",
      "\n",
      "Epoch 33 train_loss: 0.849 train_acc: 0.766 train_f1: 0.667 \t\n",
      "\n",
      "Validation 33 valid_acc: 0.720 best_acc: 0.740 \t\n",
      "\n",
      "Epoch 34 train_loss: 0.845 train_acc: 0.772 train_f1: 0.662 \t\n",
      "\n",
      "Validation 34 valid_acc: 0.739 best_acc: 0.740 \t\n",
      "\n",
      "Epoch 35 train_loss: 0.843 train_acc: 0.773 train_f1: 0.664 \t\n",
      "\n",
      "Validation 35 valid_acc: 0.738 best_acc: 0.740 \t\n",
      "\n",
      "Epoch 36 train_loss: 0.832 train_acc: 0.778 train_f1: 0.680 \t\n",
      "\n",
      "Validation 36 valid_acc: 0.745 best_acc: 0.745 \t\n",
      "\n",
      "Epoch 37 train_loss: 0.829 train_acc: 0.774 train_f1: 0.672 \t\n",
      "\n",
      "Validation 37 valid_acc: 0.729 best_acc: 0.745 \t\n",
      "\n",
      "Epoch 38 train_loss: 0.829 train_acc: 0.774 train_f1: 0.676 \t\n",
      "\n",
      "Validation 38 valid_acc: 0.734 best_acc: 0.745 \t\n",
      "\n",
      "Epoch 39 train_loss: 0.818 train_acc: 0.777 train_f1: 0.682 \t\n",
      "\n",
      "Validation 39 valid_acc: 0.738 best_acc: 0.745 \t\n",
      "\n",
      "Epoch 40 train_loss: 0.818 train_acc: 0.778 train_f1: 0.678 \t\n",
      "\n",
      "Validation 40 valid_acc: 0.738 best_acc: 0.745 \t\n",
      "\n",
      "Epoch 41 train_loss: 0.810 train_acc: 0.784 train_f1: 0.686 \t\n",
      "\n",
      "Validation 41 valid_acc: 0.737 best_acc: 0.745 \t\n",
      "\n",
      "Epoch 42 train_loss: 0.809 train_acc: 0.774 train_f1: 0.689 \t\n",
      "\n",
      "Validation 42 valid_acc: 0.745 best_acc: 0.745 \t\n",
      "\n",
      "Epoch 43 train_loss: 0.805 train_acc: 0.778 train_f1: 0.686 \t\n",
      "\n",
      "Validation 43 valid_acc: 0.745 best_acc: 0.745 \t\n",
      "\n",
      "Epoch 44 train_loss: 0.797 train_acc: 0.788 train_f1: 0.696 \t\n",
      "\n",
      "Validation 44 valid_acc: 0.745 best_acc: 0.745 \t\n",
      "\n",
      "Epoch 45 train_loss: 0.786 train_acc: 0.788 train_f1: 0.699 \t\n",
      "\n",
      "Validation 45 valid_acc: 0.738 best_acc: 0.745 \t\n",
      "\n",
      "Epoch 46 train_loss: 0.778 train_acc: 0.785 train_f1: 0.703 \t\n",
      "\n",
      "Validation 46 valid_acc: 0.741 best_acc: 0.745 \t\n",
      "\n",
      "Epoch 47 train_loss: 0.784 train_acc: 0.789 train_f1: 0.700 \t\n",
      "\n",
      "Validation 47 valid_acc: 0.736 best_acc: 0.745 \t\n",
      "\n",
      "Epoch 48 train_loss: 0.782 train_acc: 0.790 train_f1: 0.699 \t\n",
      "\n",
      "Validation 48 valid_acc: 0.740 best_acc: 0.745 \t\n",
      "\n",
      "Epoch 49 train_loss: 0.774 train_acc: 0.790 train_f1: 0.713 \t\n",
      "\n",
      "Validation 49 valid_acc: 0.740 best_acc: 0.745 \t\n",
      "\n",
      "Epoch 50 train_loss: 0.762 train_acc: 0.791 train_f1: 0.711 \t\n",
      "\n",
      "Validation 50 valid_acc: 0.749 best_acc: 0.749 \t\n",
      "\n",
      "Epoch 51 train_loss: 0.772 train_acc: 0.788 train_f1: 0.703 \t\n",
      "\n",
      "Validation 51 valid_acc: 0.733 best_acc: 0.749 \t\n",
      "\n",
      "Epoch 52 train_loss: 0.766 train_acc: 0.789 train_f1: 0.717 \t\n",
      "\n",
      "Validation 52 valid_acc: 0.737 best_acc: 0.749 \t\n",
      "\n",
      "Epoch 53 train_loss: 0.755 train_acc: 0.792 train_f1: 0.713 \t\n",
      "\n",
      "Validation 53 valid_acc: 0.744 best_acc: 0.749 \t\n",
      "\n",
      "Epoch 54 train_loss: 0.755 train_acc: 0.795 train_f1: 0.717 \t\n",
      "\n",
      "Validation 54 valid_acc: 0.741 best_acc: 0.749 \t\n",
      "\n",
      "Epoch 55 train_loss: 0.750 train_acc: 0.793 train_f1: 0.709 \t\n",
      "\n",
      "Validation 55 valid_acc: 0.743 best_acc: 0.749 \t\n",
      "\n",
      "Epoch 56 train_loss: 0.745 train_acc: 0.796 train_f1: 0.719 \t\n",
      "\n",
      "Validation 56 valid_acc: 0.747 best_acc: 0.749 \t\n",
      "\n",
      "Epoch 57 train_loss: 0.740 train_acc: 0.794 train_f1: 0.721 \t\n",
      "\n",
      "Validation 57 valid_acc: 0.747 best_acc: 0.749 \t\n",
      "\n",
      "Epoch 58 train_loss: 0.742 train_acc: 0.798 train_f1: 0.721 \t\n",
      "\n",
      "Validation 58 valid_acc: 0.743 best_acc: 0.749 \t\n",
      "\n",
      "Epoch 59 train_loss: 0.739 train_acc: 0.799 train_f1: 0.727 \t\n",
      "\n",
      "Validation 59 valid_acc: 0.744 best_acc: 0.749 \t\n",
      "\n",
      "Epoch 60 train_loss: 0.730 train_acc: 0.801 train_f1: 0.724 \t\n",
      "\n",
      "Validation 60 valid_acc: 0.743 best_acc: 0.749 \t\n",
      "\n",
      "Epoch 61 train_loss: 0.732 train_acc: 0.800 train_f1: 0.725 \t\n",
      "\n",
      "Validation 61 valid_acc: 0.751 best_acc: 0.751 \t\n",
      "\n",
      "Epoch 62 train_loss: 0.719 train_acc: 0.808 train_f1: 0.730 \t\n",
      "\n",
      "Validation 62 valid_acc: 0.747 best_acc: 0.751 \t\n",
      "\n",
      "Epoch 63 train_loss: 0.724 train_acc: 0.807 train_f1: 0.729 \t\n",
      "\n",
      "Validation 63 valid_acc: 0.733 best_acc: 0.751 \t\n",
      "\n",
      "Epoch 64 train_loss: 0.724 train_acc: 0.803 train_f1: 0.731 \t\n",
      "\n",
      "Validation 64 valid_acc: 0.750 best_acc: 0.751 \t\n",
      "\n",
      "Epoch 65 train_loss: 0.723 train_acc: 0.805 train_f1: 0.731 \t\n",
      "\n",
      "Validation 65 valid_acc: 0.754 best_acc: 0.754 \t\n",
      "\n",
      "Epoch 66 train_loss: 0.712 train_acc: 0.809 train_f1: 0.735 \t\n",
      "\n",
      "Validation 66 valid_acc: 0.733 best_acc: 0.754 \t\n",
      "\n",
      "Epoch 67 train_loss: 0.716 train_acc: 0.805 train_f1: 0.730 \t\n",
      "\n",
      "Validation 67 valid_acc: 0.743 best_acc: 0.754 \t\n",
      "\n",
      "Epoch 68 train_loss: 0.712 train_acc: 0.804 train_f1: 0.734 \t\n",
      "\n",
      "Validation 68 valid_acc: 0.745 best_acc: 0.754 \t\n",
      "\n",
      "Epoch 69 train_loss: 0.706 train_acc: 0.803 train_f1: 0.735 \t\n",
      "\n",
      "Validation 69 valid_acc: 0.749 best_acc: 0.754 \t\n",
      "\n",
      "Epoch 70 train_loss: 0.706 train_acc: 0.804 train_f1: 0.737 \t\n",
      "\n",
      "Validation 70 valid_acc: 0.748 best_acc: 0.754 \t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 71 train_loss: 0.707 train_acc: 0.814 train_f1: 0.737 \t\n",
      "\n",
      "Validation 71 valid_acc: 0.753 best_acc: 0.754 \t\n",
      "\n",
      "Epoch 72 train_loss: 0.703 train_acc: 0.803 train_f1: 0.737 \t\n",
      "\n",
      "Validation 72 valid_acc: 0.745 best_acc: 0.754 \t\n",
      "\n",
      "Epoch 73 train_loss: 0.697 train_acc: 0.809 train_f1: 0.741 \t\n",
      "\n",
      "Validation 73 valid_acc: 0.743 best_acc: 0.754 \t\n",
      "\n",
      "Epoch 74 train_loss: 0.688 train_acc: 0.810 train_f1: 0.744 \t\n",
      "\n",
      "Validation 74 valid_acc: 0.751 best_acc: 0.754 \t\n",
      "\n",
      "Epoch 75 train_loss: 0.689 train_acc: 0.810 train_f1: 0.742 \t\n",
      "\n",
      "Validation 75 valid_acc: 0.746 best_acc: 0.754 \t\n",
      "\n",
      "Epoch 76 train_loss: 0.686 train_acc: 0.809 train_f1: 0.749 \t\n",
      "\n",
      "Validation 76 valid_acc: 0.753 best_acc: 0.754 \t\n",
      "\n",
      "Epoch 77 train_loss: 0.686 train_acc: 0.811 train_f1: 0.740 \t\n",
      "\n",
      "Validation 77 valid_acc: 0.751 best_acc: 0.754 \t\n",
      "\n",
      "Epoch 78 train_loss: 0.680 train_acc: 0.817 train_f1: 0.742 \t\n",
      "\n",
      "Validation 78 valid_acc: 0.749 best_acc: 0.754 \t\n",
      "\n",
      "Epoch 79 train_loss: 0.688 train_acc: 0.810 train_f1: 0.745 \t\n",
      "\n",
      "Validation 79 valid_acc: 0.754 best_acc: 0.754 \t\n",
      "\n",
      "Epoch 80 train_loss: 0.683 train_acc: 0.816 train_f1: 0.744 \t\n",
      "\n",
      "Validation 80 valid_acc: 0.751 best_acc: 0.754 \t\n",
      "\n",
      "Epoch 81 train_loss: 0.681 train_acc: 0.809 train_f1: 0.745 \t\n",
      "\n",
      "Validation 81 valid_acc: 0.749 best_acc: 0.754 \t\n",
      "\n",
      "Epoch 82 train_loss: 0.682 train_acc: 0.804 train_f1: 0.749 \t\n",
      "\n",
      "Validation 82 valid_acc: 0.741 best_acc: 0.754 \t\n",
      "\n",
      "Epoch 83 train_loss: 0.672 train_acc: 0.815 train_f1: 0.748 \t\n",
      "\n",
      "Validation 83 valid_acc: 0.753 best_acc: 0.754 \t\n",
      "\n",
      "Epoch 84 train_loss: 0.676 train_acc: 0.818 train_f1: 0.750 \t\n",
      "\n",
      "Validation 84 valid_acc: 0.751 best_acc: 0.754 \t\n",
      "\n",
      "Epoch 85 train_loss: 0.673 train_acc: 0.819 train_f1: 0.755 \t\n",
      "\n",
      "Validation 85 valid_acc: 0.741 best_acc: 0.754 \t\n",
      "\n",
      "Epoch 86 train_loss: 0.664 train_acc: 0.821 train_f1: 0.756 \t\n",
      "\n",
      "Validation 86 valid_acc: 0.753 best_acc: 0.754 \t\n",
      "\n",
      "Epoch 87 train_loss: 0.660 train_acc: 0.822 train_f1: 0.749 \t\n",
      "\n",
      "Validation 87 valid_acc: 0.760 best_acc: 0.760 \t\n",
      "\n",
      "Epoch 88 train_loss: 0.658 train_acc: 0.824 train_f1: 0.756 \t\n",
      "\n",
      "Validation 88 valid_acc: 0.745 best_acc: 0.760 \t\n",
      "\n",
      "Epoch 89 train_loss: 0.665 train_acc: 0.816 train_f1: 0.754 \t\n",
      "\n",
      "Validation 89 valid_acc: 0.754 best_acc: 0.760 \t\n",
      "\n",
      "Epoch 90 train_loss: 0.655 train_acc: 0.822 train_f1: 0.757 \t\n",
      "\n",
      "Validation 90 valid_acc: 0.764 best_acc: 0.764 \t\n",
      "\n",
      "Epoch 91 train_loss: 0.649 train_acc: 0.822 train_f1: 0.763 \t\n",
      "\n",
      "Validation 91 valid_acc: 0.756 best_acc: 0.764 \t\n",
      "\n",
      "Epoch 92 train_loss: 0.645 train_acc: 0.826 train_f1: 0.760 \t\n",
      "\n",
      "Validation 92 valid_acc: 0.758 best_acc: 0.764 \t\n",
      "\n",
      "Epoch 93 train_loss: 0.648 train_acc: 0.827 train_f1: 0.760 \t\n",
      "\n",
      "Validation 93 valid_acc: 0.747 best_acc: 0.764 \t\n",
      "\n",
      "Epoch 94 train_loss: 0.649 train_acc: 0.823 train_f1: 0.761 \t\n",
      "\n",
      "Validation 94 valid_acc: 0.760 best_acc: 0.764 \t\n",
      "\n",
      "Epoch 95 train_loss: 0.650 train_acc: 0.829 train_f1: 0.759 \t\n",
      "\n",
      "Validation 95 valid_acc: 0.757 best_acc: 0.764 \t\n",
      "\n",
      "Epoch 96 train_loss: 0.648 train_acc: 0.823 train_f1: 0.761 \t\n",
      "\n",
      "Validation 96 valid_acc: 0.740 best_acc: 0.764 \t\n",
      "\n",
      "Epoch 97 train_loss: 0.641 train_acc: 0.826 train_f1: 0.763 \t\n",
      "\n",
      "Validation 97 valid_acc: 0.754 best_acc: 0.764 \t\n",
      "\n",
      "Epoch 98 train_loss: 0.643 train_acc: 0.830 train_f1: 0.763 \t\n",
      "\n",
      "Validation 98 valid_acc: 0.749 best_acc: 0.764 \t\n",
      "\n",
      "Epoch 99 train_loss: 0.642 train_acc: 0.824 train_f1: 0.763 \t\n",
      "\n",
      "Validation 99 valid_acc: 0.749 best_acc: 0.764 \t\n",
      "\n",
      "Epoch 100 train_loss: 0.632 train_acc: 0.828 train_f1: 0.767 \t\n",
      "\n",
      "Validation 100 valid_acc: 0.756 best_acc: 0.764 \t\n",
      "\n",
      "Epoch 101 train_loss: 0.631 train_acc: 0.835 train_f1: 0.768 \t\n",
      "\n",
      "Validation 101 valid_acc: 0.765 best_acc: 0.765 \t\n",
      "\n",
      "Epoch 102 train_loss: 0.631 train_acc: 0.833 train_f1: 0.773 \t\n",
      "\n",
      "Validation 102 valid_acc: 0.754 best_acc: 0.765 \t\n",
      "\n",
      "Epoch 103 train_loss: 0.629 train_acc: 0.830 train_f1: 0.771 \t\n",
      "\n",
      "Validation 103 valid_acc: 0.762 best_acc: 0.765 \t\n",
      "\n",
      "Epoch 104 train_loss: 0.630 train_acc: 0.826 train_f1: 0.772 \t\n",
      "\n",
      "Validation 104 valid_acc: 0.755 best_acc: 0.765 \t\n",
      "\n",
      "Epoch 105 train_loss: 0.622 train_acc: 0.831 train_f1: 0.775 \t\n",
      "\n",
      "Validation 105 valid_acc: 0.762 best_acc: 0.765 \t\n",
      "\n",
      "Epoch 106 train_loss: 0.625 train_acc: 0.831 train_f1: 0.775 \t\n",
      "\n",
      "Validation 106 valid_acc: 0.754 best_acc: 0.765 \t\n",
      "\n",
      "Epoch 107 train_loss: 0.621 train_acc: 0.833 train_f1: 0.772 \t\n",
      "\n",
      "Validation 107 valid_acc: 0.755 best_acc: 0.765 \t\n",
      "\n",
      "Epoch 108 train_loss: 0.630 train_acc: 0.827 train_f1: 0.770 \t\n",
      "\n",
      "Validation 108 valid_acc: 0.747 best_acc: 0.765 \t\n",
      "\n",
      "Epoch 109 train_loss: 0.619 train_acc: 0.838 train_f1: 0.775 \t\n",
      "\n",
      "Validation 109 valid_acc: 0.751 best_acc: 0.765 \t\n",
      "\n",
      "Epoch 110 train_loss: 0.618 train_acc: 0.835 train_f1: 0.773 \t\n",
      "\n",
      "Validation 110 valid_acc: 0.760 best_acc: 0.765 \t\n",
      "\n",
      "Epoch 111 train_loss: 0.618 train_acc: 0.835 train_f1: 0.773 \t\n",
      "\n",
      "Validation 111 valid_acc: 0.754 best_acc: 0.765 \t\n",
      "\n",
      "Epoch 112 train_loss: 0.618 train_acc: 0.834 train_f1: 0.773 \t\n",
      "\n",
      "Validation 112 valid_acc: 0.751 best_acc: 0.765 \t\n",
      "\n",
      "Epoch 113 train_loss: 0.616 train_acc: 0.831 train_f1: 0.777 \t\n",
      "\n",
      "Validation 113 valid_acc: 0.751 best_acc: 0.765 \t\n",
      "\n",
      "Epoch 114 train_loss: 0.611 train_acc: 0.846 train_f1: 0.776 \t\n",
      "\n",
      "Validation 114 valid_acc: 0.756 best_acc: 0.765 \t\n",
      "\n",
      "Epoch 115 train_loss: 0.608 train_acc: 0.837 train_f1: 0.783 \t\n",
      "\n",
      "Validation 115 valid_acc: 0.766 best_acc: 0.766 \t\n",
      "\n",
      "Epoch 116 train_loss: 0.607 train_acc: 0.831 train_f1: 0.777 \t\n",
      "\n",
      "Validation 116 valid_acc: 0.759 best_acc: 0.766 \t\n",
      "\n",
      "Epoch 117 train_loss: 0.604 train_acc: 0.839 train_f1: 0.775 \t\n",
      "\n",
      "Validation 117 valid_acc: 0.758 best_acc: 0.766 \t\n",
      "\n",
      "Epoch 118 train_loss: 0.605 train_acc: 0.835 train_f1: 0.777 \t\n",
      "\n",
      "Validation 118 valid_acc: 0.758 best_acc: 0.766 \t\n",
      "\n",
      "Epoch 119 train_loss: 0.605 train_acc: 0.841 train_f1: 0.779 \t\n",
      "\n",
      "Validation 119 valid_acc: 0.751 best_acc: 0.766 \t\n",
      "\n",
      "Epoch 120 train_loss: 0.605 train_acc: 0.838 train_f1: 0.777 \t\n",
      "\n",
      "Validation 120 valid_acc: 0.747 best_acc: 0.766 \t\n",
      "\n",
      "Epoch 121 train_loss: 0.596 train_acc: 0.839 train_f1: 0.783 \t\n",
      "\n",
      "Validation 121 valid_acc: 0.762 best_acc: 0.766 \t\n",
      "\n",
      "Epoch 122 train_loss: 0.590 train_acc: 0.844 train_f1: 0.784 \t\n",
      "\n",
      "Validation 122 valid_acc: 0.744 best_acc: 0.766 \t\n",
      "\n",
      "Epoch 123 train_loss: 0.597 train_acc: 0.840 train_f1: 0.779 \t\n",
      "\n",
      "Validation 123 valid_acc: 0.758 best_acc: 0.766 \t\n",
      "\n",
      "Epoch 124 train_loss: 0.590 train_acc: 0.844 train_f1: 0.786 \t\n",
      "\n",
      "Validation 124 valid_acc: 0.759 best_acc: 0.766 \t\n",
      "\n",
      "Epoch 125 train_loss: 0.597 train_acc: 0.840 train_f1: 0.785 \t\n",
      "\n",
      "Validation 125 valid_acc: 0.751 best_acc: 0.766 \t\n",
      "\n",
      "Epoch 126 train_loss: 0.590 train_acc: 0.845 train_f1: 0.792 \t\n",
      "\n",
      "Validation 126 valid_acc: 0.752 best_acc: 0.766 \t\n",
      "\n",
      "Epoch 127 train_loss: 0.597 train_acc: 0.842 train_f1: 0.784 \t\n",
      "\n",
      "Validation 127 valid_acc: 0.747 best_acc: 0.766 \t\n",
      "\n",
      "Epoch 128 train_loss: 0.593 train_acc: 0.842 train_f1: 0.787 \t\n",
      "\n",
      "Validation 128 valid_acc: 0.769 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 129 train_loss: 0.583 train_acc: 0.847 train_f1: 0.791 \t\n",
      "\n",
      "Validation 129 valid_acc: 0.764 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 130 train_loss: 0.586 train_acc: 0.842 train_f1: 0.789 \t\n",
      "\n",
      "Validation 130 valid_acc: 0.750 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 131 train_loss: 0.590 train_acc: 0.839 train_f1: 0.784 \t\n",
      "\n",
      "Validation 131 valid_acc: 0.749 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 132 train_loss: 0.576 train_acc: 0.853 train_f1: 0.790 \t\n",
      "\n",
      "Validation 132 valid_acc: 0.763 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 133 train_loss: 0.589 train_acc: 0.847 train_f1: 0.786 \t\n",
      "\n",
      "Validation 133 valid_acc: 0.753 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 134 train_loss: 0.581 train_acc: 0.845 train_f1: 0.784 \t\n",
      "\n",
      "Validation 134 valid_acc: 0.763 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 135 train_loss: 0.573 train_acc: 0.852 train_f1: 0.791 \t\n",
      "\n",
      "Validation 135 valid_acc: 0.752 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 136 train_loss: 0.573 train_acc: 0.851 train_f1: 0.796 \t\n",
      "\n",
      "Validation 136 valid_acc: 0.759 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 137 train_loss: 0.575 train_acc: 0.846 train_f1: 0.793 \t\n",
      "\n",
      "Validation 137 valid_acc: 0.754 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 138 train_loss: 0.575 train_acc: 0.846 train_f1: 0.797 \t\n",
      "\n",
      "Validation 138 valid_acc: 0.762 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 139 train_loss: 0.572 train_acc: 0.854 train_f1: 0.796 \t\n",
      "\n",
      "Validation 139 valid_acc: 0.765 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 140 train_loss: 0.571 train_acc: 0.852 train_f1: 0.796 \t\n",
      "\n",
      "Validation 140 valid_acc: 0.755 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 141 train_loss: 0.573 train_acc: 0.849 train_f1: 0.797 \t\n",
      "\n",
      "Validation 141 valid_acc: 0.761 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 142 train_loss: 0.566 train_acc: 0.852 train_f1: 0.795 \t\n",
      "\n",
      "Validation 142 valid_acc: 0.756 best_acc: 0.769 \t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 143 train_loss: 0.565 train_acc: 0.850 train_f1: 0.796 \t\n",
      "\n",
      "Validation 143 valid_acc: 0.763 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 144 train_loss: 0.567 train_acc: 0.853 train_f1: 0.795 \t\n",
      "\n",
      "Validation 144 valid_acc: 0.760 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 145 train_loss: 0.565 train_acc: 0.848 train_f1: 0.797 \t\n",
      "\n",
      "Validation 145 valid_acc: 0.764 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 146 train_loss: 0.556 train_acc: 0.857 train_f1: 0.798 \t\n",
      "\n",
      "Validation 146 valid_acc: 0.760 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 147 train_loss: 0.566 train_acc: 0.851 train_f1: 0.796 \t\n",
      "\n",
      "Validation 147 valid_acc: 0.750 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 148 train_loss: 0.562 train_acc: 0.856 train_f1: 0.797 \t\n",
      "\n",
      "Validation 148 valid_acc: 0.766 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 149 train_loss: 0.556 train_acc: 0.864 train_f1: 0.799 \t\n",
      "\n",
      "Validation 149 valid_acc: 0.769 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 150 train_loss: 0.558 train_acc: 0.857 train_f1: 0.803 \t\n",
      "\n",
      "Validation 150 valid_acc: 0.758 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 151 train_loss: 0.550 train_acc: 0.862 train_f1: 0.804 \t\n",
      "\n",
      "Validation 151 valid_acc: 0.758 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 152 train_loss: 0.555 train_acc: 0.856 train_f1: 0.798 \t\n",
      "\n",
      "Validation 152 valid_acc: 0.754 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 153 train_loss: 0.555 train_acc: 0.854 train_f1: 0.802 \t\n",
      "\n",
      "Validation 153 valid_acc: 0.752 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 154 train_loss: 0.554 train_acc: 0.855 train_f1: 0.799 \t\n",
      "\n",
      "Validation 154 valid_acc: 0.756 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 155 train_loss: 0.549 train_acc: 0.863 train_f1: 0.806 \t\n",
      "\n",
      "Validation 155 valid_acc: 0.758 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 156 train_loss: 0.545 train_acc: 0.864 train_f1: 0.808 \t\n",
      "\n",
      "Validation 156 valid_acc: 0.762 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 157 train_loss: 0.543 train_acc: 0.858 train_f1: 0.805 \t\n",
      "\n",
      "Validation 157 valid_acc: 0.763 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 158 train_loss: 0.544 train_acc: 0.864 train_f1: 0.802 \t\n",
      "\n",
      "Validation 158 valid_acc: 0.759 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 159 train_loss: 0.551 train_acc: 0.860 train_f1: 0.803 \t\n",
      "\n",
      "Validation 159 valid_acc: 0.766 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 160 train_loss: 0.540 train_acc: 0.860 train_f1: 0.808 \t\n",
      "\n",
      "Validation 160 valid_acc: 0.754 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 161 train_loss: 0.541 train_acc: 0.863 train_f1: 0.803 \t\n",
      "\n",
      "Validation 161 valid_acc: 0.770 best_acc: 0.770 \t\n",
      "\n",
      "Epoch 162 train_loss: 0.548 train_acc: 0.858 train_f1: 0.801 \t\n",
      "\n",
      "Validation 162 valid_acc: 0.753 best_acc: 0.770 \t\n",
      "\n",
      "Epoch 163 train_loss: 0.537 train_acc: 0.869 train_f1: 0.809 \t\n",
      "\n",
      "Validation 163 valid_acc: 0.765 best_acc: 0.770 \t\n",
      "\n",
      "Epoch 164 train_loss: 0.535 train_acc: 0.865 train_f1: 0.812 \t\n",
      "\n",
      "Validation 164 valid_acc: 0.764 best_acc: 0.770 \t\n",
      "\n",
      "Epoch 165 train_loss: 0.534 train_acc: 0.863 train_f1: 0.813 \t\n",
      "\n",
      "Validation 165 valid_acc: 0.756 best_acc: 0.770 \t\n",
      "\n",
      "Epoch 166 train_loss: 0.536 train_acc: 0.862 train_f1: 0.807 \t\n",
      "\n",
      "Validation 166 valid_acc: 0.774 best_acc: 0.774 \t\n",
      "\n",
      "Epoch 167 train_loss: 0.533 train_acc: 0.864 train_f1: 0.810 \t\n",
      "\n",
      "Validation 167 valid_acc: 0.761 best_acc: 0.774 \t\n",
      "\n",
      "Epoch 168 train_loss: 0.523 train_acc: 0.872 train_f1: 0.813 \t\n",
      "\n",
      "Validation 168 valid_acc: 0.769 best_acc: 0.774 \t\n",
      "\n",
      "Epoch 169 train_loss: 0.535 train_acc: 0.859 train_f1: 0.809 \t\n",
      "\n",
      "Validation 169 valid_acc: 0.762 best_acc: 0.774 \t\n",
      "\n",
      "Epoch 170 train_loss: 0.528 train_acc: 0.864 train_f1: 0.816 \t\n",
      "\n",
      "Validation 170 valid_acc: 0.765 best_acc: 0.774 \t\n",
      "\n",
      "Epoch 171 train_loss: 0.535 train_acc: 0.864 train_f1: 0.810 \t\n",
      "\n",
      "Validation 171 valid_acc: 0.758 best_acc: 0.774 \t\n",
      "\n",
      "Epoch 172 train_loss: 0.527 train_acc: 0.863 train_f1: 0.810 \t\n",
      "\n",
      "Validation 172 valid_acc: 0.770 best_acc: 0.774 \t\n",
      "\n",
      "Epoch 173 train_loss: 0.525 train_acc: 0.866 train_f1: 0.815 \t\n",
      "\n",
      "Validation 173 valid_acc: 0.757 best_acc: 0.774 \t\n",
      "\n",
      "Epoch 174 train_loss: 0.517 train_acc: 0.868 train_f1: 0.817 \t\n",
      "\n",
      "Validation 174 valid_acc: 0.765 best_acc: 0.774 \t\n",
      "\n",
      "Epoch 175 train_loss: 0.528 train_acc: 0.857 train_f1: 0.814 \t\n",
      "\n",
      "Validation 175 valid_acc: 0.771 best_acc: 0.774 \t\n",
      "\n",
      "Epoch 176 train_loss: 0.514 train_acc: 0.876 train_f1: 0.817 \t\n",
      "\n",
      "Validation 176 valid_acc: 0.759 best_acc: 0.774 \t\n",
      "\n",
      "Epoch 177 train_loss: 0.522 train_acc: 0.867 train_f1: 0.810 \t\n",
      "\n",
      "Validation 177 valid_acc: 0.761 best_acc: 0.774 \t\n",
      "\n",
      "Epoch 178 train_loss: 0.520 train_acc: 0.866 train_f1: 0.821 \t\n",
      "\n",
      "Validation 178 valid_acc: 0.756 best_acc: 0.774 \t\n",
      "\n",
      "Epoch 179 train_loss: 0.514 train_acc: 0.874 train_f1: 0.818 \t\n",
      "\n",
      "Validation 179 valid_acc: 0.758 best_acc: 0.774 \t\n",
      "\n",
      "Epoch 180 train_loss: 0.518 train_acc: 0.869 train_f1: 0.817 \t\n",
      "\n",
      "Validation 180 valid_acc: 0.768 best_acc: 0.774 \t\n",
      "\n",
      "Epoch 181 train_loss: 0.515 train_acc: 0.865 train_f1: 0.815 \t\n",
      "\n",
      "Validation 181 valid_acc: 0.756 best_acc: 0.774 \t\n",
      "\n",
      "Epoch 182 train_loss: 0.516 train_acc: 0.870 train_f1: 0.818 \t\n",
      "\n",
      "Validation 182 valid_acc: 0.763 best_acc: 0.774 \t\n",
      "\n",
      "Epoch 183 train_loss: 0.520 train_acc: 0.867 train_f1: 0.816 \t\n",
      "\n",
      "Validation 183 valid_acc: 0.762 best_acc: 0.774 \t\n",
      "\n",
      "Epoch 184 train_loss: 0.516 train_acc: 0.866 train_f1: 0.820 \t\n",
      "\n",
      "Validation 184 valid_acc: 0.762 best_acc: 0.774 \t\n",
      "\n",
      "Epoch 185 train_loss: 0.510 train_acc: 0.872 train_f1: 0.824 \t\n",
      "\n",
      "Validation 185 valid_acc: 0.772 best_acc: 0.774 \t\n",
      "\n",
      "Epoch 186 train_loss: 0.510 train_acc: 0.871 train_f1: 0.823 \t\n",
      "\n",
      "Validation 186 valid_acc: 0.763 best_acc: 0.774 \t\n",
      "\n",
      "Epoch 187 train_loss: 0.506 train_acc: 0.871 train_f1: 0.826 \t\n",
      "\n",
      "Validation 187 valid_acc: 0.762 best_acc: 0.774 \t\n",
      "\n",
      "Epoch 188 train_loss: 0.508 train_acc: 0.876 train_f1: 0.821 \t\n",
      "\n",
      "Validation 188 valid_acc: 0.767 best_acc: 0.774 \t\n",
      "\n",
      "Epoch 189 train_loss: 0.503 train_acc: 0.870 train_f1: 0.827 \t\n",
      "\n",
      "Validation 189 valid_acc: 0.769 best_acc: 0.774 \t\n",
      "\n",
      "Epoch 190 train_loss: 0.506 train_acc: 0.874 train_f1: 0.825 \t\n",
      "\n",
      "Validation 190 valid_acc: 0.771 best_acc: 0.774 \t\n",
      "\n",
      "Epoch 191 train_loss: 0.503 train_acc: 0.872 train_f1: 0.825 \t\n",
      "\n",
      "Validation 191 valid_acc: 0.762 best_acc: 0.774 \t\n",
      "\n",
      "Epoch 192 train_loss: 0.506 train_acc: 0.873 train_f1: 0.825 \t\n",
      "\n",
      "Validation 192 valid_acc: 0.762 best_acc: 0.774 \t\n",
      "\n",
      "Epoch 193 train_loss: 0.502 train_acc: 0.872 train_f1: 0.825 \t\n",
      "\n",
      "Validation 193 valid_acc: 0.765 best_acc: 0.774 \t\n",
      "\n",
      "Epoch 194 train_loss: 0.498 train_acc: 0.877 train_f1: 0.829 \t\n",
      "\n",
      "Validation 194 valid_acc: 0.773 best_acc: 0.774 \t\n",
      "\n",
      "Epoch 195 train_loss: 0.491 train_acc: 0.877 train_f1: 0.829 \t\n",
      "\n",
      "Validation 195 valid_acc: 0.767 best_acc: 0.774 \t\n",
      "\n",
      "Epoch 196 train_loss: 0.503 train_acc: 0.874 train_f1: 0.822 \t\n",
      "\n",
      "Validation 196 valid_acc: 0.770 best_acc: 0.774 \t\n",
      "\n",
      "Epoch 197 train_loss: 0.503 train_acc: 0.875 train_f1: 0.826 \t\n",
      "\n",
      "Validation 197 valid_acc: 0.769 best_acc: 0.774 \t\n",
      "\n",
      "Epoch 198 train_loss: 0.507 train_acc: 0.874 train_f1: 0.825 \t\n",
      "\n",
      "Validation 198 valid_acc: 0.765 best_acc: 0.774 \t\n",
      "\n",
      "Epoch 199 train_loss: 0.497 train_acc: 0.877 train_f1: 0.831 \t\n",
      "\n",
      "Validation 199 valid_acc: 0.763 best_acc: 0.774 \t\n",
      "\n",
      "Epoch 200 train_loss: 0.500 train_acc: 0.873 train_f1: 0.827 \t\n",
      "\n",
      "Validation 200 valid_acc: 0.767 best_acc: 0.774 \t\n",
      "\n",
      "Epoch 201 train_loss: 0.495 train_acc: 0.874 train_f1: 0.828 \t\n",
      "\n",
      "Validation 201 valid_acc: 0.776 best_acc: 0.776 \t\n",
      "\n",
      "Epoch 202 train_loss: 0.486 train_acc: 0.883 train_f1: 0.834 \t\n",
      "\n",
      "Validation 202 valid_acc: 0.775 best_acc: 0.776 \t\n",
      "\n",
      "Epoch 203 train_loss: 0.488 train_acc: 0.881 train_f1: 0.835 \t\n",
      "\n",
      "Validation 203 valid_acc: 0.769 best_acc: 0.776 \t\n",
      "\n",
      "Epoch 204 train_loss: 0.491 train_acc: 0.878 train_f1: 0.831 \t\n",
      "\n",
      "Validation 204 valid_acc: 0.767 best_acc: 0.776 \t\n",
      "\n",
      "Epoch 205 train_loss: 0.492 train_acc: 0.879 train_f1: 0.828 \t\n",
      "\n",
      "Validation 205 valid_acc: 0.771 best_acc: 0.776 \t\n",
      "\n",
      "Epoch 206 train_loss: 0.491 train_acc: 0.884 train_f1: 0.830 \t\n",
      "\n",
      "Validation 206 valid_acc: 0.763 best_acc: 0.776 \t\n",
      "\n",
      "Epoch 207 train_loss: 0.484 train_acc: 0.885 train_f1: 0.834 \t\n",
      "\n",
      "Validation 207 valid_acc: 0.761 best_acc: 0.776 \t\n",
      "\n",
      "Epoch 208 train_loss: 0.490 train_acc: 0.879 train_f1: 0.827 \t\n",
      "\n",
      "Validation 208 valid_acc: 0.763 best_acc: 0.776 \t\n",
      "\n",
      "Epoch 209 train_loss: 0.485 train_acc: 0.878 train_f1: 0.831 \t\n",
      "\n",
      "Validation 209 valid_acc: 0.768 best_acc: 0.776 \t\n",
      "\n",
      "Epoch 210 train_loss: 0.480 train_acc: 0.883 train_f1: 0.833 \t\n",
      "\n",
      "Validation 210 valid_acc: 0.773 best_acc: 0.776 \t\n",
      "\n",
      "Epoch 211 train_loss: 0.484 train_acc: 0.881 train_f1: 0.831 \t\n",
      "\n",
      "Validation 211 valid_acc: 0.769 best_acc: 0.776 \t\n",
      "\n",
      "Epoch 212 train_loss: 0.480 train_acc: 0.884 train_f1: 0.833 \t\n",
      "\n",
      "Validation 212 valid_acc: 0.771 best_acc: 0.776 \t\n",
      "\n",
      "Epoch 213 train_loss: 0.474 train_acc: 0.885 train_f1: 0.839 \t\n",
      "\n",
      "Validation 213 valid_acc: 0.766 best_acc: 0.776 \t\n",
      "\n",
      "Epoch 214 train_loss: 0.479 train_acc: 0.882 train_f1: 0.836 \t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation 214 valid_acc: 0.776 best_acc: 0.776 \t\n",
      "\n",
      "Epoch 215 train_loss: 0.480 train_acc: 0.884 train_f1: 0.836 \t\n",
      "\n",
      "Validation 215 valid_acc: 0.775 best_acc: 0.776 \t\n",
      "\n",
      "Epoch 216 train_loss: 0.480 train_acc: 0.885 train_f1: 0.832 \t\n",
      "\n",
      "Validation 216 valid_acc: 0.767 best_acc: 0.776 \t\n",
      "\n",
      "Epoch 217 train_loss: 0.473 train_acc: 0.885 train_f1: 0.838 \t\n",
      "\n",
      "Validation 217 valid_acc: 0.755 best_acc: 0.776 \t\n",
      "\n",
      "Epoch 218 train_loss: 0.473 train_acc: 0.883 train_f1: 0.834 \t\n",
      "\n",
      "Validation 218 valid_acc: 0.774 best_acc: 0.776 \t\n",
      "\n",
      "Epoch 219 train_loss: 0.477 train_acc: 0.884 train_f1: 0.838 \t\n",
      "\n",
      "Validation 219 valid_acc: 0.767 best_acc: 0.776 \t\n",
      "\n",
      "Epoch 220 train_loss: 0.473 train_acc: 0.890 train_f1: 0.839 \t\n",
      "\n",
      "Validation 220 valid_acc: 0.774 best_acc: 0.776 \t\n",
      "\n",
      "Epoch 221 train_loss: 0.471 train_acc: 0.886 train_f1: 0.837 \t\n",
      "\n",
      "Validation 221 valid_acc: 0.769 best_acc: 0.776 \t\n",
      "\n",
      "Epoch 222 train_loss: 0.475 train_acc: 0.889 train_f1: 0.839 \t\n",
      "\n",
      "Validation 222 valid_acc: 0.771 best_acc: 0.776 \t\n",
      "\n",
      "Epoch 223 train_loss: 0.470 train_acc: 0.886 train_f1: 0.839 \t\n",
      "\n",
      "Validation 223 valid_acc: 0.765 best_acc: 0.776 \t\n",
      "\n",
      "Epoch 224 train_loss: 0.466 train_acc: 0.884 train_f1: 0.841 \t\n",
      "\n",
      "Validation 224 valid_acc: 0.773 best_acc: 0.776 \t\n",
      "\n",
      "Epoch 225 train_loss: 0.472 train_acc: 0.882 train_f1: 0.839 \t\n",
      "\n",
      "Validation 225 valid_acc: 0.765 best_acc: 0.776 \t\n",
      "\n",
      "Epoch 226 train_loss: 0.464 train_acc: 0.887 train_f1: 0.844 \t\n",
      "\n",
      "Validation 226 valid_acc: 0.769 best_acc: 0.776 \t\n",
      "\n",
      "Epoch 227 train_loss: 0.477 train_acc: 0.886 train_f1: 0.830 \t\n",
      "\n",
      "Validation 227 valid_acc: 0.772 best_acc: 0.776 \t\n",
      "\n",
      "Epoch 228 train_loss: 0.466 train_acc: 0.885 train_f1: 0.843 \t\n",
      "\n",
      "Validation 228 valid_acc: 0.762 best_acc: 0.776 \t\n",
      "\n",
      "Epoch 229 train_loss: 0.464 train_acc: 0.883 train_f1: 0.840 \t\n",
      "\n",
      "Validation 229 valid_acc: 0.782 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 230 train_loss: 0.460 train_acc: 0.890 train_f1: 0.843 \t\n",
      "\n",
      "Validation 230 valid_acc: 0.772 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 231 train_loss: 0.462 train_acc: 0.892 train_f1: 0.842 \t\n",
      "\n",
      "Validation 231 valid_acc: 0.765 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 232 train_loss: 0.464 train_acc: 0.895 train_f1: 0.843 \t\n",
      "\n",
      "Validation 232 valid_acc: 0.781 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 233 train_loss: 0.464 train_acc: 0.889 train_f1: 0.843 \t\n",
      "\n",
      "Validation 233 valid_acc: 0.767 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 234 train_loss: 0.467 train_acc: 0.890 train_f1: 0.842 \t\n",
      "\n",
      "Validation 234 valid_acc: 0.771 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 235 train_loss: 0.457 train_acc: 0.892 train_f1: 0.848 \t\n",
      "\n",
      "Validation 235 valid_acc: 0.768 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 236 train_loss: 0.456 train_acc: 0.890 train_f1: 0.844 \t\n",
      "\n",
      "Validation 236 valid_acc: 0.772 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 237 train_loss: 0.460 train_acc: 0.887 train_f1: 0.843 \t\n",
      "\n",
      "Validation 237 valid_acc: 0.769 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 238 train_loss: 0.455 train_acc: 0.895 train_f1: 0.846 \t\n",
      "\n",
      "Validation 238 valid_acc: 0.773 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 239 train_loss: 0.453 train_acc: 0.894 train_f1: 0.845 \t\n",
      "\n",
      "Validation 239 valid_acc: 0.767 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 240 train_loss: 0.455 train_acc: 0.894 train_f1: 0.850 \t\n",
      "\n",
      "Validation 240 valid_acc: 0.772 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 241 train_loss: 0.455 train_acc: 0.897 train_f1: 0.847 \t\n",
      "\n",
      "Validation 241 valid_acc: 0.765 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 242 train_loss: 0.454 train_acc: 0.894 train_f1: 0.847 \t\n",
      "\n",
      "Validation 242 valid_acc: 0.773 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 243 train_loss: 0.454 train_acc: 0.891 train_f1: 0.844 \t\n",
      "\n",
      "Validation 243 valid_acc: 0.766 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 244 train_loss: 0.451 train_acc: 0.893 train_f1: 0.848 \t\n",
      "\n",
      "Validation 244 valid_acc: 0.773 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 245 train_loss: 0.450 train_acc: 0.895 train_f1: 0.849 \t\n",
      "\n",
      "Validation 245 valid_acc: 0.772 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 246 train_loss: 0.453 train_acc: 0.892 train_f1: 0.849 \t\n",
      "\n",
      "Validation 246 valid_acc: 0.757 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 247 train_loss: 0.442 train_acc: 0.900 train_f1: 0.852 \t\n",
      "\n",
      "Validation 247 valid_acc: 0.777 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 248 train_loss: 0.449 train_acc: 0.892 train_f1: 0.849 \t\n",
      "\n",
      "Validation 248 valid_acc: 0.765 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 249 train_loss: 0.446 train_acc: 0.892 train_f1: 0.850 \t\n",
      "\n",
      "Validation 249 valid_acc: 0.768 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 250 train_loss: 0.447 train_acc: 0.899 train_f1: 0.850 \t\n",
      "\n",
      "Validation 250 valid_acc: 0.772 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 251 train_loss: 0.445 train_acc: 0.896 train_f1: 0.850 \t\n",
      "\n",
      "Validation 251 valid_acc: 0.762 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 252 train_loss: 0.448 train_acc: 0.897 train_f1: 0.847 \t\n",
      "\n",
      "Validation 252 valid_acc: 0.773 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 253 train_loss: 0.436 train_acc: 0.900 train_f1: 0.853 \t\n",
      "\n",
      "Validation 253 valid_acc: 0.769 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 254 train_loss: 0.445 train_acc: 0.898 train_f1: 0.849 \t\n",
      "\n",
      "Validation 254 valid_acc: 0.775 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 255 train_loss: 0.450 train_acc: 0.895 train_f1: 0.850 \t\n",
      "\n",
      "Validation 255 valid_acc: 0.780 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 256 train_loss: 0.431 train_acc: 0.901 train_f1: 0.859 \t\n",
      "\n",
      "Validation 256 valid_acc: 0.772 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 257 train_loss: 0.441 train_acc: 0.901 train_f1: 0.853 \t\n",
      "\n",
      "Validation 257 valid_acc: 0.760 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 258 train_loss: 0.444 train_acc: 0.896 train_f1: 0.853 \t\n",
      "\n",
      "Validation 258 valid_acc: 0.768 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 259 train_loss: 0.435 train_acc: 0.900 train_f1: 0.851 \t\n",
      "\n",
      "Validation 259 valid_acc: 0.772 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 260 train_loss: 0.436 train_acc: 0.899 train_f1: 0.859 \t\n",
      "\n",
      "Validation 260 valid_acc: 0.780 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 261 train_loss: 0.436 train_acc: 0.901 train_f1: 0.856 \t\n",
      "\n",
      "Validation 261 valid_acc: 0.778 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 262 train_loss: 0.437 train_acc: 0.899 train_f1: 0.857 \t\n",
      "\n",
      "Validation 262 valid_acc: 0.766 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 263 train_loss: 0.437 train_acc: 0.898 train_f1: 0.852 \t\n",
      "\n",
      "Validation 263 valid_acc: 0.774 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 264 train_loss: 0.432 train_acc: 0.899 train_f1: 0.857 \t\n",
      "\n",
      "Validation 264 valid_acc: 0.776 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 265 train_loss: 0.422 train_acc: 0.909 train_f1: 0.865 \t\n",
      "\n",
      "Validation 265 valid_acc: 0.767 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 266 train_loss: 0.434 train_acc: 0.901 train_f1: 0.855 \t\n",
      "\n",
      "Validation 266 valid_acc: 0.776 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 267 train_loss: 0.434 train_acc: 0.899 train_f1: 0.855 \t\n",
      "\n",
      "Validation 267 valid_acc: 0.767 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 268 train_loss: 0.425 train_acc: 0.905 train_f1: 0.859 \t\n",
      "\n",
      "Validation 268 valid_acc: 0.788 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 269 train_loss: 0.433 train_acc: 0.902 train_f1: 0.859 \t\n",
      "\n",
      "Validation 269 valid_acc: 0.773 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 270 train_loss: 0.431 train_acc: 0.897 train_f1: 0.858 \t\n",
      "\n",
      "Validation 270 valid_acc: 0.772 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 271 train_loss: 0.429 train_acc: 0.904 train_f1: 0.860 \t\n",
      "\n",
      "Validation 271 valid_acc: 0.774 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 272 train_loss: 0.427 train_acc: 0.900 train_f1: 0.857 \t\n",
      "\n",
      "Validation 272 valid_acc: 0.765 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 273 train_loss: 0.433 train_acc: 0.903 train_f1: 0.854 \t\n",
      "\n",
      "Validation 273 valid_acc: 0.761 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 274 train_loss: 0.422 train_acc: 0.903 train_f1: 0.866 \t\n",
      "\n",
      "Validation 274 valid_acc: 0.779 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 275 train_loss: 0.429 train_acc: 0.905 train_f1: 0.860 \t\n",
      "\n",
      "Validation 275 valid_acc: 0.780 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 276 train_loss: 0.426 train_acc: 0.899 train_f1: 0.862 \t\n",
      "\n",
      "Validation 276 valid_acc: 0.776 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 277 train_loss: 0.418 train_acc: 0.903 train_f1: 0.862 \t\n",
      "\n",
      "Validation 277 valid_acc: 0.773 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 278 train_loss: 0.422 train_acc: 0.904 train_f1: 0.860 \t\n",
      "\n",
      "Validation 278 valid_acc: 0.776 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 279 train_loss: 0.413 train_acc: 0.908 train_f1: 0.867 \t\n",
      "\n",
      "Validation 279 valid_acc: 0.779 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 280 train_loss: 0.420 train_acc: 0.908 train_f1: 0.865 \t\n",
      "\n",
      "Validation 280 valid_acc: 0.779 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 281 train_loss: 0.420 train_acc: 0.906 train_f1: 0.865 \t\n",
      "\n",
      "Validation 281 valid_acc: 0.756 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 282 train_loss: 0.419 train_acc: 0.907 train_f1: 0.864 \t\n",
      "\n",
      "Validation 282 valid_acc: 0.771 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 283 train_loss: 0.413 train_acc: 0.911 train_f1: 0.868 \t\n",
      "\n",
      "Validation 283 valid_acc: 0.775 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 284 train_loss: 0.424 train_acc: 0.906 train_f1: 0.863 \t\n",
      "\n",
      "Validation 284 valid_acc: 0.772 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 285 train_loss: 0.431 train_acc: 0.898 train_f1: 0.858 \t\n",
      "\n",
      "Validation 285 valid_acc: 0.782 best_acc: 0.788 \t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 286 train_loss: 0.418 train_acc: 0.908 train_f1: 0.865 \t\n",
      "\n",
      "Validation 286 valid_acc: 0.764 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 287 train_loss: 0.413 train_acc: 0.907 train_f1: 0.866 \t\n",
      "\n",
      "Validation 287 valid_acc: 0.773 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 288 train_loss: 0.418 train_acc: 0.905 train_f1: 0.863 \t\n",
      "\n",
      "Validation 288 valid_acc: 0.778 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 289 train_loss: 0.419 train_acc: 0.905 train_f1: 0.865 \t\n",
      "\n",
      "Validation 289 valid_acc: 0.775 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 290 train_loss: 0.413 train_acc: 0.911 train_f1: 0.863 \t\n",
      "\n",
      "Validation 290 valid_acc: 0.788 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 291 train_loss: 0.404 train_acc: 0.916 train_f1: 0.872 \t\n",
      "\n",
      "Validation 291 valid_acc: 0.783 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 292 train_loss: 0.414 train_acc: 0.911 train_f1: 0.868 \t\n",
      "\n",
      "Validation 292 valid_acc: 0.765 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 293 train_loss: 0.413 train_acc: 0.908 train_f1: 0.869 \t\n",
      "\n",
      "Validation 293 valid_acc: 0.769 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 294 train_loss: 0.412 train_acc: 0.908 train_f1: 0.870 \t\n",
      "\n",
      "Validation 294 valid_acc: 0.768 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 295 train_loss: 0.407 train_acc: 0.905 train_f1: 0.868 \t\n",
      "\n",
      "Validation 295 valid_acc: 0.781 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 296 train_loss: 0.414 train_acc: 0.904 train_f1: 0.864 \t\n",
      "\n",
      "Validation 296 valid_acc: 0.783 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 297 train_loss: 0.404 train_acc: 0.910 train_f1: 0.868 \t\n",
      "\n",
      "Validation 297 valid_acc: 0.776 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 298 train_loss: 0.409 train_acc: 0.914 train_f1: 0.869 \t\n",
      "\n",
      "Validation 298 valid_acc: 0.772 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 299 train_loss: 0.403 train_acc: 0.910 train_f1: 0.869 \t\n",
      "\n",
      "Validation 299 valid_acc: 0.770 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 300 train_loss: 0.406 train_acc: 0.913 train_f1: 0.869 \t\n",
      "\n",
      "Validation 300 valid_acc: 0.773 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 301 train_loss: 0.404 train_acc: 0.910 train_f1: 0.872 \t\n",
      "\n",
      "Validation 301 valid_acc: 0.784 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 302 train_loss: 0.412 train_acc: 0.909 train_f1: 0.868 \t\n",
      "\n",
      "Validation 302 valid_acc: 0.769 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 303 train_loss: 0.408 train_acc: 0.909 train_f1: 0.869 \t\n",
      "\n",
      "Validation 303 valid_acc: 0.774 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 304 train_loss: 0.406 train_acc: 0.912 train_f1: 0.868 \t\n",
      "\n",
      "Validation 304 valid_acc: 0.776 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 305 train_loss: 0.407 train_acc: 0.905 train_f1: 0.869 \t\n",
      "\n",
      "Validation 305 valid_acc: 0.772 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 306 train_loss: 0.402 train_acc: 0.917 train_f1: 0.871 \t\n",
      "\n",
      "Validation 306 valid_acc: 0.778 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 307 train_loss: 0.396 train_acc: 0.916 train_f1: 0.875 \t\n",
      "\n",
      "Validation 307 valid_acc: 0.768 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 308 train_loss: 0.403 train_acc: 0.908 train_f1: 0.871 \t\n",
      "\n",
      "Validation 308 valid_acc: 0.765 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 309 train_loss: 0.394 train_acc: 0.915 train_f1: 0.875 \t\n",
      "\n",
      "Validation 309 valid_acc: 0.772 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 310 train_loss: 0.392 train_acc: 0.916 train_f1: 0.879 \t\n",
      "\n",
      "Validation 310 valid_acc: 0.770 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 311 train_loss: 0.396 train_acc: 0.917 train_f1: 0.873 \t\n",
      "\n",
      "Validation 311 valid_acc: 0.769 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 312 train_loss: 0.391 train_acc: 0.918 train_f1: 0.875 \t\n",
      "\n",
      "Validation 312 valid_acc: 0.772 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 313 train_loss: 0.392 train_acc: 0.914 train_f1: 0.876 \t\n",
      "\n",
      "Validation 313 valid_acc: 0.781 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 314 train_loss: 0.394 train_acc: 0.918 train_f1: 0.875 \t\n",
      "\n",
      "Validation 314 valid_acc: 0.781 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 315 train_loss: 0.386 train_acc: 0.916 train_f1: 0.879 \t\n",
      "\n",
      "Validation 315 valid_acc: 0.776 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 316 train_loss: 0.391 train_acc: 0.919 train_f1: 0.875 \t\n",
      "\n",
      "Validation 316 valid_acc: 0.782 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 317 train_loss: 0.396 train_acc: 0.913 train_f1: 0.878 \t\n",
      "\n",
      "Validation 317 valid_acc: 0.781 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 318 train_loss: 0.392 train_acc: 0.917 train_f1: 0.879 \t\n",
      "\n",
      "Validation 318 valid_acc: 0.767 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 319 train_loss: 0.390 train_acc: 0.913 train_f1: 0.881 \t\n",
      "\n",
      "Validation 319 valid_acc: 0.775 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 320 train_loss: 0.397 train_acc: 0.916 train_f1: 0.873 \t\n",
      "\n",
      "Validation 320 valid_acc: 0.761 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 321 train_loss: 0.384 train_acc: 0.920 train_f1: 0.880 \t\n",
      "\n",
      "Validation 321 valid_acc: 0.770 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 322 train_loss: 0.395 train_acc: 0.912 train_f1: 0.871 \t\n",
      "\n",
      "Validation 322 valid_acc: 0.774 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 323 train_loss: 0.386 train_acc: 0.914 train_f1: 0.877 \t\n",
      "\n",
      "Validation 323 valid_acc: 0.776 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 324 train_loss: 0.385 train_acc: 0.922 train_f1: 0.882 \t\n",
      "\n",
      "Validation 324 valid_acc: 0.783 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 325 train_loss: 0.385 train_acc: 0.921 train_f1: 0.878 \t\n",
      "\n",
      "Validation 325 valid_acc: 0.781 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 326 train_loss: 0.391 train_acc: 0.916 train_f1: 0.874 \t\n",
      "\n",
      "Validation 326 valid_acc: 0.784 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 327 train_loss: 0.379 train_acc: 0.917 train_f1: 0.882 \t\n",
      "\n",
      "Validation 327 valid_acc: 0.786 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 328 train_loss: 0.391 train_acc: 0.920 train_f1: 0.876 \t\n",
      "\n",
      "Validation 328 valid_acc: 0.772 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 329 train_loss: 0.384 train_acc: 0.918 train_f1: 0.879 \t\n",
      "\n",
      "Validation 329 valid_acc: 0.783 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 330 train_loss: 0.384 train_acc: 0.916 train_f1: 0.880 \t\n",
      "\n",
      "Validation 330 valid_acc: 0.784 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 331 train_loss: 0.387 train_acc: 0.914 train_f1: 0.875 \t\n",
      "\n",
      "Validation 331 valid_acc: 0.784 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 332 train_loss: 0.381 train_acc: 0.919 train_f1: 0.881 \t\n",
      "\n",
      "Validation 332 valid_acc: 0.768 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 333 train_loss: 0.375 train_acc: 0.924 train_f1: 0.885 \t\n",
      "\n",
      "Validation 333 valid_acc: 0.786 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 334 train_loss: 0.379 train_acc: 0.921 train_f1: 0.881 \t\n",
      "\n",
      "Validation 334 valid_acc: 0.788 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 335 train_loss: 0.381 train_acc: 0.917 train_f1: 0.882 \t\n",
      "\n",
      "Validation 335 valid_acc: 0.778 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 336 train_loss: 0.383 train_acc: 0.918 train_f1: 0.880 \t\n",
      "\n",
      "Validation 336 valid_acc: 0.774 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 337 train_loss: 0.376 train_acc: 0.916 train_f1: 0.882 \t\n",
      "\n",
      "Validation 337 valid_acc: 0.784 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 338 train_loss: 0.376 train_acc: 0.919 train_f1: 0.880 \t\n",
      "\n",
      "Validation 338 valid_acc: 0.786 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 339 train_loss: 0.380 train_acc: 0.919 train_f1: 0.885 \t\n",
      "\n",
      "Validation 339 valid_acc: 0.780 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 340 train_loss: 0.377 train_acc: 0.923 train_f1: 0.884 \t\n",
      "\n",
      "Validation 340 valid_acc: 0.769 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 341 train_loss: 0.368 train_acc: 0.926 train_f1: 0.886 \t\n",
      "\n",
      "Validation 341 valid_acc: 0.774 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 342 train_loss: 0.369 train_acc: 0.924 train_f1: 0.889 \t\n",
      "\n",
      "Validation 342 valid_acc: 0.784 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 343 train_loss: 0.378 train_acc: 0.923 train_f1: 0.884 \t\n",
      "\n",
      "Validation 343 valid_acc: 0.771 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 344 train_loss: 0.373 train_acc: 0.922 train_f1: 0.885 \t\n",
      "\n",
      "Validation 344 valid_acc: 0.780 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 345 train_loss: 0.378 train_acc: 0.914 train_f1: 0.882 \t\n",
      "\n",
      "Validation 345 valid_acc: 0.771 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 346 train_loss: 0.381 train_acc: 0.916 train_f1: 0.878 \t\n",
      "\n",
      "Validation 346 valid_acc: 0.783 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 347 train_loss: 0.368 train_acc: 0.926 train_f1: 0.886 \t\n",
      "\n",
      "Validation 347 valid_acc: 0.775 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 348 train_loss: 0.373 train_acc: 0.921 train_f1: 0.883 \t\n",
      "\n",
      "Validation 348 valid_acc: 0.780 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 349 train_loss: 0.370 train_acc: 0.923 train_f1: 0.887 \t\n",
      "\n",
      "Validation 349 valid_acc: 0.770 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 350 train_loss: 0.367 train_acc: 0.919 train_f1: 0.886 \t\n",
      "\n",
      "Validation 350 valid_acc: 0.780 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 351 train_loss: 0.376 train_acc: 0.915 train_f1: 0.882 \t\n",
      "\n",
      "Validation 351 valid_acc: 0.782 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 352 train_loss: 0.366 train_acc: 0.926 train_f1: 0.886 \t\n",
      "\n",
      "Validation 352 valid_acc: 0.786 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 353 train_loss: 0.365 train_acc: 0.921 train_f1: 0.888 \t\n",
      "\n",
      "Validation 353 valid_acc: 0.782 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 354 train_loss: 0.361 train_acc: 0.923 train_f1: 0.887 \t\n",
      "\n",
      "Validation 354 valid_acc: 0.780 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 355 train_loss: 0.356 train_acc: 0.927 train_f1: 0.891 \t\n",
      "\n",
      "Validation 355 valid_acc: 0.781 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 356 train_loss: 0.356 train_acc: 0.929 train_f1: 0.891 \t\n",
      "\n",
      "Validation 356 valid_acc: 0.769 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 357 train_loss: 0.365 train_acc: 0.921 train_f1: 0.888 \t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation 357 valid_acc: 0.776 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 358 train_loss: 0.369 train_acc: 0.920 train_f1: 0.887 \t\n",
      "\n",
      "Validation 358 valid_acc: 0.778 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 359 train_loss: 0.360 train_acc: 0.927 train_f1: 0.891 \t\n",
      "\n",
      "Validation 359 valid_acc: 0.776 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 360 train_loss: 0.365 train_acc: 0.924 train_f1: 0.893 \t\n",
      "\n",
      "Validation 360 valid_acc: 0.783 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 361 train_loss: 0.357 train_acc: 0.926 train_f1: 0.891 \t\n",
      "\n",
      "Validation 361 valid_acc: 0.779 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 362 train_loss: 0.368 train_acc: 0.919 train_f1: 0.883 \t\n",
      "\n",
      "Validation 362 valid_acc: 0.781 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 363 train_loss: 0.360 train_acc: 0.926 train_f1: 0.895 \t\n",
      "\n",
      "Validation 363 valid_acc: 0.776 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 364 train_loss: 0.354 train_acc: 0.930 train_f1: 0.893 \t\n",
      "\n",
      "Validation 364 valid_acc: 0.767 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 365 train_loss: 0.356 train_acc: 0.924 train_f1: 0.893 \t\n",
      "\n",
      "Validation 365 valid_acc: 0.781 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 366 train_loss: 0.355 train_acc: 0.924 train_f1: 0.891 \t\n",
      "\n",
      "Validation 366 valid_acc: 0.777 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 367 train_loss: 0.357 train_acc: 0.926 train_f1: 0.893 \t\n",
      "\n",
      "Validation 367 valid_acc: 0.787 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 368 train_loss: 0.351 train_acc: 0.929 train_f1: 0.891 \t\n",
      "\n",
      "Validation 368 valid_acc: 0.784 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 369 train_loss: 0.363 train_acc: 0.929 train_f1: 0.887 \t\n",
      "\n",
      "Validation 369 valid_acc: 0.769 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 370 train_loss: 0.358 train_acc: 0.927 train_f1: 0.893 \t\n",
      "\n",
      "Validation 370 valid_acc: 0.780 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 371 train_loss: 0.356 train_acc: 0.926 train_f1: 0.889 \t\n",
      "\n",
      "Validation 371 valid_acc: 0.777 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 372 train_loss: 0.354 train_acc: 0.926 train_f1: 0.892 \t\n",
      "\n",
      "Validation 372 valid_acc: 0.777 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 373 train_loss: 0.361 train_acc: 0.926 train_f1: 0.890 \t\n",
      "\n",
      "Validation 373 valid_acc: 0.767 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 374 train_loss: 0.360 train_acc: 0.927 train_f1: 0.893 \t\n",
      "\n",
      "Validation 374 valid_acc: 0.783 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 375 train_loss: 0.357 train_acc: 0.925 train_f1: 0.892 \t\n",
      "\n",
      "Validation 375 valid_acc: 0.783 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 376 train_loss: 0.356 train_acc: 0.927 train_f1: 0.892 \t\n",
      "\n",
      "Validation 376 valid_acc: 0.772 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 377 train_loss: 0.348 train_acc: 0.927 train_f1: 0.896 \t\n",
      "\n",
      "Validation 377 valid_acc: 0.784 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 378 train_loss: 0.355 train_acc: 0.928 train_f1: 0.891 \t\n",
      "\n",
      "Validation 378 valid_acc: 0.783 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 379 train_loss: 0.349 train_acc: 0.929 train_f1: 0.894 \t\n",
      "\n",
      "Validation 379 valid_acc: 0.781 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 380 train_loss: 0.349 train_acc: 0.929 train_f1: 0.893 \t\n",
      "\n",
      "Validation 380 valid_acc: 0.777 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 381 train_loss: 0.346 train_acc: 0.927 train_f1: 0.895 \t\n",
      "\n",
      "Validation 381 valid_acc: 0.770 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 382 train_loss: 0.348 train_acc: 0.929 train_f1: 0.898 \t\n",
      "\n",
      "Validation 382 valid_acc: 0.783 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 383 train_loss: 0.359 train_acc: 0.930 train_f1: 0.891 \t\n",
      "\n",
      "Validation 383 valid_acc: 0.784 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 384 train_loss: 0.349 train_acc: 0.929 train_f1: 0.896 \t\n",
      "\n",
      "Validation 384 valid_acc: 0.786 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 385 train_loss: 0.343 train_acc: 0.929 train_f1: 0.896 \t\n",
      "\n",
      "Validation 385 valid_acc: 0.779 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 386 train_loss: 0.348 train_acc: 0.930 train_f1: 0.897 \t\n",
      "\n",
      "Validation 386 valid_acc: 0.790 best_acc: 0.790 \t\n",
      "\n",
      "Epoch 387 train_loss: 0.350 train_acc: 0.929 train_f1: 0.893 \t\n",
      "\n",
      "Validation 387 valid_acc: 0.778 best_acc: 0.790 \t\n",
      "\n",
      "Epoch 388 train_loss: 0.346 train_acc: 0.928 train_f1: 0.895 \t\n",
      "\n",
      "Validation 388 valid_acc: 0.786 best_acc: 0.790 \t\n",
      "\n",
      "Epoch 389 train_loss: 0.343 train_acc: 0.932 train_f1: 0.900 \t\n",
      "\n",
      "Validation 389 valid_acc: 0.782 best_acc: 0.790 \t\n",
      "\n",
      "Epoch 390 train_loss: 0.345 train_acc: 0.929 train_f1: 0.896 \t\n",
      "\n",
      "Validation 390 valid_acc: 0.778 best_acc: 0.790 \t\n",
      "\n",
      "Epoch 391 train_loss: 0.341 train_acc: 0.929 train_f1: 0.899 \t\n",
      "\n",
      "Validation 391 valid_acc: 0.774 best_acc: 0.790 \t\n",
      "\n",
      "Epoch 392 train_loss: 0.346 train_acc: 0.929 train_f1: 0.894 \t\n",
      "\n",
      "Validation 392 valid_acc: 0.773 best_acc: 0.790 \t\n",
      "\n",
      "Epoch 393 train_loss: 0.342 train_acc: 0.931 train_f1: 0.898 \t\n",
      "\n",
      "Validation 393 valid_acc: 0.787 best_acc: 0.790 \t\n",
      "\n",
      "Epoch 394 train_loss: 0.340 train_acc: 0.934 train_f1: 0.901 \t\n",
      "\n",
      "Validation 394 valid_acc: 0.777 best_acc: 0.790 \t\n",
      "\n",
      "Epoch 395 train_loss: 0.340 train_acc: 0.932 train_f1: 0.900 \t\n",
      "\n",
      "Validation 395 valid_acc: 0.776 best_acc: 0.790 \t\n",
      "\n",
      "Epoch 396 train_loss: 0.346 train_acc: 0.928 train_f1: 0.892 \t\n",
      "\n",
      "Validation 396 valid_acc: 0.793 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 397 train_loss: 0.337 train_acc: 0.938 train_f1: 0.904 \t\n",
      "\n",
      "Validation 397 valid_acc: 0.787 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 398 train_loss: 0.339 train_acc: 0.935 train_f1: 0.904 \t\n",
      "\n",
      "Validation 398 valid_acc: 0.785 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 399 train_loss: 0.333 train_acc: 0.932 train_f1: 0.901 \t\n",
      "\n",
      "Validation 399 valid_acc: 0.772 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 400 train_loss: 0.338 train_acc: 0.933 train_f1: 0.900 \t\n",
      "\n",
      "Validation 400 valid_acc: 0.781 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 401 train_loss: 0.333 train_acc: 0.938 train_f1: 0.901 \t\n",
      "\n",
      "Validation 401 valid_acc: 0.786 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 402 train_loss: 0.342 train_acc: 0.932 train_f1: 0.902 \t\n",
      "\n",
      "Validation 402 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 403 train_loss: 0.342 train_acc: 0.930 train_f1: 0.897 \t\n",
      "\n",
      "Validation 403 valid_acc: 0.789 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 404 train_loss: 0.342 train_acc: 0.932 train_f1: 0.898 \t\n",
      "\n",
      "Validation 404 valid_acc: 0.773 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 405 train_loss: 0.333 train_acc: 0.937 train_f1: 0.902 \t\n",
      "\n",
      "Validation 405 valid_acc: 0.777 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 406 train_loss: 0.335 train_acc: 0.933 train_f1: 0.898 \t\n",
      "\n",
      "Validation 406 valid_acc: 0.779 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 407 train_loss: 0.338 train_acc: 0.934 train_f1: 0.903 \t\n",
      "\n",
      "Validation 407 valid_acc: 0.777 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 408 train_loss: 0.339 train_acc: 0.929 train_f1: 0.900 \t\n",
      "\n",
      "Validation 408 valid_acc: 0.789 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 409 train_loss: 0.331 train_acc: 0.936 train_f1: 0.905 \t\n",
      "\n",
      "Validation 409 valid_acc: 0.783 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 410 train_loss: 0.337 train_acc: 0.933 train_f1: 0.897 \t\n",
      "\n",
      "Validation 410 valid_acc: 0.771 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 411 train_loss: 0.329 train_acc: 0.938 train_f1: 0.905 \t\n",
      "\n",
      "Validation 411 valid_acc: 0.778 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 412 train_loss: 0.342 train_acc: 0.933 train_f1: 0.900 \t\n",
      "\n",
      "Validation 412 valid_acc: 0.781 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 413 train_loss: 0.325 train_acc: 0.935 train_f1: 0.904 \t\n",
      "\n",
      "Validation 413 valid_acc: 0.778 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 414 train_loss: 0.326 train_acc: 0.934 train_f1: 0.901 \t\n",
      "\n",
      "Validation 414 valid_acc: 0.777 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 415 train_loss: 0.333 train_acc: 0.935 train_f1: 0.905 \t\n",
      "\n",
      "Validation 415 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 416 train_loss: 0.327 train_acc: 0.930 train_f1: 0.901 \t\n",
      "\n",
      "Validation 416 valid_acc: 0.778 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 417 train_loss: 0.332 train_acc: 0.936 train_f1: 0.904 \t\n",
      "\n",
      "Validation 417 valid_acc: 0.783 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 418 train_loss: 0.328 train_acc: 0.937 train_f1: 0.906 \t\n",
      "\n",
      "Validation 418 valid_acc: 0.786 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 419 train_loss: 0.331 train_acc: 0.931 train_f1: 0.900 \t\n",
      "\n",
      "Validation 419 valid_acc: 0.768 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 420 train_loss: 0.331 train_acc: 0.932 train_f1: 0.903 \t\n",
      "\n",
      "Validation 420 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 421 train_loss: 0.323 train_acc: 0.938 train_f1: 0.906 \t\n",
      "\n",
      "Validation 421 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 422 train_loss: 0.334 train_acc: 0.934 train_f1: 0.901 \t\n",
      "\n",
      "Validation 422 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 423 train_loss: 0.328 train_acc: 0.934 train_f1: 0.907 \t\n",
      "\n",
      "Validation 423 valid_acc: 0.785 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 424 train_loss: 0.326 train_acc: 0.938 train_f1: 0.905 \t\n",
      "\n",
      "Validation 424 valid_acc: 0.781 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 425 train_loss: 0.329 train_acc: 0.936 train_f1: 0.904 \t\n",
      "\n",
      "Validation 425 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 426 train_loss: 0.327 train_acc: 0.936 train_f1: 0.904 \t\n",
      "\n",
      "Validation 426 valid_acc: 0.779 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 427 train_loss: 0.324 train_acc: 0.937 train_f1: 0.907 \t\n",
      "\n",
      "Validation 427 valid_acc: 0.769 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 428 train_loss: 0.323 train_acc: 0.936 train_f1: 0.908 \t\n",
      "\n",
      "Validation 428 valid_acc: 0.777 best_acc: 0.793 \t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 429 train_loss: 0.325 train_acc: 0.936 train_f1: 0.907 \t\n",
      "\n",
      "Validation 429 valid_acc: 0.779 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 430 train_loss: 0.320 train_acc: 0.938 train_f1: 0.907 \t\n",
      "\n",
      "Validation 430 valid_acc: 0.783 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 431 train_loss: 0.322 train_acc: 0.934 train_f1: 0.908 \t\n",
      "\n",
      "Validation 431 valid_acc: 0.770 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 432 train_loss: 0.318 train_acc: 0.939 train_f1: 0.909 \t\n",
      "\n",
      "Validation 432 valid_acc: 0.781 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 433 train_loss: 0.320 train_acc: 0.939 train_f1: 0.910 \t\n",
      "\n",
      "Validation 433 valid_acc: 0.779 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 434 train_loss: 0.319 train_acc: 0.939 train_f1: 0.910 \t\n",
      "\n",
      "Validation 434 valid_acc: 0.774 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 435 train_loss: 0.320 train_acc: 0.941 train_f1: 0.909 \t\n",
      "\n",
      "Validation 435 valid_acc: 0.790 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 436 train_loss: 0.317 train_acc: 0.935 train_f1: 0.910 \t\n",
      "\n",
      "Validation 436 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 437 train_loss: 0.324 train_acc: 0.936 train_f1: 0.909 \t\n",
      "\n",
      "Validation 437 valid_acc: 0.783 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 438 train_loss: 0.317 train_acc: 0.940 train_f1: 0.907 \t\n",
      "\n",
      "Validation 438 valid_acc: 0.777 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 439 train_loss: 0.324 train_acc: 0.936 train_f1: 0.905 \t\n",
      "\n",
      "Validation 439 valid_acc: 0.765 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 440 train_loss: 0.317 train_acc: 0.941 train_f1: 0.910 \t\n",
      "\n",
      "Validation 440 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 441 train_loss: 0.317 train_acc: 0.937 train_f1: 0.909 \t\n",
      "\n",
      "Validation 441 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 442 train_loss: 0.318 train_acc: 0.938 train_f1: 0.910 \t\n",
      "\n",
      "Validation 442 valid_acc: 0.778 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 443 train_loss: 0.326 train_acc: 0.937 train_f1: 0.901 \t\n",
      "\n",
      "Validation 443 valid_acc: 0.768 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 444 train_loss: 0.318 train_acc: 0.940 train_f1: 0.909 \t\n",
      "\n",
      "Validation 444 valid_acc: 0.783 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 445 train_loss: 0.314 train_acc: 0.941 train_f1: 0.906 \t\n",
      "\n",
      "Validation 445 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 446 train_loss: 0.319 train_acc: 0.938 train_f1: 0.909 \t\n",
      "\n",
      "Validation 446 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 447 train_loss: 0.315 train_acc: 0.940 train_f1: 0.906 \t\n",
      "\n",
      "Validation 447 valid_acc: 0.779 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 448 train_loss: 0.311 train_acc: 0.941 train_f1: 0.914 \t\n",
      "\n",
      "Validation 448 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 449 train_loss: 0.313 train_acc: 0.941 train_f1: 0.909 \t\n",
      "\n",
      "Validation 449 valid_acc: 0.783 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 450 train_loss: 0.308 train_acc: 0.947 train_f1: 0.914 \t\n",
      "\n",
      "Validation 450 valid_acc: 0.782 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 451 train_loss: 0.315 train_acc: 0.941 train_f1: 0.909 \t\n",
      "\n",
      "Validation 451 valid_acc: 0.787 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 452 train_loss: 0.315 train_acc: 0.938 train_f1: 0.905 \t\n",
      "\n",
      "Validation 452 valid_acc: 0.777 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 453 train_loss: 0.314 train_acc: 0.941 train_f1: 0.913 \t\n",
      "\n",
      "Validation 453 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 454 train_loss: 0.313 train_acc: 0.944 train_f1: 0.912 \t\n",
      "\n",
      "Validation 454 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 455 train_loss: 0.311 train_acc: 0.941 train_f1: 0.909 \t\n",
      "\n",
      "Validation 455 valid_acc: 0.785 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 456 train_loss: 0.305 train_acc: 0.947 train_f1: 0.914 \t\n",
      "\n",
      "Validation 456 valid_acc: 0.773 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 457 train_loss: 0.307 train_acc: 0.946 train_f1: 0.916 \t\n",
      "\n",
      "Validation 457 valid_acc: 0.781 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 458 train_loss: 0.308 train_acc: 0.942 train_f1: 0.913 \t\n",
      "\n",
      "Validation 458 valid_acc: 0.774 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 459 train_loss: 0.309 train_acc: 0.942 train_f1: 0.913 \t\n",
      "\n",
      "Validation 459 valid_acc: 0.772 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 460 train_loss: 0.310 train_acc: 0.942 train_f1: 0.913 \t\n",
      "\n",
      "Validation 460 valid_acc: 0.785 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 461 train_loss: 0.311 train_acc: 0.943 train_f1: 0.912 \t\n",
      "\n",
      "Validation 461 valid_acc: 0.774 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 462 train_loss: 0.315 train_acc: 0.936 train_f1: 0.909 \t\n",
      "\n",
      "Validation 462 valid_acc: 0.778 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 463 train_loss: 0.308 train_acc: 0.941 train_f1: 0.914 \t\n",
      "\n",
      "Validation 463 valid_acc: 0.774 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 464 train_loss: 0.314 train_acc: 0.941 train_f1: 0.910 \t\n",
      "\n",
      "Validation 464 valid_acc: 0.783 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 465 train_loss: 0.306 train_acc: 0.942 train_f1: 0.913 \t\n",
      "\n",
      "Validation 465 valid_acc: 0.771 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 466 train_loss: 0.308 train_acc: 0.939 train_f1: 0.912 \t\n",
      "\n",
      "Validation 466 valid_acc: 0.778 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 467 train_loss: 0.298 train_acc: 0.945 train_f1: 0.916 \t\n",
      "\n",
      "Validation 467 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 468 train_loss: 0.305 train_acc: 0.940 train_f1: 0.916 \t\n",
      "\n",
      "Validation 468 valid_acc: 0.783 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 469 train_loss: 0.302 train_acc: 0.940 train_f1: 0.915 \t\n",
      "\n",
      "Validation 469 valid_acc: 0.783 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 470 train_loss: 0.305 train_acc: 0.946 train_f1: 0.915 \t\n",
      "\n",
      "Validation 470 valid_acc: 0.778 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 471 train_loss: 0.306 train_acc: 0.943 train_f1: 0.915 \t\n",
      "\n",
      "Validation 471 valid_acc: 0.783 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 472 train_loss: 0.305 train_acc: 0.946 train_f1: 0.917 \t\n",
      "\n",
      "Validation 472 valid_acc: 0.787 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 473 train_loss: 0.304 train_acc: 0.941 train_f1: 0.913 \t\n",
      "\n",
      "Validation 473 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 474 train_loss: 0.299 train_acc: 0.946 train_f1: 0.921 \t\n",
      "\n",
      "Validation 474 valid_acc: 0.775 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 475 train_loss: 0.299 train_acc: 0.945 train_f1: 0.915 \t\n",
      "\n",
      "Validation 475 valid_acc: 0.787 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 476 train_loss: 0.291 train_acc: 0.950 train_f1: 0.922 \t\n",
      "\n",
      "Validation 476 valid_acc: 0.785 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 477 train_loss: 0.298 train_acc: 0.948 train_f1: 0.918 \t\n",
      "\n",
      "Validation 477 valid_acc: 0.781 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 478 train_loss: 0.302 train_acc: 0.942 train_f1: 0.915 \t\n",
      "\n",
      "Validation 478 valid_acc: 0.785 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 479 train_loss: 0.311 train_acc: 0.938 train_f1: 0.909 \t\n",
      "\n",
      "Validation 479 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 480 train_loss: 0.296 train_acc: 0.944 train_f1: 0.917 \t\n",
      "\n",
      "Validation 480 valid_acc: 0.782 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 481 train_loss: 0.299 train_acc: 0.943 train_f1: 0.918 \t\n",
      "\n",
      "Validation 481 valid_acc: 0.781 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 482 train_loss: 0.300 train_acc: 0.944 train_f1: 0.916 \t\n",
      "\n",
      "Validation 482 valid_acc: 0.782 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 483 train_loss: 0.301 train_acc: 0.946 train_f1: 0.917 \t\n",
      "\n",
      "Validation 483 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 484 train_loss: 0.303 train_acc: 0.945 train_f1: 0.917 \t\n",
      "\n",
      "Validation 484 valid_acc: 0.774 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 485 train_loss: 0.303 train_acc: 0.940 train_f1: 0.916 \t\n",
      "\n",
      "Validation 485 valid_acc: 0.783 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 486 train_loss: 0.299 train_acc: 0.944 train_f1: 0.917 \t\n",
      "\n",
      "Validation 486 valid_acc: 0.763 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 487 train_loss: 0.290 train_acc: 0.947 train_f1: 0.923 \t\n",
      "\n",
      "Validation 487 valid_acc: 0.778 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 488 train_loss: 0.299 train_acc: 0.942 train_f1: 0.919 \t\n",
      "\n",
      "Validation 488 valid_acc: 0.785 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 489 train_loss: 0.292 train_acc: 0.951 train_f1: 0.921 \t\n",
      "\n",
      "Validation 489 valid_acc: 0.782 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 490 train_loss: 0.300 train_acc: 0.942 train_f1: 0.916 \t\n",
      "\n",
      "Validation 490 valid_acc: 0.790 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 491 train_loss: 0.294 train_acc: 0.946 train_f1: 0.921 \t\n",
      "\n",
      "Validation 491 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 492 train_loss: 0.292 train_acc: 0.946 train_f1: 0.918 \t\n",
      "\n",
      "Validation 492 valid_acc: 0.782 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 493 train_loss: 0.290 train_acc: 0.947 train_f1: 0.922 \t\n",
      "\n",
      "Validation 493 valid_acc: 0.783 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 494 train_loss: 0.289 train_acc: 0.947 train_f1: 0.922 \t\n",
      "\n",
      "Validation 494 valid_acc: 0.779 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 495 train_loss: 0.295 train_acc: 0.945 train_f1: 0.917 \t\n",
      "\n",
      "Validation 495 valid_acc: 0.779 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 496 train_loss: 0.293 train_acc: 0.946 train_f1: 0.919 \t\n",
      "\n",
      "Validation 496 valid_acc: 0.783 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 497 train_loss: 0.287 train_acc: 0.949 train_f1: 0.924 \t\n",
      "\n",
      "Validation 497 valid_acc: 0.790 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 498 train_loss: 0.295 train_acc: 0.946 train_f1: 0.919 \t\n",
      "\n",
      "Validation 498 valid_acc: 0.773 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 499 train_loss: 0.295 train_acc: 0.946 train_f1: 0.921 \t\n",
      "\n",
      "Validation 499 valid_acc: 0.774 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 500 train_loss: 0.295 train_acc: 0.945 train_f1: 0.920 \t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation 500 valid_acc: 0.775 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 501 train_loss: 0.283 train_acc: 0.949 train_f1: 0.922 \t\n",
      "\n",
      "Validation 501 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 502 train_loss: 0.293 train_acc: 0.947 train_f1: 0.920 \t\n",
      "\n",
      "Validation 502 valid_acc: 0.772 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 503 train_loss: 0.285 train_acc: 0.950 train_f1: 0.922 \t\n",
      "\n",
      "Validation 503 valid_acc: 0.769 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 504 train_loss: 0.292 train_acc: 0.949 train_f1: 0.921 \t\n",
      "\n",
      "Validation 504 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 505 train_loss: 0.287 train_acc: 0.946 train_f1: 0.924 \t\n",
      "\n",
      "Validation 505 valid_acc: 0.786 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 506 train_loss: 0.291 train_acc: 0.948 train_f1: 0.924 \t\n",
      "\n",
      "Validation 506 valid_acc: 0.773 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 507 train_loss: 0.293 train_acc: 0.946 train_f1: 0.920 \t\n",
      "\n",
      "Validation 507 valid_acc: 0.783 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 508 train_loss: 0.287 train_acc: 0.947 train_f1: 0.924 \t\n",
      "\n",
      "Validation 508 valid_acc: 0.787 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 509 train_loss: 0.283 train_acc: 0.948 train_f1: 0.924 \t\n",
      "\n",
      "Validation 509 valid_acc: 0.778 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 510 train_loss: 0.280 train_acc: 0.949 train_f1: 0.924 \t\n",
      "\n",
      "Validation 510 valid_acc: 0.787 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 511 train_loss: 0.284 train_acc: 0.951 train_f1: 0.925 \t\n",
      "\n",
      "Validation 511 valid_acc: 0.783 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 512 train_loss: 0.291 train_acc: 0.948 train_f1: 0.919 \t\n",
      "\n",
      "Validation 512 valid_acc: 0.783 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 513 train_loss: 0.287 train_acc: 0.952 train_f1: 0.925 \t\n",
      "\n",
      "Validation 513 valid_acc: 0.770 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 514 train_loss: 0.291 train_acc: 0.949 train_f1: 0.919 \t\n",
      "\n",
      "Validation 514 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 515 train_loss: 0.288 train_acc: 0.945 train_f1: 0.924 \t\n",
      "\n",
      "Validation 515 valid_acc: 0.784 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 516 train_loss: 0.282 train_acc: 0.949 train_f1: 0.927 \t\n",
      "\n",
      "Validation 516 valid_acc: 0.781 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 517 train_loss: 0.286 train_acc: 0.948 train_f1: 0.923 \t\n",
      "\n",
      "Validation 517 valid_acc: 0.783 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 518 train_loss: 0.287 train_acc: 0.947 train_f1: 0.923 \t\n",
      "\n",
      "Validation 518 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 519 train_loss: 0.279 train_acc: 0.950 train_f1: 0.927 \t\n",
      "\n",
      "Validation 519 valid_acc: 0.769 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 520 train_loss: 0.280 train_acc: 0.948 train_f1: 0.929 \t\n",
      "\n",
      "Validation 520 valid_acc: 0.770 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 521 train_loss: 0.283 train_acc: 0.950 train_f1: 0.925 \t\n",
      "\n",
      "Validation 521 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 522 train_loss: 0.284 train_acc: 0.946 train_f1: 0.922 \t\n",
      "\n",
      "Validation 522 valid_acc: 0.772 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 523 train_loss: 0.284 train_acc: 0.950 train_f1: 0.923 \t\n",
      "\n",
      "Validation 523 valid_acc: 0.783 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 524 train_loss: 0.275 train_acc: 0.953 train_f1: 0.928 \t\n",
      "\n",
      "Validation 524 valid_acc: 0.778 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 525 train_loss: 0.285 train_acc: 0.946 train_f1: 0.921 \t\n",
      "\n",
      "Validation 525 valid_acc: 0.770 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 526 train_loss: 0.275 train_acc: 0.950 train_f1: 0.929 \t\n",
      "\n",
      "Validation 526 valid_acc: 0.774 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 527 train_loss: 0.281 train_acc: 0.949 train_f1: 0.927 \t\n",
      "\n",
      "Validation 527 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 528 train_loss: 0.280 train_acc: 0.951 train_f1: 0.927 \t\n",
      "\n",
      "Validation 528 valid_acc: 0.771 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 529 train_loss: 0.274 train_acc: 0.954 train_f1: 0.930 \t\n",
      "\n",
      "Validation 529 valid_acc: 0.772 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 530 train_loss: 0.282 train_acc: 0.948 train_f1: 0.925 \t\n",
      "\n",
      "Validation 530 valid_acc: 0.777 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 531 train_loss: 0.274 train_acc: 0.951 train_f1: 0.929 \t\n",
      "\n",
      "Validation 531 valid_acc: 0.778 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 532 train_loss: 0.281 train_acc: 0.952 train_f1: 0.925 \t\n",
      "\n",
      "Validation 532 valid_acc: 0.778 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 533 train_loss: 0.277 train_acc: 0.952 train_f1: 0.927 \t\n",
      "\n",
      "Validation 533 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 534 train_loss: 0.279 train_acc: 0.948 train_f1: 0.927 \t\n",
      "\n",
      "Validation 534 valid_acc: 0.787 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 535 train_loss: 0.280 train_acc: 0.950 train_f1: 0.924 \t\n",
      "\n",
      "Validation 535 valid_acc: 0.775 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 536 train_loss: 0.276 train_acc: 0.953 train_f1: 0.926 \t\n",
      "\n",
      "Validation 536 valid_acc: 0.773 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 537 train_loss: 0.277 train_acc: 0.952 train_f1: 0.926 \t\n",
      "\n",
      "Validation 537 valid_acc: 0.771 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 538 train_loss: 0.273 train_acc: 0.955 train_f1: 0.931 \t\n",
      "\n",
      "Validation 538 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 539 train_loss: 0.281 train_acc: 0.948 train_f1: 0.925 \t\n",
      "\n",
      "Validation 539 valid_acc: 0.770 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 540 train_loss: 0.274 train_acc: 0.952 train_f1: 0.929 \t\n",
      "\n",
      "Validation 540 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 541 train_loss: 0.272 train_acc: 0.950 train_f1: 0.926 \t\n",
      "\n",
      "Validation 541 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 542 train_loss: 0.273 train_acc: 0.951 train_f1: 0.928 \t\n",
      "\n",
      "Validation 542 valid_acc: 0.782 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 543 train_loss: 0.275 train_acc: 0.950 train_f1: 0.926 \t\n",
      "\n",
      "Validation 543 valid_acc: 0.777 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 544 train_loss: 0.272 train_acc: 0.950 train_f1: 0.930 \t\n",
      "\n",
      "Validation 544 valid_acc: 0.782 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 545 train_loss: 0.270 train_acc: 0.953 train_f1: 0.931 \t\n",
      "\n",
      "Validation 545 valid_acc: 0.781 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 546 train_loss: 0.271 train_acc: 0.951 train_f1: 0.930 \t\n",
      "\n",
      "Validation 546 valid_acc: 0.779 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 547 train_loss: 0.273 train_acc: 0.950 train_f1: 0.925 \t\n",
      "\n",
      "Validation 547 valid_acc: 0.772 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 548 train_loss: 0.270 train_acc: 0.957 train_f1: 0.932 \t\n",
      "\n",
      "Validation 548 valid_acc: 0.774 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 549 train_loss: 0.270 train_acc: 0.952 train_f1: 0.930 \t\n",
      "\n",
      "Validation 549 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 550 train_loss: 0.271 train_acc: 0.953 train_f1: 0.929 \t\n",
      "\n",
      "Validation 550 valid_acc: 0.783 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 551 train_loss: 0.271 train_acc: 0.953 train_f1: 0.931 \t\n",
      "\n",
      "Validation 551 valid_acc: 0.783 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 552 train_loss: 0.264 train_acc: 0.957 train_f1: 0.933 \t\n",
      "\n",
      "Validation 552 valid_acc: 0.781 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 553 train_loss: 0.269 train_acc: 0.951 train_f1: 0.929 \t\n",
      "\n",
      "Validation 553 valid_acc: 0.781 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 554 train_loss: 0.263 train_acc: 0.955 train_f1: 0.934 \t\n",
      "\n",
      "Validation 554 valid_acc: 0.789 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 555 train_loss: 0.274 train_acc: 0.949 train_f1: 0.926 \t\n",
      "\n",
      "Validation 555 valid_acc: 0.783 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 556 train_loss: 0.267 train_acc: 0.955 train_f1: 0.931 \t\n",
      "\n",
      "Validation 556 valid_acc: 0.783 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 557 train_loss: 0.271 train_acc: 0.953 train_f1: 0.929 \t\n",
      "\n",
      "Validation 557 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 558 train_loss: 0.270 train_acc: 0.952 train_f1: 0.931 \t\n",
      "\n",
      "Validation 558 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 559 train_loss: 0.270 train_acc: 0.951 train_f1: 0.931 \t\n",
      "\n",
      "Validation 559 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 560 train_loss: 0.268 train_acc: 0.954 train_f1: 0.931 \t\n",
      "\n",
      "Validation 560 valid_acc: 0.779 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 561 train_loss: 0.268 train_acc: 0.952 train_f1: 0.931 \t\n",
      "\n",
      "Validation 561 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 562 train_loss: 0.266 train_acc: 0.953 train_f1: 0.930 \t\n",
      "\n",
      "Validation 562 valid_acc: 0.782 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 563 train_loss: 0.264 train_acc: 0.953 train_f1: 0.932 \t\n",
      "\n",
      "Validation 563 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 564 train_loss: 0.265 train_acc: 0.953 train_f1: 0.930 \t\n",
      "\n",
      "Validation 564 valid_acc: 0.770 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 565 train_loss: 0.263 train_acc: 0.955 train_f1: 0.932 \t\n",
      "\n",
      "Validation 565 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 566 train_loss: 0.264 train_acc: 0.950 train_f1: 0.929 \t\n",
      "\n",
      "Validation 566 valid_acc: 0.779 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 567 train_loss: 0.265 train_acc: 0.953 train_f1: 0.929 \t\n",
      "\n",
      "Validation 567 valid_acc: 0.772 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 568 train_loss: 0.264 train_acc: 0.954 train_f1: 0.933 \t\n",
      "\n",
      "Validation 568 valid_acc: 0.784 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 569 train_loss: 0.267 train_acc: 0.953 train_f1: 0.930 \t\n",
      "\n",
      "Validation 569 valid_acc: 0.783 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 570 train_loss: 0.260 train_acc: 0.957 train_f1: 0.933 \t\n",
      "\n",
      "Validation 570 valid_acc: 0.783 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 571 train_loss: 0.265 train_acc: 0.952 train_f1: 0.930 \t\n",
      "\n",
      "Validation 571 valid_acc: 0.780 best_acc: 0.793 \t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 572 train_loss: 0.267 train_acc: 0.953 train_f1: 0.933 \t\n",
      "\n",
      "Validation 572 valid_acc: 0.770 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 573 train_loss: 0.259 train_acc: 0.957 train_f1: 0.934 \t\n",
      "\n",
      "Validation 573 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 574 train_loss: 0.267 train_acc: 0.955 train_f1: 0.928 \t\n",
      "\n",
      "Validation 574 valid_acc: 0.770 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 575 train_loss: 0.264 train_acc: 0.956 train_f1: 0.933 \t\n",
      "\n",
      "Validation 575 valid_acc: 0.785 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 576 train_loss: 0.260 train_acc: 0.957 train_f1: 0.935 \t\n",
      "\n",
      "Validation 576 valid_acc: 0.787 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 577 train_loss: 0.265 train_acc: 0.952 train_f1: 0.928 \t\n",
      "\n",
      "Validation 577 valid_acc: 0.783 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 578 train_loss: 0.263 train_acc: 0.953 train_f1: 0.932 \t\n",
      "\n",
      "Validation 578 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 579 train_loss: 0.265 train_acc: 0.953 train_f1: 0.929 \t\n",
      "\n",
      "Validation 579 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 580 train_loss: 0.258 train_acc: 0.955 train_f1: 0.932 \t\n",
      "\n",
      "Validation 580 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 581 train_loss: 0.261 train_acc: 0.956 train_f1: 0.933 \t\n",
      "\n",
      "Validation 581 valid_acc: 0.781 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 582 train_loss: 0.260 train_acc: 0.959 train_f1: 0.935 \t\n",
      "\n",
      "Validation 582 valid_acc: 0.787 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 583 train_loss: 0.259 train_acc: 0.954 train_f1: 0.934 \t\n",
      "\n",
      "Validation 583 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 584 train_loss: 0.260 train_acc: 0.953 train_f1: 0.931 \t\n",
      "\n",
      "Validation 584 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 585 train_loss: 0.258 train_acc: 0.956 train_f1: 0.932 \t\n",
      "\n",
      "Validation 585 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 586 train_loss: 0.254 train_acc: 0.958 train_f1: 0.936 \t\n",
      "\n",
      "Validation 586 valid_acc: 0.769 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 587 train_loss: 0.257 train_acc: 0.957 train_f1: 0.934 \t\n",
      "\n",
      "Validation 587 valid_acc: 0.768 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 588 train_loss: 0.258 train_acc: 0.954 train_f1: 0.932 \t\n",
      "\n",
      "Validation 588 valid_acc: 0.779 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 589 train_loss: 0.264 train_acc: 0.955 train_f1: 0.929 \t\n",
      "\n",
      "Validation 589 valid_acc: 0.774 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 590 train_loss: 0.252 train_acc: 0.958 train_f1: 0.936 \t\n",
      "\n",
      "Validation 590 valid_acc: 0.769 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 591 train_loss: 0.257 train_acc: 0.953 train_f1: 0.932 \t\n",
      "\n",
      "Validation 591 valid_acc: 0.777 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 592 train_loss: 0.257 train_acc: 0.954 train_f1: 0.932 \t\n",
      "\n",
      "Validation 592 valid_acc: 0.782 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 593 train_loss: 0.254 train_acc: 0.959 train_f1: 0.936 \t\n",
      "\n",
      "Validation 593 valid_acc: 0.771 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 594 train_loss: 0.253 train_acc: 0.956 train_f1: 0.936 \t\n",
      "\n",
      "Validation 594 valid_acc: 0.778 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 595 train_loss: 0.256 train_acc: 0.955 train_f1: 0.932 \t\n",
      "\n",
      "Validation 595 valid_acc: 0.779 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 596 train_loss: 0.255 train_acc: 0.956 train_f1: 0.936 \t\n",
      "\n",
      "Validation 596 valid_acc: 0.775 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 597 train_loss: 0.258 train_acc: 0.957 train_f1: 0.938 \t\n",
      "\n",
      "Validation 597 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 598 train_loss: 0.252 train_acc: 0.956 train_f1: 0.937 \t\n",
      "\n",
      "Validation 598 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 599 train_loss: 0.251 train_acc: 0.960 train_f1: 0.937 \t\n",
      "\n",
      "Validation 599 valid_acc: 0.775 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 600 train_loss: 0.253 train_acc: 0.954 train_f1: 0.936 \t\n",
      "\n",
      "Validation 600 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 601 train_loss: 0.250 train_acc: 0.958 train_f1: 0.936 \t\n",
      "\n",
      "Validation 601 valid_acc: 0.785 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 602 train_loss: 0.251 train_acc: 0.957 train_f1: 0.937 \t\n",
      "\n",
      "Validation 602 valid_acc: 0.773 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 603 train_loss: 0.247 train_acc: 0.959 train_f1: 0.937 \t\n",
      "\n",
      "Validation 603 valid_acc: 0.773 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 604 train_loss: 0.249 train_acc: 0.954 train_f1: 0.937 \t\n",
      "\n",
      "Validation 604 valid_acc: 0.783 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 605 train_loss: 0.250 train_acc: 0.958 train_f1: 0.935 \t\n",
      "\n",
      "Validation 605 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 606 train_loss: 0.247 train_acc: 0.959 train_f1: 0.936 \t\n",
      "\n",
      "Validation 606 valid_acc: 0.782 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 607 train_loss: 0.252 train_acc: 0.958 train_f1: 0.936 \t\n",
      "\n",
      "Validation 607 valid_acc: 0.774 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 608 train_loss: 0.247 train_acc: 0.958 train_f1: 0.939 \t\n",
      "\n",
      "Validation 608 valid_acc: 0.775 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 609 train_loss: 0.256 train_acc: 0.957 train_f1: 0.935 \t\n",
      "\n",
      "Validation 609 valid_acc: 0.783 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 610 train_loss: 0.255 train_acc: 0.958 train_f1: 0.937 \t\n",
      "\n",
      "Validation 610 valid_acc: 0.770 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 611 train_loss: 0.257 train_acc: 0.955 train_f1: 0.935 \t\n",
      "\n",
      "Validation 611 valid_acc: 0.787 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 612 train_loss: 0.245 train_acc: 0.961 train_f1: 0.942 \t\n",
      "\n",
      "Validation 612 valid_acc: 0.778 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 613 train_loss: 0.251 train_acc: 0.957 train_f1: 0.935 \t\n",
      "\n",
      "Validation 613 valid_acc: 0.771 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 614 train_loss: 0.248 train_acc: 0.957 train_f1: 0.936 \t\n",
      "\n",
      "Validation 614 valid_acc: 0.775 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 615 train_loss: 0.257 train_acc: 0.953 train_f1: 0.933 \t\n",
      "\n",
      "Validation 615 valid_acc: 0.768 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 616 train_loss: 0.246 train_acc: 0.957 train_f1: 0.937 \t\n",
      "\n",
      "Validation 616 valid_acc: 0.772 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 617 train_loss: 0.251 train_acc: 0.956 train_f1: 0.933 \t\n",
      "\n",
      "Validation 617 valid_acc: 0.778 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 618 train_loss: 0.250 train_acc: 0.960 train_f1: 0.936 \t\n",
      "\n",
      "Validation 618 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 619 train_loss: 0.250 train_acc: 0.958 train_f1: 0.937 \t\n",
      "\n",
      "Validation 619 valid_acc: 0.785 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 620 train_loss: 0.248 train_acc: 0.958 train_f1: 0.937 \t\n",
      "\n",
      "Validation 620 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 621 train_loss: 0.247 train_acc: 0.960 train_f1: 0.937 \t\n",
      "\n",
      "Validation 621 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 622 train_loss: 0.247 train_acc: 0.960 train_f1: 0.938 \t\n",
      "\n",
      "Validation 622 valid_acc: 0.783 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 623 train_loss: 0.253 train_acc: 0.959 train_f1: 0.937 \t\n",
      "\n",
      "Validation 623 valid_acc: 0.786 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 624 train_loss: 0.247 train_acc: 0.961 train_f1: 0.937 \t\n",
      "\n",
      "Validation 624 valid_acc: 0.777 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 625 train_loss: 0.246 train_acc: 0.961 train_f1: 0.938 \t\n",
      "\n",
      "Validation 625 valid_acc: 0.779 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 626 train_loss: 0.247 train_acc: 0.958 train_f1: 0.937 \t\n",
      "\n",
      "Validation 626 valid_acc: 0.790 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 627 train_loss: 0.248 train_acc: 0.958 train_f1: 0.937 \t\n",
      "\n",
      "Validation 627 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 628 train_loss: 0.244 train_acc: 0.960 train_f1: 0.939 \t\n",
      "\n",
      "Validation 628 valid_acc: 0.773 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 629 train_loss: 0.242 train_acc: 0.959 train_f1: 0.940 \t\n",
      "\n",
      "Validation 629 valid_acc: 0.783 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 630 train_loss: 0.247 train_acc: 0.959 train_f1: 0.936 \t\n",
      "\n",
      "Validation 630 valid_acc: 0.775 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 631 train_loss: 0.251 train_acc: 0.956 train_f1: 0.937 \t\n",
      "\n",
      "Validation 631 valid_acc: 0.777 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 632 train_loss: 0.244 train_acc: 0.961 train_f1: 0.942 \t\n",
      "\n",
      "Validation 632 valid_acc: 0.770 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 633 train_loss: 0.243 train_acc: 0.963 train_f1: 0.941 \t\n",
      "\n",
      "Validation 633 valid_acc: 0.782 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 634 train_loss: 0.249 train_acc: 0.960 train_f1: 0.940 \t\n",
      "\n",
      "Validation 634 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 635 train_loss: 0.244 train_acc: 0.959 train_f1: 0.939 \t\n",
      "\n",
      "Validation 635 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 636 train_loss: 0.242 train_acc: 0.960 train_f1: 0.939 \t\n",
      "\n",
      "Validation 636 valid_acc: 0.774 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 637 train_loss: 0.245 train_acc: 0.961 train_f1: 0.938 \t\n",
      "\n",
      "Validation 637 valid_acc: 0.770 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 638 train_loss: 0.244 train_acc: 0.961 train_f1: 0.939 \t\n",
      "\n",
      "Validation 638 valid_acc: 0.773 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 639 train_loss: 0.252 train_acc: 0.957 train_f1: 0.938 \t\n",
      "\n",
      "Validation 639 valid_acc: 0.779 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 640 train_loss: 0.242 train_acc: 0.960 train_f1: 0.939 \t\n",
      "\n",
      "Validation 640 valid_acc: 0.769 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 641 train_loss: 0.240 train_acc: 0.959 train_f1: 0.943 \t\n",
      "\n",
      "Validation 641 valid_acc: 0.782 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 642 train_loss: 0.245 train_acc: 0.961 train_f1: 0.939 \t\n",
      "\n",
      "Validation 642 valid_acc: 0.770 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 643 train_loss: 0.236 train_acc: 0.962 train_f1: 0.942 \t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation 643 valid_acc: 0.773 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 644 train_loss: 0.245 train_acc: 0.961 train_f1: 0.938 \t\n",
      "\n",
      "Validation 644 valid_acc: 0.777 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 645 train_loss: 0.242 train_acc: 0.961 train_f1: 0.939 \t\n",
      "\n",
      "Validation 645 valid_acc: 0.790 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 646 train_loss: 0.242 train_acc: 0.960 train_f1: 0.940 \t\n",
      "\n",
      "Validation 646 valid_acc: 0.778 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 647 train_loss: 0.230 train_acc: 0.964 train_f1: 0.944 \t\n",
      "\n",
      "Validation 647 valid_acc: 0.769 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 648 train_loss: 0.246 train_acc: 0.960 train_f1: 0.939 \t\n",
      "\n",
      "Validation 648 valid_acc: 0.771 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 649 train_loss: 0.241 train_acc: 0.962 train_f1: 0.939 \t\n",
      "\n",
      "Validation 649 valid_acc: 0.777 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 650 train_loss: 0.235 train_acc: 0.963 train_f1: 0.943 \t\n",
      "\n",
      "Validation 650 valid_acc: 0.779 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 651 train_loss: 0.235 train_acc: 0.959 train_f1: 0.941 \t\n",
      "\n",
      "Validation 651 valid_acc: 0.775 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 652 train_loss: 0.238 train_acc: 0.962 train_f1: 0.942 \t\n",
      "\n",
      "Validation 652 valid_acc: 0.773 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 653 train_loss: 0.237 train_acc: 0.961 train_f1: 0.942 \t\n",
      "\n",
      "Validation 653 valid_acc: 0.779 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 654 train_loss: 0.236 train_acc: 0.959 train_f1: 0.942 \t\n",
      "\n",
      "Validation 654 valid_acc: 0.783 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 655 train_loss: 0.233 train_acc: 0.962 train_f1: 0.943 \t\n",
      "\n",
      "Validation 655 valid_acc: 0.782 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 656 train_loss: 0.235 train_acc: 0.961 train_f1: 0.941 \t\n",
      "\n",
      "Validation 656 valid_acc: 0.769 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 657 train_loss: 0.231 train_acc: 0.963 train_f1: 0.945 \t\n",
      "\n",
      "Validation 657 valid_acc: 0.782 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 658 train_loss: 0.237 train_acc: 0.959 train_f1: 0.941 \t\n",
      "\n",
      "Validation 658 valid_acc: 0.782 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 659 train_loss: 0.235 train_acc: 0.961 train_f1: 0.942 \t\n",
      "\n",
      "Validation 659 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 660 train_loss: 0.235 train_acc: 0.962 train_f1: 0.943 \t\n",
      "\n",
      "Validation 660 valid_acc: 0.783 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 661 train_loss: 0.241 train_acc: 0.962 train_f1: 0.940 \t\n",
      "\n",
      "Validation 661 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 662 train_loss: 0.241 train_acc: 0.958 train_f1: 0.938 \t\n",
      "\n",
      "Validation 662 valid_acc: 0.783 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 663 train_loss: 0.236 train_acc: 0.963 train_f1: 0.943 \t\n",
      "\n",
      "Validation 663 valid_acc: 0.774 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 664 train_loss: 0.231 train_acc: 0.962 train_f1: 0.945 \t\n",
      "\n",
      "Validation 664 valid_acc: 0.781 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 665 train_loss: 0.236 train_acc: 0.961 train_f1: 0.942 \t\n",
      "\n",
      "Validation 665 valid_acc: 0.781 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 666 train_loss: 0.235 train_acc: 0.959 train_f1: 0.941 \t\n",
      "\n",
      "Validation 666 valid_acc: 0.773 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 667 train_loss: 0.231 train_acc: 0.965 train_f1: 0.944 \t\n",
      "\n",
      "Validation 667 valid_acc: 0.775 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 668 train_loss: 0.235 train_acc: 0.964 train_f1: 0.943 \t\n",
      "\n",
      "Validation 668 valid_acc: 0.769 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 669 train_loss: 0.232 train_acc: 0.960 train_f1: 0.942 \t\n",
      "\n",
      "Validation 669 valid_acc: 0.779 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 670 train_loss: 0.234 train_acc: 0.961 train_f1: 0.939 \t\n",
      "\n",
      "Validation 670 valid_acc: 0.778 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 671 train_loss: 0.235 train_acc: 0.963 train_f1: 0.944 \t\n",
      "\n",
      "Validation 671 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 672 train_loss: 0.233 train_acc: 0.962 train_f1: 0.941 \t\n",
      "\n",
      "Validation 672 valid_acc: 0.777 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 673 train_loss: 0.238 train_acc: 0.962 train_f1: 0.942 \t\n",
      "\n",
      "Validation 673 valid_acc: 0.773 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 674 train_loss: 0.234 train_acc: 0.962 train_f1: 0.944 \t\n",
      "\n",
      "Validation 674 valid_acc: 0.778 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 675 train_loss: 0.229 train_acc: 0.961 train_f1: 0.945 \t\n",
      "\n",
      "Validation 675 valid_acc: 0.785 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 676 train_loss: 0.235 train_acc: 0.962 train_f1: 0.942 \t\n",
      "\n",
      "Validation 676 valid_acc: 0.777 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 677 train_loss: 0.228 train_acc: 0.963 train_f1: 0.942 \t\n",
      "\n",
      "Validation 677 valid_acc: 0.781 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 678 train_loss: 0.233 train_acc: 0.964 train_f1: 0.944 \t\n",
      "\n",
      "Validation 678 valid_acc: 0.781 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 679 train_loss: 0.228 train_acc: 0.965 train_f1: 0.943 \t\n",
      "\n",
      "Validation 679 valid_acc: 0.775 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 680 train_loss: 0.230 train_acc: 0.964 train_f1: 0.944 \t\n",
      "\n",
      "Validation 680 valid_acc: 0.784 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 681 train_loss: 0.229 train_acc: 0.965 train_f1: 0.943 \t\n",
      "\n",
      "Validation 681 valid_acc: 0.775 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 682 train_loss: 0.225 train_acc: 0.961 train_f1: 0.947 \t\n",
      "\n",
      "Validation 682 valid_acc: 0.783 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 683 train_loss: 0.231 train_acc: 0.965 train_f1: 0.946 \t\n",
      "\n",
      "Validation 683 valid_acc: 0.770 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 684 train_loss: 0.234 train_acc: 0.964 train_f1: 0.943 \t\n",
      "\n",
      "Validation 684 valid_acc: 0.773 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 685 train_loss: 0.229 train_acc: 0.962 train_f1: 0.945 \t\n",
      "\n",
      "Validation 685 valid_acc: 0.787 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 686 train_loss: 0.232 train_acc: 0.961 train_f1: 0.944 \t\n",
      "\n",
      "Validation 686 valid_acc: 0.783 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 687 train_loss: 0.231 train_acc: 0.964 train_f1: 0.944 \t\n",
      "\n",
      "Validation 687 valid_acc: 0.771 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 688 train_loss: 0.223 train_acc: 0.966 train_f1: 0.948 \t\n",
      "\n",
      "Validation 688 valid_acc: 0.774 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 689 train_loss: 0.231 train_acc: 0.963 train_f1: 0.943 \t\n",
      "\n",
      "Validation 689 valid_acc: 0.777 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 690 train_loss: 0.228 train_acc: 0.964 train_f1: 0.947 \t\n",
      "\n",
      "Validation 690 valid_acc: 0.773 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 691 train_loss: 0.231 train_acc: 0.963 train_f1: 0.942 \t\n",
      "\n",
      "Validation 691 valid_acc: 0.775 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 692 train_loss: 0.224 train_acc: 0.965 train_f1: 0.947 \t\n",
      "\n",
      "Validation 692 valid_acc: 0.783 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 693 train_loss: 0.224 train_acc: 0.963 train_f1: 0.946 \t\n",
      "\n",
      "Validation 693 valid_acc: 0.782 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 694 train_loss: 0.227 train_acc: 0.966 train_f1: 0.947 \t\n",
      "\n",
      "Validation 694 valid_acc: 0.788 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 695 train_loss: 0.225 train_acc: 0.961 train_f1: 0.947 \t\n",
      "\n",
      "Validation 695 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 696 train_loss: 0.234 train_acc: 0.960 train_f1: 0.942 \t\n",
      "\n",
      "Validation 696 valid_acc: 0.768 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 697 train_loss: 0.226 train_acc: 0.963 train_f1: 0.945 \t\n",
      "\n",
      "Validation 697 valid_acc: 0.779 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 698 train_loss: 0.225 train_acc: 0.962 train_f1: 0.947 \t\n",
      "\n",
      "Validation 698 valid_acc: 0.784 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 699 train_loss: 0.226 train_acc: 0.963 train_f1: 0.946 \t\n",
      "\n",
      "Validation 699 valid_acc: 0.773 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 700 train_loss: 0.225 train_acc: 0.966 train_f1: 0.947 \t\n",
      "\n",
      "Validation 700 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 701 train_loss: 0.227 train_acc: 0.960 train_f1: 0.944 \t\n",
      "\n",
      "Validation 701 valid_acc: 0.763 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 702 train_loss: 0.227 train_acc: 0.967 train_f1: 0.946 \t\n",
      "\n",
      "Validation 702 valid_acc: 0.779 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 703 train_loss: 0.230 train_acc: 0.961 train_f1: 0.944 \t\n",
      "\n",
      "Validation 703 valid_acc: 0.771 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 704 train_loss: 0.228 train_acc: 0.962 train_f1: 0.944 \t\n",
      "\n",
      "Validation 704 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 705 train_loss: 0.226 train_acc: 0.963 train_f1: 0.944 \t\n",
      "\n",
      "Validation 705 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 706 train_loss: 0.222 train_acc: 0.965 train_f1: 0.947 \t\n",
      "\n",
      "Validation 706 valid_acc: 0.769 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 707 train_loss: 0.227 train_acc: 0.961 train_f1: 0.945 \t\n",
      "\n",
      "Validation 707 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 708 train_loss: 0.227 train_acc: 0.962 train_f1: 0.946 \t\n",
      "\n",
      "Validation 708 valid_acc: 0.775 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 709 train_loss: 0.221 train_acc: 0.966 train_f1: 0.950 \t\n",
      "\n",
      "Validation 709 valid_acc: 0.771 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 710 train_loss: 0.220 train_acc: 0.965 train_f1: 0.949 \t\n",
      "\n",
      "Validation 710 valid_acc: 0.771 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 711 train_loss: 0.221 train_acc: 0.967 train_f1: 0.948 \t\n",
      "\n",
      "Validation 711 valid_acc: 0.783 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 712 train_loss: 0.223 train_acc: 0.965 train_f1: 0.947 \t\n",
      "\n",
      "Validation 712 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 713 train_loss: 0.221 train_acc: 0.963 train_f1: 0.946 \t\n",
      "\n",
      "Validation 713 valid_acc: 0.775 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 714 train_loss: 0.223 train_acc: 0.969 train_f1: 0.947 \t\n",
      "\n",
      "Validation 714 valid_acc: 0.781 best_acc: 0.793 \t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 715 train_loss: 0.215 train_acc: 0.968 train_f1: 0.950 \t\n",
      "\n",
      "Validation 715 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 716 train_loss: 0.226 train_acc: 0.963 train_f1: 0.947 \t\n",
      "\n",
      "Validation 716 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 717 train_loss: 0.222 train_acc: 0.965 train_f1: 0.946 \t\n",
      "\n",
      "Validation 717 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 718 train_loss: 0.222 train_acc: 0.965 train_f1: 0.947 \t\n",
      "\n",
      "Validation 718 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 719 train_loss: 0.224 train_acc: 0.965 train_f1: 0.946 \t\n",
      "\n",
      "Validation 719 valid_acc: 0.778 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 720 train_loss: 0.222 train_acc: 0.966 train_f1: 0.945 \t\n",
      "\n",
      "Validation 720 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 721 train_loss: 0.224 train_acc: 0.962 train_f1: 0.948 \t\n",
      "\n",
      "Validation 721 valid_acc: 0.771 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 722 train_loss: 0.218 train_acc: 0.966 train_f1: 0.948 \t\n",
      "\n",
      "Validation 722 valid_acc: 0.781 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 723 train_loss: 0.216 train_acc: 0.967 train_f1: 0.948 \t\n",
      "\n",
      "Validation 723 valid_acc: 0.785 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 724 train_loss: 0.225 train_acc: 0.964 train_f1: 0.949 \t\n",
      "\n",
      "Validation 724 valid_acc: 0.774 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 725 train_loss: 0.223 train_acc: 0.965 train_f1: 0.948 \t\n",
      "\n",
      "Validation 725 valid_acc: 0.774 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 726 train_loss: 0.230 train_acc: 0.961 train_f1: 0.943 \t\n",
      "\n",
      "Validation 726 valid_acc: 0.765 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 727 train_loss: 0.220 train_acc: 0.965 train_f1: 0.948 \t\n",
      "\n",
      "Validation 727 valid_acc: 0.783 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 728 train_loss: 0.215 train_acc: 0.969 train_f1: 0.950 \t\n",
      "\n",
      "Validation 728 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 729 train_loss: 0.220 train_acc: 0.964 train_f1: 0.946 \t\n",
      "\n",
      "Validation 729 valid_acc: 0.785 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 730 train_loss: 0.214 train_acc: 0.968 train_f1: 0.952 \t\n",
      "\n",
      "Validation 730 valid_acc: 0.779 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 731 train_loss: 0.214 train_acc: 0.965 train_f1: 0.950 \t\n",
      "\n",
      "Validation 731 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 732 train_loss: 0.215 train_acc: 0.968 train_f1: 0.951 \t\n",
      "\n",
      "Validation 732 valid_acc: 0.775 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 733 train_loss: 0.209 train_acc: 0.970 train_f1: 0.953 \t\n",
      "\n",
      "Validation 733 valid_acc: 0.777 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 734 train_loss: 0.220 train_acc: 0.964 train_f1: 0.947 \t\n",
      "\n",
      "Validation 734 valid_acc: 0.768 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 735 train_loss: 0.216 train_acc: 0.968 train_f1: 0.950 \t\n",
      "\n",
      "Validation 735 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 736 train_loss: 0.222 train_acc: 0.966 train_f1: 0.949 \t\n",
      "\n",
      "Validation 736 valid_acc: 0.773 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 737 train_loss: 0.210 train_acc: 0.968 train_f1: 0.952 \t\n",
      "\n",
      "Validation 737 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 738 train_loss: 0.218 train_acc: 0.964 train_f1: 0.948 \t\n",
      "\n",
      "Validation 738 valid_acc: 0.779 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 739 train_loss: 0.214 train_acc: 0.966 train_f1: 0.948 \t\n",
      "\n",
      "Validation 739 valid_acc: 0.779 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 740 train_loss: 0.216 train_acc: 0.968 train_f1: 0.949 \t\n",
      "\n",
      "Validation 740 valid_acc: 0.785 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 741 train_loss: 0.219 train_acc: 0.963 train_f1: 0.946 \t\n",
      "\n",
      "Validation 741 valid_acc: 0.781 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 742 train_loss: 0.213 train_acc: 0.967 train_f1: 0.949 \t\n",
      "\n",
      "Validation 742 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 743 train_loss: 0.212 train_acc: 0.968 train_f1: 0.950 \t\n",
      "\n",
      "Validation 743 valid_acc: 0.772 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 744 train_loss: 0.215 train_acc: 0.966 train_f1: 0.952 \t\n",
      "\n",
      "Validation 744 valid_acc: 0.781 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 745 train_loss: 0.217 train_acc: 0.966 train_f1: 0.948 \t\n",
      "\n",
      "Validation 745 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 746 train_loss: 0.218 train_acc: 0.970 train_f1: 0.951 \t\n",
      "\n",
      "Validation 746 valid_acc: 0.778 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 747 train_loss: 0.211 train_acc: 0.968 train_f1: 0.951 \t\n",
      "\n",
      "Validation 747 valid_acc: 0.786 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 748 train_loss: 0.215 train_acc: 0.966 train_f1: 0.950 \t\n",
      "\n",
      "Validation 748 valid_acc: 0.772 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 749 train_loss: 0.213 train_acc: 0.970 train_f1: 0.953 \t\n",
      "\n",
      "Validation 749 valid_acc: 0.774 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 750 train_loss: 0.211 train_acc: 0.968 train_f1: 0.950 \t\n",
      "\n",
      "Validation 750 valid_acc: 0.775 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 751 train_loss: 0.212 train_acc: 0.968 train_f1: 0.950 \t\n",
      "\n",
      "Validation 751 valid_acc: 0.783 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 752 train_loss: 0.212 train_acc: 0.968 train_f1: 0.950 \t\n",
      "\n",
      "Validation 752 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 753 train_loss: 0.211 train_acc: 0.971 train_f1: 0.952 \t\n",
      "\n",
      "Validation 753 valid_acc: 0.784 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 754 train_loss: 0.212 train_acc: 0.966 train_f1: 0.949 \t\n",
      "\n",
      "Validation 754 valid_acc: 0.777 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 755 train_loss: 0.213 train_acc: 0.968 train_f1: 0.950 \t\n",
      "\n",
      "Validation 755 valid_acc: 0.774 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 756 train_loss: 0.213 train_acc: 0.968 train_f1: 0.950 \t\n",
      "\n",
      "Validation 756 valid_acc: 0.773 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 757 train_loss: 0.212 train_acc: 0.968 train_f1: 0.952 \t\n",
      "\n",
      "Validation 757 valid_acc: 0.775 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 758 train_loss: 0.222 train_acc: 0.963 train_f1: 0.947 \t\n",
      "\n",
      "Validation 758 valid_acc: 0.778 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 759 train_loss: 0.212 train_acc: 0.968 train_f1: 0.951 \t\n",
      "\n",
      "Validation 759 valid_acc: 0.775 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 760 train_loss: 0.210 train_acc: 0.967 train_f1: 0.954 \t\n",
      "\n",
      "Validation 760 valid_acc: 0.769 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 761 train_loss: 0.209 train_acc: 0.970 train_f1: 0.952 \t\n",
      "\n",
      "Validation 761 valid_acc: 0.778 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 762 train_loss: 0.207 train_acc: 0.971 train_f1: 0.953 \t\n",
      "\n",
      "Validation 762 valid_acc: 0.773 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 763 train_loss: 0.207 train_acc: 0.972 train_f1: 0.953 \t\n",
      "\n",
      "Validation 763 valid_acc: 0.772 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 764 train_loss: 0.210 train_acc: 0.968 train_f1: 0.953 \t\n",
      "\n",
      "Validation 764 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 765 train_loss: 0.209 train_acc: 0.972 train_f1: 0.954 \t\n",
      "\n",
      "Validation 765 valid_acc: 0.769 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 766 train_loss: 0.209 train_acc: 0.967 train_f1: 0.952 \t\n",
      "\n",
      "Validation 766 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 767 train_loss: 0.208 train_acc: 0.968 train_f1: 0.952 \t\n",
      "\n",
      "Validation 767 valid_acc: 0.778 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 768 train_loss: 0.209 train_acc: 0.968 train_f1: 0.952 \t\n",
      "\n",
      "Validation 768 valid_acc: 0.769 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 769 train_loss: 0.210 train_acc: 0.968 train_f1: 0.951 \t\n",
      "\n",
      "Validation 769 valid_acc: 0.779 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 770 train_loss: 0.210 train_acc: 0.967 train_f1: 0.951 \t\n",
      "\n",
      "Validation 770 valid_acc: 0.783 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 771 train_loss: 0.209 train_acc: 0.971 train_f1: 0.954 \t\n",
      "\n",
      "Validation 771 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 772 train_loss: 0.206 train_acc: 0.971 train_f1: 0.953 \t\n",
      "\n",
      "Validation 772 valid_acc: 0.769 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 773 train_loss: 0.208 train_acc: 0.970 train_f1: 0.952 \t\n",
      "\n",
      "Validation 773 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 774 train_loss: 0.205 train_acc: 0.969 train_f1: 0.954 \t\n",
      "\n",
      "Validation 774 valid_acc: 0.779 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 775 train_loss: 0.206 train_acc: 0.969 train_f1: 0.954 \t\n",
      "\n",
      "Validation 775 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 776 train_loss: 0.208 train_acc: 0.969 train_f1: 0.952 \t\n",
      "\n",
      "Validation 776 valid_acc: 0.777 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 777 train_loss: 0.208 train_acc: 0.968 train_f1: 0.950 \t\n",
      "\n",
      "Validation 777 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 778 train_loss: 0.202 train_acc: 0.971 train_f1: 0.955 \t\n",
      "\n",
      "Validation 778 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 779 train_loss: 0.210 train_acc: 0.969 train_f1: 0.953 \t\n",
      "\n",
      "Validation 779 valid_acc: 0.772 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 780 train_loss: 0.205 train_acc: 0.970 train_f1: 0.952 \t\n",
      "\n",
      "Validation 780 valid_acc: 0.784 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 781 train_loss: 0.212 train_acc: 0.969 train_f1: 0.951 \t\n",
      "\n",
      "Validation 781 valid_acc: 0.778 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 782 train_loss: 0.210 train_acc: 0.968 train_f1: 0.952 \t\n",
      "\n",
      "Validation 782 valid_acc: 0.771 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 783 train_loss: 0.207 train_acc: 0.967 train_f1: 0.951 \t\n",
      "\n",
      "Validation 783 valid_acc: 0.772 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 784 train_loss: 0.204 train_acc: 0.970 train_f1: 0.957 \t\n",
      "\n",
      "Validation 784 valid_acc: 0.777 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 785 train_loss: 0.206 train_acc: 0.970 train_f1: 0.950 \t\n",
      "\n",
      "Validation 785 valid_acc: 0.775 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 786 train_loss: 0.208 train_acc: 0.971 train_f1: 0.953 \t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation 786 valid_acc: 0.774 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 787 train_loss: 0.204 train_acc: 0.971 train_f1: 0.955 \t\n",
      "\n",
      "Validation 787 valid_acc: 0.774 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 788 train_loss: 0.211 train_acc: 0.970 train_f1: 0.951 \t\n",
      "\n",
      "Validation 788 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 789 train_loss: 0.200 train_acc: 0.973 train_f1: 0.956 \t\n",
      "\n",
      "Validation 789 valid_acc: 0.783 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 790 train_loss: 0.203 train_acc: 0.972 train_f1: 0.953 \t\n",
      "\n",
      "Validation 790 valid_acc: 0.772 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 791 train_loss: 0.212 train_acc: 0.966 train_f1: 0.950 \t\n",
      "\n",
      "Validation 791 valid_acc: 0.771 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 792 train_loss: 0.215 train_acc: 0.968 train_f1: 0.951 \t\n",
      "\n",
      "Validation 792 valid_acc: 0.775 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 793 train_loss: 0.204 train_acc: 0.970 train_f1: 0.953 \t\n",
      "\n",
      "Validation 793 valid_acc: 0.783 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 794 train_loss: 0.209 train_acc: 0.969 train_f1: 0.949 \t\n",
      "\n",
      "Validation 794 valid_acc: 0.770 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 795 train_loss: 0.209 train_acc: 0.970 train_f1: 0.951 \t\n",
      "\n",
      "Validation 795 valid_acc: 0.771 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 796 train_loss: 0.206 train_acc: 0.967 train_f1: 0.951 \t\n",
      "\n",
      "Validation 796 valid_acc: 0.771 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 797 train_loss: 0.207 train_acc: 0.969 train_f1: 0.951 \t\n",
      "\n",
      "Validation 797 valid_acc: 0.772 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 798 train_loss: 0.204 train_acc: 0.967 train_f1: 0.952 \t\n",
      "\n",
      "Validation 798 valid_acc: 0.778 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 799 train_loss: 0.204 train_acc: 0.973 train_f1: 0.955 \t\n",
      "\n",
      "Validation 799 valid_acc: 0.774 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 800 train_loss: 0.202 train_acc: 0.970 train_f1: 0.953 \t\n",
      "\n",
      "Validation 800 valid_acc: 0.782 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 801 train_loss: 0.197 train_acc: 0.972 train_f1: 0.956 \t\n",
      "\n",
      "Validation 801 valid_acc: 0.779 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 802 train_loss: 0.202 train_acc: 0.971 train_f1: 0.954 \t\n",
      "\n",
      "Validation 802 valid_acc: 0.781 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 803 train_loss: 0.202 train_acc: 0.970 train_f1: 0.952 \t\n",
      "\n",
      "Validation 803 valid_acc: 0.787 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 804 train_loss: 0.204 train_acc: 0.969 train_f1: 0.953 \t\n",
      "\n",
      "Validation 804 valid_acc: 0.788 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 805 train_loss: 0.194 train_acc: 0.974 train_f1: 0.958 \t\n",
      "\n",
      "Validation 805 valid_acc: 0.769 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 806 train_loss: 0.201 train_acc: 0.972 train_f1: 0.955 \t\n",
      "\n",
      "Validation 806 valid_acc: 0.770 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 807 train_loss: 0.201 train_acc: 0.971 train_f1: 0.954 \t\n",
      "\n",
      "Validation 807 valid_acc: 0.769 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 808 train_loss: 0.202 train_acc: 0.970 train_f1: 0.955 \t\n",
      "\n",
      "Validation 808 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 809 train_loss: 0.201 train_acc: 0.970 train_f1: 0.955 \t\n",
      "\n",
      "Validation 809 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 810 train_loss: 0.203 train_acc: 0.969 train_f1: 0.955 \t\n",
      "\n",
      "Validation 810 valid_acc: 0.775 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 811 train_loss: 0.204 train_acc: 0.970 train_f1: 0.955 \t\n",
      "\n",
      "Validation 811 valid_acc: 0.778 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 812 train_loss: 0.197 train_acc: 0.973 train_f1: 0.958 \t\n",
      "\n",
      "Validation 812 valid_acc: 0.784 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 813 train_loss: 0.199 train_acc: 0.974 train_f1: 0.955 \t\n",
      "\n",
      "Validation 813 valid_acc: 0.765 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 814 train_loss: 0.199 train_acc: 0.972 train_f1: 0.955 \t\n",
      "\n",
      "Validation 814 valid_acc: 0.774 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 815 train_loss: 0.201 train_acc: 0.969 train_f1: 0.954 \t\n",
      "\n",
      "Validation 815 valid_acc: 0.774 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 816 train_loss: 0.200 train_acc: 0.973 train_f1: 0.956 \t\n",
      "\n",
      "Validation 816 valid_acc: 0.769 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 817 train_loss: 0.201 train_acc: 0.971 train_f1: 0.955 \t\n",
      "\n",
      "Validation 817 valid_acc: 0.772 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 818 train_loss: 0.192 train_acc: 0.972 train_f1: 0.957 \t\n",
      "\n",
      "Validation 818 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 819 train_loss: 0.197 train_acc: 0.974 train_f1: 0.956 \t\n",
      "\n",
      "Validation 819 valid_acc: 0.773 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 820 train_loss: 0.201 train_acc: 0.971 train_f1: 0.955 \t\n",
      "\n",
      "Validation 820 valid_acc: 0.769 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 821 train_loss: 0.202 train_acc: 0.969 train_f1: 0.954 \t\n",
      "\n",
      "Validation 821 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 822 train_loss: 0.192 train_acc: 0.974 train_f1: 0.956 \t\n",
      "\n",
      "Validation 822 valid_acc: 0.774 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 823 train_loss: 0.190 train_acc: 0.973 train_f1: 0.958 \t\n",
      "\n",
      "Validation 823 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 824 train_loss: 0.195 train_acc: 0.970 train_f1: 0.957 \t\n",
      "\n",
      "Validation 824 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 825 train_loss: 0.195 train_acc: 0.971 train_f1: 0.956 \t\n",
      "\n",
      "Validation 825 valid_acc: 0.777 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 826 train_loss: 0.197 train_acc: 0.973 train_f1: 0.956 \t\n",
      "\n",
      "Validation 826 valid_acc: 0.772 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 827 train_loss: 0.199 train_acc: 0.972 train_f1: 0.954 \t\n",
      "\n",
      "Validation 827 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 828 train_loss: 0.201 train_acc: 0.971 train_f1: 0.955 \t\n",
      "\n",
      "Validation 828 valid_acc: 0.782 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 829 train_loss: 0.196 train_acc: 0.971 train_f1: 0.956 \t\n",
      "\n",
      "Validation 829 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 830 train_loss: 0.192 train_acc: 0.974 train_f1: 0.957 \t\n",
      "\n",
      "Validation 830 valid_acc: 0.773 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 831 train_loss: 0.196 train_acc: 0.973 train_f1: 0.957 \t\n",
      "\n",
      "Validation 831 valid_acc: 0.786 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 832 train_loss: 0.200 train_acc: 0.972 train_f1: 0.957 \t\n",
      "\n",
      "Validation 832 valid_acc: 0.779 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 833 train_loss: 0.195 train_acc: 0.974 train_f1: 0.955 \t\n",
      "\n",
      "Validation 833 valid_acc: 0.777 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 834 train_loss: 0.200 train_acc: 0.969 train_f1: 0.955 \t\n",
      "\n",
      "Validation 834 valid_acc: 0.768 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 835 train_loss: 0.199 train_acc: 0.971 train_f1: 0.955 \t\n",
      "\n",
      "Validation 835 valid_acc: 0.772 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 836 train_loss: 0.195 train_acc: 0.970 train_f1: 0.956 \t\n",
      "\n",
      "Validation 836 valid_acc: 0.769 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 837 train_loss: 0.192 train_acc: 0.972 train_f1: 0.958 \t\n",
      "\n",
      "Validation 837 valid_acc: 0.783 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 838 train_loss: 0.188 train_acc: 0.976 train_f1: 0.960 \t\n",
      "\n",
      "Validation 838 valid_acc: 0.783 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 839 train_loss: 0.195 train_acc: 0.972 train_f1: 0.957 \t\n",
      "\n",
      "Validation 839 valid_acc: 0.779 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 840 train_loss: 0.194 train_acc: 0.972 train_f1: 0.958 \t\n",
      "\n",
      "Validation 840 valid_acc: 0.782 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 841 train_loss: 0.192 train_acc: 0.971 train_f1: 0.957 \t\n",
      "\n",
      "Validation 841 valid_acc: 0.783 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 842 train_loss: 0.198 train_acc: 0.972 train_f1: 0.954 \t\n",
      "\n",
      "Validation 842 valid_acc: 0.769 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 843 train_loss: 0.193 train_acc: 0.973 train_f1: 0.957 \t\n",
      "\n",
      "Validation 843 valid_acc: 0.773 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 844 train_loss: 0.196 train_acc: 0.974 train_f1: 0.955 \t\n",
      "\n",
      "Validation 844 valid_acc: 0.775 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 845 train_loss: 0.199 train_acc: 0.970 train_f1: 0.954 \t\n",
      "\n",
      "Validation 845 valid_acc: 0.779 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 846 train_loss: 0.195 train_acc: 0.973 train_f1: 0.959 \t\n",
      "\n",
      "Validation 846 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 847 train_loss: 0.195 train_acc: 0.974 train_f1: 0.956 \t\n",
      "\n",
      "Validation 847 valid_acc: 0.772 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 848 train_loss: 0.191 train_acc: 0.973 train_f1: 0.958 \t\n",
      "\n",
      "Validation 848 valid_acc: 0.783 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 849 train_loss: 0.196 train_acc: 0.972 train_f1: 0.956 \t\n",
      "\n",
      "Validation 849 valid_acc: 0.772 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 850 train_loss: 0.188 train_acc: 0.973 train_f1: 0.958 \t\n",
      "\n",
      "Validation 850 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 851 train_loss: 0.192 train_acc: 0.974 train_f1: 0.958 \t\n",
      "\n",
      "Validation 851 valid_acc: 0.781 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 852 train_loss: 0.191 train_acc: 0.975 train_f1: 0.959 \t\n",
      "\n",
      "Validation 852 valid_acc: 0.773 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 853 train_loss: 0.196 train_acc: 0.972 train_f1: 0.956 \t\n",
      "\n",
      "Validation 853 valid_acc: 0.781 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 854 train_loss: 0.191 train_acc: 0.972 train_f1: 0.958 \t\n",
      "\n",
      "Validation 854 valid_acc: 0.783 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 855 train_loss: 0.192 train_acc: 0.974 train_f1: 0.956 \t\n",
      "\n",
      "Validation 855 valid_acc: 0.772 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 856 train_loss: 0.193 train_acc: 0.977 train_f1: 0.958 \t\n",
      "\n",
      "Validation 856 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 857 train_loss: 0.195 train_acc: 0.973 train_f1: 0.957 \t\n",
      "\n",
      "Validation 857 valid_acc: 0.776 best_acc: 0.793 \t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 858 train_loss: 0.188 train_acc: 0.973 train_f1: 0.957 \t\n",
      "\n",
      "Validation 858 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 859 train_loss: 0.192 train_acc: 0.972 train_f1: 0.955 \t\n",
      "\n",
      "Validation 859 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 860 train_loss: 0.189 train_acc: 0.972 train_f1: 0.959 \t\n",
      "\n",
      "Validation 860 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 861 train_loss: 0.194 train_acc: 0.973 train_f1: 0.956 \t\n",
      "\n",
      "Validation 861 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 862 train_loss: 0.191 train_acc: 0.972 train_f1: 0.957 \t\n",
      "\n",
      "Validation 862 valid_acc: 0.775 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 863 train_loss: 0.191 train_acc: 0.973 train_f1: 0.957 \t\n",
      "\n",
      "Validation 863 valid_acc: 0.783 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 864 train_loss: 0.194 train_acc: 0.973 train_f1: 0.957 \t\n",
      "\n",
      "Validation 864 valid_acc: 0.765 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 865 train_loss: 0.186 train_acc: 0.976 train_f1: 0.961 \t\n",
      "\n",
      "Validation 865 valid_acc: 0.767 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 866 train_loss: 0.187 train_acc: 0.973 train_f1: 0.959 \t\n",
      "\n",
      "Validation 866 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 867 train_loss: 0.194 train_acc: 0.971 train_f1: 0.957 \t\n",
      "\n",
      "Validation 867 valid_acc: 0.783 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 868 train_loss: 0.188 train_acc: 0.974 train_f1: 0.960 \t\n",
      "\n",
      "Validation 868 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 869 train_loss: 0.189 train_acc: 0.973 train_f1: 0.958 \t\n",
      "\n",
      "Validation 869 valid_acc: 0.773 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 870 train_loss: 0.190 train_acc: 0.976 train_f1: 0.959 \t\n",
      "\n",
      "Validation 870 valid_acc: 0.778 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 871 train_loss: 0.186 train_acc: 0.977 train_f1: 0.959 \t\n",
      "\n",
      "Validation 871 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 872 train_loss: 0.189 train_acc: 0.972 train_f1: 0.957 \t\n",
      "\n",
      "Validation 872 valid_acc: 0.771 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 873 train_loss: 0.190 train_acc: 0.974 train_f1: 0.959 \t\n",
      "\n",
      "Validation 873 valid_acc: 0.781 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 874 train_loss: 0.186 train_acc: 0.977 train_f1: 0.961 \t\n",
      "\n",
      "Validation 874 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 875 train_loss: 0.191 train_acc: 0.974 train_f1: 0.957 \t\n",
      "\n",
      "Validation 875 valid_acc: 0.779 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 876 train_loss: 0.192 train_acc: 0.974 train_f1: 0.956 \t\n",
      "\n",
      "Validation 876 valid_acc: 0.779 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 877 train_loss: 0.188 train_acc: 0.976 train_f1: 0.960 \t\n",
      "\n",
      "Validation 877 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 878 train_loss: 0.185 train_acc: 0.978 train_f1: 0.962 \t\n",
      "\n",
      "Validation 878 valid_acc: 0.778 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 879 train_loss: 0.187 train_acc: 0.974 train_f1: 0.957 \t\n",
      "\n",
      "Validation 879 valid_acc: 0.777 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 880 train_loss: 0.186 train_acc: 0.974 train_f1: 0.960 \t\n",
      "\n",
      "Validation 880 valid_acc: 0.783 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 881 train_loss: 0.186 train_acc: 0.976 train_f1: 0.961 \t\n",
      "\n",
      "Validation 881 valid_acc: 0.775 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 882 train_loss: 0.186 train_acc: 0.973 train_f1: 0.959 \t\n",
      "\n",
      "Validation 882 valid_acc: 0.774 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 883 train_loss: 0.188 train_acc: 0.973 train_f1: 0.959 \t\n",
      "\n",
      "Validation 883 valid_acc: 0.768 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 884 train_loss: 0.187 train_acc: 0.972 train_f1: 0.960 \t\n",
      "\n",
      "Validation 884 valid_acc: 0.779 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 885 train_loss: 0.183 train_acc: 0.978 train_f1: 0.961 \t\n",
      "\n",
      "Validation 885 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 886 train_loss: 0.183 train_acc: 0.973 train_f1: 0.960 \t\n",
      "\n",
      "Validation 886 valid_acc: 0.784 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 887 train_loss: 0.189 train_acc: 0.972 train_f1: 0.959 \t\n",
      "\n",
      "Validation 887 valid_acc: 0.777 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 888 train_loss: 0.182 train_acc: 0.976 train_f1: 0.963 \t\n",
      "\n",
      "Validation 888 valid_acc: 0.773 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 889 train_loss: 0.185 train_acc: 0.974 train_f1: 0.959 \t\n",
      "\n",
      "Validation 889 valid_acc: 0.777 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 890 train_loss: 0.186 train_acc: 0.973 train_f1: 0.958 \t\n",
      "\n",
      "Validation 890 valid_acc: 0.777 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 891 train_loss: 0.189 train_acc: 0.974 train_f1: 0.959 \t\n",
      "\n",
      "Validation 891 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 892 train_loss: 0.184 train_acc: 0.977 train_f1: 0.960 \t\n",
      "\n",
      "Validation 892 valid_acc: 0.779 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 893 train_loss: 0.184 train_acc: 0.977 train_f1: 0.962 \t\n",
      "\n",
      "Validation 893 valid_acc: 0.775 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 894 train_loss: 0.189 train_acc: 0.974 train_f1: 0.960 \t\n",
      "\n",
      "Validation 894 valid_acc: 0.778 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 895 train_loss: 0.187 train_acc: 0.976 train_f1: 0.957 \t\n",
      "\n",
      "Validation 895 valid_acc: 0.773 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 896 train_loss: 0.188 train_acc: 0.975 train_f1: 0.958 \t\n",
      "\n",
      "Validation 896 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 897 train_loss: 0.175 train_acc: 0.977 train_f1: 0.964 \t\n",
      "\n",
      "Validation 897 valid_acc: 0.784 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 898 train_loss: 0.183 train_acc: 0.974 train_f1: 0.959 \t\n",
      "\n",
      "Validation 898 valid_acc: 0.778 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 899 train_loss: 0.185 train_acc: 0.975 train_f1: 0.961 \t\n",
      "\n",
      "Validation 899 valid_acc: 0.781 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 900 train_loss: 0.183 train_acc: 0.978 train_f1: 0.962 \t\n",
      "\n",
      "Validation 900 valid_acc: 0.783 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 901 train_loss: 0.179 train_acc: 0.978 train_f1: 0.963 \t\n",
      "\n",
      "Validation 901 valid_acc: 0.775 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 902 train_loss: 0.184 train_acc: 0.978 train_f1: 0.960 \t\n",
      "\n",
      "Validation 902 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 903 train_loss: 0.186 train_acc: 0.974 train_f1: 0.959 \t\n",
      "\n",
      "Validation 903 valid_acc: 0.777 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 904 train_loss: 0.183 train_acc: 0.976 train_f1: 0.962 \t\n",
      "\n",
      "Validation 904 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 905 train_loss: 0.183 train_acc: 0.974 train_f1: 0.960 \t\n",
      "\n",
      "Validation 905 valid_acc: 0.763 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 906 train_loss: 0.182 train_acc: 0.975 train_f1: 0.960 \t\n",
      "\n",
      "Validation 906 valid_acc: 0.778 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 907 train_loss: 0.184 train_acc: 0.974 train_f1: 0.960 \t\n",
      "\n",
      "Validation 907 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 908 train_loss: 0.179 train_acc: 0.979 train_f1: 0.963 \t\n",
      "\n",
      "Validation 908 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 909 train_loss: 0.179 train_acc: 0.977 train_f1: 0.963 \t\n",
      "\n",
      "Validation 909 valid_acc: 0.773 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 910 train_loss: 0.177 train_acc: 0.975 train_f1: 0.961 \t\n",
      "\n",
      "Validation 910 valid_acc: 0.774 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 911 train_loss: 0.183 train_acc: 0.976 train_f1: 0.959 \t\n",
      "\n",
      "Validation 911 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 912 train_loss: 0.183 train_acc: 0.974 train_f1: 0.958 \t\n",
      "\n",
      "Validation 912 valid_acc: 0.775 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 913 train_loss: 0.186 train_acc: 0.976 train_f1: 0.960 \t\n",
      "\n",
      "Validation 913 valid_acc: 0.783 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 914 train_loss: 0.178 train_acc: 0.975 train_f1: 0.962 \t\n",
      "\n",
      "Validation 914 valid_acc: 0.778 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 915 train_loss: 0.191 train_acc: 0.974 train_f1: 0.958 \t\n",
      "\n",
      "Validation 915 valid_acc: 0.772 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 916 train_loss: 0.181 train_acc: 0.976 train_f1: 0.960 \t\n",
      "\n",
      "Validation 916 valid_acc: 0.775 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 917 train_loss: 0.179 train_acc: 0.976 train_f1: 0.961 \t\n",
      "\n",
      "Validation 917 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 918 train_loss: 0.182 train_acc: 0.974 train_f1: 0.961 \t\n",
      "\n",
      "Validation 918 valid_acc: 0.783 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 919 train_loss: 0.182 train_acc: 0.977 train_f1: 0.961 \t\n",
      "\n",
      "Validation 919 valid_acc: 0.778 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 920 train_loss: 0.180 train_acc: 0.975 train_f1: 0.961 \t\n",
      "\n",
      "Validation 920 valid_acc: 0.777 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 921 train_loss: 0.179 train_acc: 0.976 train_f1: 0.961 \t\n",
      "\n",
      "Validation 921 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 922 train_loss: 0.182 train_acc: 0.976 train_f1: 0.960 \t\n",
      "\n",
      "Validation 922 valid_acc: 0.778 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 923 train_loss: 0.179 train_acc: 0.975 train_f1: 0.960 \t\n",
      "\n",
      "Validation 923 valid_acc: 0.771 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 924 train_loss: 0.177 train_acc: 0.979 train_f1: 0.964 \t\n",
      "\n",
      "Validation 924 valid_acc: 0.775 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 925 train_loss: 0.177 train_acc: 0.976 train_f1: 0.961 \t\n",
      "\n",
      "Validation 925 valid_acc: 0.786 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 926 train_loss: 0.177 train_acc: 0.978 train_f1: 0.961 \t\n",
      "\n",
      "Validation 926 valid_acc: 0.778 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 927 train_loss: 0.172 train_acc: 0.978 train_f1: 0.965 \t\n",
      "\n",
      "Validation 927 valid_acc: 0.773 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 928 train_loss: 0.180 train_acc: 0.977 train_f1: 0.963 \t\n",
      "\n",
      "Validation 928 valid_acc: 0.771 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 929 train_loss: 0.179 train_acc: 0.976 train_f1: 0.962 \t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation 929 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 930 train_loss: 0.177 train_acc: 0.979 train_f1: 0.963 \t\n",
      "\n",
      "Validation 930 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 931 train_loss: 0.177 train_acc: 0.976 train_f1: 0.962 \t\n",
      "\n",
      "Validation 931 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 932 train_loss: 0.177 train_acc: 0.978 train_f1: 0.963 \t\n",
      "\n",
      "Validation 932 valid_acc: 0.771 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 933 train_loss: 0.177 train_acc: 0.977 train_f1: 0.964 \t\n",
      "\n",
      "Validation 933 valid_acc: 0.770 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 934 train_loss: 0.181 train_acc: 0.977 train_f1: 0.962 \t\n",
      "\n",
      "Validation 934 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 935 train_loss: 0.179 train_acc: 0.976 train_f1: 0.962 \t\n",
      "\n",
      "Validation 935 valid_acc: 0.774 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 936 train_loss: 0.176 train_acc: 0.979 train_f1: 0.964 \t\n",
      "\n",
      "Validation 936 valid_acc: 0.773 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 937 train_loss: 0.175 train_acc: 0.978 train_f1: 0.963 \t\n",
      "\n",
      "Validation 937 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 938 train_loss: 0.175 train_acc: 0.980 train_f1: 0.964 \t\n",
      "\n",
      "Validation 938 valid_acc: 0.767 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 939 train_loss: 0.175 train_acc: 0.980 train_f1: 0.965 \t\n",
      "\n",
      "Validation 939 valid_acc: 0.771 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 940 train_loss: 0.177 train_acc: 0.977 train_f1: 0.963 \t\n",
      "\n",
      "Validation 940 valid_acc: 0.770 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 941 train_loss: 0.178 train_acc: 0.977 train_f1: 0.961 \t\n",
      "\n",
      "Validation 941 valid_acc: 0.779 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 942 train_loss: 0.179 train_acc: 0.976 train_f1: 0.961 \t\n",
      "\n",
      "Validation 942 valid_acc: 0.774 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 943 train_loss: 0.177 train_acc: 0.977 train_f1: 0.963 \t\n",
      "\n",
      "Validation 943 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 944 train_loss: 0.175 train_acc: 0.977 train_f1: 0.964 \t\n",
      "\n",
      "Validation 944 valid_acc: 0.773 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 945 train_loss: 0.176 train_acc: 0.976 train_f1: 0.963 \t\n",
      "\n",
      "Validation 945 valid_acc: 0.771 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 946 train_loss: 0.173 train_acc: 0.977 train_f1: 0.964 \t\n",
      "\n",
      "Validation 946 valid_acc: 0.779 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 947 train_loss: 0.177 train_acc: 0.978 train_f1: 0.964 \t\n",
      "\n",
      "Validation 947 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 948 train_loss: 0.178 train_acc: 0.975 train_f1: 0.961 \t\n",
      "\n",
      "Validation 948 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 949 train_loss: 0.175 train_acc: 0.978 train_f1: 0.962 \t\n",
      "\n",
      "Validation 949 valid_acc: 0.773 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 950 train_loss: 0.173 train_acc: 0.979 train_f1: 0.965 \t\n",
      "\n",
      "Validation 950 valid_acc: 0.768 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 951 train_loss: 0.182 train_acc: 0.976 train_f1: 0.960 \t\n",
      "\n",
      "Validation 951 valid_acc: 0.778 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 952 train_loss: 0.168 train_acc: 0.980 train_f1: 0.967 \t\n",
      "\n",
      "Validation 952 valid_acc: 0.778 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 953 train_loss: 0.177 train_acc: 0.978 train_f1: 0.965 \t\n",
      "\n",
      "Validation 953 valid_acc: 0.782 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 954 train_loss: 0.176 train_acc: 0.978 train_f1: 0.962 \t\n",
      "\n",
      "Validation 954 valid_acc: 0.775 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 955 train_loss: 0.178 train_acc: 0.977 train_f1: 0.963 \t\n",
      "\n",
      "Validation 955 valid_acc: 0.773 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 956 train_loss: 0.176 train_acc: 0.975 train_f1: 0.963 \t\n",
      "\n",
      "Validation 956 valid_acc: 0.781 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 957 train_loss: 0.179 train_acc: 0.977 train_f1: 0.962 \t\n",
      "\n",
      "Validation 957 valid_acc: 0.772 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 958 train_loss: 0.176 train_acc: 0.979 train_f1: 0.964 \t\n",
      "\n",
      "Validation 958 valid_acc: 0.770 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 959 train_loss: 0.173 train_acc: 0.979 train_f1: 0.965 \t\n",
      "\n",
      "Validation 959 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 960 train_loss: 0.177 train_acc: 0.978 train_f1: 0.962 \t\n",
      "\n",
      "Validation 960 valid_acc: 0.781 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 961 train_loss: 0.170 train_acc: 0.979 train_f1: 0.965 \t\n",
      "\n",
      "Validation 961 valid_acc: 0.786 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 962 train_loss: 0.169 train_acc: 0.979 train_f1: 0.966 \t\n",
      "\n",
      "Validation 962 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 963 train_loss: 0.174 train_acc: 0.973 train_f1: 0.963 \t\n",
      "\n",
      "Validation 963 valid_acc: 0.771 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 964 train_loss: 0.179 train_acc: 0.977 train_f1: 0.963 \t\n",
      "\n",
      "Validation 964 valid_acc: 0.775 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 965 train_loss: 0.173 train_acc: 0.978 train_f1: 0.965 \t\n",
      "\n",
      "Validation 965 valid_acc: 0.779 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 966 train_loss: 0.172 train_acc: 0.978 train_f1: 0.965 \t\n",
      "\n",
      "Validation 966 valid_acc: 0.769 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 967 train_loss: 0.174 train_acc: 0.977 train_f1: 0.962 \t\n",
      "\n",
      "Validation 967 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 968 train_loss: 0.175 train_acc: 0.977 train_f1: 0.964 \t\n",
      "\n",
      "Validation 968 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 969 train_loss: 0.174 train_acc: 0.977 train_f1: 0.963 \t\n",
      "\n",
      "Validation 969 valid_acc: 0.774 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 970 train_loss: 0.170 train_acc: 0.980 train_f1: 0.965 \t\n",
      "\n",
      "Validation 970 valid_acc: 0.769 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 971 train_loss: 0.170 train_acc: 0.979 train_f1: 0.965 \t\n",
      "\n",
      "Validation 971 valid_acc: 0.785 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 972 train_loss: 0.172 train_acc: 0.977 train_f1: 0.964 \t\n",
      "\n",
      "Validation 972 valid_acc: 0.783 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 973 train_loss: 0.172 train_acc: 0.981 train_f1: 0.969 \t\n",
      "\n",
      "Validation 973 valid_acc: 0.777 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 974 train_loss: 0.168 train_acc: 0.980 train_f1: 0.965 \t\n",
      "\n",
      "Validation 974 valid_acc: 0.781 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 975 train_loss: 0.168 train_acc: 0.980 train_f1: 0.965 \t\n",
      "\n",
      "Validation 975 valid_acc: 0.774 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 976 train_loss: 0.172 train_acc: 0.979 train_f1: 0.965 \t\n",
      "\n",
      "Validation 976 valid_acc: 0.772 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 977 train_loss: 0.170 train_acc: 0.978 train_f1: 0.966 \t\n",
      "\n",
      "Validation 977 valid_acc: 0.768 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 978 train_loss: 0.171 train_acc: 0.978 train_f1: 0.965 \t\n",
      "\n",
      "Validation 978 valid_acc: 0.775 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 979 train_loss: 0.173 train_acc: 0.979 train_f1: 0.965 \t\n",
      "\n",
      "Validation 979 valid_acc: 0.772 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 980 train_loss: 0.170 train_acc: 0.977 train_f1: 0.965 \t\n",
      "\n",
      "Validation 980 valid_acc: 0.782 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 981 train_loss: 0.169 train_acc: 0.979 train_f1: 0.966 \t\n",
      "\n",
      "Validation 981 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 982 train_loss: 0.170 train_acc: 0.979 train_f1: 0.965 \t\n",
      "\n",
      "Validation 982 valid_acc: 0.775 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 983 train_loss: 0.170 train_acc: 0.978 train_f1: 0.966 \t\n",
      "\n",
      "Validation 983 valid_acc: 0.768 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 984 train_loss: 0.168 train_acc: 0.978 train_f1: 0.964 \t\n",
      "\n",
      "Validation 984 valid_acc: 0.778 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 985 train_loss: 0.171 train_acc: 0.978 train_f1: 0.965 \t\n",
      "\n",
      "Validation 985 valid_acc: 0.774 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 986 train_loss: 0.168 train_acc: 0.979 train_f1: 0.965 \t\n",
      "\n",
      "Validation 986 valid_acc: 0.775 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 987 train_loss: 0.171 train_acc: 0.977 train_f1: 0.965 \t\n",
      "\n",
      "Validation 987 valid_acc: 0.780 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 988 train_loss: 0.166 train_acc: 0.980 train_f1: 0.967 \t\n",
      "\n",
      "Validation 988 valid_acc: 0.773 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 989 train_loss: 0.170 train_acc: 0.979 train_f1: 0.965 \t\n",
      "\n",
      "Validation 989 valid_acc: 0.772 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 990 train_loss: 0.171 train_acc: 0.979 train_f1: 0.964 \t\n",
      "\n",
      "Validation 990 valid_acc: 0.769 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 991 train_loss: 0.166 train_acc: 0.981 train_f1: 0.965 \t\n",
      "\n",
      "Validation 991 valid_acc: 0.771 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 992 train_loss: 0.170 train_acc: 0.978 train_f1: 0.965 \t\n",
      "\n",
      "Validation 992 valid_acc: 0.773 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 993 train_loss: 0.171 train_acc: 0.979 train_f1: 0.964 \t\n",
      "\n",
      "Validation 993 valid_acc: 0.778 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 994 train_loss: 0.170 train_acc: 0.979 train_f1: 0.965 \t\n",
      "\n",
      "Validation 994 valid_acc: 0.774 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 995 train_loss: 0.169 train_acc: 0.980 train_f1: 0.966 \t\n",
      "\n",
      "Validation 995 valid_acc: 0.773 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 996 train_loss: 0.170 train_acc: 0.980 train_f1: 0.967 \t\n",
      "\n",
      "Validation 996 valid_acc: 0.773 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 997 train_loss: 0.165 train_acc: 0.981 train_f1: 0.967 \t\n",
      "\n",
      "Validation 997 valid_acc: 0.776 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 998 train_loss: 0.175 train_acc: 0.978 train_f1: 0.964 \t\n",
      "\n",
      "Validation 998 valid_acc: 0.779 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 999 train_loss: 0.167 train_acc: 0.980 train_f1: 0.966 \t\n",
      "\n",
      "Validation 999 valid_acc: 0.774 best_acc: 0.793 \t\n",
      "\n",
      "Epoch 1000 train_loss: 0.166 train_acc: 0.980 train_f1: 0.967 \t\n",
      "\n",
      "Validation 1000 valid_acc: 0.772 best_acc: 0.793 \t\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import keras\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras.applications.densenet import DenseNet121, DenseNet169\n",
    "#from keras.applications.nasnet import NASNetLarge\n",
    "# from keras_efficientnets import EfficientNetB7\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras import initializers, regularizers, constraints\n",
    "from keras.layers.normalization import BatchNormalization \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from keras import backend as K\n",
    "\n",
    "tf.set_random_seed(1234)\n",
    "random.seed(100)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "\n",
    "def score_f1(y_true, y_pred): #taken from old keras source code\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val\n",
    "\n",
    "def dot_product(x, kernel):\n",
    "    if K.backend() == 'tensorflow':\n",
    "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
    "    else:\n",
    "        return K.dot(x, kernel)\n",
    "    \n",
    "class AttentionWithContext(Layer):\n",
    "    def __init__(self,\n",
    "                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, u_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.u_regularizer = regularizers.get(u_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.u_constraint = constraints.get(u_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "        self.bias = bias\n",
    "        super(AttentionWithContext, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "        self.W = self.add_weight((input_shape[-1], input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight((input_shape[-1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "            self.u = self.add_weight((input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_u'.format(self.name),\n",
    "                                 regularizer=self.u_regularizer,\n",
    "                                 constraint=self.u_constraint)\n",
    "        super(AttentionWithContext, self).build(input_shape)\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        uit = dot_product(x, self.W)\n",
    "        if self.bias:\n",
    "            uit += self.b\n",
    "        uit = K.tanh(uit)\n",
    "        ait = dot_product(uit, self.u)\n",
    "        a = K.exp(ait)\n",
    "        if mask is not None:\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], input_shape[-1]\n",
    "\n",
    "    \n",
    "def cce_f1_loss(y_true, y_pred):\n",
    "    return 1 + 0.1*keras.losses.categorical_crossentropy(y_true, y_pred) - keras.metrics.categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "# Find unique number of classes  \n",
    "def get_unique_classes(input_directory,files):\n",
    "\n",
    "    unique_classes=set()\n",
    "    for f in files:\n",
    "        g = f.replace('.mat','.hea')\n",
    "        input_file = os.path.join(input_directory,g)\n",
    "        with open(input_file,'r') as f:\n",
    "            for lines in f:\n",
    "                if lines.startswith('#Dx'):\n",
    "                    tmp = lines.split(': ')[1].split(',')\n",
    "                    for c in tmp:\n",
    "                        unique_classes.add(c.strip())\n",
    "    return sorted(unique_classes)\n",
    "\n",
    "def one_hot_encoding(one_hot_vector,y, class2index):\n",
    "    ind=class2index[y]\n",
    "    one_hot_vector[ind]=1\n",
    "    return one_hot_vector\n",
    "\n",
    "# Search for multi-label subjects\n",
    "def searching_overlap(input_directory,class2index, input_file_names):\n",
    "    multiclasses=[]\n",
    "    multisubjects=[]\n",
    "    number = []\n",
    "    for file in input_file_names:\n",
    "        f=file\n",
    "        g = f.replace('.mat','.hea')\n",
    "        input_file = os.path.join(input_directory,g)\n",
    "        with open(input_file,'r') as f:\n",
    "            for lines in f:\n",
    "                if lines.startswith('#Dx'):\n",
    "                    tmp = lines.split(': ')[1].split(',')\n",
    "                    if len(tmp)>1:\n",
    "                        one_hot_vector = [0]*(len(class2index))\n",
    "                        for c in tmp:\n",
    "                            one_hot_vector = one_hot_encoding(one_hot_vector, c.strip(), class2index)\n",
    "                        multiclasses.append(one_hot_vector)\n",
    "                        multisubjects.append(g)\n",
    "                        number.append(len(tmp))\n",
    "    return multisubjects, multiclasses, number\n",
    "\n",
    "def block_feature(sequence_en, minimum_len): \n",
    "    new_en = []\n",
    "    if len(sequence_en) > minimum_len:  #  minimum  \n",
    "        start = random.randint(0,len(sequence_en)-minimum_len)\n",
    "        #print(start)\n",
    "        new_en = sequence_en[start:start+minimum_len]\n",
    "    elif len(sequence_en) == minimum_len: #  minimum\n",
    "        new_en = sequence_en\n",
    "    else: \n",
    "        assert len(sequence_en) <= minimum_len\n",
    "    return new_en\n",
    "\n",
    "def exploratory_look(input_directory,file, class2index):\n",
    "    classes = []\n",
    "    f = file\n",
    "    g = f.replace('.mat','.hea')\n",
    "    input_file = os.path.join(input_directory,g)\n",
    "    with open(input_file,'r') as f:\n",
    "        for lines in f:\n",
    "            if lines.startswith('#Dx'):\n",
    "                tmp = lines.split(': ')[1].split(',')\n",
    "                print(tmp, len(tmp))\n",
    "    return tmp     \n",
    "\n",
    "# Get classes of sorted file names\n",
    "def get_labels(input_directory,file, class2index):\n",
    "    f = file\n",
    "    g = f.replace('.mat','.hea')\n",
    "    input_file = os.path.join(input_directory,g)\n",
    "    with open(input_file,'r') as f:\n",
    "        for lines in f:\n",
    "            if lines.startswith('#Dx'):\n",
    "                tmp = lines.split(': ')[1].split(',')\n",
    "                one_hot_vector = [0]*(len(class2index))\n",
    "                for c in tmp:\n",
    "                    one_hot_vector = one_hot_encoding(one_hot_vector, c.strip(), class2index)\n",
    "                \n",
    "    return one_hot_vector\n",
    "\n",
    "def randextract_mels(curr_step, batch_size, data, mel_directory, class2index, minimum_len, x_mean_final, x_std_final):\n",
    "    mel_files = []\n",
    "    classes = []\n",
    "    start = batch_size*curr_step\n",
    "    end = batch_size*(curr_step+1)\n",
    "    curr_file_indices = data[start:end]\n",
    "    for file in curr_file_indices:\n",
    "        tmp_file = np.load(mel_directory + '/' + file.replace('.mat', '.npy'))\n",
    "        clip_file = block_feature(tmp_file, minimum_len)\n",
    "        #print(clip_file.shape)\n",
    "        #clip_file = tmp_file[:minimum_len]\n",
    "        clip_file -= x_mean_final\n",
    "        clip_file /= x_std_final\n",
    "        mel_files.append(clip_file)\n",
    "        label = get_labels(input_directory, file, class2index)\n",
    "        classes.append(label)\n",
    "    concat = list(zip(mel_files, classes))\n",
    "    random.shuffle(concat)\n",
    "    mel_files, classes = zip(*concat)\n",
    "    return mel_files, classes\n",
    "\n",
    "def train(data_train, mel_directory, batch_size, class2index, minimum_len, x_mean_final, x_std_final): \n",
    "    loss=[]\n",
    "    acc = []\n",
    "    f1 = []\n",
    "\n",
    "    total_steps = int(np.ceil(len(data_train)/batch_size))\n",
    "    for curr_step in range(total_steps):\n",
    "        batch_mels, batch_labels = randextract_mels(curr_step, batch_size, data_train, mel_directory, class2index, minimum_len, x_mean_final, x_std_final)\n",
    "        batch_mels = np.asarray(batch_mels)\n",
    "        batch_labels = np.asarray(np.squeeze(batch_labels))\n",
    "        train_tmp = model.train_on_batch(batch_mels, batch_labels)\n",
    "        loss.append(train_tmp[0])\n",
    "        acc.append(train_tmp[1])\n",
    "        f1.append(train_tmp[2])\n",
    "\n",
    "    loss = np.mean(np.array(loss))\n",
    "    acc = np.mean(np.array(acc))\n",
    "    f1 = np.mean(np.array(f1))\n",
    "    return loss, acc, f1\n",
    "\n",
    "def test(data, mel_directory, input_directory, class2index, minimum_len, model, x_mean_final, x_std_final):\n",
    "    scores = []\n",
    "    predicted_labels=[]\n",
    "    accuracy=np.zeros(len(data))\n",
    "    #total_loss=[]\n",
    "    total_acc = 0\n",
    "    total_f1 = 0\n",
    "    \n",
    "    mel_files = []\n",
    "    classes = []\n",
    "    for i, file in enumerate(data):\n",
    "        tmp_file = np.load(mel_directory + '/' + file.replace('.mat', '.npy'))\n",
    "        steps = int(np.floor(tmp_file.shape[0]/minimum_len))\n",
    "        mel_files = []\n",
    "        for block in range(steps): # 128    predict\n",
    "            start = block*minimum_len\n",
    "            end = (block+1)*minimum_len\n",
    "            clip_file = tmp_file[start:end]\n",
    "            clip_file -= x_mean_final\n",
    "            clip_file /= x_std_final\n",
    "            mel_files.append(clip_file)\n",
    "        mel_files = np.asarray(mel_files)\n",
    "        logit = model.predict(mel_files)\n",
    "        logit = np.mean(logit, axis=0)\n",
    "        pred = np.argmax(logit)\n",
    "        label = np.argmax(get_labels(input_directory, file, class2index))\n",
    "        #f1 = f1_score(label, logit)\n",
    "        #print(pred, label)\n",
    "        if pred == label:\n",
    "            acc = 1\n",
    "        else:\n",
    "            acc = 0\n",
    "        total_acc += acc\n",
    "        #total_f1 += f1\n",
    "    final_acc = total_acc / i\n",
    "    #final_f1 = total_f1 / i\n",
    "    return final_acc#, final_f1\n",
    "\n",
    "batch_size = 32\n",
    "minimum_len = 2880\n",
    "epochs = 1000\n",
    "loss_function = 'categorical_crossentropy'\n",
    "activation_function = 'softmax'\n",
    "rootdir = '../'\n",
    "date = datetime.today().strftime(\"%Y%m%d\")\n",
    "input_directory = os.path.join(rootdir, 'Training_WFDB')\n",
    "mel_name = 'Raw_data_20200424' \n",
    "mel_directory = os.path.join(rootdir, mel_name)\n",
    "results_directory = os.path.join(rootdir, 'results_'+date+'_0')\n",
    "if not os.path.isdir(input_directory):\n",
    "    os.mkdir(input_directory)\n",
    "if not os.path.isdir(mel_directory):\n",
    "    os.mkdir(mel_directory)\n",
    "if not os.path.isdir(results_directory):\n",
    "    os.mkdir(results_directory)\n",
    "        \n",
    "input_files = []\n",
    "for f in os.listdir(input_directory):\n",
    "    if os.path.isfile(os.path.join(input_directory, f)) and not f.lower().startswith('.') and f.lower().endswith('mat'):\n",
    "        input_files.append(f)\n",
    "input_file_names = sorted(input_files)\n",
    "\n",
    "unique_classes = get_unique_classes(input_directory, input_files)\n",
    "class2index = {}\n",
    "for a, b in enumerate(unique_classes):\n",
    "    class2index[b] = a\n",
    "    \n",
    "classes_orig= [x.replace('.mat', '.hea') for x in input_file_names] # total subjects\n",
    "classes_multi, _, _ = searching_overlap(input_directory,class2index, input_file_names)\n",
    "classes_single = [x for x in classes_orig if x not in classes_multi]\n",
    "classes_single = [x.replace('.hea', '.mat') for x in classes_single]\n",
    "\n",
    "# double-checking if classes_single have single-label\n",
    "a, b, c  = searching_overlap(input_directory,class2index,classes_single)\n",
    "\n",
    "# we can safely use classes_single as input_file_names\n",
    "input_file_names = classes_single\n",
    "random.shuffle(input_file_names)\n",
    "np.shape(input_file_names)\n",
    "\n",
    "x_mean_all = []\n",
    "x_std_all = []\n",
    "for file in input_file_names:\n",
    "    x = np.load(mel_directory + '/' + file.replace('.mat', '.npy'))\n",
    "    x_mean = [np.mean(x[:,0]), np.mean(x[:,1]), np.mean(x[:,2]), np.mean(x[:,3]), np.mean(x[:,4]), np.mean(x[:,5]),\n",
    "             np.mean(x[:,6]), np.mean(x[:,7]), np.mean(x[:,8]), np.mean(x[:,9]), np.mean(x[:,10]), np.mean(x[:,11])]\n",
    "    \n",
    "    x_std = [np.std(x[:,0]), np.std(x[:,1]), np.std(x[:,2]), np.std(x[:,3]), np.std(x[:,4]), np.std(x[:,5]),\n",
    "             np.std(x[:,6]), np.std(x[:,7]), np.std(x[:,8]), np.std(x[:,9]), np.std(x[:,10]), np.std(x[:,11])]\n",
    "    #print(x_mean)\n",
    "    x_mean_all.append(x_mean)\n",
    "    x_std_all.append(x_mean)\n",
    "x_mean_final = np.mean(x_mean_all, axis=0)\n",
    "x_std_final = np.mean(x_std_all, axis=0)\n",
    "print(x_mean_final)\n",
    "\n",
    "data, data_test = train_test_split(input_file_names, test_size = 0.2, train_size = 0.8, shuffle=True)\n",
    "data_train, data_val = train_test_split(data, test_size = 0.25, train_size = 0.75, shuffle=True)\n",
    "print(np.shape(data_train), np.shape(data_val), np.shape(data_test))\n",
    "\n",
    "main_input = Input(shape=(minimum_len,12), dtype='float32', name='main_input')\n",
    "\n",
    "branch_pred = []\n",
    "for i in range(12):\n",
    "    # Slicing the ith channel:\n",
    "    input_sl = Lambda(lambda x: x[:, :, i:i+1])(main_input)\n",
    "    #print(input_sl)\n",
    "    x1 = GaussianNoise(0.01 ,input_shape=(minimum_len, 1))(input_sl)\n",
    "    x1 = Conv1D(32, 10, dilation_rate=3, padding='same')(x1)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = LeakyReLU(alpha=0.3)(x1)\n",
    "    x2 = Conv1D(32, 10, dilation_rate=3, padding='same')(x1)\n",
    "    x2 = add([x2, x1])\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = LeakyReLU(alpha=0.3)(x2)\n",
    "    #x2 = MaxPooling1D(pool_size=2)(x2)\n",
    "    x2 = Convolution1D(32, 20, strides = 2, padding='same')(x2)\n",
    "    #x2 = Dropout(0.25)(x2)\n",
    "\n",
    "    x3 = Conv1D(64, 10, dilation_rate=2, padding='same')(x2)\n",
    "    x3 = BatchNormalization()(x3)\n",
    "    x3 = LeakyReLU(alpha=0.3)(x3)\n",
    "    x4 = Conv1D(64, 10, dilation_rate=2, padding='same')(x3)\n",
    "    x4 = add([x4, x3])\n",
    "    x4 = BatchNormalization()(x4)\n",
    "    x4 = LeakyReLU(alpha=0.3)(x4)\n",
    "    #x4 = MaxPooling1D(pool_size=2)(x4)\n",
    "    x4 = Convolution1D(32, 20, strides = 2, padding='same')(x4)\n",
    "    #x4 = Dropout(0.25)(x4)\n",
    "\n",
    "    x5 = Conv1D(128, 10, dilation_rate=1, padding='same')(x4)\n",
    "    x5 = BatchNormalization()(x5)\n",
    "    x5 = LeakyReLU(alpha=0.3)(x5)\n",
    "    x6 = Conv1D(128, 10, dilation_rate=1, padding='same')(x5)\n",
    "    x6 = add([x6, x5])\n",
    "    x6 = BatchNormalization()(x6)\n",
    "    x6 = LeakyReLU(alpha=0.3)(x6)\n",
    "    #x6 = MaxPooling1D(pool_size=2)(x6)\n",
    "    x6 = Convolution1D(64, 20, strides = 2, padding='same')(x6)\n",
    "    #x6 = Dropout(0.25)(x6)\n",
    "    '''\n",
    "    x7 = Conv1D(64, 10, dilation_rate=1, padding='same')(x6)\n",
    "    x7 = BatchNormalization()(x7)\n",
    "    x7 = LeakyReLU(alpha=0.3)(x7)\n",
    "    x8 = Conv1D(64, 10, dilation_rate=1, padding='same')(x7)\n",
    "    x8 = add([x8, x7])\n",
    "    x8 = BatchNormalization()(x8)\n",
    "    x8 = LeakyReLU(alpha=0.3)(x8)\n",
    "    #x8 = MaxPooling1D(pool_size=2)(x8)\n",
    "    x8 = Convolution1D(64, 20, strides = 2, padding='same')(x8)\n",
    "    #cnnout = GlobalAveragePooling1D()(x8)\n",
    "    #x8 = Dropout(0.25)(x8)\n",
    "    '''\n",
    "    x = Bidirectional(CuDNNGRU(128, input_shape=(360,128),return_sequences=True,return_state=False))(x6)\n",
    "    x = LeakyReLU(alpha=0.3)(x)\n",
    "    x = AttentionWithContext()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.3)(x)\n",
    "    \n",
    "    #x = GlobalAveragePooling1D()(x8)\n",
    "    #x = Flatten()(x8)\n",
    "    #x = Dense(512)(x)\n",
    "    #x = BatchNormalization()(x)\n",
    "    #x = Activation('relu')(x)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    x = Dense(9)(x)\n",
    "    pred  = Activation('softmax')(x)\n",
    "    branch_pred.append(pred)\n",
    "    \n",
    "out = Average()(branch_pred)\n",
    "#print(out)\n",
    "\n",
    "model = Model(inputs=main_input, outputs=out)\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=loss_function,\n",
    "              optimizer=optimizers.Adam(lr=1e-5),\n",
    "              metrics=['acc', score_f1])\n",
    "\n",
    "val_acc_sum=[]\n",
    "train_loss_sum=[]\n",
    "train_acc_sum=[]\n",
    "val_loss_sum=[]\n",
    "val_acc_min = 0\n",
    "for num_epoch in range(epochs):\n",
    "    random.shuffle(data_train)\n",
    "    train_loss, train_acc, train_f1 = train(data_train, mel_directory, batch_size, class2index, minimum_len, x_mean_final, x_std_final)\n",
    "    print('\\nEpoch',num_epoch+1,'train_loss:',f'{train_loss:.3f}','train_acc:',f'{train_acc:.3f}','train_f1:',f'{train_f1:.3f}',\"\\t\")\n",
    "    model_output = \"ecg_mel_E%02dL%.2f\" % (num_epoch, train_loss)\n",
    "    save_name = os.path.join(results_directory, model_output)\n",
    "    #val_acc, val_f1 = test(data_val, mel_directory, input_directory, class2index, minimum_len, model, x_mean_final, x_std_final)\n",
    "    val_acc = test(data_val, mel_directory, input_directory, class2index, minimum_len, model, x_mean_final, x_std_final)\n",
    "    #print('\\nValidation', num_epoch+1,'valid_loss:',f'{val_loss:.3f}','valid_acc:',f'{val_acc:.3f}',\"\\t\", dt.datetime.now())\n",
    "    if val_acc > val_acc_min:\n",
    "        val_acc_min = val_acc\n",
    "        model.save(save_name)\n",
    "        #print(\"Validation loss is improved\")\n",
    "    #print('\\nValidation', num_epoch+1, 'valid_acc:',f'{val_acc:.3f}', 'valid_f1:',f'{valid_f1:.3f}', 'best_f1:',f'{val_f1_min:.3f}', \"\\t\")\n",
    "    print('\\nValidation', num_epoch+1, 'valid_acc:',f'{val_acc:.3f}', 'best_acc:',f'{val_acc_min:.3f}', \"\\t\")\n",
    "    #val_acc_sum.append(val_acc)\n",
    "    #val_loss_sum.append(val_loss)\n",
    "    #train_loss_sum.append(train_loss)\n",
    "    #train_acc_sum.append(train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
