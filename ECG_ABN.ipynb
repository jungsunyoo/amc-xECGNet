{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/numba/errors.py:137: UserWarning: Insufficiently recent colorama version found. Numba requires colorama >= 0.3.9\n",
      "  warnings.warn(msg)\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow.contrib.eager as tfe\n",
    "\n",
    "\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import keras\n",
    "# import datetime as dt\n",
    "from datetime import datetime\n",
    "import time\n",
    "# import datetime.datetime\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from keras import layers\n",
    "from keras import models\n",
    "# from keras import optimizers\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "from keras.applications.densenet import DenseNet121, DenseNet169\n",
    "#from keras.applications.nasnet import NASNetLarge\n",
    "# from keras_efficientnets import EfficientNetB7\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras import initializers, regularizers, constraints\n",
    "from keras.layers.normalization import BatchNormalization \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tf.set_random_seed(1234)\n",
    "random.seed(100)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.24290386e-03 -4.58280585e-05  4.31697309e-03 -3.00174693e-03\n",
      " -2.36609229e-04  1.28997408e-03  2.17347589e-04 -7.99152384e-04\n",
      " -3.42993744e-03 -1.69711686e-03  1.27138164e-03  1.94670545e-03]\n",
      "(3840,) (1280,) (1281,)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def score_f1(y_true, y_pred): #taken from old keras source code\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val\n",
    "\n",
    "def dot_product(x, kernel):\n",
    "    if K.backend() == 'tensorflow':\n",
    "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
    "    else:\n",
    "        return K.dot(x, kernel)\n",
    "    \n",
    "def get_unique_classes(input_directory,files):\n",
    "\n",
    "    unique_classes=set()\n",
    "    for f in files:\n",
    "        g = f.replace('.mat','.hea')\n",
    "        input_file = os.path.join(input_directory,g)\n",
    "        with open(input_file,'r') as f:\n",
    "            for lines in f:\n",
    "                if lines.startswith('#Dx'):\n",
    "                    tmp = lines.split(': ')[1].split(',')\n",
    "                    for c in tmp:\n",
    "                        unique_classes.add(c.strip())\n",
    "    return sorted(unique_classes)\n",
    "\n",
    "def one_hot_encoding(one_hot_vector,y, class2index):\n",
    "    ind=class2index[y]\n",
    "    one_hot_vector[ind]=1\n",
    "    return one_hot_vector\n",
    "\n",
    "# Search for multi-label subjects\n",
    "def searching_overlap(input_directory,class2index, input_file_names):\n",
    "    multiclasses=[]\n",
    "    multisubjects=[]\n",
    "    number = []\n",
    "    for file in input_file_names:\n",
    "        f=file\n",
    "        g = f.replace('.mat','.hea')\n",
    "        input_file = os.path.join(input_directory,g)\n",
    "        with open(input_file,'r') as f:\n",
    "            for lines in f:\n",
    "                if lines.startswith('#Dx'):\n",
    "                    tmp = lines.split(': ')[1].split(',')\n",
    "                    if len(tmp)>1:\n",
    "                        one_hot_vector = [0]*(len(class2index))\n",
    "                        for c in tmp:\n",
    "                            one_hot_vector = one_hot_encoding(one_hot_vector, c.strip(), class2index)\n",
    "                        multiclasses.append(one_hot_vector)\n",
    "                        multisubjects.append(g)\n",
    "                        number.append(len(tmp))\n",
    "    return multisubjects, multiclasses, number\n",
    "\n",
    "def block_feature(sequence_en, minimum_len): \n",
    "    new_en = []\n",
    "    if len(sequence_en) > minimum_len:  # 길이가 minimum보다 긴 경우\n",
    "        start = random.randint(0,len(sequence_en)-minimum_len)\n",
    "        #print(start)\n",
    "        new_en = sequence_en[start:start+minimum_len]\n",
    "    elif len(sequence_en) == minimum_len: # 길이가 minimum\n",
    "        new_en = sequence_en\n",
    "    else: \n",
    "        assert len(sequence_en) <= minimum_len\n",
    "    return new_en\n",
    "\n",
    "def exploratory_look(input_directory,file, class2index):\n",
    "    classes = []\n",
    "    f = file\n",
    "    g = f.replace('.mat','.hea')\n",
    "    input_file = os.path.join(input_directory,g)\n",
    "    with open(input_file,'r') as f:\n",
    "        for lines in f:\n",
    "            if lines.startswith('#Dx'):\n",
    "                tmp = lines.split(': ')[1].split(',')\n",
    "                print(tmp, len(tmp))\n",
    "    return tmp     \n",
    "\n",
    "# Get classes of sorted file names\n",
    "def get_labels(input_directory,file, class2index):\n",
    "    f = file\n",
    "    g = f.replace('.mat','.hea')\n",
    "    input_file = os.path.join(input_directory,g)\n",
    "    with open(input_file,'r') as f:\n",
    "        for lines in f:\n",
    "            if lines.startswith('#Dx'):\n",
    "                tmp = lines.split(': ')[1].split(',')\n",
    "                one_hot_vector = [0]*(len(class2index))\n",
    "                for c in tmp:\n",
    "                    one_hot_vector = one_hot_encoding(one_hot_vector, c.strip(), class2index)\n",
    "                \n",
    "    return one_hot_vector\n",
    "\n",
    "def randextract_mels(curr_step, batch_size, data, mel_directory, class2index, minimum_len, x_mean_final, x_std_final):\n",
    "    mel_files = []\n",
    "    classes = []\n",
    "    start = batch_size*curr_step\n",
    "    end = batch_size*(curr_step+1)\n",
    "    curr_file_indices = data[start:end]\n",
    "    for file in curr_file_indices:\n",
    "        tmp_file = np.load(mel_directory + '/' + file.replace('.mat', '.npy'))\n",
    "        clip_file = block_feature(tmp_file, minimum_len)\n",
    "        #print(clip_file.shape)\n",
    "        #clip_file = tmp_file[:minimum_len]\n",
    "        clip_file -= x_mean_final\n",
    "        clip_file /= x_std_final\n",
    "        mel_files.append(clip_file)\n",
    "        label = get_labels(input_directory, file, class2index)\n",
    "        classes.append(label)\n",
    "    \n",
    "    # YJS added for ABN -> should calculate 2 losses\n",
    "#     classes_abn = [classes,classes]\n",
    "    \n",
    "    concat = list(zip(mel_files, classes))\n",
    "#     concat = list(zip(mel_files, classes_abn))\n",
    "    random.shuffle(concat)\n",
    "    mel_files, classes = zip(*concat)\n",
    "    return mel_files, classes\n",
    "\n",
    "def train(data_train, mel_directory, batch_size, class2index, minimum_len, x_mean_final, x_std_final): \n",
    "    loss=[]\n",
    "#     acc = []\n",
    "    f1 = []\n",
    "\n",
    "    total_steps = int(np.ceil(len(data_train)/batch_size))\n",
    "    for curr_step in range(total_steps):\n",
    "        batch_mels, batch_labels = randextract_mels(curr_step, batch_size, data_train, mel_directory, class2index, minimum_len, x_mean_final, x_std_final)\n",
    "        batch_mels = np.asarray(batch_mels)\n",
    "        batch_labels2 = np.asarray(np.squeeze(batch_labels))\n",
    "        batch_labels = [batch_labels2, batch_labels2]\n",
    "#         print(batch_labels.shape)\n",
    "#         print(batch_labels)\n",
    "\n",
    "# return of train\n",
    "# 0 = total loss (attention branch + perception branch)\n",
    "# 1 = loss of attention pred\n",
    "# 2 = loss of perception pred\n",
    "# 3 = f1 of attention pred\n",
    "# 4 = f1 of perception pred     \n",
    "\n",
    "        train_tmp = model.train_on_batch(batch_mels, batch_labels)\n",
    "#         print(train_tmp)\n",
    "        loss_ = train_tmp[0]/2\n",
    "        f1_ = np.mean((train_tmp[3], train_tmp[4]))\n",
    "        loss.append(loss_)\n",
    "#         acc.append(train_tmp[1])\n",
    "        f1.append(f1_)\n",
    "\n",
    "    loss = np.mean(np.array(loss))\n",
    "#     acc = np.mean(np.array(acc))\n",
    "    f1 = np.mean(np.array(f1))\n",
    "    return loss, f1\n",
    "\n",
    "def test(data, mel_directory, input_directory, class2index, minimum_len, model, x_mean_final, x_std_final):\n",
    "    scores = []\n",
    "    predicted_labels=[]\n",
    "    accuracy=np.zeros(len(data))\n",
    "    #total_loss=[]\n",
    "    total_acc = 0\n",
    "    total_f1 = 0\n",
    "    \n",
    "    mel_files = []\n",
    "    classes = []\n",
    "    for i, file in enumerate(data):\n",
    "        tmp_file = np.load(mel_directory + '/' + file.replace('.mat', '.npy'))\n",
    "        steps = int(np.floor(tmp_file.shape[0]/minimum_len))\n",
    "        mel_files = []\n",
    "        for block in range(steps): # 128개씩 쪼갠 블럭 단위로 predict\n",
    "            start = block*minimum_len\n",
    "            end = (block+1)*minimum_len\n",
    "            clip_file = tmp_file[start:end]\n",
    "            clip_file -= x_mean_final\n",
    "            clip_file /= x_std_final\n",
    "            mel_files.append(clip_file)\n",
    "        mel_files = np.asarray(mel_files)\n",
    "        logit = model.predict(mel_files)\n",
    "#         print(len(logit))\n",
    "        logit = np.mean(logit, axis=0)\n",
    "        logit = np.mean(logit, axis=0)\n",
    "#         print(logit)\n",
    "        pred = np.argmax(logit)\n",
    "#         print('Pred={}'.format(pred))\n",
    "        \n",
    "        label = np.argmax(get_labels(input_directory, file, class2index))\n",
    "#         print('Label={}'.format(label))\n",
    "        #f1 = f1_score(label, logit)\n",
    "        #print(pred, label)\n",
    "        if pred == label:\n",
    "            acc = 1\n",
    "        else:\n",
    "            acc = 0\n",
    "        total_acc += acc\n",
    "        #total_f1 += f1\n",
    "    final_acc = total_acc / i\n",
    "    #final_f1 = total_f1 / i\n",
    "    return final_acc#, final_f1\n",
    "\n",
    "batch_size = 32#16#20#32#5#2#1#10#32\n",
    "\n",
    "minimum_len = 2880\n",
    "epochs = 1000\n",
    "loss_function = 'categorical_crossentropy'\n",
    "activation_function = 'softmax'\n",
    "rootdir = '../'\n",
    "date = datetime.today().strftime(\"%Y%m%d\")\n",
    "input_directory = os.path.join(rootdir, 'Training_WFDB')\n",
    "mel_name = 'Raw_data_20200424' \n",
    "mel_directory = os.path.join(rootdir, mel_name)\n",
    "results_directory = os.path.join(rootdir, 'results_'+date+'_0_IEEE_n=1')\n",
    "if not os.path.isdir(input_directory):\n",
    "    os.mkdir(input_directory)\n",
    "if not os.path.isdir(mel_directory):\n",
    "    os.mkdir(mel_directory)\n",
    "if not os.path.isdir(results_directory):\n",
    "    os.mkdir(results_directory)\n",
    "        \n",
    "input_files = []\n",
    "for f in os.listdir(input_directory):\n",
    "    if os.path.isfile(os.path.join(input_directory, f)) and not f.lower().startswith('.') and f.lower().endswith('mat'):\n",
    "        input_files.append(f)\n",
    "input_file_names = sorted(input_files)\n",
    "\n",
    "unique_classes = get_unique_classes(input_directory, input_files)\n",
    "class2index = {}\n",
    "for a, b in enumerate(unique_classes):\n",
    "    class2index[b] = a\n",
    "    \n",
    "classes_orig= [x.replace('.mat', '.hea') for x in input_file_names] # total subjects\n",
    "classes_multi, _, _ = searching_overlap(input_directory,class2index, input_file_names)\n",
    "classes_single = [x for x in classes_orig if x not in classes_multi]\n",
    "classes_single = [x.replace('.hea', '.mat') for x in classes_single]\n",
    "\n",
    "# double-checking if classes_single have single-label\n",
    "a, b, c  = searching_overlap(input_directory,class2index,classes_single)\n",
    "\n",
    "# we can safely use classes_single as input_file_names\n",
    "input_file_names = classes_single\n",
    "random.shuffle(input_file_names)\n",
    "np.shape(input_file_names)\n",
    "\n",
    "x_mean_all = []\n",
    "x_std_all = []\n",
    "for file in input_file_names:\n",
    "    x = np.load(mel_directory + '/' + file.replace('.mat', '.npy'))\n",
    "    x_mean = [np.mean(x[:,0]), np.mean(x[:,1]), np.mean(x[:,2]), np.mean(x[:,3]), np.mean(x[:,4]), np.mean(x[:,5]),\n",
    "             np.mean(x[:,6]), np.mean(x[:,7]), np.mean(x[:,8]), np.mean(x[:,9]), np.mean(x[:,10]), np.mean(x[:,11])]\n",
    "    \n",
    "    x_std = [np.std(x[:,0]), np.std(x[:,1]), np.std(x[:,2]), np.std(x[:,3]), np.std(x[:,4]), np.std(x[:,5]),\n",
    "             np.std(x[:,6]), np.std(x[:,7]), np.std(x[:,8]), np.std(x[:,9]), np.std(x[:,10]), np.std(x[:,11])]\n",
    "    #print(x_mean)\n",
    "    x_mean_all.append(x_mean)\n",
    "    x_std_all.append(x_std) # yjs corrected on 2020-05-25\n",
    "x_mean_final = np.mean(x_mean_all, axis=0)\n",
    "x_std_final = np.mean(x_std_all, axis=0)\n",
    "print(x_mean_final)\n",
    "\n",
    "data, data_test = train_test_split(input_file_names, test_size = 0.2, train_size = 0.8, shuffle=True)\n",
    "data_train, data_val = train_test_split(data, test_size = 0.25, train_size = 0.75, shuffle=True)\n",
    "print(np.shape(data_train), np.shape(data_val), np.shape(data_test))\n",
    "\n",
    "\n",
    "main_input = Input(shape=(minimum_len,12), dtype='float32', name='main_input')\n",
    "\n",
    "branch_pred = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_image (InputLayer)        [(None, None, 12)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, None, 64)     2368        input_image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, None, 64)     256         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, None, 64)     12352       batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, 64)     256         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, None, 64)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, None, 128)    24704       max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, 128)    512         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, None, 128)    49280       batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, None, 128)    512         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, None, 128)    0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, None, 256)    98560       max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, None, 256)    1024        conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, None, 256)    196864      batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, None, 256)    1024        conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, None, 256)    196864      batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, None, 256)    1024        conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, None, 256)    0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, None, 512)    393728      max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, None, 512)    2048        conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, None, 512)    786944      batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, None, 512)    2048        conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, None, 512)    786944      batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, None, 512)    2048        conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, None, 512)    0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, None, 512)    786944      max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, None, 512)    2048        conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, None, 256)    393472      batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, None, 256)    1024        conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, None, 128)    98432       batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, None, 128)    512         conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, None, 128)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, None, 64)     8192        max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, None, 64)     256         conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, None, 64)     0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, None, 64)     12288       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, None, 64)     256         conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, None, 64)     0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, None, 256)    16384       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, None, 256)    32768       max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, None, 256)    1024        conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, None, 256)    1024        conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, None, 256)    0           batch_normalization_16[0][0]     \n",
      "                                                                 batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, None, 256)    0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "attention_branch_bn_1 (BatchNor (None, None, 256)    1024        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "attention_branch_conv_1 (Conv1D (None, None, 9)      2304        attention_branch_bn_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attention_branch_att_conv_1 (Co (None, None, 1)      9           attention_branch_conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "attention_branch_att_bn_1 (Batc (None, None, 1)      4           attention_branch_att_conv_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "attention_branch_att_sigmoid_1  (None, None, 1)      0           attention_branch_att_bn_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, None, 128)    0           max_pooling1d_4[0][0]            \n",
      "                                                                 attention_branch_att_sigmoid_1[0]\n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, None, 64)     8192        lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, None, 64)     256         conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, None, 64)     0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, None, 64)     12288       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, None, 64)     256         conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, None, 64)     0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, None, 256)    16384       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, None, 256)    32768       lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, None, 256)    1024        conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, None, 256)    1024        conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, None, 256)    0           batch_normalization_20[0][0]     \n",
      "                                                                 batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, None, 256)    0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "perception_branch_avgpool_1 (Gl (None, 256)          0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "attention_branch_pred_conv_1 (C (None, None, 9)      81          attention_branch_conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "perception_branch_dense_1 (Dens (None, 256)          65792       perception_branch_avgpool_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "attention_branch_gap_1 (GlobalA (None, 9)            0           attention_branch_pred_conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "perception_branch_dense_2 (Dens (None, 9)            2313        perception_branch_dense_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "attention_branch_output (Softma (None, 9)            0           attention_branch_gap_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "perception_branch_output (Softm (None, 9)            0           perception_branch_dense_2[0][0]  \n",
      "==================================================================================================\n",
      "Total params: 4,057,703\n",
      "Trainable params: 4,047,461\n",
      "Non-trainable params: 10,242\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from ABNmodules import *\n",
    "\n",
    "# def get_custom_model(input_shape, n_classes, minimum_len, target_classes, out_ch=256, n=18):\n",
    "model = get_custom_model((None, 12), 9, minimum_len, 1, out_ch=256, n=1)\n",
    "# model = get_model((None, 12), 9, n=7)\n",
    "\n",
    "# model = cam_model((None, 12), 9, minimum_len, out_ch=256, n=18)\n",
    "model.summary()\n",
    "model.compile(loss=loss_function,\n",
    "              optimizer=optimizers.Adam(lr=1e-5),           \n",
    "              metrics=[score_f1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../results_20200529_0_IEEE_n=1\n",
      "\n",
      "Epoch 1 train_loss: 1.947 train_f1: 0.110 \t\n",
      "\n",
      "Validation 1 valid_acc: 0.443 best_acc: 0.443 \t\n",
      "\n",
      "Epoch 2 train_loss: 1.590 train_f1: 0.296 \t\n",
      "\n",
      "Validation 2 valid_acc: 0.490 best_acc: 0.490 \t\n",
      "\n",
      "Epoch 3 train_loss: 1.469 train_f1: 0.362 \t\n",
      "\n",
      "Validation 3 valid_acc: 0.560 best_acc: 0.560 \t\n",
      "\n",
      "Epoch 4 train_loss: 1.383 train_f1: 0.412 \t\n",
      "\n",
      "Validation 4 valid_acc: 0.615 best_acc: 0.615 \t\n",
      "\n",
      "Epoch 5 train_loss: 1.316 train_f1: 0.452 \t\n",
      "\n",
      "Validation 5 valid_acc: 0.640 best_acc: 0.640 \t\n",
      "\n",
      "Epoch 6 train_loss: 1.256 train_f1: 0.484 \t\n",
      "\n",
      "Validation 6 valid_acc: 0.690 best_acc: 0.690 \t\n",
      "\n",
      "Epoch 7 train_loss: 1.207 train_f1: 0.512 \t\n",
      "\n",
      "Validation 7 valid_acc: 0.689 best_acc: 0.690 \t\n",
      "\n",
      "Epoch 8 train_loss: 1.168 train_f1: 0.534 \t\n",
      "\n",
      "Validation 8 valid_acc: 0.721 best_acc: 0.721 \t\n",
      "\n",
      "Epoch 9 train_loss: 1.120 train_f1: 0.556 \t\n",
      "\n",
      "Validation 9 valid_acc: 0.738 best_acc: 0.738 \t\n",
      "\n",
      "Epoch 10 train_loss: 1.080 train_f1: 0.570 \t\n",
      "\n",
      "Validation 10 valid_acc: 0.747 best_acc: 0.747 \t\n",
      "\n",
      "Epoch 11 train_loss: 1.039 train_f1: 0.589 \t\n",
      "\n",
      "Validation 11 valid_acc: 0.762 best_acc: 0.762 \t\n",
      "\n",
      "Epoch 12 train_loss: 1.006 train_f1: 0.602 \t\n",
      "\n",
      "Validation 12 valid_acc: 0.752 best_acc: 0.762 \t\n",
      "\n",
      "Epoch 13 train_loss: 0.978 train_f1: 0.608 \t\n",
      "\n",
      "Validation 13 valid_acc: 0.751 best_acc: 0.762 \t\n",
      "\n",
      "Epoch 14 train_loss: 0.959 train_f1: 0.618 \t\n",
      "\n",
      "Validation 14 valid_acc: 0.769 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 15 train_loss: 0.926 train_f1: 0.627 \t\n",
      "\n",
      "Validation 15 valid_acc: 0.764 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 16 train_loss: 0.905 train_f1: 0.637 \t\n",
      "\n",
      "Validation 16 valid_acc: 0.756 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 17 train_loss: 0.899 train_f1: 0.636 \t\n",
      "\n",
      "Validation 17 valid_acc: 0.771 best_acc: 0.771 \t\n",
      "\n",
      "Epoch 18 train_loss: 0.874 train_f1: 0.648 \t\n",
      "\n",
      "Validation 18 valid_acc: 0.756 best_acc: 0.771 \t\n",
      "\n",
      "Epoch 19 train_loss: 0.850 train_f1: 0.655 \t\n",
      "\n",
      "Validation 19 valid_acc: 0.744 best_acc: 0.771 \t\n",
      "\n",
      "Epoch 20 train_loss: 0.850 train_f1: 0.660 \t\n",
      "\n",
      "Validation 20 valid_acc: 0.763 best_acc: 0.771 \t\n",
      "\n",
      "Epoch 21 train_loss: 0.828 train_f1: 0.676 \t\n",
      "\n",
      "Validation 21 valid_acc: 0.764 best_acc: 0.771 \t\n",
      "\n",
      "Epoch 22 train_loss: 0.820 train_f1: 0.680 \t\n",
      "\n",
      "Validation 22 valid_acc: 0.746 best_acc: 0.771 \t\n",
      "\n",
      "Epoch 23 train_loss: 0.807 train_f1: 0.688 \t\n",
      "\n",
      "Validation 23 valid_acc: 0.762 best_acc: 0.771 \t\n",
      "\n",
      "Epoch 24 train_loss: 0.775 train_f1: 0.703 \t\n",
      "\n",
      "Validation 24 valid_acc: 0.765 best_acc: 0.771 \t\n",
      "\n",
      "Epoch 25 train_loss: 0.780 train_f1: 0.700 \t\n",
      "\n",
      "Validation 25 valid_acc: 0.770 best_acc: 0.771 \t\n",
      "\n",
      "Epoch 26 train_loss: 0.769 train_f1: 0.709 \t\n",
      "\n",
      "Validation 26 valid_acc: 0.756 best_acc: 0.771 \t\n",
      "\n",
      "Epoch 27 train_loss: 0.748 train_f1: 0.722 \t\n",
      "\n",
      "Validation 27 valid_acc: 0.767 best_acc: 0.771 \t\n",
      "\n",
      "Epoch 28 train_loss: 0.726 train_f1: 0.732 \t\n",
      "\n",
      "Validation 28 valid_acc: 0.783 best_acc: 0.783 \t\n",
      "\n",
      "Epoch 29 train_loss: 0.728 train_f1: 0.730 \t\n",
      "\n",
      "Validation 29 valid_acc: 0.772 best_acc: 0.783 \t\n",
      "\n",
      "Epoch 30 train_loss: 0.704 train_f1: 0.741 \t\n",
      "\n",
      "Validation 30 valid_acc: 0.771 best_acc: 0.783 \t\n",
      "\n",
      "Epoch 31 train_loss: 0.692 train_f1: 0.749 \t\n",
      "\n",
      "Validation 31 valid_acc: 0.759 best_acc: 0.783 \t\n",
      "\n",
      "Epoch 32 train_loss: 0.694 train_f1: 0.746 \t\n",
      "\n",
      "Validation 32 valid_acc: 0.779 best_acc: 0.783 \t\n",
      "\n",
      "Epoch 33 train_loss: 0.686 train_f1: 0.757 \t\n",
      "\n",
      "Validation 33 valid_acc: 0.772 best_acc: 0.783 \t\n",
      "\n",
      "Epoch 34 train_loss: 0.680 train_f1: 0.756 \t\n",
      "\n",
      "Validation 34 valid_acc: 0.769 best_acc: 0.783 \t\n",
      "\n",
      "Epoch 35 train_loss: 0.670 train_f1: 0.762 \t\n",
      "\n",
      "Validation 35 valid_acc: 0.771 best_acc: 0.783 \t\n",
      "\n",
      "Epoch 36 train_loss: 0.646 train_f1: 0.774 \t\n",
      "\n",
      "Validation 36 valid_acc: 0.770 best_acc: 0.783 \t\n",
      "\n",
      "Epoch 37 train_loss: 0.638 train_f1: 0.780 \t\n",
      "\n",
      "Validation 37 valid_acc: 0.771 best_acc: 0.783 \t\n",
      "\n",
      "Epoch 38 train_loss: 0.629 train_f1: 0.780 \t\n",
      "\n",
      "Validation 38 valid_acc: 0.779 best_acc: 0.783 \t\n",
      "\n",
      "Epoch 39 train_loss: 0.627 train_f1: 0.782 \t\n",
      "\n",
      "Validation 39 valid_acc: 0.774 best_acc: 0.783 \t\n",
      "\n",
      "Epoch 40 train_loss: 0.634 train_f1: 0.782 \t\n",
      "\n",
      "Validation 40 valid_acc: 0.766 best_acc: 0.783 \t\n",
      "\n",
      "Epoch 41 train_loss: 0.604 train_f1: 0.791 \t\n",
      "\n",
      "Validation 41 valid_acc: 0.763 best_acc: 0.783 \t\n",
      "\n",
      "Epoch 42 train_loss: 0.599 train_f1: 0.796 \t\n",
      "\n",
      "Validation 42 valid_acc: 0.769 best_acc: 0.783 \t\n",
      "\n",
      "Epoch 43 train_loss: 0.594 train_f1: 0.794 \t\n",
      "\n",
      "Validation 43 valid_acc: 0.769 best_acc: 0.783 \t\n",
      "\n",
      "Epoch 44 train_loss: 0.590 train_f1: 0.797 \t\n",
      "\n",
      "Validation 44 valid_acc: 0.781 best_acc: 0.783 \t\n",
      "\n",
      "Epoch 45 train_loss: 0.571 train_f1: 0.804 \t\n",
      "\n",
      "Validation 45 valid_acc: 0.756 best_acc: 0.783 \t\n",
      "\n",
      "Epoch 46 train_loss: 0.565 train_f1: 0.808 \t\n",
      "\n",
      "Validation 46 valid_acc: 0.781 best_acc: 0.783 \t\n",
      "\n",
      "Epoch 47 train_loss: 0.581 train_f1: 0.802 \t\n",
      "\n",
      "Validation 47 valid_acc: 0.762 best_acc: 0.783 \t\n",
      "\n",
      "Epoch 48 train_loss: 0.556 train_f1: 0.808 \t\n",
      "\n",
      "Validation 48 valid_acc: 0.782 best_acc: 0.783 \t\n",
      "\n",
      "Epoch 49 train_loss: 0.548 train_f1: 0.817 \t\n",
      "\n",
      "Validation 49 valid_acc: 0.782 best_acc: 0.783 \t\n",
      "\n",
      "Epoch 50 train_loss: 0.534 train_f1: 0.816 \t\n",
      "\n",
      "Validation 50 valid_acc: 0.778 best_acc: 0.783 \t\n",
      "\n",
      "Epoch 51 train_loss: 0.530 train_f1: 0.822 \t\n",
      "\n",
      "Validation 51 valid_acc: 0.777 best_acc: 0.783 \t\n",
      "\n",
      "Epoch 52 train_loss: 0.531 train_f1: 0.820 \t\n",
      "\n",
      "Validation 52 valid_acc: 0.769 best_acc: 0.783 \t\n",
      "\n",
      "Epoch 53 train_loss: 0.516 train_f1: 0.825 \t\n",
      "\n",
      "Validation 53 valid_acc: 0.759 best_acc: 0.783 \t\n",
      "\n",
      "Epoch 54 train_loss: 0.505 train_f1: 0.832 \t\n",
      "\n",
      "Validation 54 valid_acc: 0.769 best_acc: 0.783 \t\n",
      "\n",
      "Epoch 55 train_loss: 0.511 train_f1: 0.829 \t\n",
      "\n",
      "Validation 55 valid_acc: 0.780 best_acc: 0.783 \t\n",
      "\n",
      "Epoch 56 train_loss: 0.507 train_f1: 0.823 \t\n",
      "\n",
      "Validation 56 valid_acc: 0.767 best_acc: 0.783 \t\n",
      "\n",
      "Epoch 57 train_loss: 0.495 train_f1: 0.840 \t\n",
      "\n",
      "Validation 57 valid_acc: 0.773 best_acc: 0.783 \t\n",
      "\n",
      "Epoch 58 train_loss: 0.489 train_f1: 0.834 \t\n",
      "\n",
      "Validation 58 valid_acc: 0.776 best_acc: 0.783 \t\n",
      "\n",
      "Epoch 59 train_loss: 0.486 train_f1: 0.836 \t\n",
      "\n",
      "Validation 59 valid_acc: 0.765 best_acc: 0.783 \t\n",
      "\n",
      "Epoch 60 train_loss: 0.477 train_f1: 0.840 \t\n",
      "\n",
      "Validation 60 valid_acc: 0.776 best_acc: 0.783 \t\n",
      "\n",
      "Epoch 61 train_loss: 0.455 train_f1: 0.849 \t\n",
      "\n",
      "Validation 61 valid_acc: 0.783 best_acc: 0.783 \t\n",
      "\n",
      "Epoch 62 train_loss: 0.476 train_f1: 0.844 \t\n",
      "\n",
      "Validation 62 valid_acc: 0.779 best_acc: 0.783 \t\n",
      "\n",
      "Epoch 63 train_loss: 0.474 train_f1: 0.843 \t\n",
      "\n",
      "Validation 63 valid_acc: 0.773 best_acc: 0.783 \t\n",
      "\n",
      "Epoch 64 train_loss: 0.464 train_f1: 0.844 \t\n",
      "\n",
      "Validation 64 valid_acc: 0.751 best_acc: 0.783 \t\n",
      "\n",
      "Epoch 65 train_loss: 0.447 train_f1: 0.850 \t\n",
      "\n",
      "Validation 65 valid_acc: 0.769 best_acc: 0.783 \t\n",
      "\n",
      "Epoch 66 train_loss: 0.432 train_f1: 0.857 \t\n",
      "\n",
      "Validation 66 valid_acc: 0.775 best_acc: 0.783 \t\n",
      "\n",
      "Epoch 67 train_loss: 0.439 train_f1: 0.855 \t\n",
      "\n",
      "Validation 67 valid_acc: 0.779 best_acc: 0.783 \t\n",
      "\n",
      "Epoch 68 train_loss: 0.431 train_f1: 0.856 \t\n",
      "\n",
      "Validation 68 valid_acc: 0.770 best_acc: 0.783 \t\n",
      "\n",
      "Epoch 69 train_loss: 0.432 train_f1: 0.855 \t\n",
      "\n",
      "Validation 69 valid_acc: 0.754 best_acc: 0.783 \t\n",
      "\n",
      "Epoch 70 train_loss: 0.417 train_f1: 0.864 \t\n",
      "\n",
      "Validation 70 valid_acc: 0.777 best_acc: 0.783 \t\n",
      "\n",
      "Epoch 71 train_loss: 0.411 train_f1: 0.863 \t\n",
      "\n",
      "Validation 71 valid_acc: 0.784 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 72 train_loss: 0.422 train_f1: 0.859 \t\n",
      "\n",
      "Validation 72 valid_acc: 0.772 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 73 train_loss: 0.406 train_f1: 0.867 \t\n",
      "\n",
      "Validation 73 valid_acc: 0.780 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 74 train_loss: 0.411 train_f1: 0.864 \t\n",
      "\n",
      "Validation 74 valid_acc: 0.752 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 75 train_loss: 0.394 train_f1: 0.870 \t\n",
      "\n",
      "Validation 75 valid_acc: 0.749 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 76 train_loss: 0.409 train_f1: 0.867 \t\n",
      "\n",
      "Validation 76 valid_acc: 0.772 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 77 train_loss: 0.387 train_f1: 0.874 \t\n",
      "\n",
      "Validation 77 valid_acc: 0.775 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 78 train_loss: 0.399 train_f1: 0.869 \t\n",
      "\n",
      "Validation 78 valid_acc: 0.771 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 79 train_loss: 0.375 train_f1: 0.878 \t\n",
      "\n",
      "Validation 79 valid_acc: 0.761 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 80 train_loss: 0.356 train_f1: 0.885 \t\n",
      "\n",
      "Validation 80 valid_acc: 0.769 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 81 train_loss: 0.363 train_f1: 0.880 \t\n",
      "\n",
      "Validation 81 valid_acc: 0.768 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 82 train_loss: 0.369 train_f1: 0.878 \t\n",
      "\n",
      "Validation 82 valid_acc: 0.765 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 83 train_loss: 0.374 train_f1: 0.874 \t\n",
      "\n",
      "Validation 83 valid_acc: 0.762 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 84 train_loss: 0.356 train_f1: 0.887 \t\n",
      "\n",
      "Validation 84 valid_acc: 0.764 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 85 train_loss: 0.342 train_f1: 0.889 \t\n",
      "\n",
      "Validation 85 valid_acc: 0.770 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 86 train_loss: 0.347 train_f1: 0.887 \t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation 86 valid_acc: 0.765 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 87 train_loss: 0.342 train_f1: 0.891 \t\n",
      "\n",
      "Validation 87 valid_acc: 0.745 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 88 train_loss: 0.338 train_f1: 0.889 \t\n",
      "\n",
      "Validation 88 valid_acc: 0.769 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 89 train_loss: 0.330 train_f1: 0.896 \t\n",
      "\n",
      "Validation 89 valid_acc: 0.753 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 90 train_loss: 0.348 train_f1: 0.883 \t\n",
      "\n",
      "Validation 90 valid_acc: 0.750 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 91 train_loss: 0.334 train_f1: 0.892 \t\n",
      "\n",
      "Validation 91 valid_acc: 0.758 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 92 train_loss: 0.323 train_f1: 0.895 \t\n",
      "\n",
      "Validation 92 valid_acc: 0.769 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 93 train_loss: 0.316 train_f1: 0.901 \t\n",
      "\n",
      "Validation 93 valid_acc: 0.766 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 94 train_loss: 0.311 train_f1: 0.900 \t\n",
      "\n",
      "Validation 94 valid_acc: 0.740 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 95 train_loss: 0.320 train_f1: 0.897 \t\n",
      "\n",
      "Validation 95 valid_acc: 0.766 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 96 train_loss: 0.306 train_f1: 0.896 \t\n",
      "\n",
      "Validation 96 valid_acc: 0.754 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 97 train_loss: 0.308 train_f1: 0.901 \t\n",
      "\n",
      "Validation 97 valid_acc: 0.758 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 98 train_loss: 0.303 train_f1: 0.903 \t\n",
      "\n",
      "Validation 98 valid_acc: 0.759 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 99 train_loss: 0.291 train_f1: 0.909 \t\n",
      "\n",
      "Validation 99 valid_acc: 0.753 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 100 train_loss: 0.297 train_f1: 0.908 \t\n",
      "\n",
      "Validation 100 valid_acc: 0.757 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 101 train_loss: 0.282 train_f1: 0.912 \t\n",
      "\n",
      "Validation 101 valid_acc: 0.741 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 102 train_loss: 0.300 train_f1: 0.903 \t\n",
      "\n",
      "Validation 102 valid_acc: 0.773 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 103 train_loss: 0.279 train_f1: 0.912 \t\n",
      "\n",
      "Validation 103 valid_acc: 0.765 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 104 train_loss: 0.282 train_f1: 0.910 \t\n",
      "\n",
      "Validation 104 valid_acc: 0.740 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 105 train_loss: 0.270 train_f1: 0.914 \t\n",
      "\n",
      "Validation 105 valid_acc: 0.762 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 106 train_loss: 0.287 train_f1: 0.906 \t\n",
      "\n",
      "Validation 106 valid_acc: 0.747 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 107 train_loss: 0.265 train_f1: 0.917 \t\n",
      "\n",
      "Validation 107 valid_acc: 0.755 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 108 train_loss: 0.271 train_f1: 0.913 \t\n",
      "\n",
      "Validation 108 valid_acc: 0.744 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 109 train_loss: 0.261 train_f1: 0.919 \t\n",
      "\n",
      "Validation 109 valid_acc: 0.761 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 110 train_loss: 0.264 train_f1: 0.919 \t\n",
      "\n",
      "Validation 110 valid_acc: 0.757 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 111 train_loss: 0.255 train_f1: 0.919 \t\n",
      "\n",
      "Validation 111 valid_acc: 0.722 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 112 train_loss: 0.254 train_f1: 0.921 \t\n",
      "\n",
      "Validation 112 valid_acc: 0.752 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 113 train_loss: 0.261 train_f1: 0.919 \t\n",
      "\n",
      "Validation 113 valid_acc: 0.744 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 114 train_loss: 0.264 train_f1: 0.915 \t\n",
      "\n",
      "Validation 114 valid_acc: 0.758 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 115 train_loss: 0.251 train_f1: 0.919 \t\n",
      "\n",
      "Validation 115 valid_acc: 0.748 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 116 train_loss: 0.240 train_f1: 0.924 \t\n",
      "\n",
      "Validation 116 valid_acc: 0.729 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 117 train_loss: 0.243 train_f1: 0.924 \t\n",
      "\n",
      "Validation 117 valid_acc: 0.766 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 118 train_loss: 0.227 train_f1: 0.928 \t\n",
      "\n",
      "Validation 118 valid_acc: 0.758 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 119 train_loss: 0.248 train_f1: 0.923 \t\n",
      "\n",
      "Validation 119 valid_acc: 0.760 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 120 train_loss: 0.229 train_f1: 0.929 \t\n",
      "\n",
      "Validation 120 valid_acc: 0.744 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 121 train_loss: 0.225 train_f1: 0.931 \t\n",
      "\n",
      "Validation 121 valid_acc: 0.758 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 122 train_loss: 0.225 train_f1: 0.931 \t\n",
      "\n",
      "Validation 122 valid_acc: 0.751 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 123 train_loss: 0.228 train_f1: 0.932 \t\n",
      "\n",
      "Validation 123 valid_acc: 0.756 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 124 train_loss: 0.231 train_f1: 0.925 \t\n",
      "\n",
      "Validation 124 valid_acc: 0.756 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 125 train_loss: 0.222 train_f1: 0.930 \t\n",
      "\n",
      "Validation 125 valid_acc: 0.755 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 126 train_loss: 0.219 train_f1: 0.932 \t\n",
      "\n",
      "Validation 126 valid_acc: 0.759 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 127 train_loss: 0.224 train_f1: 0.929 \t\n",
      "\n",
      "Validation 127 valid_acc: 0.751 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 128 train_loss: 0.215 train_f1: 0.933 \t\n",
      "\n",
      "Validation 128 valid_acc: 0.770 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 129 train_loss: 0.212 train_f1: 0.936 \t\n",
      "\n",
      "Validation 129 valid_acc: 0.750 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 130 train_loss: 0.213 train_f1: 0.934 \t\n",
      "\n",
      "Validation 130 valid_acc: 0.747 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 131 train_loss: 0.219 train_f1: 0.934 \t\n",
      "\n",
      "Validation 131 valid_acc: 0.762 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 132 train_loss: 0.203 train_f1: 0.937 \t\n",
      "\n",
      "Validation 132 valid_acc: 0.749 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 133 train_loss: 0.200 train_f1: 0.941 \t\n",
      "\n",
      "Validation 133 valid_acc: 0.747 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 134 train_loss: 0.206 train_f1: 0.936 \t\n",
      "\n",
      "Validation 134 valid_acc: 0.750 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 135 train_loss: 0.202 train_f1: 0.936 \t\n",
      "\n",
      "Validation 135 valid_acc: 0.775 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 136 train_loss: 0.196 train_f1: 0.941 \t\n",
      "\n",
      "Validation 136 valid_acc: 0.758 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 137 train_loss: 0.189 train_f1: 0.940 \t\n",
      "\n",
      "Validation 137 valid_acc: 0.749 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 138 train_loss: 0.192 train_f1: 0.940 \t\n",
      "\n",
      "Validation 138 valid_acc: 0.754 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 139 train_loss: 0.188 train_f1: 0.941 \t\n",
      "\n",
      "Validation 139 valid_acc: 0.743 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 140 train_loss: 0.201 train_f1: 0.936 \t\n",
      "\n",
      "Validation 140 valid_acc: 0.759 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 141 train_loss: 0.185 train_f1: 0.942 \t\n",
      "\n",
      "Validation 141 valid_acc: 0.745 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 142 train_loss: 0.192 train_f1: 0.941 \t\n",
      "\n",
      "Validation 142 valid_acc: 0.758 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 143 train_loss: 0.165 train_f1: 0.950 \t\n",
      "\n",
      "Validation 143 valid_acc: 0.754 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 144 train_loss: 0.167 train_f1: 0.952 \t\n",
      "\n",
      "Validation 144 valid_acc: 0.747 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 145 train_loss: 0.171 train_f1: 0.948 \t\n",
      "\n",
      "Validation 145 valid_acc: 0.749 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 146 train_loss: 0.184 train_f1: 0.946 \t\n",
      "\n",
      "Validation 146 valid_acc: 0.708 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 147 train_loss: 0.173 train_f1: 0.946 \t\n",
      "\n",
      "Validation 147 valid_acc: 0.754 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 148 train_loss: 0.176 train_f1: 0.947 \t\n",
      "\n",
      "Validation 148 valid_acc: 0.760 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 149 train_loss: 0.168 train_f1: 0.950 \t\n",
      "\n",
      "Validation 149 valid_acc: 0.754 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 150 train_loss: 0.164 train_f1: 0.952 \t\n",
      "\n",
      "Validation 150 valid_acc: 0.744 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 151 train_loss: 0.161 train_f1: 0.952 \t\n",
      "\n",
      "Validation 151 valid_acc: 0.765 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 152 train_loss: 0.162 train_f1: 0.953 \t\n",
      "\n",
      "Validation 152 valid_acc: 0.751 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 153 train_loss: 0.176 train_f1: 0.946 \t\n",
      "\n",
      "Validation 153 valid_acc: 0.747 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 154 train_loss: 0.168 train_f1: 0.951 \t\n",
      "\n",
      "Validation 154 valid_acc: 0.746 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 155 train_loss: 0.157 train_f1: 0.955 \t\n",
      "\n",
      "Validation 155 valid_acc: 0.753 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 156 train_loss: 0.160 train_f1: 0.951 \t\n",
      "\n",
      "Validation 156 valid_acc: 0.735 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 157 train_loss: 0.167 train_f1: 0.950 \t\n",
      "\n",
      "Validation 157 valid_acc: 0.738 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 158 train_loss: 0.158 train_f1: 0.952 \t\n",
      "\n",
      "Validation 158 valid_acc: 0.742 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 159 train_loss: 0.151 train_f1: 0.953 \t\n",
      "\n",
      "Validation 159 valid_acc: 0.739 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 160 train_loss: 0.145 train_f1: 0.957 \t\n",
      "\n",
      "Validation 160 valid_acc: 0.745 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 161 train_loss: 0.144 train_f1: 0.960 \t\n",
      "\n",
      "Validation 161 valid_acc: 0.752 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 162 train_loss: 0.149 train_f1: 0.956 \t\n",
      "\n",
      "Validation 162 valid_acc: 0.750 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 163 train_loss: 0.150 train_f1: 0.956 \t\n",
      "\n",
      "Validation 163 valid_acc: 0.754 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 164 train_loss: 0.156 train_f1: 0.952 \t\n",
      "\n",
      "Validation 164 valid_acc: 0.745 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 165 train_loss: 0.144 train_f1: 0.958 \t\n",
      "\n",
      "Validation 165 valid_acc: 0.740 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 166 train_loss: 0.147 train_f1: 0.957 \t\n",
      "\n",
      "Validation 166 valid_acc: 0.757 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 167 train_loss: 0.158 train_f1: 0.951 \t\n",
      "\n",
      "Validation 167 valid_acc: 0.742 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 168 train_loss: 0.138 train_f1: 0.956 \t\n",
      "\n",
      "Validation 168 valid_acc: 0.737 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 169 train_loss: 0.143 train_f1: 0.957 \t\n",
      "\n",
      "Validation 169 valid_acc: 0.741 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 170 train_loss: 0.143 train_f1: 0.957 \t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation 170 valid_acc: 0.732 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 171 train_loss: 0.149 train_f1: 0.956 \t\n",
      "\n",
      "Validation 171 valid_acc: 0.749 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 172 train_loss: 0.135 train_f1: 0.959 \t\n",
      "\n",
      "Validation 172 valid_acc: 0.733 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 173 train_loss: 0.131 train_f1: 0.962 \t\n",
      "\n",
      "Validation 173 valid_acc: 0.717 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 174 train_loss: 0.137 train_f1: 0.960 \t\n",
      "\n",
      "Validation 174 valid_acc: 0.750 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 175 train_loss: 0.129 train_f1: 0.961 \t\n",
      "\n",
      "Validation 175 valid_acc: 0.729 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 176 train_loss: 0.126 train_f1: 0.961 \t\n",
      "\n",
      "Validation 176 valid_acc: 0.747 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 177 train_loss: 0.133 train_f1: 0.961 \t\n",
      "\n",
      "Validation 177 valid_acc: 0.752 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 178 train_loss: 0.129 train_f1: 0.963 \t\n",
      "\n",
      "Validation 178 valid_acc: 0.729 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 179 train_loss: 0.135 train_f1: 0.962 \t\n",
      "\n",
      "Validation 179 valid_acc: 0.746 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 180 train_loss: 0.149 train_f1: 0.953 \t\n",
      "\n",
      "Validation 180 valid_acc: 0.732 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 181 train_loss: 0.117 train_f1: 0.965 \t\n",
      "\n",
      "Validation 181 valid_acc: 0.751 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 182 train_loss: 0.135 train_f1: 0.963 \t\n",
      "\n",
      "Validation 182 valid_acc: 0.742 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 183 train_loss: 0.120 train_f1: 0.964 \t\n",
      "\n",
      "Validation 183 valid_acc: 0.743 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 184 train_loss: 0.129 train_f1: 0.962 \t\n",
      "\n",
      "Validation 184 valid_acc: 0.735 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 185 train_loss: 0.128 train_f1: 0.961 \t\n",
      "\n",
      "Validation 185 valid_acc: 0.755 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 186 train_loss: 0.130 train_f1: 0.961 \t\n",
      "\n",
      "Validation 186 valid_acc: 0.747 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 187 train_loss: 0.121 train_f1: 0.964 \t\n",
      "\n",
      "Validation 187 valid_acc: 0.737 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 188 train_loss: 0.112 train_f1: 0.969 \t\n",
      "\n",
      "Validation 188 valid_acc: 0.740 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 189 train_loss: 0.127 train_f1: 0.962 \t\n",
      "\n",
      "Validation 189 valid_acc: 0.747 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 190 train_loss: 0.113 train_f1: 0.967 \t\n",
      "\n",
      "Validation 190 valid_acc: 0.739 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 191 train_loss: 0.124 train_f1: 0.963 \t\n",
      "\n",
      "Validation 191 valid_acc: 0.762 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 192 train_loss: 0.116 train_f1: 0.966 \t\n",
      "\n",
      "Validation 192 valid_acc: 0.750 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 193 train_loss: 0.113 train_f1: 0.968 \t\n",
      "\n",
      "Validation 193 valid_acc: 0.747 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 194 train_loss: 0.131 train_f1: 0.958 \t\n",
      "\n",
      "Validation 194 valid_acc: 0.747 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 195 train_loss: 0.118 train_f1: 0.965 \t\n",
      "\n",
      "Validation 195 valid_acc: 0.733 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 196 train_loss: 0.099 train_f1: 0.973 \t\n",
      "\n",
      "Validation 196 valid_acc: 0.757 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 197 train_loss: 0.109 train_f1: 0.969 \t\n",
      "\n",
      "Validation 197 valid_acc: 0.751 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 198 train_loss: 0.105 train_f1: 0.970 \t\n",
      "\n",
      "Validation 198 valid_acc: 0.758 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 199 train_loss: 0.106 train_f1: 0.968 \t\n",
      "\n",
      "Validation 199 valid_acc: 0.746 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 200 train_loss: 0.104 train_f1: 0.972 \t\n",
      "\n",
      "Validation 200 valid_acc: 0.733 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 201 train_loss: 0.097 train_f1: 0.973 \t\n",
      "\n",
      "Validation 201 valid_acc: 0.754 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 202 train_loss: 0.103 train_f1: 0.972 \t\n",
      "\n",
      "Validation 202 valid_acc: 0.746 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 203 train_loss: 0.114 train_f1: 0.966 \t\n",
      "\n",
      "Validation 203 valid_acc: 0.733 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 204 train_loss: 0.109 train_f1: 0.968 \t\n",
      "\n",
      "Validation 204 valid_acc: 0.747 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 205 train_loss: 0.108 train_f1: 0.968 \t\n",
      "\n",
      "Validation 205 valid_acc: 0.703 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 206 train_loss: 0.088 train_f1: 0.977 \t\n",
      "\n",
      "Validation 206 valid_acc: 0.752 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 207 train_loss: 0.101 train_f1: 0.970 \t\n",
      "\n",
      "Validation 207 valid_acc: 0.737 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 208 train_loss: 0.102 train_f1: 0.970 \t\n",
      "\n",
      "Validation 208 valid_acc: 0.738 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 209 train_loss: 0.112 train_f1: 0.966 \t\n",
      "\n",
      "Validation 209 valid_acc: 0.749 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 210 train_loss: 0.118 train_f1: 0.963 \t\n",
      "\n",
      "Validation 210 valid_acc: 0.741 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 211 train_loss: 0.108 train_f1: 0.967 \t\n",
      "\n",
      "Validation 211 valid_acc: 0.737 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 212 train_loss: 0.099 train_f1: 0.972 \t\n",
      "\n",
      "Validation 212 valid_acc: 0.746 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 213 train_loss: 0.101 train_f1: 0.972 \t\n",
      "\n",
      "Validation 213 valid_acc: 0.740 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 214 train_loss: 0.099 train_f1: 0.973 \t\n",
      "\n",
      "Validation 214 valid_acc: 0.758 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 215 train_loss: 0.109 train_f1: 0.969 \t\n",
      "\n",
      "Validation 215 valid_acc: 0.736 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 216 train_loss: 0.100 train_f1: 0.972 \t\n",
      "\n",
      "Validation 216 valid_acc: 0.745 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 217 train_loss: 0.101 train_f1: 0.969 \t\n",
      "\n",
      "Validation 217 valid_acc: 0.748 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 218 train_loss: 0.091 train_f1: 0.975 \t\n",
      "\n",
      "Validation 218 valid_acc: 0.737 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 219 train_loss: 0.090 train_f1: 0.974 \t\n",
      "\n",
      "Validation 219 valid_acc: 0.753 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 220 train_loss: 0.085 train_f1: 0.976 \t\n",
      "\n",
      "Validation 220 valid_acc: 0.727 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 221 train_loss: 0.085 train_f1: 0.976 \t\n",
      "\n",
      "Validation 221 valid_acc: 0.719 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 222 train_loss: 0.083 train_f1: 0.976 \t\n",
      "\n",
      "Validation 222 valid_acc: 0.735 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 223 train_loss: 0.093 train_f1: 0.973 \t\n",
      "\n",
      "Validation 223 valid_acc: 0.727 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 224 train_loss: 0.088 train_f1: 0.975 \t\n",
      "\n",
      "Validation 224 valid_acc: 0.754 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 225 train_loss: 0.093 train_f1: 0.973 \t\n",
      "\n",
      "Validation 225 valid_acc: 0.744 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 226 train_loss: 0.083 train_f1: 0.978 \t\n",
      "\n",
      "Validation 226 valid_acc: 0.747 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 227 train_loss: 0.081 train_f1: 0.977 \t\n",
      "\n",
      "Validation 227 valid_acc: 0.754 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 228 train_loss: 0.088 train_f1: 0.973 \t\n",
      "\n",
      "Validation 228 valid_acc: 0.747 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 229 train_loss: 0.104 train_f1: 0.968 \t\n",
      "\n",
      "Validation 229 valid_acc: 0.726 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 230 train_loss: 0.106 train_f1: 0.968 \t\n",
      "\n",
      "Validation 230 valid_acc: 0.750 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 231 train_loss: 0.089 train_f1: 0.973 \t\n",
      "\n",
      "Validation 231 valid_acc: 0.742 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 232 train_loss: 0.081 train_f1: 0.977 \t\n",
      "\n",
      "Validation 232 valid_acc: 0.758 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 233 train_loss: 0.101 train_f1: 0.967 \t\n",
      "\n",
      "Validation 233 valid_acc: 0.757 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 234 train_loss: 0.076 train_f1: 0.979 \t\n",
      "\n",
      "Validation 234 valid_acc: 0.755 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 235 train_loss: 0.087 train_f1: 0.976 \t\n",
      "\n",
      "Validation 235 valid_acc: 0.744 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 236 train_loss: 0.082 train_f1: 0.975 \t\n",
      "\n",
      "Validation 236 valid_acc: 0.753 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 237 train_loss: 0.080 train_f1: 0.978 \t\n",
      "\n",
      "Validation 237 valid_acc: 0.734 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 238 train_loss: 0.087 train_f1: 0.973 \t\n",
      "\n",
      "Validation 238 valid_acc: 0.744 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 239 train_loss: 0.075 train_f1: 0.980 \t\n",
      "\n",
      "Validation 239 valid_acc: 0.749 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 240 train_loss: 0.079 train_f1: 0.977 \t\n",
      "\n",
      "Validation 240 valid_acc: 0.745 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 241 train_loss: 0.090 train_f1: 0.974 \t\n",
      "\n",
      "Validation 241 valid_acc: 0.738 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 242 train_loss: 0.083 train_f1: 0.977 \t\n",
      "\n",
      "Validation 242 valid_acc: 0.738 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 243 train_loss: 0.070 train_f1: 0.981 \t\n",
      "\n",
      "Validation 243 valid_acc: 0.722 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 244 train_loss: 0.083 train_f1: 0.976 \t\n",
      "\n",
      "Validation 244 valid_acc: 0.745 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 245 train_loss: 0.074 train_f1: 0.979 \t\n",
      "\n",
      "Validation 245 valid_acc: 0.722 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 246 train_loss: 0.073 train_f1: 0.978 \t\n",
      "\n",
      "Validation 246 valid_acc: 0.746 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 247 train_loss: 0.075 train_f1: 0.979 \t\n",
      "\n",
      "Validation 247 valid_acc: 0.751 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 248 train_loss: 0.071 train_f1: 0.980 \t\n",
      "\n",
      "Validation 248 valid_acc: 0.760 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 249 train_loss: 0.084 train_f1: 0.974 \t\n",
      "\n",
      "Validation 249 valid_acc: 0.739 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 250 train_loss: 0.084 train_f1: 0.976 \t\n",
      "\n",
      "Validation 250 valid_acc: 0.716 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 251 train_loss: 0.078 train_f1: 0.976 \t\n",
      "\n",
      "Validation 251 valid_acc: 0.739 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 252 train_loss: 0.063 train_f1: 0.980 \t\n",
      "\n",
      "Validation 252 valid_acc: 0.746 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 253 train_loss: 0.075 train_f1: 0.978 \t\n",
      "\n",
      "Validation 253 valid_acc: 0.737 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 254 train_loss: 0.072 train_f1: 0.980 \t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation 254 valid_acc: 0.749 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 255 train_loss: 0.070 train_f1: 0.981 \t\n",
      "\n",
      "Validation 255 valid_acc: 0.728 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 256 train_loss: 0.073 train_f1: 0.979 \t\n",
      "\n",
      "Validation 256 valid_acc: 0.729 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 257 train_loss: 0.060 train_f1: 0.983 \t\n",
      "\n",
      "Validation 257 valid_acc: 0.716 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 258 train_loss: 0.078 train_f1: 0.975 \t\n",
      "\n",
      "Validation 258 valid_acc: 0.742 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 259 train_loss: 0.065 train_f1: 0.982 \t\n",
      "\n",
      "Validation 259 valid_acc: 0.740 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 260 train_loss: 0.062 train_f1: 0.982 \t\n",
      "\n",
      "Validation 260 valid_acc: 0.726 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 261 train_loss: 0.071 train_f1: 0.979 \t\n",
      "\n",
      "Validation 261 valid_acc: 0.732 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 262 train_loss: 0.088 train_f1: 0.972 \t\n",
      "\n",
      "Validation 262 valid_acc: 0.729 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 263 train_loss: 0.065 train_f1: 0.981 \t\n",
      "\n",
      "Validation 263 valid_acc: 0.743 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 264 train_loss: 0.070 train_f1: 0.980 \t\n",
      "\n",
      "Validation 264 valid_acc: 0.726 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 265 train_loss: 0.071 train_f1: 0.980 \t\n",
      "\n",
      "Validation 265 valid_acc: 0.740 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 266 train_loss: 0.074 train_f1: 0.975 \t\n",
      "\n",
      "Validation 266 valid_acc: 0.756 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 267 train_loss: 0.086 train_f1: 0.974 \t\n",
      "\n",
      "Validation 267 valid_acc: 0.745 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 268 train_loss: 0.069 train_f1: 0.981 \t\n",
      "\n",
      "Validation 268 valid_acc: 0.749 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 269 train_loss: 0.073 train_f1: 0.979 \t\n",
      "\n",
      "Validation 269 valid_acc: 0.724 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 270 train_loss: 0.063 train_f1: 0.982 \t\n",
      "\n",
      "Validation 270 valid_acc: 0.745 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 271 train_loss: 0.060 train_f1: 0.983 \t\n",
      "\n",
      "Validation 271 valid_acc: 0.711 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 272 train_loss: 0.061 train_f1: 0.982 \t\n",
      "\n",
      "Validation 272 valid_acc: 0.738 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 273 train_loss: 0.064 train_f1: 0.980 \t\n",
      "\n",
      "Validation 273 valid_acc: 0.733 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 274 train_loss: 0.067 train_f1: 0.982 \t\n",
      "\n",
      "Validation 274 valid_acc: 0.733 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 275 train_loss: 0.074 train_f1: 0.976 \t\n",
      "\n",
      "Validation 275 valid_acc: 0.722 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 276 train_loss: 0.065 train_f1: 0.982 \t\n",
      "\n",
      "Validation 276 valid_acc: 0.747 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 277 train_loss: 0.049 train_f1: 0.988 \t\n",
      "\n",
      "Validation 277 valid_acc: 0.744 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 278 train_loss: 0.065 train_f1: 0.982 \t\n",
      "\n",
      "Validation 278 valid_acc: 0.748 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 279 train_loss: 0.066 train_f1: 0.980 \t\n",
      "\n",
      "Validation 279 valid_acc: 0.742 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 280 train_loss: 0.056 train_f1: 0.985 \t\n",
      "\n",
      "Validation 280 valid_acc: 0.746 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 281 train_loss: 0.059 train_f1: 0.984 \t\n",
      "\n",
      "Validation 281 valid_acc: 0.732 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 282 train_loss: 0.051 train_f1: 0.987 \t\n",
      "\n",
      "Validation 282 valid_acc: 0.738 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 283 train_loss: 0.062 train_f1: 0.982 \t\n",
      "\n",
      "Validation 283 valid_acc: 0.740 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 284 train_loss: 0.057 train_f1: 0.984 \t\n",
      "\n",
      "Validation 284 valid_acc: 0.740 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 285 train_loss: 0.062 train_f1: 0.982 \t\n",
      "\n",
      "Validation 285 valid_acc: 0.745 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 286 train_loss: 0.064 train_f1: 0.982 \t\n",
      "\n",
      "Validation 286 valid_acc: 0.743 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 287 train_loss: 0.055 train_f1: 0.985 \t\n",
      "\n",
      "Validation 287 valid_acc: 0.740 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 288 train_loss: 0.060 train_f1: 0.985 \t\n",
      "\n",
      "Validation 288 valid_acc: 0.747 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 289 train_loss: 0.052 train_f1: 0.986 \t\n",
      "\n",
      "Validation 289 valid_acc: 0.746 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 290 train_loss: 0.069 train_f1: 0.979 \t\n",
      "\n",
      "Validation 290 valid_acc: 0.740 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 291 train_loss: 0.063 train_f1: 0.982 \t\n",
      "\n",
      "Validation 291 valid_acc: 0.747 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 292 train_loss: 0.054 train_f1: 0.985 \t\n",
      "\n",
      "Validation 292 valid_acc: 0.735 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 293 train_loss: 0.058 train_f1: 0.983 \t\n",
      "\n",
      "Validation 293 valid_acc: 0.734 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 294 train_loss: 0.054 train_f1: 0.985 \t\n",
      "\n",
      "Validation 294 valid_acc: 0.736 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 295 train_loss: 0.061 train_f1: 0.983 \t\n",
      "\n",
      "Validation 295 valid_acc: 0.742 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 296 train_loss: 0.057 train_f1: 0.984 \t\n",
      "\n",
      "Validation 296 valid_acc: 0.737 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 297 train_loss: 0.060 train_f1: 0.981 \t\n",
      "\n",
      "Validation 297 valid_acc: 0.740 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 298 train_loss: 0.054 train_f1: 0.985 \t\n",
      "\n",
      "Validation 298 valid_acc: 0.751 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 299 train_loss: 0.060 train_f1: 0.983 \t\n",
      "\n",
      "Validation 299 valid_acc: 0.738 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 300 train_loss: 0.061 train_f1: 0.984 \t\n",
      "\n",
      "Validation 300 valid_acc: 0.710 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 301 train_loss: 0.046 train_f1: 0.987 \t\n",
      "\n",
      "Validation 301 valid_acc: 0.736 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 302 train_loss: 0.046 train_f1: 0.988 \t\n",
      "\n",
      "Validation 302 valid_acc: 0.748 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 303 train_loss: 0.062 train_f1: 0.982 \t\n",
      "\n",
      "Validation 303 valid_acc: 0.738 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 304 train_loss: 0.053 train_f1: 0.985 \t\n",
      "\n",
      "Validation 304 valid_acc: 0.676 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 305 train_loss: 0.062 train_f1: 0.981 \t\n",
      "\n",
      "Validation 305 valid_acc: 0.740 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 306 train_loss: 0.059 train_f1: 0.982 \t\n",
      "\n",
      "Validation 306 valid_acc: 0.739 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 307 train_loss: 0.054 train_f1: 0.984 \t\n",
      "\n",
      "Validation 307 valid_acc: 0.741 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 308 train_loss: 0.046 train_f1: 0.987 \t\n",
      "\n",
      "Validation 308 valid_acc: 0.741 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 309 train_loss: 0.047 train_f1: 0.987 \t\n",
      "\n",
      "Validation 309 valid_acc: 0.740 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 310 train_loss: 0.046 train_f1: 0.986 \t\n",
      "\n",
      "Validation 310 valid_acc: 0.745 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 311 train_loss: 0.048 train_f1: 0.985 \t\n",
      "\n",
      "Validation 311 valid_acc: 0.740 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 312 train_loss: 0.051 train_f1: 0.984 \t\n",
      "\n",
      "Validation 312 valid_acc: 0.734 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 313 train_loss: 0.062 train_f1: 0.983 \t\n",
      "\n",
      "Validation 313 valid_acc: 0.744 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 314 train_loss: 0.066 train_f1: 0.979 \t\n",
      "\n",
      "Validation 314 valid_acc: 0.741 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 315 train_loss: 0.063 train_f1: 0.981 \t\n",
      "\n",
      "Validation 315 valid_acc: 0.694 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 316 train_loss: 0.052 train_f1: 0.985 \t\n",
      "\n",
      "Validation 316 valid_acc: 0.751 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 317 train_loss: 0.055 train_f1: 0.983 \t\n",
      "\n",
      "Validation 317 valid_acc: 0.740 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 318 train_loss: 0.051 train_f1: 0.985 \t\n",
      "\n",
      "Validation 318 valid_acc: 0.733 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 319 train_loss: 0.059 train_f1: 0.981 \t\n",
      "\n",
      "Validation 319 valid_acc: 0.725 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 320 train_loss: 0.049 train_f1: 0.986 \t\n",
      "\n",
      "Validation 320 valid_acc: 0.745 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 321 train_loss: 0.052 train_f1: 0.984 \t\n",
      "\n",
      "Validation 321 valid_acc: 0.742 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 322 train_loss: 0.049 train_f1: 0.987 \t\n",
      "\n",
      "Validation 322 valid_acc: 0.750 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 323 train_loss: 0.055 train_f1: 0.985 \t\n",
      "\n",
      "Validation 323 valid_acc: 0.711 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 324 train_loss: 0.065 train_f1: 0.979 \t\n",
      "\n",
      "Validation 324 valid_acc: 0.750 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 325 train_loss: 0.046 train_f1: 0.987 \t\n",
      "\n",
      "Validation 325 valid_acc: 0.758 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 326 train_loss: 0.057 train_f1: 0.983 \t\n",
      "\n",
      "Validation 326 valid_acc: 0.754 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 327 train_loss: 0.049 train_f1: 0.985 \t\n",
      "\n",
      "Validation 327 valid_acc: 0.721 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 328 train_loss: 0.049 train_f1: 0.985 \t\n",
      "\n",
      "Validation 328 valid_acc: 0.754 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 329 train_loss: 0.054 train_f1: 0.984 \t\n",
      "\n",
      "Validation 329 valid_acc: 0.753 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 330 train_loss: 0.049 train_f1: 0.987 \t\n",
      "\n",
      "Validation 330 valid_acc: 0.749 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 331 train_loss: 0.069 train_f1: 0.979 \t\n",
      "\n",
      "Validation 331 valid_acc: 0.719 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 332 train_loss: 0.059 train_f1: 0.983 \t\n",
      "\n",
      "Validation 332 valid_acc: 0.735 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 333 train_loss: 0.058 train_f1: 0.984 \t\n",
      "\n",
      "Validation 333 valid_acc: 0.752 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 334 train_loss: 0.041 train_f1: 0.989 \t\n",
      "\n",
      "Validation 334 valid_acc: 0.745 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 335 train_loss: 0.036 train_f1: 0.990 \t\n",
      "\n",
      "Validation 335 valid_acc: 0.724 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 336 train_loss: 0.046 train_f1: 0.987 \t\n",
      "\n",
      "Validation 336 valid_acc: 0.755 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 337 train_loss: 0.052 train_f1: 0.985 \t\n",
      "\n",
      "Validation 337 valid_acc: 0.722 best_acc: 0.784 \t\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-329a09d14b4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnum_epoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmel_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass2index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminimum_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_mean_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_std_final\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nEpoch'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'train_loss:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf'{train_loss:.3f}'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'train_f1:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf'{train_f1:.3f}'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mmodel_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ECG_ABN_E%02dL%.2f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-fdd42621e9c7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(data_train, mel_directory, batch_size, class2index, minimum_len, x_mean_final, x_std_final)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mtotal_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcurr_step\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0mbatch_mels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandextract_mels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmel_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass2index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminimum_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_mean_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_std_final\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0mbatch_mels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_mels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0mbatch_labels2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-fdd42621e9c7>\u001b[0m in \u001b[0;36mrandextract_mels\u001b[0;34m(curr_step, batch_size, data, mel_directory, class2index, minimum_len, x_mean_final, x_std_final)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0mcurr_file_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcurr_file_indices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mtmp_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel_directory\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.mat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0mclip_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminimum_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;31m#print(clip_file.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[0;32m--> 453\u001b[0;31m                                          pickle_kwargs=pickle_kwargs)\n\u001b[0m\u001b[1;32m    454\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Try a pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    710\u001b[0m     \u001b[0mversion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0m_check_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m     \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfortran_order\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_array_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    713\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36m_read_array_header\u001b[0;34m(fp, version)\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;31m#   \"fortran_order\" : bool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[0;31m#   \"descr\" : dtype.descr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m     \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_filter_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36m_filter_header\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m    537\u001b[0m     \u001b[0;31m# adding newline as python 2.7.5 workaround\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m     \u001b[0mstring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStringIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m         \u001b[0mtoken_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0mtoken_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/tokenize.py\u001b[0m in \u001b[0;36m_tokenize\u001b[0;34m(readline, encoding)\u001b[0m\n\u001b[1;32m    656\u001b[0m                 \u001b[0;31m# Also note that single quote checking must come after\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m                 \u001b[0;31m#  triple quote checking (above).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m                 elif (initial in single_quoted or\n\u001b[0m\u001b[1;32m    659\u001b[0m                       \u001b[0mtoken\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msingle_quoted\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m                       token[:3] in single_quoted):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# DISP DATETIME FOR CHECKING TIME\n",
    "start = time.time()\n",
    "val_acc_sum=[]\n",
    "train_loss_sum=[]\n",
    "train_acc_sum=[]\n",
    "val_loss_sum=[]\n",
    "val_acc_min = 0\n",
    "print(results_directory)\n",
    "\n",
    "for num_epoch in range(epochs):\n",
    "    random.shuffle(data_train)\n",
    "    train_loss, train_f1 = train(data_train, mel_directory, batch_size, class2index, minimum_len, x_mean_final, x_std_final)\n",
    "    print('\\nEpoch',num_epoch+1,'train_loss:',f'{train_loss:.3f}','train_f1:',f'{train_f1:.3f}',\"\\t\")\n",
    "    model_output = \"ECG_ABN_E%02dL%.2f\" % (num_epoch, train_loss)\n",
    "    save_name = os.path.join(results_directory, model_output)\n",
    "    \n",
    "    val_acc = test(data_val, mel_directory, input_directory, class2index, minimum_len, model, x_mean_final, x_std_final)\n",
    "\n",
    "    if val_acc > val_acc_min:\n",
    "        val_acc_min = val_acc\n",
    "        model.save(save_name)\n",
    "    print('\\nValidation', num_epoch+1, 'valid_acc:',f'{val_acc:.3f}', 'best_acc:',f'{val_acc_min:.3f}', \"\\t\")\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "395.881px",
    "left": "1487.43px",
    "right": "20px",
    "top": "128.94px",
    "width": "200.142px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
