{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/numba/errors.py:137: UserWarning: Insufficiently recent colorama version found. Numba requires colorama >= 0.3.9\n",
      "  warnings.warn(msg)\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow.contrib.eager as tfe\n",
    "\n",
    "\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import keras\n",
    "# import datetime as dt\n",
    "from datetime import datetime\n",
    "import time\n",
    "# import datetime.datetime\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from keras import layers\n",
    "from keras import models\n",
    "# from keras import optimizers\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "from keras.applications.densenet import DenseNet121, DenseNet169\n",
    "#from keras.applications.nasnet import NASNetLarge\n",
    "# from keras_efficientnets import EfficientNetB7\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras import initializers, regularizers, constraints\n",
    "from keras.layers.normalization import BatchNormalization \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "# from keras import backend as K\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tf.set_random_seed(1234)\n",
    "random.seed(100)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.24290386e-03 -4.58280585e-05  4.31697309e-03 -3.00174693e-03\n",
      " -2.36609229e-04  1.28997408e-03  2.17347589e-04 -7.99152384e-04\n",
      " -3.42993744e-03 -1.69711686e-03  1.27138164e-03  1.94670545e-03]\n",
      "(4864,) (256,) (1281,)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def score_f1(y_true, y_pred): #taken from old keras source code\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val\n",
    "\n",
    "def dot_product(x, kernel):\n",
    "    if K.backend() == 'tensorflow':\n",
    "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
    "    else:\n",
    "        return K.dot(x, kernel)\n",
    "    \n",
    "def get_unique_classes(input_directory,files):\n",
    "\n",
    "    unique_classes=set()\n",
    "    for f in files:\n",
    "        g = f.replace('.mat','.hea')\n",
    "        input_file = os.path.join(input_directory,g)\n",
    "        with open(input_file,'r') as f:\n",
    "            for lines in f:\n",
    "                if lines.startswith('#Dx'):\n",
    "                    tmp = lines.split(': ')[1].split(',')\n",
    "                    for c in tmp:\n",
    "                        unique_classes.add(c.strip())\n",
    "    return sorted(unique_classes)\n",
    "\n",
    "def one_hot_encoding(one_hot_vector,y, class2index):\n",
    "    ind=class2index[y]\n",
    "    one_hot_vector[ind]=1\n",
    "    return one_hot_vector\n",
    "\n",
    "# Search for multi-label subjects\n",
    "def searching_overlap(input_directory,class2index, input_file_names):\n",
    "    multiclasses=[]\n",
    "    multisubjects=[]\n",
    "    number = []\n",
    "    for file in input_file_names:\n",
    "        f=file\n",
    "        g = f.replace('.mat','.hea')\n",
    "        input_file = os.path.join(input_directory,g)\n",
    "        with open(input_file,'r') as f:\n",
    "            for lines in f:\n",
    "                if lines.startswith('#Dx'):\n",
    "                    tmp = lines.split(': ')[1].split(',')\n",
    "                    if len(tmp)>1:\n",
    "                        one_hot_vector = [0]*(len(class2index))\n",
    "                        for c in tmp:\n",
    "                            one_hot_vector = one_hot_encoding(one_hot_vector, c.strip(), class2index)\n",
    "                        multiclasses.append(one_hot_vector)\n",
    "                        multisubjects.append(g)\n",
    "                        number.append(len(tmp))\n",
    "    return multisubjects, multiclasses, number\n",
    "\n",
    "def block_feature(sequence_en, minimum_len): \n",
    "    new_en = []\n",
    "    if len(sequence_en) > minimum_len:  # 길이가 minimum보다 긴 경우\n",
    "        start = random.randint(0,len(sequence_en)-minimum_len)\n",
    "        #print(start)\n",
    "        new_en = sequence_en[start:start+minimum_len]\n",
    "    elif len(sequence_en) == minimum_len: # 길이가 minimum\n",
    "        new_en = sequence_en\n",
    "    else: \n",
    "        assert len(sequence_en) <= minimum_len\n",
    "    return new_en\n",
    "\n",
    "def exploratory_look(input_directory,file, class2index):\n",
    "    classes = []\n",
    "    f = file\n",
    "    g = f.replace('.mat','.hea')\n",
    "    input_file = os.path.join(input_directory,g)\n",
    "    with open(input_file,'r') as f:\n",
    "        for lines in f:\n",
    "            if lines.startswith('#Dx'):\n",
    "                tmp = lines.split(': ')[1].split(',')\n",
    "                print(tmp, len(tmp))\n",
    "    return tmp     \n",
    "\n",
    "# Get classes of sorted file names\n",
    "def get_labels(input_directory,file, class2index):\n",
    "    f = file\n",
    "    g = f.replace('.mat','.hea')\n",
    "    input_file = os.path.join(input_directory,g)\n",
    "    with open(input_file,'r') as f:\n",
    "        for lines in f:\n",
    "            if lines.startswith('#Dx'):\n",
    "                tmp = lines.split(': ')[1].split(',')\n",
    "                one_hot_vector = [0]*(len(class2index))\n",
    "                for c in tmp:\n",
    "                    one_hot_vector = one_hot_encoding(one_hot_vector, c.strip(), class2index)\n",
    "                \n",
    "    return one_hot_vector\n",
    "\n",
    "def randextract_mels(curr_step, batch_size, data, mel_directory, class2index, minimum_len, x_mean_final, x_std_final):\n",
    "    mel_files = []\n",
    "    classes = []\n",
    "    start = batch_size*curr_step\n",
    "    end = batch_size*(curr_step+1)\n",
    "    curr_file_indices = data[start:end]\n",
    "    for file in curr_file_indices:\n",
    "        tmp_file = np.load(mel_directory + '/' + file.replace('.mat', '.npy'))\n",
    "        clip_file = block_feature(tmp_file, minimum_len)\n",
    "        #print(clip_file.shape)\n",
    "        #clip_file = tmp_file[:minimum_len]\n",
    "        clip_file -= x_mean_final\n",
    "        clip_file /= x_std_final\n",
    "        mel_files.append(clip_file)\n",
    "        label = get_labels(input_directory, file, class2index)\n",
    "        classes.append(label)\n",
    "    \n",
    "    # YJS added for ABN -> should calculate 2 losses\n",
    "#     classes_abn = [classes,classes]\n",
    "    \n",
    "    concat = list(zip(mel_files, classes))\n",
    "#     concat = list(zip(mel_files, classes_abn))\n",
    "    random.shuffle(concat)\n",
    "    mel_files, classes = zip(*concat)\n",
    "    return mel_files, classes\n",
    "\n",
    "def train(data_train, mel_directory, batch_size, class2index, minimum_len, x_mean_final, x_std_final): \n",
    "    loss=[]\n",
    "#     acc = []\n",
    "    f1 = []\n",
    "\n",
    "    total_steps = int(np.ceil(len(data_train)/batch_size))\n",
    "    for curr_step in range(total_steps): # loops over batches\n",
    "        batch_mels, batch_labels = randextract_mels(curr_step, batch_size, data_train, mel_directory, class2index, minimum_len, x_mean_final, x_std_final)\n",
    "\n",
    "        batch_mels = np.asarray(batch_mels)\n",
    "        batch_labels = np.asarray(np.squeeze(batch_labels))\n",
    "        \n",
    "        batch_labels = [batch_labels, batch_labels]\n",
    "\n",
    "\n",
    "# return of train\n",
    "# 0 = total loss (attention branch + perception branch)\n",
    "# 1 = loss of attention pred\n",
    "# 2 = loss of perception pred\n",
    "# 3 = f1 of attention pred\n",
    "# 4 = f1 of perception pred     \n",
    "\n",
    "\n",
    "        train_tmp = model.train_on_batch(batch_mels, batch_labels)\n",
    "        loss_ = train_tmp[0]/2\n",
    "        f1_ = np.mean((train_tmp[3], train_tmp[4]))\n",
    "        loss.append(loss_)\n",
    "        f1.append(f1_)\n",
    "\n",
    "    loss = np.mean(np.array(loss))\n",
    "    f1 = np.mean(np.array(f1))\n",
    "    return loss, f1\n",
    "\n",
    "def train_edit(data_train, mel_directory, batch_size, class2index, minimum_len, x_mean_final, x_std_final): \n",
    "    loss=[]\n",
    "#     acc = []\n",
    "    f1 = []\n",
    "\n",
    "    total_steps = int(np.ceil(len(data_train)/batch_size))\n",
    "    for curr_step in range(total_steps): # loops over batches\n",
    "        batch_mels, batch_labels = randextract_mels(curr_step, batch_size, data_train, mel_directory, class2index, minimum_len, x_mean_final, x_std_final)\n",
    "\n",
    "        batch_mels = np.asarray(batch_mels)\n",
    "        batch_labels = np.asarray(np.squeeze(batch_labels))\n",
    "\n",
    "\n",
    "        heatmap = CAM_conv1D(minimum_len, n_channels, batch_mels, batch_labels, out_len, get_conv_out)        \n",
    "        heatmap = np.asarray(heatmap)\n",
    "        \n",
    "        batch_labels = [batch_labels, batch_labels]\n",
    "\n",
    "\n",
    "# return of train\n",
    "# 0 = total loss (attention branch + perception branch)\n",
    "# 1 = loss of attention pred\n",
    "# 2 = loss of perception pred\n",
    "# 3 = f1 of attention pred\n",
    "# 4 = f1 of perception pred     \n",
    "\n",
    "        train_tmp = model.train_on_batch([batch_mels, heatmap], batch_labels)\n",
    "        loss_ = train_tmp[0]/2\n",
    "        f1_ = np.mean((train_tmp[3], train_tmp[4]))\n",
    "        loss.append(loss_)\n",
    "        f1.append(f1_)\n",
    "\n",
    "    loss = np.mean(np.array(loss))\n",
    "    f1 = np.mean(np.array(f1))\n",
    "    return loss, f1\n",
    "\n",
    "def test(data, mel_directory, input_directory, class2index, minimum_len, model, x_mean_final, x_std_final):\n",
    "    scores = []\n",
    "    predicted_labels=[]\n",
    "    accuracy=np.zeros(len(data))\n",
    "    #total_loss=[]\n",
    "    total_acc = 0\n",
    "    total_f1 = 0\n",
    "    \n",
    "    mel_files = []\n",
    "    classes = []\n",
    "    for i, file in enumerate(data):\n",
    "        tmp_file = np.load(mel_directory + '/' + file.replace('.mat', '.npy'))\n",
    "        steps = int(np.floor(tmp_file.shape[0]/minimum_len))\n",
    "        mel_files = []\n",
    "#         gradcam_files = []\n",
    "        heatmap_files=[]\n",
    "        label = get_labels(input_directory, file, class2index)\n",
    "        label = [label]\n",
    "        for block in range(steps): # 128개씩 쪼갠 블럭 단위로 predict\n",
    "            start = block*minimum_len\n",
    "            end = (block+1)*minimum_len\n",
    "            clip_file = tmp_file[start:end]\n",
    "            clip_file -= x_mean_final\n",
    "            clip_file /= x_std_final\n",
    "\n",
    "            clip_file = clip_file.reshape(1,minimum_len,n_channels)\n",
    "\n",
    "\n",
    "            mel_files.append(clip_file)    \n",
    "#             gradcam_files.append(gradcam)\n",
    "\n",
    "        mel_files = np.asarray(mel_files)\n",
    "\n",
    "        mel_files = mel_files.reshape(steps,minimum_len,n_channels)\n",
    "\n",
    "        logit = model.predict(mel_files)\n",
    "        # YJS changed on 2020-06-02: input으로 두개 들어가야하니까 predict도 수정?\n",
    "#         print(len(logit))\n",
    "        logit = np.mean(logit, axis=0)\n",
    "        logit = np.mean(logit, axis=0)\n",
    "#         print(logit)\n",
    "        pred = np.argmax(logit)\n",
    "#         print('Pred={}'.format(pred))\n",
    "        \n",
    "        label = np.argmax(get_labels(input_directory, file, class2index))\n",
    "#         print('Label={}'.format(label))\n",
    "        #f1 = f1_score(label, logit)\n",
    "        #print(pred, label)\n",
    "        if pred == label:\n",
    "            acc = 1\n",
    "        else:\n",
    "            acc = 0\n",
    "        total_acc += acc\n",
    "        #total_f1 += f1\n",
    "    final_acc = total_acc / i\n",
    "    #final_f1 = total_f1 / i\n",
    "    return final_acc#, final_f1\n",
    "\n",
    "def test_edit(data, mel_directory, input_directory, class2index, minimum_len, model, x_mean_final, x_std_final):\n",
    "    scores = []\n",
    "    predicted_labels=[]\n",
    "    accuracy=np.zeros(len(data))\n",
    "\n",
    "    total_acc = 0\n",
    "    total_f1 = 0\n",
    "    \n",
    "    mel_files = []\n",
    "    classes = []\n",
    "    for i, file in enumerate(data):\n",
    "        tmp_file = np.load(mel_directory + '/' + file.replace('.mat', '.npy'))\n",
    "        steps = int(np.floor(tmp_file.shape[0]/minimum_len))\n",
    "        mel_files = []\n",
    "\n",
    "        heatmap_files=[]\n",
    "        label = get_labels(input_directory, file, class2index)\n",
    "        label = [label]\n",
    "        for block in range(steps): # 128개씩 쪼갠 블럭 단위로 predict\n",
    "            start = block*minimum_len\n",
    "            end = (block+1)*minimum_len\n",
    "            clip_file = tmp_file[start:end]\n",
    "            clip_file -= x_mean_final\n",
    "            clip_file /= x_std_final\n",
    "\n",
    "            clip_file = clip_file.reshape(1,minimum_len,n_channels)\n",
    " \n",
    "            heatmap = CAM_conv1D(minimum_len, n_channels, clip_file, label, out_len, get_conv_out)\n",
    "    \n",
    "            mel_files.append(clip_file)    \n",
    "\n",
    "            heatmap_files.append(heatmap)\n",
    "        mel_files = np.asarray(mel_files)\n",
    "        heatmap_files = np.asarray(heatmap_files)\n",
    "#         heatmap_files = heatmap_files.reshape(steps,1,out_len)\n",
    "        heatmap_files = heatmap_files.reshape(steps, out_len,1)\n",
    "        mel_files = mel_files.reshape(steps,minimum_len,n_channels)\n",
    "\n",
    "        logit = model.predict([mel_files, heatmap_files])\n",
    "\n",
    "        logit = np.mean(logit, axis=0)\n",
    "        logit = np.mean(logit, axis=0)\n",
    "\n",
    "        pred = np.argmax(logit)\n",
    "\n",
    "        label = np.argmax(get_labels(input_directory, file, class2index))\n",
    "\n",
    "        if pred == label:\n",
    "            acc = 1\n",
    "        else:\n",
    "            acc = 0\n",
    "        total_acc += acc\n",
    "\n",
    "    final_acc = total_acc / i\n",
    "\n",
    "    return final_acc\n",
    "\n",
    "\n",
    "def test_short(data, mel_directory, input_directory, class2index, minimum_len, model, x_mean_final, x_std_final):\n",
    "    scores = []\n",
    "    predicted_labels=[]\n",
    "    accuracy=np.zeros(len(data))\n",
    "    #total_loss=[]\n",
    "    total_acc = 0\n",
    "    total_f1 = 0\n",
    "    \n",
    "    mel_files = []\n",
    "    classes = []\n",
    "    for i, file in enumerate(data):\n",
    "        tmp_file = np.load(mel_directory + '/' + file.replace('.mat', '.npy'))\n",
    "        steps = int(np.floor(tmp_file.shape[0]/minimum_len))\n",
    "        mel_files = []\n",
    "#         gradcam_files = []\n",
    "        heatmap_files=[]\n",
    "        label = get_labels(input_directory, file, class2index)\n",
    "        label = [label]\n",
    "#         for block in range(steps): # 128개씩 쪼갠 블럭 단위로 predict\n",
    "        steps=1\n",
    "        block = 0\n",
    "        start = block*minimum_len\n",
    "        end = (block+1)*minimum_len\n",
    "        clip_file = tmp_file[start:end]\n",
    "        clip_file -= x_mean_final\n",
    "        clip_file /= x_std_final\n",
    "\n",
    "        clip_file = clip_file.reshape(1,minimum_len,n_channels)\n",
    "#         heatmap = CAM_conv1D(p_model, conv_layer, softmax_layer,  x_mean_final, x_std_final, minimum_len, \n",
    "#                                       n_channels, clip_file, label, out_len)\n",
    "\n",
    "        mel_files.append(clip_file)    \n",
    "#         heatmap_files.append(heatmap)\n",
    "        mel_files = np.asarray(mel_files)\n",
    "#         heatmap_files = np.asarray(heatmap_files)\n",
    "#         heatmap_files = heatmap_files.reshape(steps,out_len,1) # changed for modified attention editting\n",
    "        mel_files = mel_files.reshape(steps,minimum_len,n_channels)\n",
    "\n",
    "        logit = model.predict([mel_files, heatmap_files])\n",
    "        # YJS changed on 2020-06-02: input으로 두개 들어가야하니까 predict도 수정?\n",
    "\n",
    "        \n",
    "        logit = np.mean(logit, axis=0)\n",
    "        logit = np.mean(logit, axis=0)\n",
    "        pred = np.argmax(logit)\n",
    "        \n",
    "        label = np.argmax(get_labels(input_directory, file, class2index))\n",
    "        if pred == label:\n",
    "            acc = 1\n",
    "        else:\n",
    "            acc = 0\n",
    "\n",
    "        total_acc += acc\n",
    "\n",
    "    final_acc = total_acc / i\n",
    "\n",
    "    return final_acc#, final_f1\n",
    "batch_size = 32#16#20#32#5#2#1#10#32\n",
    "minimum_len = 2880\n",
    "epochs = 1000\n",
    "loss_function = 'categorical_crossentropy'\n",
    "activation_function = 'softmax'\n",
    "rootdir = '../'\n",
    "date = datetime.today().strftime(\"%Y%m%d\")\n",
    "input_directory = os.path.join(rootdir, 'Training_WFDB')\n",
    "mel_name = 'Raw_data_20200424' \n",
    "mel_directory = os.path.join(rootdir, mel_name)\n",
    "# results_directory = os.path.join(rootdir, 'results_'+date+'_0_IEEE_n=1')\n",
    "results_directory = os.path.join(rootdir, 'results_'+date+'_edit_ABN_changed')\n",
    "if not os.path.isdir(input_directory):\n",
    "    os.mkdir(input_directory)\n",
    "if not os.path.isdir(mel_directory):\n",
    "    os.mkdir(mel_directory)\n",
    "if not os.path.isdir(results_directory):\n",
    "    os.mkdir(results_directory)\n",
    "        \n",
    "input_files = []\n",
    "for f in os.listdir(input_directory):\n",
    "    if os.path.isfile(os.path.join(input_directory, f)) and not f.lower().startswith('.') and f.lower().endswith('mat'):\n",
    "        input_files.append(f)\n",
    "input_file_names = sorted(input_files)\n",
    "\n",
    "unique_classes = get_unique_classes(input_directory, input_files)\n",
    "class2index = {}\n",
    "for a, b in enumerate(unique_classes):\n",
    "    class2index[b] = a\n",
    "    \n",
    "classes_orig= [x.replace('.mat', '.hea') for x in input_file_names] # total subjects\n",
    "classes_multi, _, _ = searching_overlap(input_directory,class2index, input_file_names)\n",
    "classes_single = [x for x in classes_orig if x not in classes_multi]\n",
    "classes_single = [x.replace('.hea', '.mat') for x in classes_single]\n",
    "\n",
    "# double-checking if classes_single have single-label\n",
    "a, b, c  = searching_overlap(input_directory,class2index,classes_single)\n",
    "\n",
    "# we can safely use classes_single as input_file_names\n",
    "input_file_names = classes_single\n",
    "random.shuffle(input_file_names)\n",
    "np.shape(input_file_names)\n",
    "\n",
    "x_mean_all = []\n",
    "x_std_all = []\n",
    "for file in input_file_names:\n",
    "    x = np.load(mel_directory + '/' + file.replace('.mat', '.npy'))\n",
    "    x_mean = [np.mean(x[:,0]), np.mean(x[:,1]), np.mean(x[:,2]), np.mean(x[:,3]), np.mean(x[:,4]), np.mean(x[:,5]),\n",
    "             np.mean(x[:,6]), np.mean(x[:,7]), np.mean(x[:,8]), np.mean(x[:,9]), np.mean(x[:,10]), np.mean(x[:,11])]\n",
    "    \n",
    "    x_std = [np.std(x[:,0]), np.std(x[:,1]), np.std(x[:,2]), np.std(x[:,3]), np.std(x[:,4]), np.std(x[:,5]),\n",
    "             np.std(x[:,6]), np.std(x[:,7]), np.std(x[:,8]), np.std(x[:,9]), np.std(x[:,10]), np.std(x[:,11])]\n",
    "    #print(x_mean)\n",
    "    x_mean_all.append(x_mean)\n",
    "    x_std_all.append(x_std) # yjs corrected on 2020-05-25\n",
    "x_mean_final = np.mean(x_mean_all, axis=0)\n",
    "x_std_final = np.mean(x_std_all, axis=0)\n",
    "print(x_mean_final)\n",
    "\n",
    "data, data_test = train_test_split(input_file_names, test_size = 0.2, train_size = 0.8, shuffle=True)\n",
    "data_train, data_val = train_test_split(data, test_size = 0.05, train_size = 0.95, shuffle=True)\n",
    "print(np.shape(data_train), np.shape(data_val), np.shape(data_test))\n",
    "\n",
    "\n",
    "main_input = Input(shape=(minimum_len,12), dtype='float32', name='main_input')\n",
    "\n",
    "branch_pred = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# val_acc = test_short(data_val, mel_directory, input_directory, class2index, minimum_len, model, x_mean_final, x_std_final)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention editting by CAM"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "batch_mels, batch_labels = randextract_mels(1, batch_size, data_train, mel_directory, class2index, minimum_len, x_mean_final, x_std_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_x = batch_mels[0]\n",
    "# curr_x = curr_x.reshape(1,minimum_len,n_channels)\n",
    "# print(curr_x.shape)\n",
    "# softmax_layer = 'dense_final'\n",
    "# softmax_out = p_model.get_layer(softmax_layer)\n",
    "# softmax_weights = softmax_out.weights\n",
    "\n",
    "# conv_layer = 'batch_normalization_12'\n",
    "# conv_out = p_model.get_layer(conv_layer).output\n",
    "# get_conv_out = K.function(p_model.input, [conv_out, softmax_weights[0]])\n",
    "# conv_out, softmax_weights = get_conv_out(curr_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Batch-wise to reduce time\n",
    "\n",
    "CAMdir = '/home/taejoon/PhysioNetChallenge/results_20200601_1_CAM_primitive_model'\n",
    "bestmodel = 'ECG_ABN_E87L0.33'\n",
    "p_model = tf.keras.models.load_model(os.path.join(CAMdir, bestmodel), custom_objects={'score_f1' : score_f1}) # primitive model\n",
    "conv_layer = 'batch_normalization_12'\n",
    "softmax_layer = 'dense_final'\n",
    "n_channels=12\n",
    "out_len=12#128\n",
    "softmax_weights = p_model.get_layer('dense_final').weights[0]\n",
    "\n",
    "\n",
    "# yjs added on 2020-06-15: define the function outside loop\n",
    "\n",
    "get_conv_out = K.function(p_model.input, [p_model.get_layer(conv_layer).output, p_model.get_layer(softmax_layer).weights[0]])\n",
    "\n",
    "# model.get_layer(softmax_layer).weights[0]\n",
    "def CAM_conv1D(minimum_len, n_channels, x, y, out_len, get_conv_out):\n",
    "    \n",
    "    # x랑 y는 batch size만큼의 리스트 (32)\n",
    "    heatmaps=[]    \n",
    "    \n",
    "    curr_x = np.asarray(x)\n",
    "    curr_x = curr_x.reshape(len(x),minimum_len,n_channels)\n",
    "    \n",
    "    conv_out, softmax_weights = get_conv_out(curr_x)\n",
    "\n",
    "    for i in range(len(x)):\n",
    "\n",
    "        curr_classes = y[i]\n",
    "        class_index=[]\n",
    "        [class_index.append(j) for j in range(len(curr_classes)) if curr_classes[j]==1]\n",
    "        heatmap=np.zeros((1,36)) # might need to fix this if GradCAM or primitive model changes\n",
    "\n",
    "        conv_out_ = conv_out[i] # (36, 128)\n",
    "\n",
    "\n",
    "        for label in class_index:  # multiclass일 경우 대비해서 for문\n",
    "            curr_weights = softmax_weights[:,label]\n",
    "            weighted_conv = conv_out_*curr_weights\n",
    "            \n",
    "            weighted_conv = weighted_conv.sum(axis=-1) # output = (1,36)\n",
    "            heatmap += weighted_conv\n",
    "            \n",
    "\n",
    "        heatmap %= len(class_index) # 단일 class일 경우 1로 나눠짐. 두개일 경우 더해진 heatmap들이 2로 나눠짐\n",
    "#         heatmap = np.resize(heatmap, (1,out_len))\n",
    "        heatmap = np.resize(heatmap, (out_len, 1))\n",
    "        heatmaps.append(heatmap)\n",
    "        \n",
    "    return heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# heatmap = CAM_conv1D(p_model, conv_layer, softmax_layer,  x_mean_final, x_std_final, minimum_len, \n",
    "#                                   n_channels, batch_mels, batch_labels, out_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(heatmap[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(heatmap[0][0][0]) # 32, 1, 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_x, _ = randextract_mels(0,32, data_train, mel_directory, class2index, minimum_len, x_mean_final, x_std_final)\n",
    "# curr_x = np.asarray(curr_x)\n",
    "# curr_x.shape\n",
    "# curr_x = curr_x.reshape(32,minimum_len,12)\n",
    "\n",
    "# # curr_x = curr_x[0]\n",
    "# # curr_x = curr_x.reshape(1,minimum_len,12)\n",
    "# CAMdir = '/home/taejoon/PhysioNetChallenge/results_20200601_1_CAM_primitive_model'\n",
    "# bestmodel = 'ECG_ABN_E87L0.33'\n",
    "# p_model = tf.keras.models.load_model(os.path.join(CAMdir, bestmodel), custom_objects={'score_f1' : score_f1}) # primitive model\n",
    "# conv_layer = 'batch_normalization_12'\n",
    "# softmax_layer = 'dense_final'\n",
    "# n_channels=12\n",
    "# out_len=128\n",
    "# softmax_weights = p_model.get_layer('dense_final').weights[0]\n",
    "\n",
    "# get_conv_out = K.function(p_model.input, p_model.get_layer(conv_layer).output)\n",
    "\n",
    "# # conv_out = get_conv_out(curr_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv_out = get_conv_out(curr_x)\n",
    "# conv_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv_out[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAMdir = '/home/taejoon/PhysioNetChallenge/results_20200601_1_CAM_primitive_model'\n",
    "# bestmodel = 'ECG_ABN_E87L0.33'\n",
    "# p_model = tf.keras.models.load_model(os.path.join(CAMdir, bestmodel), custom_objects={'score_f1' : score_f1}) # primitive model\n",
    "# conv_layer = 'batch_normalization_12'\n",
    "# softmax_layer = 'dense_final'\n",
    "# n_channels=12\n",
    "# out_len=128\n",
    "# def CAM_conv1D(model, conv_layer, softmax_layer, x_mean_final, x_std_final, minimum_len, \n",
    "#                     n_channels, x, y, out_len):\n",
    "    \n",
    "#     # x랑 y는 batch size만큼의 리스트 (32)\n",
    "       \n",
    "#     #레이어 이름에 해당되는 레이어 정보를 가져옴 \n",
    "# #     conv_out = model.get_layer(conv_layer).output\n",
    "# #     print(conv_out)\n",
    "# #     conv_output= conv_out.output\n",
    "# #     softmax_out = model.get_layer(softmax_layer)\n",
    "# #     softmax_weights = softmax_out.weights\n",
    "#     heatmaps=[]    \n",
    "#     for file in range(len(x)): # 굳이 이렇게 batch 따로돌리는 이유는 나중에 multilable일 때 heatmap 두개일 경우를 대비하기위해\n",
    "#         # 일단은 single label로 하기 \n",
    "#         class_index=[]\n",
    "#         curr_x  = x[file]\n",
    "#         curr_x = curr_x.reshape(1,minimum_len,n_channels)\n",
    "#         curr_classes = y[file]\n",
    "#         [class_index.append(i) for i in range(len(curr_classes)) if curr_classes[i]==1]\n",
    "#         heatmap=np.zeros((1,36)) # might need to fix this if GradCAM or primitive model changes\n",
    "# #         curr_x = tf.convert_to_tensor(curr_x)\n",
    "#         get_conv_out = K.function(model.input, [model.get_layer(conv_layer).output, model.get_layer(softmax_layer).weights[0]])\n",
    "#         conv_out, softmax_weights = get_conv_out(curr_x)\n",
    "#         print(file)\n",
    "#         for label in class_index:  # multiclass일 경우 대비해서 for문\n",
    "#             curr_weights = softmax_weights[:,label]\n",
    "#             weighted_conv = conv_out*curr_weights\n",
    "#             weighted_conv = weighted_conv.sum(axis=2) # output = (1,36)            \n",
    "#             heatmap += weighted_conv\n",
    "            \n",
    "#         heatmap %= len(class_index) # 단일 class일 경우 1로 나눠짐. 두개일 경우 더해진 heatmap들이 2로 나눠짐\n",
    "#         heatmap = np.resize(heatmap, (1,out_len))\n",
    "# #         heatmap = cv2.resize(heatmap, (1,out_len))\n",
    "#         heatmaps.append(heatmap)\n",
    "        \n",
    "#     return heatmaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention editting by GradCAM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "GradCAMdir = '/home/taejoon/PhysioNetChallenge/results_20200601_1_CAM_primitive_model'\n",
    "bestmodel = 'ECG_ABN_E87L0.33'\n",
    "p_model = tf.keras.models.load_model(os.path.join(GradCAMdir, bestmodel), custom_objects={'score_f1' : score_f1}) # primitive model\n",
    "layer_nm = 'conv1d_12'\n",
    "n_channels=12\n",
    "out_len=128\n",
    "def gradCAM_conv1D(model, layer_nm,x_mean_final, x_std_final, minimum_len, \n",
    "                    n_channels, x, y, out_len,sample_weight=1,  keras_phase=0):\n",
    "    \n",
    "    # x랑 y는 batch size만큼의 리스트 (32)\n",
    "       \n",
    "    #레이어 이름에 해당되는 레이어 정보를 가져옴 \n",
    "    layers_wt = model.get_layer(layer_nm).weights\n",
    "    layers = model.get_layer(layer_nm)\n",
    "    layers_weights = model.get_layer(layer_nm).get_weights()\n",
    "\n",
    "    heatmaps=[]    \n",
    "    for file in range(len(x)): # 굳이 이렇게 batch 따로돌리는 이유는 나중에 multilable일 때 heatmap 두개일 경우를 대비하기위해\n",
    "        # 일단은 single label로 하기 \n",
    "        print(file)\n",
    "        class_index=[]\n",
    "        curr_x  = x[file]\n",
    "#         print(curr_x.shape)\n",
    "        curr_x = curr_x.reshape(1,minimum_len,n_channels)\n",
    "        curr_classes = y[file]\n",
    "#         print(curr_classes)\n",
    "#         print(curr_classes.shape)\n",
    "        [class_index.append(i) for i in range(len(curr_classes)) if curr_classes[i]==1]\n",
    "        heatmap=np.zeros(36) # might need to fix this if GradCAM or primitive model changes\n",
    "        for label in class_index:  # multiclass일 경우 대비해서 for문\n",
    "\n",
    "            #긍정 클래스를 설명할 수 있게 컨볼루션 필터 가중치의 gradient를 구함  \n",
    "            grads = K.gradients(model.output[:,label], layers_wt)[0]\n",
    "\n",
    "            #필터별로 가중치를 구함 \n",
    "            pooled_grads = K.mean(grads, axis=(0,1))\n",
    "            get_pooled_grads = K.function(model.input, \n",
    "                                 [pooled_grads, layers.output[0]])\n",
    "\n",
    "            pooled_grads_value, conv_layer_output_value = get_pooled_grads(curr_x)\n",
    "#             print(conv_layer_output_value.shape) # (36,128)\n",
    "            for i in range(conv_layer_output_value.shape[-1]):\n",
    "                conv_layer_output_value[:, i] *= pooled_grads_value[i]\n",
    "                for j in range(len(conv_layer_output_value[:,i])):\n",
    "                    conv_layer_output_value[j,i] = np.maximum(0, conv_layer_output_value[j,i])\n",
    "                #YJS manually added RELU function on 2020-06-02\n",
    "#                 conv_layer_output_value[:,i] = max(0, conv_layer_output_value[:,i])\n",
    "            heatmap += np.mean(conv_layer_output_value, axis=-1)\n",
    "#         print(class_index)\n",
    "        heatmap %= len(class_index) # 단일 class일 경우 1로 나눠짐. 두개일 경우 더해진 heatmap들이 2로 나눠짐\n",
    "        heatmap = cv2.resize(heatmap, (1,out_len))\n",
    "        heatmaps.append(heatmap)\n",
    "#     heatmaps = heatmaps.reshape(len(x),1,36)\n",
    "    return heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_image (InputLayer)        [(None, None, 12)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, None, 64)     2368        input_image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, None, 64)     256         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, None, 64)     12352       batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, 64)     256         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, None, 64)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, None, 128)    24704       max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, 128)    512         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, None, 128)    49280       batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, None, 128)    512         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, None, 128)    0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, None, 256)    98560       max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, None, 256)    1024        conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, None, 256)    196864      batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, None, 256)    1024        conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, None, 256)    196864      batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, None, 256)    1024        conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, None, 256)    0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, None, 512)    393728      max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, None, 512)    2048        conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, None, 512)    786944      batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, None, 512)    2048        conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, None, 512)    786944      batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, None, 512)    2048        conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, None, 512)    0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, None, 512)    786944      max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, None, 512)    2048        conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, None, 256)    393472      batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, None, 256)    1024        conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, None, 128)    98432       batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, None, 128)    512         conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, None, 128)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, None, 64)     8192        max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, None, 64)     256         conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, None, 64)     0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, None, 64)     12288       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, None, 64)     256         conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, None, 64)     0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, None, 256)    16384       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, None, 256)    32768       max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, None, 256)    1024        conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, None, 256)    1024        conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, None, 256)    0           batch_normalization_16[0][0]     \n",
      "                                                                 batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, None, 256)    0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "attention_branch_bn_1 (BatchNor (None, None, 256)    1024        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "attention_branch_conv_1 (Conv1D (None, None, 9)      2304        attention_branch_bn_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attention_branch_att_conv_1 (Co (None, None, 1)      9           attention_branch_conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "attention_branch_att_bn_1 (Batc (None, None, 1)      4           attention_branch_att_conv_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "attention_branch_att_sigmoid_1  (None, None, 1)      0           attention_branch_att_bn_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, None, 128)    0           max_pooling1d_4[0][0]            \n",
      "                                                                 attention_branch_att_sigmoid_1[0]\n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, None, 64)     8192        lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, None, 64)     256         conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, None, 64)     0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, None, 64)     12288       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, None, 64)     256         conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, None, 64)     0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, None, 256)    16384       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, None, 256)    32768       lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, None, 256)    1024        conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, None, 256)    1024        conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, None, 256)    0           batch_normalization_20[0][0]     \n",
      "                                                                 batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, None, 256)    0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "perception_branch_avgpool_1 (Gl (None, 256)          0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "attention_branch_pred_conv_1 (C (None, None, 9)      81          attention_branch_conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "perception_branch_dense_1 (Dens (None, 256)          65792       perception_branch_avgpool_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "attention_branch_gap_1 (GlobalA (None, 9)            0           attention_branch_pred_conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "perception_branch_dense_2 (Dens (None, 9)            2313        perception_branch_dense_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "attention_branch_output (Softma (None, 9)            0           attention_branch_gap_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "perception_branch_output (Softm (None, 9)            0           perception_branch_dense_2[0][0]  \n",
      "==================================================================================================\n",
      "Total params: 4,057,703\n",
      "Trainable params: 4,047,461\n",
      "Non-trainable params: 10,242\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from ABNmodules import *\n",
    "\n",
    "# def get_custom_model(input_shape, n_classes, minimum_len, target_classes, out_ch=256, n=18):\n",
    "# model = get_custom_model((None, 12), 9, minimum_len, 1, out_ch=256, n=1)\n",
    "# model = get_model((None, 12), 9, n=7)\n",
    "\n",
    "# model = cam_model((None, 12), 9, minimum_len, out_ch=256, n=18)\n",
    "\n",
    "\n",
    "# model = edit_model((None,12), len(unique_classes), minimum_len)\n",
    "model = get_custom_model((None, 12), 9, minimum_len, 1, out_ch=256, n=1)\n",
    "model.summary()\n",
    "model.compile(loss=loss_function,\n",
    "              optimizer=optimizers.Adam(lr=1e-5),           \n",
    "              metrics=[score_f1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "batch_mels, batch_labels = randextract_mels(0, batch_size, data_train, mel_directory, class2index, minimum_len, x_mean_final, x_std_final)\n",
    "batch_mels = np.asarray(batch_mels)\n",
    "batch_labels = np.asarray(np.squeeze(batch_labels))\n",
    "heatmap =  CAM_conv1D(minimum_len, n_channels, batch_mels, batch_labels, out_len, get_conv_out)   "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dimension_check = K.function(model.input, model.get_layer('max_pooling1d_4').output)\n",
    "out = dimension_check([batch_mels, heatmap])\n",
    "# get_conv_out = K.function(p_model.input, [p_model.get_layer(conv_layer).output, p_model.get_layer(softmax_layer).weights[0]])\n",
    "\n",
    "# a = model.get_layer('attention_branch_att_sigmoid_1')\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "a = tf.placeholder(tf.float32, shape=(32,12,1))\n",
    "d = tf.placeholder(tf.float32, shape=(32,12,1))\n",
    "\n",
    "layer = layers.concatenate([a,d], axis=2)\n",
    "layer.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "b = tf.placeholder(tf.float32, shape=(32,12,128))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "bb = tf.expand_dims(b,axis=2)\n",
    "bb.shape\n",
    "\n",
    "layer2 = layers.concatenate([bb, bb], axis=2)\n",
    "layer2.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "layer=tf.expand_dims(layer,axis=3)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "layer*layer2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "c = a*b + b\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cc = layer*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 중단된 training 이어돌리기위해 임시로 사용\n",
    "# results_directory = results_directory.replace(\"0608\", \"0604\")\n",
    "# results_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 중단된 training 이어돌리기 위해 임시로 사용\n",
    "# latest = tf.train.latest_checkpoint(results_directory)\n",
    "# latest\n",
    "# model.load_weights(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../results_20200615_edit_ABN_changed\n",
      "\n",
      "Epoch 1 train_loss: 1.934 train_f1: 0.132 \t\n",
      "\n",
      "Validation 1 valid_acc: 0.506 best_acc: 0.506 \t\n",
      "\n",
      "Epoch 2 train_loss: 1.573 train_f1: 0.336 \t\n",
      "\n",
      "Validation 2 valid_acc: 0.600 best_acc: 0.600 \t\n",
      "\n",
      "Epoch 3 train_loss: 1.443 train_f1: 0.401 \t\n",
      "\n",
      "Validation 3 valid_acc: 0.651 best_acc: 0.651 \t\n",
      "\n",
      "Epoch 4 train_loss: 1.356 train_f1: 0.443 \t\n",
      "\n",
      "Validation 4 valid_acc: 0.663 best_acc: 0.663 \t\n",
      "\n",
      "Epoch 5 train_loss: 1.271 train_f1: 0.478 \t\n",
      "\n",
      "Validation 5 valid_acc: 0.702 best_acc: 0.702 \t\n",
      "\n",
      "Epoch 6 train_loss: 1.206 train_f1: 0.507 \t\n",
      "\n",
      "Validation 6 valid_acc: 0.690 best_acc: 0.702 \t\n",
      "\n",
      "Epoch 7 train_loss: 1.139 train_f1: 0.540 \t\n",
      "\n",
      "Validation 7 valid_acc: 0.737 best_acc: 0.737 \t\n",
      "\n",
      "Epoch 8 train_loss: 1.072 train_f1: 0.565 \t\n",
      "\n",
      "Validation 8 valid_acc: 0.753 best_acc: 0.753 \t\n",
      "\n",
      "Epoch 9 train_loss: 1.044 train_f1: 0.587 \t\n",
      "\n",
      "Validation 9 valid_acc: 0.757 best_acc: 0.757 \t\n",
      "\n",
      "Epoch 10 train_loss: 0.992 train_f1: 0.609 \t\n",
      "\n",
      "Validation 10 valid_acc: 0.745 best_acc: 0.757 \t\n",
      "\n",
      "Epoch 11 train_loss: 0.981 train_f1: 0.618 \t\n",
      "\n",
      "Validation 11 valid_acc: 0.749 best_acc: 0.757 \t\n",
      "\n",
      "Epoch 12 train_loss: 0.947 train_f1: 0.641 \t\n",
      "\n",
      "Validation 12 valid_acc: 0.749 best_acc: 0.757 \t\n",
      "\n",
      "Epoch 13 train_loss: 0.903 train_f1: 0.655 \t\n",
      "\n",
      "Validation 13 valid_acc: 0.749 best_acc: 0.757 \t\n",
      "\n",
      "Epoch 14 train_loss: 0.891 train_f1: 0.665 \t\n",
      "\n",
      "Validation 14 valid_acc: 0.757 best_acc: 0.757 \t\n",
      "\n",
      "Epoch 15 train_loss: 0.871 train_f1: 0.676 \t\n",
      "\n",
      "Validation 15 valid_acc: 0.765 best_acc: 0.765 \t\n",
      "\n",
      "Epoch 16 train_loss: 0.846 train_f1: 0.690 \t\n",
      "\n",
      "Validation 16 valid_acc: 0.765 best_acc: 0.765 \t\n",
      "\n",
      "Epoch 17 train_loss: 0.831 train_f1: 0.695 \t\n",
      "\n",
      "Validation 17 valid_acc: 0.765 best_acc: 0.765 \t\n",
      "\n",
      "Epoch 18 train_loss: 0.808 train_f1: 0.705 \t\n",
      "\n",
      "Validation 18 valid_acc: 0.753 best_acc: 0.765 \t\n",
      "\n",
      "Epoch 19 train_loss: 0.806 train_f1: 0.714 \t\n",
      "\n",
      "Validation 19 valid_acc: 0.753 best_acc: 0.765 \t\n",
      "\n",
      "Epoch 20 train_loss: 0.790 train_f1: 0.724 \t\n",
      "\n",
      "Validation 20 valid_acc: 0.749 best_acc: 0.765 \t\n",
      "\n",
      "Epoch 21 train_loss: 0.769 train_f1: 0.731 \t\n",
      "\n",
      "Validation 21 valid_acc: 0.776 best_acc: 0.776 \t\n",
      "\n",
      "Epoch 22 train_loss: 0.753 train_f1: 0.739 \t\n",
      "\n",
      "Validation 22 valid_acc: 0.761 best_acc: 0.776 \t\n",
      "\n",
      "Epoch 23 train_loss: 0.738 train_f1: 0.744 \t\n",
      "\n",
      "Validation 23 valid_acc: 0.753 best_acc: 0.776 \t\n",
      "\n",
      "Epoch 24 train_loss: 0.741 train_f1: 0.746 \t\n",
      "\n",
      "Validation 24 valid_acc: 0.745 best_acc: 0.776 \t\n",
      "\n",
      "Epoch 25 train_loss: 0.721 train_f1: 0.754 \t\n",
      "\n",
      "Validation 25 valid_acc: 0.773 best_acc: 0.776 \t\n",
      "\n",
      "Epoch 26 train_loss: 0.711 train_f1: 0.760 \t\n",
      "\n",
      "Validation 26 valid_acc: 0.757 best_acc: 0.776 \t\n",
      "\n",
      "Epoch 27 train_loss: 0.699 train_f1: 0.762 \t\n",
      "\n",
      "Validation 27 valid_acc: 0.761 best_acc: 0.776 \t\n",
      "\n",
      "Epoch 28 train_loss: 0.690 train_f1: 0.767 \t\n",
      "\n",
      "Validation 28 valid_acc: 0.780 best_acc: 0.780 \t\n",
      "\n",
      "Epoch 29 train_loss: 0.679 train_f1: 0.772 \t\n",
      "\n",
      "Validation 29 valid_acc: 0.773 best_acc: 0.780 \t\n",
      "\n",
      "Epoch 30 train_loss: 0.660 train_f1: 0.780 \t\n",
      "\n",
      "Validation 30 valid_acc: 0.757 best_acc: 0.780 \t\n",
      "\n",
      "Epoch 31 train_loss: 0.661 train_f1: 0.781 \t\n",
      "\n",
      "Validation 31 valid_acc: 0.773 best_acc: 0.780 \t\n",
      "\n",
      "Epoch 32 train_loss: 0.658 train_f1: 0.782 \t\n",
      "\n",
      "Validation 32 valid_acc: 0.769 best_acc: 0.780 \t\n",
      "\n",
      "Epoch 33 train_loss: 0.642 train_f1: 0.787 \t\n",
      "\n",
      "Validation 33 valid_acc: 0.773 best_acc: 0.780 \t\n",
      "\n",
      "Epoch 34 train_loss: 0.632 train_f1: 0.790 \t\n",
      "\n",
      "Validation 34 valid_acc: 0.757 best_acc: 0.780 \t\n",
      "\n",
      "Epoch 35 train_loss: 0.625 train_f1: 0.792 \t\n",
      "\n",
      "Validation 35 valid_acc: 0.773 best_acc: 0.780 \t\n",
      "\n",
      "Epoch 36 train_loss: 0.632 train_f1: 0.792 \t\n",
      "\n",
      "Validation 36 valid_acc: 0.784 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 37 train_loss: 0.602 train_f1: 0.799 \t\n",
      "\n",
      "Validation 37 valid_acc: 0.784 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 38 train_loss: 0.607 train_f1: 0.798 \t\n",
      "\n",
      "Validation 38 valid_acc: 0.784 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 39 train_loss: 0.603 train_f1: 0.801 \t\n",
      "\n",
      "Validation 39 valid_acc: 0.788 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 40 train_loss: 0.597 train_f1: 0.804 \t\n",
      "\n",
      "Validation 40 valid_acc: 0.769 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 41 train_loss: 0.569 train_f1: 0.812 \t\n",
      "\n",
      "Validation 41 valid_acc: 0.757 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 42 train_loss: 0.586 train_f1: 0.804 \t\n",
      "\n",
      "Validation 42 valid_acc: 0.780 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 43 train_loss: 0.587 train_f1: 0.805 \t\n",
      "\n",
      "Validation 43 valid_acc: 0.769 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 44 train_loss: 0.565 train_f1: 0.816 \t\n",
      "\n",
      "Validation 44 valid_acc: 0.769 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 45 train_loss: 0.562 train_f1: 0.814 \t\n",
      "\n",
      "Validation 45 valid_acc: 0.765 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 46 train_loss: 0.550 train_f1: 0.814 \t\n",
      "\n",
      "Validation 46 valid_acc: 0.761 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 47 train_loss: 0.543 train_f1: 0.819 \t\n",
      "\n",
      "Validation 47 valid_acc: 0.796 best_acc: 0.796 \t\n",
      "\n",
      "Epoch 48 train_loss: 0.536 train_f1: 0.825 \t\n",
      "\n",
      "Validation 48 valid_acc: 0.780 best_acc: 0.796 \t\n",
      "\n",
      "Epoch 49 train_loss: 0.531 train_f1: 0.823 \t\n",
      "\n",
      "Validation 49 valid_acc: 0.776 best_acc: 0.796 \t\n",
      "\n",
      "Epoch 50 train_loss: 0.538 train_f1: 0.822 \t\n",
      "\n",
      "Validation 50 valid_acc: 0.776 best_acc: 0.796 \t\n",
      "\n",
      "Epoch 51 train_loss: 0.515 train_f1: 0.826 \t\n",
      "\n",
      "Validation 51 valid_acc: 0.784 best_acc: 0.796 \t\n",
      "\n",
      "Epoch 52 train_loss: 0.522 train_f1: 0.826 \t\n",
      "\n",
      "Validation 52 valid_acc: 0.761 best_acc: 0.796 \t\n",
      "\n",
      "Epoch 53 train_loss: 0.520 train_f1: 0.827 \t\n",
      "\n",
      "Validation 53 valid_acc: 0.792 best_acc: 0.796 \t\n",
      "\n",
      "Epoch 54 train_loss: 0.496 train_f1: 0.832 \t\n",
      "\n",
      "Validation 54 valid_acc: 0.765 best_acc: 0.796 \t\n",
      "\n",
      "Epoch 55 train_loss: 0.494 train_f1: 0.836 \t\n",
      "\n",
      "Validation 55 valid_acc: 0.780 best_acc: 0.796 \t\n",
      "\n",
      "Epoch 56 train_loss: 0.504 train_f1: 0.832 \t\n",
      "\n",
      "Validation 56 valid_acc: 0.776 best_acc: 0.796 \t\n",
      "\n",
      "Epoch 57 train_loss: 0.477 train_f1: 0.839 \t\n",
      "\n",
      "Validation 57 valid_acc: 0.784 best_acc: 0.796 \t\n",
      "\n",
      "Epoch 58 train_loss: 0.481 train_f1: 0.841 \t\n",
      "\n",
      "Validation 58 valid_acc: 0.769 best_acc: 0.796 \t\n",
      "\n",
      "Epoch 59 train_loss: 0.479 train_f1: 0.836 \t\n",
      "\n",
      "Validation 59 valid_acc: 0.792 best_acc: 0.796 \t\n",
      "\n",
      "Epoch 60 train_loss: 0.464 train_f1: 0.845 \t\n",
      "\n",
      "Validation 60 valid_acc: 0.780 best_acc: 0.796 \t\n",
      "\n",
      "Epoch 61 train_loss: 0.476 train_f1: 0.840 \t\n",
      "\n",
      "Validation 61 valid_acc: 0.788 best_acc: 0.796 \t\n",
      "\n",
      "Epoch 62 train_loss: 0.466 train_f1: 0.845 \t\n",
      "\n",
      "Validation 62 valid_acc: 0.765 best_acc: 0.796 \t\n",
      "\n",
      "Epoch 63 train_loss: 0.456 train_f1: 0.846 \t\n",
      "\n",
      "Validation 63 valid_acc: 0.792 best_acc: 0.796 \t\n",
      "\n",
      "Epoch 64 train_loss: 0.440 train_f1: 0.855 \t\n",
      "\n",
      "Validation 64 valid_acc: 0.753 best_acc: 0.796 \t\n",
      "\n",
      "Epoch 65 train_loss: 0.446 train_f1: 0.849 \t\n",
      "\n",
      "Validation 65 valid_acc: 0.780 best_acc: 0.796 \t\n",
      "\n",
      "Epoch 66 train_loss: 0.435 train_f1: 0.853 \t\n",
      "\n",
      "Validation 66 valid_acc: 0.761 best_acc: 0.796 \t\n",
      "\n",
      "Epoch 67 train_loss: 0.433 train_f1: 0.854 \t\n",
      "\n",
      "Validation 67 valid_acc: 0.788 best_acc: 0.796 \t\n",
      "\n",
      "Epoch 68 train_loss: 0.429 train_f1: 0.854 \t\n",
      "\n",
      "Validation 68 valid_acc: 0.776 best_acc: 0.796 \t\n",
      "\n",
      "Epoch 69 train_loss: 0.421 train_f1: 0.858 \t\n",
      "\n",
      "Validation 69 valid_acc: 0.773 best_acc: 0.796 \t\n",
      "\n",
      "Epoch 70 train_loss: 0.429 train_f1: 0.855 \t\n",
      "\n",
      "Validation 70 valid_acc: 0.773 best_acc: 0.796 \t\n",
      "\n",
      "Epoch 71 train_loss: 0.419 train_f1: 0.861 \t\n",
      "\n",
      "Validation 71 valid_acc: 0.796 best_acc: 0.796 \t\n",
      "\n",
      "Epoch 72 train_loss: 0.421 train_f1: 0.861 \t\n",
      "\n",
      "Validation 72 valid_acc: 0.757 best_acc: 0.796 \t\n",
      "\n",
      "Epoch 73 train_loss: 0.403 train_f1: 0.864 \t\n",
      "\n",
      "Validation 73 valid_acc: 0.776 best_acc: 0.796 \t\n",
      "\n",
      "Epoch 74 train_loss: 0.397 train_f1: 0.868 \t\n",
      "\n",
      "Validation 74 valid_acc: 0.788 best_acc: 0.796 \t\n",
      "\n",
      "Epoch 75 train_loss: 0.394 train_f1: 0.868 \t\n",
      "\n",
      "Validation 75 valid_acc: 0.773 best_acc: 0.796 \t\n",
      "\n",
      "Epoch 76 train_loss: 0.392 train_f1: 0.869 \t\n",
      "\n",
      "Validation 76 valid_acc: 0.788 best_acc: 0.796 \t\n",
      "\n",
      "Epoch 77 train_loss: 0.397 train_f1: 0.866 \t\n",
      "\n",
      "Validation 77 valid_acc: 0.773 best_acc: 0.796 \t\n",
      "\n",
      "Epoch 78 train_loss: 0.391 train_f1: 0.868 \t\n",
      "\n",
      "Validation 78 valid_acc: 0.769 best_acc: 0.796 \t\n",
      "\n",
      "Epoch 79 train_loss: 0.382 train_f1: 0.871 \t\n",
      "\n",
      "Validation 79 valid_acc: 0.761 best_acc: 0.796 \t\n",
      "\n",
      "Epoch 80 train_loss: 0.374 train_f1: 0.876 \t\n",
      "\n",
      "Validation 80 valid_acc: 0.780 best_acc: 0.796 \t\n",
      "\n",
      "Epoch 81 train_loss: 0.367 train_f1: 0.881 \t\n",
      "\n",
      "Validation 81 valid_acc: 0.757 best_acc: 0.796 \t\n",
      "\n",
      "Epoch 82 train_loss: 0.380 train_f1: 0.869 \t\n",
      "\n",
      "Validation 82 valid_acc: 0.757 best_acc: 0.796 \t\n",
      "\n",
      "Epoch 83 train_loss: 0.353 train_f1: 0.881 \t\n",
      "\n",
      "Validation 83 valid_acc: 0.773 best_acc: 0.796 \t\n",
      "\n",
      "Epoch 84 train_loss: 0.366 train_f1: 0.878 \t\n",
      "\n",
      "Validation 84 valid_acc: 0.773 best_acc: 0.796 \t\n",
      "\n",
      "Epoch 85 train_loss: 0.345 train_f1: 0.882 \t\n",
      "\n",
      "Validation 85 valid_acc: 0.788 best_acc: 0.796 \t\n",
      "\n",
      "Epoch 86 train_loss: 0.336 train_f1: 0.887 \t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation 86 valid_acc: 0.741 best_acc: 0.796 \t\n",
      "\n",
      "Epoch 87 train_loss: 0.355 train_f1: 0.883 \t\n",
      "\n",
      "Validation 87 valid_acc: 0.776 best_acc: 0.796 \t\n",
      "\n",
      "Epoch 88 train_loss: 0.339 train_f1: 0.886 \t\n",
      "\n",
      "Validation 88 valid_acc: 0.765 best_acc: 0.796 \t\n",
      "\n",
      "Epoch 89 train_loss: 0.344 train_f1: 0.887 \t\n",
      "\n",
      "Validation 89 valid_acc: 0.792 best_acc: 0.796 \t\n",
      "\n",
      "Epoch 90 train_loss: 0.350 train_f1: 0.883 \t\n",
      "\n",
      "Validation 90 valid_acc: 0.776 best_acc: 0.796 \t\n",
      "\n",
      "Epoch 91 train_loss: 0.342 train_f1: 0.886 \t\n",
      "\n",
      "Validation 91 valid_acc: 0.776 best_acc: 0.796 \t\n",
      "\n",
      "Epoch 92 train_loss: 0.319 train_f1: 0.895 \t\n",
      "\n",
      "Validation 92 valid_acc: 0.792 best_acc: 0.796 \t\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-55279f2a3913>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#     train_loss, train_f1 = train_edit(data_train, mel_directory, batch_size, class2index, minimum_len, x_mean_final, x_std_final)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmel_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass2index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminimum_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_mean_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_std_final\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nEpoch'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'train_loss:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf'{train_loss:.3f}'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'train_f1:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf'{train_f1:.3f}'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mmodel_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ECG_ABN_E%02dL%.2f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-f49685717ee3>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(data_train, mel_directory, batch_size, class2index, minimum_len, x_mean_final, x_std_final)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mtrain_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_mels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mloss_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_tmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mf1_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_tmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_tmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1173\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_sample_weight_modes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# DISP DATETIME FOR CHECKING TIME\n",
    "start = time.time()\n",
    "val_acc_sum=[]\n",
    "train_loss_sum=[]\n",
    "train_acc_sum=[]\n",
    "val_loss_sum=[]\n",
    "val_acc_min = 0\n",
    "print(results_directory)\n",
    "\n",
    "for num_epoch in range(epochs):\n",
    "#     num_epoch += 32 # 중단된 코드 돌리기 위해 임의로 사용\n",
    "    random.shuffle(data_train)\n",
    "#     train_loss, train_f1 = train_edit(data_train, mel_directory, batch_size, class2index, minimum_len, x_mean_final, x_std_final)\n",
    "    train_loss, train_f1 = train(data_train, mel_directory, batch_size, class2index, minimum_len, x_mean_final, x_std_final)\n",
    "    print('\\nEpoch',num_epoch+1,'train_loss:',f'{train_loss:.3f}','train_f1:',f'{train_f1:.3f}',\"\\t\")\n",
    "    model_output = \"ECG_ABN_E%02dL%.2f\" % (num_epoch, train_loss)\n",
    "    save_name = os.path.join(results_directory, model_output)\n",
    "    \n",
    "    val_acc = test(data_val, mel_directory, input_directory, class2index, minimum_len, model, x_mean_final, x_std_final)\n",
    "#     val_acc = test_edit(data_val, mel_directory, input_directory, class2index, minimum_len, model, x_mean_final, x_std_final)\n",
    "\n",
    "    if val_acc > val_acc_min:\n",
    "        val_acc_min = val_acc\n",
    "#         model.save_weights(save_name.format(epoch=0))\n",
    "    print('\\nValidation', num_epoch+1, 'valid_acc:',f'{val_acc:.3f}', 'best_acc:',f'{val_acc_min:.3f}', \"\\t\")\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_mels =np.asarray(batch_mels)\n",
    "# batch_mels = batch_mels.reshape(32,2880,12)\n",
    "# heatmap = np.asarray(heatmap)\n",
    "# heatmap = heatmap.reshape(batch_size, 1, out_len)\n",
    "# a = model2.predict([batch_mels, heatmap])\n",
    "# a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "617.813px",
    "left": "1544.27px",
    "right": "20px",
    "top": "79.75px",
    "width": "296.719px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
