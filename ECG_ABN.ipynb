{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/numba/errors.py:137: UserWarning: Insufficiently recent colorama version found. Numba requires colorama >= 0.3.9\n",
      "  warnings.warn(msg)\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import keras\n",
    "# import datetime as dt\n",
    "from datetime import datetime\n",
    "import time\n",
    "# import datetime.datetime\n",
    "\n",
    "\n",
    "\n",
    "from keras import layers\n",
    "from keras import models\n",
    "# from keras import optimizers\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "from keras.applications.densenet import DenseNet121, DenseNet169\n",
    "#from keras.applications.nasnet import NASNetLarge\n",
    "# from keras_efficientnets import EfficientNetB7\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras import initializers, regularizers, constraints\n",
    "from keras.layers.normalization import BatchNormalization \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from keras import backend as K\n",
    "\n",
    "tf.set_random_seed(1234)\n",
    "random.seed(100)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.24290386e-03 -4.58280585e-05  4.31697309e-03 -3.00174693e-03\n",
      " -2.36609229e-04  1.28997408e-03  2.17347589e-04 -7.99152384e-04\n",
      " -3.42993744e-03 -1.69711686e-03  1.27138164e-03  1.94670545e-03]\n",
      "(3840,) (1280,) (1281,)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def score_f1(y_true, y_pred): #taken from old keras source code\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val\n",
    "\n",
    "def dot_product(x, kernel):\n",
    "    if K.backend() == 'tensorflow':\n",
    "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
    "    else:\n",
    "        return K.dot(x, kernel)\n",
    "    \n",
    "def get_unique_classes(input_directory,files):\n",
    "\n",
    "    unique_classes=set()\n",
    "    for f in files:\n",
    "        g = f.replace('.mat','.hea')\n",
    "        input_file = os.path.join(input_directory,g)\n",
    "        with open(input_file,'r') as f:\n",
    "            for lines in f:\n",
    "                if lines.startswith('#Dx'):\n",
    "                    tmp = lines.split(': ')[1].split(',')\n",
    "                    for c in tmp:\n",
    "                        unique_classes.add(c.strip())\n",
    "    return sorted(unique_classes)\n",
    "\n",
    "def one_hot_encoding(one_hot_vector,y, class2index):\n",
    "    ind=class2index[y]\n",
    "    one_hot_vector[ind]=1\n",
    "    return one_hot_vector\n",
    "\n",
    "# Search for multi-label subjects\n",
    "def searching_overlap(input_directory,class2index, input_file_names):\n",
    "    multiclasses=[]\n",
    "    multisubjects=[]\n",
    "    number = []\n",
    "    for file in input_file_names:\n",
    "        f=file\n",
    "        g = f.replace('.mat','.hea')\n",
    "        input_file = os.path.join(input_directory,g)\n",
    "        with open(input_file,'r') as f:\n",
    "            for lines in f:\n",
    "                if lines.startswith('#Dx'):\n",
    "                    tmp = lines.split(': ')[1].split(',')\n",
    "                    if len(tmp)>1:\n",
    "                        one_hot_vector = [0]*(len(class2index))\n",
    "                        for c in tmp:\n",
    "                            one_hot_vector = one_hot_encoding(one_hot_vector, c.strip(), class2index)\n",
    "                        multiclasses.append(one_hot_vector)\n",
    "                        multisubjects.append(g)\n",
    "                        number.append(len(tmp))\n",
    "    return multisubjects, multiclasses, number\n",
    "\n",
    "def block_feature(sequence_en, minimum_len): \n",
    "    new_en = []\n",
    "    if len(sequence_en) > minimum_len:  # 길이가 minimum보다 긴 경우\n",
    "        start = random.randint(0,len(sequence_en)-minimum_len)\n",
    "        #print(start)\n",
    "        new_en = sequence_en[start:start+minimum_len]\n",
    "    elif len(sequence_en) == minimum_len: # 길이가 minimum\n",
    "        new_en = sequence_en\n",
    "    else: \n",
    "        assert len(sequence_en) <= minimum_len\n",
    "    return new_en\n",
    "\n",
    "def exploratory_look(input_directory,file, class2index):\n",
    "    classes = []\n",
    "    f = file\n",
    "    g = f.replace('.mat','.hea')\n",
    "    input_file = os.path.join(input_directory,g)\n",
    "    with open(input_file,'r') as f:\n",
    "        for lines in f:\n",
    "            if lines.startswith('#Dx'):\n",
    "                tmp = lines.split(': ')[1].split(',')\n",
    "                print(tmp, len(tmp))\n",
    "    return tmp     \n",
    "\n",
    "# Get classes of sorted file names\n",
    "def get_labels(input_directory,file, class2index):\n",
    "    f = file\n",
    "    g = f.replace('.mat','.hea')\n",
    "    input_file = os.path.join(input_directory,g)\n",
    "    with open(input_file,'r') as f:\n",
    "        for lines in f:\n",
    "            if lines.startswith('#Dx'):\n",
    "                tmp = lines.split(': ')[1].split(',')\n",
    "                one_hot_vector = [0]*(len(class2index))\n",
    "                for c in tmp:\n",
    "                    one_hot_vector = one_hot_encoding(one_hot_vector, c.strip(), class2index)\n",
    "                \n",
    "    return one_hot_vector\n",
    "\n",
    "def randextract_mels(curr_step, batch_size, data, mel_directory, class2index, minimum_len, x_mean_final, x_std_final):\n",
    "    mel_files = []\n",
    "    classes = []\n",
    "    start = batch_size*curr_step\n",
    "    end = batch_size*(curr_step+1)\n",
    "    curr_file_indices = data[start:end]\n",
    "    for file in curr_file_indices:\n",
    "        tmp_file = np.load(mel_directory + '/' + file.replace('.mat', '.npy'))\n",
    "        clip_file = block_feature(tmp_file, minimum_len)\n",
    "        #print(clip_file.shape)\n",
    "        #clip_file = tmp_file[:minimum_len]\n",
    "        clip_file -= x_mean_final\n",
    "        clip_file /= x_std_final\n",
    "        mel_files.append(clip_file)\n",
    "        label = get_labels(input_directory, file, class2index)\n",
    "        classes.append(label)\n",
    "    \n",
    "    # YJS added for ABN -> should calculate 2 losses\n",
    "#     classes_abn = [classes,classes]\n",
    "    \n",
    "    concat = list(zip(mel_files, classes))\n",
    "#     concat = list(zip(mel_files, classes_abn))\n",
    "    random.shuffle(concat)\n",
    "    mel_files, classes = zip(*concat)\n",
    "    return mel_files, classes\n",
    "\n",
    "def train(data_train, mel_directory, batch_size, class2index, minimum_len, x_mean_final, x_std_final): \n",
    "    loss=[]\n",
    "#     acc = []\n",
    "    f1 = []\n",
    "\n",
    "    total_steps = int(np.ceil(len(data_train)/batch_size))\n",
    "    for curr_step in range(total_steps):\n",
    "        batch_mels, batch_labels = randextract_mels(curr_step, batch_size, data_train, mel_directory, class2index, minimum_len, x_mean_final, x_std_final)\n",
    "        batch_mels = np.asarray(batch_mels)\n",
    "        batch_labels2 = np.asarray(np.squeeze(batch_labels))\n",
    "        batch_labels = [batch_labels2, batch_labels2]\n",
    "#         print(batch_labels.shape)\n",
    "#         print(batch_labels)\n",
    "\n",
    "# return of train\n",
    "# 0 = total loss (attention branch + perception branch)\n",
    "# 1 = loss of attention pred\n",
    "# 2 = loss of perception pred\n",
    "# 3 = f1 of attention pred\n",
    "# 4 = f1 of perception pred     \n",
    "\n",
    "        train_tmp = model.train_on_batch(batch_mels, batch_labels)\n",
    "#         print(train_tmp)\n",
    "        loss_ = train_tmp[0]/2\n",
    "        f1_ = np.mean((train_tmp[3], train_tmp[4]))\n",
    "        loss.append(loss_)\n",
    "#         acc.append(train_tmp[1])\n",
    "        f1.append(f1_)\n",
    "\n",
    "    loss = np.mean(np.array(loss))\n",
    "#     acc = np.mean(np.array(acc))\n",
    "    f1 = np.mean(np.array(f1))\n",
    "    return loss, f1\n",
    "\n",
    "def test(data, mel_directory, input_directory, class2index, minimum_len, model, x_mean_final, x_std_final):\n",
    "    scores = []\n",
    "    predicted_labels=[]\n",
    "    accuracy=np.zeros(len(data))\n",
    "    #total_loss=[]\n",
    "    total_acc = 0\n",
    "    total_f1 = 0\n",
    "    \n",
    "    mel_files = []\n",
    "    classes = []\n",
    "    for i, file in enumerate(data):\n",
    "        tmp_file = np.load(mel_directory + '/' + file.replace('.mat', '.npy'))\n",
    "        steps = int(np.floor(tmp_file.shape[0]/minimum_len))\n",
    "        mel_files = []\n",
    "        for block in range(steps): # 128개씩 쪼갠 블럭 단위로 predict\n",
    "            start = block*minimum_len\n",
    "            end = (block+1)*minimum_len\n",
    "            clip_file = tmp_file[start:end]\n",
    "            clip_file -= x_mean_final\n",
    "            clip_file /= x_std_final\n",
    "            mel_files.append(clip_file)\n",
    "        mel_files = np.asarray(mel_files)\n",
    "        logit = model.predict(mel_files)\n",
    "#         print(len(logit))\n",
    "        logit = np.mean(logit, axis=0)\n",
    "        logit = np.mean(logit, axis=0)\n",
    "#         print(logit)\n",
    "        pred = np.argmax(logit)\n",
    "#         print('Pred={}'.format(pred))\n",
    "        \n",
    "        label = np.argmax(get_labels(input_directory, file, class2index))\n",
    "#         print('Label={}'.format(label))\n",
    "        #f1 = f1_score(label, logit)\n",
    "        #print(pred, label)\n",
    "        if pred == label:\n",
    "            acc = 1\n",
    "        else:\n",
    "            acc = 0\n",
    "        total_acc += acc\n",
    "        #total_f1 += f1\n",
    "    final_acc = total_acc / i\n",
    "    #final_f1 = total_f1 / i\n",
    "    return final_acc#, final_f1\n",
    "\n",
    "batch_size = 32#16#20#32#5#2#1#10#32\n",
    "\n",
    "minimum_len = 2880\n",
    "epochs = 1000\n",
    "loss_function = 'categorical_crossentropy'\n",
    "activation_function = 'softmax'\n",
    "rootdir = '../'\n",
    "date = datetime.today().strftime(\"%Y%m%d\")\n",
    "input_directory = os.path.join(rootdir, 'Training_WFDB')\n",
    "mel_name = 'Raw_data_20200424' \n",
    "mel_directory = os.path.join(rootdir, mel_name)\n",
    "results_directory = os.path.join(rootdir, 'results_'+date+'_0_ieee_model')\n",
    "if not os.path.isdir(input_directory):\n",
    "    os.mkdir(input_directory)\n",
    "if not os.path.isdir(mel_directory):\n",
    "    os.mkdir(mel_directory)\n",
    "if not os.path.isdir(results_directory):\n",
    "    os.mkdir(results_directory)\n",
    "        \n",
    "input_files = []\n",
    "for f in os.listdir(input_directory):\n",
    "    if os.path.isfile(os.path.join(input_directory, f)) and not f.lower().startswith('.') and f.lower().endswith('mat'):\n",
    "        input_files.append(f)\n",
    "input_file_names = sorted(input_files)\n",
    "\n",
    "unique_classes = get_unique_classes(input_directory, input_files)\n",
    "class2index = {}\n",
    "for a, b in enumerate(unique_classes):\n",
    "    class2index[b] = a\n",
    "    \n",
    "classes_orig= [x.replace('.mat', '.hea') for x in input_file_names] # total subjects\n",
    "classes_multi, _, _ = searching_overlap(input_directory,class2index, input_file_names)\n",
    "classes_single = [x for x in classes_orig if x not in classes_multi]\n",
    "classes_single = [x.replace('.hea', '.mat') for x in classes_single]\n",
    "\n",
    "# double-checking if classes_single have single-label\n",
    "a, b, c  = searching_overlap(input_directory,class2index,classes_single)\n",
    "\n",
    "# we can safely use classes_single as input_file_names\n",
    "input_file_names = classes_single\n",
    "random.shuffle(input_file_names)\n",
    "np.shape(input_file_names)\n",
    "\n",
    "x_mean_all = []\n",
    "x_std_all = []\n",
    "for file in input_file_names:\n",
    "    x = np.load(mel_directory + '/' + file.replace('.mat', '.npy'))\n",
    "    x_mean = [np.mean(x[:,0]), np.mean(x[:,1]), np.mean(x[:,2]), np.mean(x[:,3]), np.mean(x[:,4]), np.mean(x[:,5]),\n",
    "             np.mean(x[:,6]), np.mean(x[:,7]), np.mean(x[:,8]), np.mean(x[:,9]), np.mean(x[:,10]), np.mean(x[:,11])]\n",
    "    \n",
    "    x_std = [np.std(x[:,0]), np.std(x[:,1]), np.std(x[:,2]), np.std(x[:,3]), np.std(x[:,4]), np.std(x[:,5]),\n",
    "             np.std(x[:,6]), np.std(x[:,7]), np.std(x[:,8]), np.std(x[:,9]), np.std(x[:,10]), np.std(x[:,11])]\n",
    "    #print(x_mean)\n",
    "    x_mean_all.append(x_mean)\n",
    "    x_std_all.append(x_std) # yjs corrected on 2020-05-25\n",
    "x_mean_final = np.mean(x_mean_all, axis=0)\n",
    "x_std_final = np.mean(x_std_all, axis=0)\n",
    "print(x_mean_final)\n",
    "\n",
    "data, data_test = train_test_split(input_file_names, test_size = 0.2, train_size = 0.8, shuffle=True)\n",
    "data_train, data_val = train_test_split(data, test_size = 0.25, train_size = 0.75, shuffle=True)\n",
    "print(np.shape(data_train), np.shape(data_val), np.shape(data_test))\n",
    "\n",
    "\n",
    "main_input = Input(shape=(minimum_len,12), dtype='float32', name='main_input')\n",
    "\n",
    "branch_pred = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.layers import GaussianNoise\n",
    "\n",
    "# GaussianNoise(0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_image (InputLayer)        [(None, None, 12)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, None, 64)     2368        input_image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, None, 64)     256         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, None, 64)     12352       batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, 64)     256         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, None, 64)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, None, 128)    24704       max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, 128)    512         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, None, 128)    49280       batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, None, 128)    512         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, None, 128)    0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, None, 256)    98560       max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, None, 256)    1024        conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, None, 256)    196864      batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, None, 256)    1024        conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, None, 256)    196864      batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, None, 256)    1024        conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, None, 256)    0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, None, 512)    393728      max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, None, 512)    2048        conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, None, 512)    786944      batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, None, 512)    2048        conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, None, 512)    786944      batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, None, 512)    2048        conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, None, 512)    0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, None, 512)    786944      max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, None, 512)    2048        conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, None, 256)    393472      batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, None, 256)    1024        conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, None, 128)    98432       batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, None, 128)    512         conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, None, 128)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, None, 64)     8192        max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, None, 64)     256         conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, None, 64)     0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, None, 64)     12288       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, None, 64)     256         conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, None, 64)     0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, None, 256)    16384       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, None, 256)    32768       max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, None, 256)    1024        conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, None, 256)    1024        conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, None, 256)    0           batch_normalization_16[0][0]     \n",
      "                                                                 batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, None, 256)    0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, None, 64)     16384       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, None, 64)     256         conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, None, 64)     0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, None, 64)     12288       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, None, 64)     256         conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, None, 64)     0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, None, 256)    16384       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, None, 256)    1024        conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, None, 256)    0           batch_normalization_19[0][0]     \n",
      "                                                                 activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, None, 256)    0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, None, 64)     16384       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, None, 64)     256         conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, None, 64)     0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, None, 64)     12288       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, None, 64)     256         conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, None, 64)     0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, None, 256)    16384       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, None, 256)    1024        conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, None, 256)    0           batch_normalization_22[0][0]     \n",
      "                                                                 activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, None, 256)    0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, None, 64)     16384       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, None, 64)     256         conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, None, 64)     0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, None, 64)     12288       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, None, 64)     256         conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, None, 64)     0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, None, 256)    16384       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, None, 256)    1024        conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, None, 256)    0           batch_normalization_25[0][0]     \n",
      "                                                                 activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, None, 256)    0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, None, 64)     16384       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, None, 64)     256         conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, None, 64)     0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, None, 64)     12288       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, None, 64)     256         conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, None, 64)     0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, None, 256)    16384       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, None, 256)    1024        conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, None, 256)    0           batch_normalization_28[0][0]     \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, None, 256)    0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, None, 64)     16384       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, None, 64)     256         conv1d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, None, 64)     0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, None, 64)     12288       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, None, 64)     256         conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, None, 64)     0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, None, 256)    16384       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, None, 256)    1024        conv1d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, None, 256)    0           batch_normalization_31[0][0]     \n",
      "                                                                 activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, None, 256)    0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, None, 64)     16384       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, None, 64)     256         conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, None, 64)     0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, None, 64)     12288       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, None, 64)     256         conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, None, 64)     0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, None, 256)    16384       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, None, 256)    1024        conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, None, 256)    0           batch_normalization_34[0][0]     \n",
      "                                                                 activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, None, 256)    0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, None, 64)     16384       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, None, 64)     256         conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, None, 64)     0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, None, 64)     12288       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, None, 64)     256         conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, None, 64)     0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, None, 256)    16384       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, None, 256)    1024        conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, None, 256)    0           batch_normalization_37[0][0]     \n",
      "                                                                 activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, None, 256)    0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, None, 64)     16384       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, None, 64)     256         conv1d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, None, 64)     0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_39 (Conv1D)              (None, None, 64)     12288       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, None, 64)     256         conv1d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, None, 64)     0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_40 (Conv1D)              (None, None, 256)    16384       activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, None, 256)    1024        conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, None, 256)    0           batch_normalization_40[0][0]     \n",
      "                                                                 activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, None, 256)    0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_41 (Conv1D)              (None, None, 64)     16384       activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, None, 64)     256         conv1d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, None, 64)     0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_42 (Conv1D)              (None, None, 64)     12288       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, None, 64)     256         conv1d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, None, 64)     0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_43 (Conv1D)              (None, None, 256)    16384       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, None, 256)    1024        conv1d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, None, 256)    0           batch_normalization_43[0][0]     \n",
      "                                                                 activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, None, 256)    0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_44 (Conv1D)              (None, None, 64)     16384       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, None, 64)     256         conv1d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, None, 64)     0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_45 (Conv1D)              (None, None, 64)     12288       activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, None, 64)     256         conv1d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, None, 64)     0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_46 (Conv1D)              (None, None, 256)    16384       activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, None, 256)    1024        conv1d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, None, 256)    0           batch_normalization_46[0][0]     \n",
      "                                                                 activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, None, 256)    0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_47 (Conv1D)              (None, None, 64)     16384       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, None, 64)     256         conv1d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, None, 64)     0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_48 (Conv1D)              (None, None, 64)     12288       activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, None, 64)     256         conv1d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, None, 64)     0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_49 (Conv1D)              (None, None, 256)    16384       activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, None, 256)    1024        conv1d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, None, 256)    0           batch_normalization_49[0][0]     \n",
      "                                                                 activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, None, 256)    0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_50 (Conv1D)              (None, None, 64)     16384       activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, None, 64)     256         conv1d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, None, 64)     0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_51 (Conv1D)              (None, None, 64)     12288       activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, None, 64)     256         conv1d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, None, 64)     0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_52 (Conv1D)              (None, None, 256)    16384       activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, None, 256)    1024        conv1d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, None, 256)    0           batch_normalization_52[0][0]     \n",
      "                                                                 activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, None, 256)    0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_53 (Conv1D)              (None, None, 64)     16384       activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, None, 64)     256         conv1d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, None, 64)     0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_54 (Conv1D)              (None, None, 64)     12288       activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, None, 64)     256         conv1d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, None, 64)     0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_55 (Conv1D)              (None, None, 256)    16384       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, None, 256)    1024        conv1d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, None, 256)    0           batch_normalization_55[0][0]     \n",
      "                                                                 activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, None, 256)    0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_56 (Conv1D)              (None, None, 64)     16384       activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, None, 64)     256         conv1d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, None, 64)     0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_57 (Conv1D)              (None, None, 64)     12288       activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, None, 64)     256         conv1d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, None, 64)     0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_58 (Conv1D)              (None, None, 256)    16384       activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, None, 256)    1024        conv1d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, None, 256)    0           batch_normalization_58[0][0]     \n",
      "                                                                 activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, None, 256)    0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_59 (Conv1D)              (None, None, 64)     16384       activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, None, 64)     256         conv1d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, None, 64)     0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_60 (Conv1D)              (None, None, 64)     12288       activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, None, 64)     256         conv1d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, None, 64)     0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_61 (Conv1D)              (None, None, 256)    16384       activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, None, 256)    1024        conv1d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, None, 256)    0           batch_normalization_61[0][0]     \n",
      "                                                                 activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, None, 256)    0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_62 (Conv1D)              (None, None, 64)     16384       activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, None, 64)     256         conv1d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, None, 64)     0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_63 (Conv1D)              (None, None, 64)     12288       activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, None, 64)     256         conv1d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, None, 64)     0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_64 (Conv1D)              (None, None, 256)    16384       activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, None, 256)    1024        conv1d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, None, 256)    0           batch_normalization_64[0][0]     \n",
      "                                                                 activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, None, 256)    0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_65 (Conv1D)              (None, None, 64)     16384       activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, None, 64)     256         conv1d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, None, 64)     0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_66 (Conv1D)              (None, None, 64)     12288       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, None, 64)     256         conv1d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, None, 64)     0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_67 (Conv1D)              (None, None, 256)    16384       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, None, 256)    1024        conv1d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, None, 256)    0           batch_normalization_67[0][0]     \n",
      "                                                                 activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, None, 256)    0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_branch_bn_1 (BatchNor (None, None, 256)    1024        activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "attention_branch_conv_1 (Conv1D (None, None, 9)      2304        attention_branch_bn_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attention_branch_att_conv_1 (Co (None, None, 1)      9           attention_branch_conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "attention_branch_att_bn_1 (Batc (None, None, 1)      4           attention_branch_att_conv_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "attention_branch_att_sigmoid_1  (None, None, 1)      0           attention_branch_att_bn_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, None, 128)    0           max_pooling1d_4[0][0]            \n",
      "                                                                 attention_branch_att_sigmoid_1[0]\n",
      "__________________________________________________________________________________________________\n",
      "conv1d_69 (Conv1D)              (None, None, 64)     8192        lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, None, 64)     256         conv1d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, None, 64)     0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_70 (Conv1D)              (None, None, 64)     12288       activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, None, 64)     256         conv1d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, None, 64)     0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_71 (Conv1D)              (None, None, 256)    16384       activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_68 (Conv1D)              (None, None, 256)    32768       lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, None, 256)    1024        conv1d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, None, 256)    1024        conv1d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, None, 256)    0           batch_normalization_71[0][0]     \n",
      "                                                                 batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, None, 256)    0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_72 (Conv1D)              (None, None, 64)     16384       activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, None, 64)     256         conv1d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, None, 64)     0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_73 (Conv1D)              (None, None, 64)     12288       activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, None, 64)     256         conv1d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, None, 64)     0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_74 (Conv1D)              (None, None, 256)    16384       activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, None, 256)    1024        conv1d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, None, 256)    0           batch_normalization_74[0][0]     \n",
      "                                                                 activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, None, 256)    0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_75 (Conv1D)              (None, None, 64)     16384       activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, None, 64)     256         conv1d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, None, 64)     0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_76 (Conv1D)              (None, None, 64)     12288       activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, None, 64)     256         conv1d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, None, 64)     0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_77 (Conv1D)              (None, None, 256)    16384       activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, None, 256)    1024        conv1d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, None, 256)    0           batch_normalization_77[0][0]     \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, None, 256)    0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_78 (Conv1D)              (None, None, 64)     16384       activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, None, 64)     256         conv1d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, None, 64)     0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_79 (Conv1D)              (None, None, 64)     12288       activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, None, 64)     256         conv1d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, None, 64)     0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_80 (Conv1D)              (None, None, 256)    16384       activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, None, 256)    1024        conv1d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, None, 256)    0           batch_normalization_80[0][0]     \n",
      "                                                                 activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, None, 256)    0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_81 (Conv1D)              (None, None, 64)     16384       activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, None, 64)     256         conv1d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, None, 64)     0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_82 (Conv1D)              (None, None, 64)     12288       activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, None, 64)     256         conv1d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, None, 64)     0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_83 (Conv1D)              (None, None, 256)    16384       activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, None, 256)    1024        conv1d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, None, 256)    0           batch_normalization_83[0][0]     \n",
      "                                                                 activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, None, 256)    0           add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_84 (Conv1D)              (None, None, 64)     16384       activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, None, 64)     256         conv1d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, None, 64)     0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_85 (Conv1D)              (None, None, 64)     12288       activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, None, 64)     256         conv1d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, None, 64)     0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_86 (Conv1D)              (None, None, 256)    16384       activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, None, 256)    1024        conv1d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, None, 256)    0           batch_normalization_86[0][0]     \n",
      "                                                                 activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, None, 256)    0           add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_87 (Conv1D)              (None, None, 64)     16384       activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, None, 64)     256         conv1d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, None, 64)     0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_88 (Conv1D)              (None, None, 64)     12288       activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, None, 64)     256         conv1d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, None, 64)     0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_89 (Conv1D)              (None, None, 256)    16384       activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, None, 256)    1024        conv1d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, None, 256)    0           batch_normalization_89[0][0]     \n",
      "                                                                 activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, None, 256)    0           add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_90 (Conv1D)              (None, None, 64)     16384       activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, None, 64)     256         conv1d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, None, 64)     0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_91 (Conv1D)              (None, None, 64)     12288       activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, None, 64)     256         conv1d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, None, 64)     0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_92 (Conv1D)              (None, None, 256)    16384       activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, None, 256)    1024        conv1d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, None, 256)    0           batch_normalization_92[0][0]     \n",
      "                                                                 activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, None, 256)    0           add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_93 (Conv1D)              (None, None, 64)     16384       activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, None, 64)     256         conv1d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, None, 64)     0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_94 (Conv1D)              (None, None, 64)     12288       activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, None, 64)     256         conv1d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, None, 64)     0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_95 (Conv1D)              (None, None, 256)    16384       activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, None, 256)    1024        conv1d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, None, 256)    0           batch_normalization_95[0][0]     \n",
      "                                                                 activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, None, 256)    0           add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_96 (Conv1D)              (None, None, 64)     16384       activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, None, 64)     256         conv1d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, None, 64)     0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_97 (Conv1D)              (None, None, 64)     12288       activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, None, 64)     256         conv1d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, None, 64)     0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_98 (Conv1D)              (None, None, 256)    16384       activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, None, 256)    1024        conv1d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, None, 256)    0           batch_normalization_98[0][0]     \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, None, 256)    0           add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_99 (Conv1D)              (None, None, 64)     16384       activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, None, 64)     256         conv1d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, None, 64)     0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_100 (Conv1D)             (None, None, 64)     12288       activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, None, 64)     256         conv1d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, None, 64)     0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_101 (Conv1D)             (None, None, 256)    16384       activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, None, 256)    1024        conv1d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, None, 256)    0           batch_normalization_101[0][0]    \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, None, 256)    0           add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_102 (Conv1D)             (None, None, 64)     16384       activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, None, 64)     256         conv1d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, None, 64)     0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_103 (Conv1D)             (None, None, 64)     12288       activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, None, 64)     256         conv1d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, None, 64)     0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_104 (Conv1D)             (None, None, 256)    16384       activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, None, 256)    1024        conv1d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, None, 256)    0           batch_normalization_104[0][0]    \n",
      "                                                                 activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, None, 256)    0           add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_105 (Conv1D)             (None, None, 64)     16384       activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, None, 64)     256         conv1d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, None, 64)     0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_106 (Conv1D)             (None, None, 64)     12288       activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, None, 64)     256         conv1d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, None, 64)     0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_107 (Conv1D)             (None, None, 256)    16384       activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, None, 256)    1024        conv1d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, None, 256)    0           batch_normalization_107[0][0]    \n",
      "                                                                 activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, None, 256)    0           add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_108 (Conv1D)             (None, None, 64)     16384       activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, None, 64)     256         conv1d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, None, 64)     0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_109 (Conv1D)             (None, None, 64)     12288       activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, None, 64)     256         conv1d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, None, 64)     0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_110 (Conv1D)             (None, None, 256)    16384       activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, None, 256)    1024        conv1d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, None, 256)    0           batch_normalization_110[0][0]    \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, None, 256)    0           add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_111 (Conv1D)             (None, None, 64)     16384       activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, None, 64)     256         conv1d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, None, 64)     0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_112 (Conv1D)             (None, None, 64)     12288       activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, None, 64)     256         conv1d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, None, 64)     0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_113 (Conv1D)             (None, None, 256)    16384       activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, None, 256)    1024        conv1d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, None, 256)    0           batch_normalization_113[0][0]    \n",
      "                                                                 activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, None, 256)    0           add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_114 (Conv1D)             (None, None, 64)     16384       activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, None, 64)     256         conv1d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, None, 64)     0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_115 (Conv1D)             (None, None, 64)     12288       activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, None, 64)     256         conv1d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, None, 64)     0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_116 (Conv1D)             (None, None, 256)    16384       activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, None, 256)    1024        conv1d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_33 (Add)                    (None, None, 256)    0           batch_normalization_116[0][0]    \n",
      "                                                                 activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, None, 256)    0           add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_117 (Conv1D)             (None, None, 64)     16384       activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, None, 64)     256         conv1d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, None, 64)     0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_118 (Conv1D)             (None, None, 64)     12288       activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, None, 64)     256         conv1d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, None, 64)     0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_119 (Conv1D)             (None, None, 256)    16384       activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, None, 256)    1024        conv1d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_34 (Add)                    (None, None, 256)    0           batch_normalization_119[0][0]    \n",
      "                                                                 activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, None, 256)    0           add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_120 (Conv1D)             (None, None, 64)     16384       activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, None, 64)     256         conv1d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, None, 64)     0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_121 (Conv1D)             (None, None, 64)     12288       activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, None, 64)     256         conv1d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, None, 64)     0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_122 (Conv1D)             (None, None, 256)    16384       activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, None, 256)    1024        conv1d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_35 (Add)                    (None, None, 256)    0           batch_normalization_122[0][0]    \n",
      "                                                                 activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, None, 256)    0           add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "perception_branch_avgpool_1 (Gl (None, 256)          0           activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_branch_pred_conv_1 (C (None, None, 9)      81          attention_branch_conv_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "perception_branch_dense_1 (Dens (None, 256)          65792       perception_branch_avgpool_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "attention_branch_gap_1 (GlobalA (None, 9)            0           attention_branch_pred_conv_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "perception_branch_dense_2 (Dens (None, 9)            2313        perception_branch_dense_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "attention_branch_output (Softma (None, 9)            0           attention_branch_gap_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "perception_branch_output (Softm (None, 9)            0           perception_branch_dense_2[0][0]  \n",
      "==================================================================================================\n",
      "Total params: 5,641,831\n",
      "Trainable params: 5,605,477\n",
      "Non-trainable params: 36,354\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from ABNmodules import *\n",
    "\n",
    "\n",
    "model = get_custom_model((None, 12), 9, out_ch=256, n=18)\n",
    "# model = get_model((None, 12), 9, n=7)\n",
    "model.summary()\n",
    "model.compile(loss=[loss_function, loss_function],\n",
    "              optimizer=optimizers.Adam(lr=1e-5),\n",
    "              \n",
    "              \n",
    "              \n",
    "              metrics=[score_f1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../results_20200526_0_ieee_model\n",
      "\n",
      "Epoch 1 train_loss: 2.645 train_f1: 0.033 \t\n",
      "\n",
      "Validation 1 valid_acc: 0.145 best_acc: 0.145 \t\n",
      "\n",
      "Epoch 2 train_loss: 2.188 train_f1: 0.031 \t\n",
      "\n",
      "Validation 2 valid_acc: 0.157 best_acc: 0.157 \t\n",
      "\n",
      "Epoch 3 train_loss: 2.159 train_f1: 0.036 \t\n",
      "\n",
      "Validation 3 valid_acc: 0.178 best_acc: 0.178 \t\n",
      "\n",
      "Epoch 4 train_loss: 2.155 train_f1: 0.042 \t\n",
      "\n",
      "Validation 4 valid_acc: 0.205 best_acc: 0.205 \t\n",
      "\n",
      "Epoch 5 train_loss: 2.124 train_f1: 0.042 \t\n",
      "\n",
      "Validation 5 valid_acc: 0.257 best_acc: 0.257 \t\n",
      "\n",
      "Epoch 6 train_loss: 2.109 train_f1: 0.044 \t\n",
      "\n",
      "Validation 6 valid_acc: 0.270 best_acc: 0.270 \t\n",
      "\n",
      "Epoch 7 train_loss: 2.096 train_f1: 0.049 \t\n",
      "\n",
      "Validation 7 valid_acc: 0.291 best_acc: 0.291 \t\n",
      "\n",
      "Epoch 8 train_loss: 2.090 train_f1: 0.061 \t\n",
      "\n",
      "Validation 8 valid_acc: 0.284 best_acc: 0.291 \t\n",
      "\n",
      "Epoch 9 train_loss: 2.084 train_f1: 0.063 \t\n",
      "\n",
      "Validation 9 valid_acc: 0.306 best_acc: 0.306 \t\n",
      "\n",
      "Epoch 10 train_loss: 2.061 train_f1: 0.062 \t\n",
      "\n",
      "Validation 10 valid_acc: 0.299 best_acc: 0.306 \t\n",
      "\n",
      "Epoch 11 train_loss: 2.051 train_f1: 0.079 \t\n",
      "\n",
      "Validation 11 valid_acc: 0.328 best_acc: 0.328 \t\n",
      "\n",
      "Epoch 12 train_loss: 2.031 train_f1: 0.080 \t\n",
      "\n",
      "Validation 12 valid_acc: 0.332 best_acc: 0.332 \t\n",
      "\n",
      "Epoch 13 train_loss: 2.021 train_f1: 0.094 \t\n",
      "\n",
      "Validation 13 valid_acc: 0.332 best_acc: 0.332 \t\n",
      "\n",
      "Epoch 14 train_loss: 2.014 train_f1: 0.098 \t\n",
      "\n",
      "Validation 14 valid_acc: 0.365 best_acc: 0.365 \t\n",
      "\n",
      "Epoch 15 train_loss: 1.991 train_f1: 0.105 \t\n",
      "\n",
      "Validation 15 valid_acc: 0.372 best_acc: 0.372 \t\n",
      "\n",
      "Epoch 16 train_loss: 1.971 train_f1: 0.104 \t\n",
      "\n",
      "Validation 16 valid_acc: 0.387 best_acc: 0.387 \t\n",
      "\n",
      "Epoch 17 train_loss: 1.972 train_f1: 0.112 \t\n",
      "\n",
      "Validation 17 valid_acc: 0.376 best_acc: 0.387 \t\n",
      "\n",
      "Epoch 18 train_loss: 1.950 train_f1: 0.126 \t\n",
      "\n",
      "Validation 18 valid_acc: 0.413 best_acc: 0.413 \t\n",
      "\n",
      "Epoch 19 train_loss: 1.924 train_f1: 0.137 \t\n",
      "\n",
      "Validation 19 valid_acc: 0.399 best_acc: 0.413 \t\n",
      "\n",
      "Epoch 20 train_loss: 1.916 train_f1: 0.143 \t\n",
      "\n",
      "Validation 20 valid_acc: 0.409 best_acc: 0.413 \t\n",
      "\n",
      "Epoch 21 train_loss: 1.899 train_f1: 0.147 \t\n",
      "\n",
      "Validation 21 valid_acc: 0.440 best_acc: 0.440 \t\n",
      "\n",
      "Epoch 22 train_loss: 1.892 train_f1: 0.154 \t\n",
      "\n",
      "Validation 22 valid_acc: 0.412 best_acc: 0.440 \t\n",
      "\n",
      "Epoch 23 train_loss: 1.874 train_f1: 0.161 \t\n",
      "\n",
      "Validation 23 valid_acc: 0.443 best_acc: 0.443 \t\n",
      "\n",
      "Epoch 24 train_loss: 1.869 train_f1: 0.166 \t\n",
      "\n",
      "Validation 24 valid_acc: 0.422 best_acc: 0.443 \t\n",
      "\n",
      "Epoch 25 train_loss: 1.863 train_f1: 0.168 \t\n",
      "\n",
      "Validation 25 valid_acc: 0.446 best_acc: 0.446 \t\n",
      "\n",
      "Epoch 26 train_loss: 1.856 train_f1: 0.164 \t\n",
      "\n",
      "Validation 26 valid_acc: 0.454 best_acc: 0.454 \t\n",
      "\n",
      "Epoch 27 train_loss: 1.838 train_f1: 0.175 \t\n",
      "\n",
      "Validation 27 valid_acc: 0.421 best_acc: 0.454 \t\n",
      "\n",
      "Epoch 28 train_loss: 1.824 train_f1: 0.186 \t\n",
      "\n",
      "Validation 28 valid_acc: 0.433 best_acc: 0.454 \t\n",
      "\n",
      "Epoch 29 train_loss: 1.825 train_f1: 0.176 \t\n",
      "\n",
      "Validation 29 valid_acc: 0.461 best_acc: 0.461 \t\n",
      "\n",
      "Epoch 30 train_loss: 1.805 train_f1: 0.182 \t\n",
      "\n",
      "Validation 30 valid_acc: 0.461 best_acc: 0.461 \t\n",
      "\n",
      "Epoch 31 train_loss: 1.786 train_f1: 0.188 \t\n",
      "\n",
      "Validation 31 valid_acc: 0.474 best_acc: 0.474 \t\n",
      "\n",
      "Epoch 32 train_loss: 1.770 train_f1: 0.195 \t\n",
      "\n",
      "Validation 32 valid_acc: 0.454 best_acc: 0.474 \t\n",
      "\n",
      "Epoch 33 train_loss: 1.768 train_f1: 0.195 \t\n",
      "\n",
      "Validation 33 valid_acc: 0.460 best_acc: 0.474 \t\n",
      "\n",
      "Epoch 34 train_loss: 1.771 train_f1: 0.192 \t\n",
      "\n",
      "Validation 34 valid_acc: 0.461 best_acc: 0.474 \t\n",
      "\n",
      "Epoch 35 train_loss: 1.759 train_f1: 0.199 \t\n",
      "\n",
      "Validation 35 valid_acc: 0.471 best_acc: 0.474 \t\n",
      "\n",
      "Epoch 36 train_loss: 1.743 train_f1: 0.206 \t\n",
      "\n",
      "Validation 36 valid_acc: 0.464 best_acc: 0.474 \t\n",
      "\n",
      "Epoch 37 train_loss: 1.729 train_f1: 0.218 \t\n",
      "\n",
      "Validation 37 valid_acc: 0.487 best_acc: 0.487 \t\n",
      "\n",
      "Epoch 38 train_loss: 1.722 train_f1: 0.223 \t\n",
      "\n",
      "Validation 38 valid_acc: 0.487 best_acc: 0.487 \t\n",
      "\n",
      "Epoch 39 train_loss: 1.718 train_f1: 0.221 \t\n",
      "\n",
      "Validation 39 valid_acc: 0.489 best_acc: 0.489 \t\n",
      "\n",
      "Epoch 40 train_loss: 1.695 train_f1: 0.241 \t\n",
      "\n",
      "Validation 40 valid_acc: 0.501 best_acc: 0.501 \t\n",
      "\n",
      "Epoch 41 train_loss: 1.698 train_f1: 0.252 \t\n",
      "\n",
      "Validation 41 valid_acc: 0.500 best_acc: 0.501 \t\n",
      "\n",
      "Epoch 42 train_loss: 1.676 train_f1: 0.265 \t\n",
      "\n",
      "Validation 42 valid_acc: 0.504 best_acc: 0.504 \t\n",
      "\n",
      "Epoch 43 train_loss: 1.669 train_f1: 0.268 \t\n",
      "\n",
      "Validation 43 valid_acc: 0.493 best_acc: 0.504 \t\n",
      "\n",
      "Epoch 44 train_loss: 1.673 train_f1: 0.282 \t\n",
      "\n",
      "Validation 44 valid_acc: 0.500 best_acc: 0.504 \t\n",
      "\n",
      "Epoch 45 train_loss: 1.656 train_f1: 0.292 \t\n",
      "\n",
      "Validation 45 valid_acc: 0.501 best_acc: 0.504 \t\n",
      "\n",
      "Epoch 46 train_loss: 1.645 train_f1: 0.301 \t\n",
      "\n",
      "Validation 46 valid_acc: 0.502 best_acc: 0.504 \t\n",
      "\n",
      "Epoch 47 train_loss: 1.635 train_f1: 0.312 \t\n",
      "\n",
      "Validation 47 valid_acc: 0.499 best_acc: 0.504 \t\n",
      "\n",
      "Epoch 48 train_loss: 1.643 train_f1: 0.311 \t\n",
      "\n",
      "Validation 48 valid_acc: 0.504 best_acc: 0.504 \t\n",
      "\n",
      "Epoch 49 train_loss: 1.639 train_f1: 0.313 \t\n",
      "\n",
      "Validation 49 valid_acc: 0.508 best_acc: 0.508 \t\n",
      "\n",
      "Epoch 50 train_loss: 1.627 train_f1: 0.322 \t\n",
      "\n",
      "Validation 50 valid_acc: 0.513 best_acc: 0.513 \t\n",
      "\n",
      "Epoch 51 train_loss: 1.619 train_f1: 0.328 \t\n",
      "\n",
      "Validation 51 valid_acc: 0.528 best_acc: 0.528 \t\n",
      "\n",
      "Epoch 52 train_loss: 1.612 train_f1: 0.335 \t\n",
      "\n",
      "Validation 52 valid_acc: 0.507 best_acc: 0.528 \t\n",
      "\n",
      "Epoch 53 train_loss: 1.603 train_f1: 0.340 \t\n",
      "\n",
      "Validation 53 valid_acc: 0.514 best_acc: 0.528 \t\n",
      "\n",
      "Epoch 54 train_loss: 1.581 train_f1: 0.346 \t\n",
      "\n",
      "Validation 54 valid_acc: 0.522 best_acc: 0.528 \t\n",
      "\n",
      "Epoch 55 train_loss: 1.602 train_f1: 0.342 \t\n",
      "\n",
      "Validation 55 valid_acc: 0.527 best_acc: 0.528 \t\n",
      "\n",
      "Epoch 56 train_loss: 1.593 train_f1: 0.352 \t\n",
      "\n",
      "Validation 56 valid_acc: 0.517 best_acc: 0.528 \t\n",
      "\n",
      "Epoch 57 train_loss: 1.583 train_f1: 0.345 \t\n",
      "\n",
      "Validation 57 valid_acc: 0.525 best_acc: 0.528 \t\n",
      "\n",
      "Epoch 58 train_loss: 1.564 train_f1: 0.365 \t\n",
      "\n",
      "Validation 58 valid_acc: 0.542 best_acc: 0.542 \t\n",
      "\n",
      "Epoch 59 train_loss: 1.551 train_f1: 0.364 \t\n",
      "\n",
      "Validation 59 valid_acc: 0.533 best_acc: 0.542 \t\n",
      "\n",
      "Epoch 60 train_loss: 1.534 train_f1: 0.373 \t\n",
      "\n",
      "Validation 60 valid_acc: 0.527 best_acc: 0.542 \t\n",
      "\n",
      "Epoch 61 train_loss: 1.551 train_f1: 0.369 \t\n",
      "\n",
      "Validation 61 valid_acc: 0.530 best_acc: 0.542 \t\n",
      "\n",
      "Epoch 62 train_loss: 1.539 train_f1: 0.378 \t\n",
      "\n",
      "Validation 62 valid_acc: 0.538 best_acc: 0.542 \t\n",
      "\n",
      "Epoch 63 train_loss: 1.542 train_f1: 0.378 \t\n",
      "\n",
      "Validation 63 valid_acc: 0.526 best_acc: 0.542 \t\n",
      "\n",
      "Epoch 64 train_loss: 1.541 train_f1: 0.371 \t\n",
      "\n",
      "Validation 64 valid_acc: 0.526 best_acc: 0.542 \t\n",
      "\n",
      "Epoch 65 train_loss: 1.540 train_f1: 0.372 \t\n",
      "\n",
      "Validation 65 valid_acc: 0.538 best_acc: 0.542 \t\n",
      "\n",
      "Epoch 66 train_loss: 1.527 train_f1: 0.382 \t\n",
      "\n",
      "Validation 66 valid_acc: 0.530 best_acc: 0.542 \t\n",
      "\n",
      "Epoch 67 train_loss: 1.526 train_f1: 0.379 \t\n",
      "\n",
      "Validation 67 valid_acc: 0.539 best_acc: 0.542 \t\n",
      "\n",
      "Epoch 68 train_loss: 1.523 train_f1: 0.380 \t\n",
      "\n",
      "Validation 68 valid_acc: 0.547 best_acc: 0.547 \t\n",
      "\n",
      "Epoch 69 train_loss: 1.501 train_f1: 0.389 \t\n",
      "\n",
      "Validation 69 valid_acc: 0.547 best_acc: 0.547 \t\n",
      "\n",
      "Epoch 70 train_loss: 1.507 train_f1: 0.388 \t\n",
      "\n",
      "Validation 70 valid_acc: 0.554 best_acc: 0.554 \t\n",
      "\n",
      "Epoch 71 train_loss: 1.504 train_f1: 0.390 \t\n",
      "\n",
      "Validation 71 valid_acc: 0.550 best_acc: 0.554 \t\n",
      "\n",
      "Epoch 72 train_loss: 1.500 train_f1: 0.391 \t\n",
      "\n",
      "Validation 72 valid_acc: 0.562 best_acc: 0.562 \t\n",
      "\n",
      "Epoch 73 train_loss: 1.501 train_f1: 0.387 \t\n",
      "\n",
      "Validation 73 valid_acc: 0.554 best_acc: 0.562 \t\n",
      "\n",
      "Epoch 74 train_loss: 1.499 train_f1: 0.392 \t\n",
      "\n",
      "Validation 74 valid_acc: 0.555 best_acc: 0.562 \t\n",
      "\n",
      "Epoch 75 train_loss: 1.490 train_f1: 0.393 \t\n",
      "\n",
      "Validation 75 valid_acc: 0.553 best_acc: 0.562 \t\n",
      "\n",
      "Epoch 76 train_loss: 1.479 train_f1: 0.400 \t\n",
      "\n",
      "Validation 76 valid_acc: 0.543 best_acc: 0.562 \t\n",
      "\n",
      "Epoch 77 train_loss: 1.472 train_f1: 0.400 \t\n",
      "\n",
      "Validation 77 valid_acc: 0.565 best_acc: 0.565 \t\n",
      "\n",
      "Epoch 78 train_loss: 1.472 train_f1: 0.399 \t\n",
      "\n",
      "Validation 78 valid_acc: 0.573 best_acc: 0.573 \t\n",
      "\n",
      "Epoch 79 train_loss: 1.486 train_f1: 0.400 \t\n",
      "\n",
      "Validation 79 valid_acc: 0.559 best_acc: 0.573 \t\n",
      "\n",
      "Epoch 80 train_loss: 1.470 train_f1: 0.403 \t\n",
      "\n",
      "Validation 80 valid_acc: 0.568 best_acc: 0.573 \t\n",
      "\n",
      "Epoch 81 train_loss: 1.458 train_f1: 0.406 \t\n",
      "\n",
      "Validation 81 valid_acc: 0.570 best_acc: 0.573 \t\n",
      "\n",
      "Epoch 82 train_loss: 1.458 train_f1: 0.407 \t\n",
      "\n",
      "Validation 82 valid_acc: 0.577 best_acc: 0.577 \t\n",
      "\n",
      "Epoch 83 train_loss: 1.439 train_f1: 0.413 \t\n",
      "\n",
      "Validation 83 valid_acc: 0.587 best_acc: 0.587 \t\n",
      "\n",
      "Epoch 84 train_loss: 1.450 train_f1: 0.413 \t\n",
      "\n",
      "Validation 84 valid_acc: 0.581 best_acc: 0.587 \t\n",
      "\n",
      "Epoch 85 train_loss: 1.430 train_f1: 0.418 \t\n",
      "\n",
      "Validation 85 valid_acc: 0.587 best_acc: 0.587 \t\n",
      "\n",
      "Epoch 86 train_loss: 1.436 train_f1: 0.416 \t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation 86 valid_acc: 0.571 best_acc: 0.587 \t\n",
      "\n",
      "Epoch 87 train_loss: 1.417 train_f1: 0.423 \t\n",
      "\n",
      "Validation 87 valid_acc: 0.575 best_acc: 0.587 \t\n",
      "\n",
      "Epoch 88 train_loss: 1.427 train_f1: 0.418 \t\n",
      "\n",
      "Validation 88 valid_acc: 0.581 best_acc: 0.587 \t\n",
      "\n",
      "Epoch 89 train_loss: 1.424 train_f1: 0.425 \t\n",
      "\n",
      "Validation 89 valid_acc: 0.594 best_acc: 0.594 \t\n",
      "\n",
      "Epoch 90 train_loss: 1.419 train_f1: 0.425 \t\n",
      "\n",
      "Validation 90 valid_acc: 0.590 best_acc: 0.594 \t\n",
      "\n",
      "Epoch 91 train_loss: 1.395 train_f1: 0.431 \t\n",
      "\n",
      "Validation 91 valid_acc: 0.588 best_acc: 0.594 \t\n",
      "\n",
      "Epoch 92 train_loss: 1.404 train_f1: 0.434 \t\n",
      "\n",
      "Validation 92 valid_acc: 0.590 best_acc: 0.594 \t\n",
      "\n",
      "Epoch 93 train_loss: 1.394 train_f1: 0.439 \t\n",
      "\n",
      "Validation 93 valid_acc: 0.607 best_acc: 0.607 \t\n",
      "\n",
      "Epoch 94 train_loss: 1.388 train_f1: 0.446 \t\n",
      "\n",
      "Validation 94 valid_acc: 0.601 best_acc: 0.607 \t\n",
      "\n",
      "Epoch 95 train_loss: 1.389 train_f1: 0.436 \t\n",
      "\n",
      "Validation 95 valid_acc: 0.597 best_acc: 0.607 \t\n",
      "\n",
      "Epoch 96 train_loss: 1.378 train_f1: 0.445 \t\n",
      "\n",
      "Validation 96 valid_acc: 0.606 best_acc: 0.607 \t\n",
      "\n",
      "Epoch 97 train_loss: 1.365 train_f1: 0.448 \t\n",
      "\n",
      "Validation 97 valid_acc: 0.605 best_acc: 0.607 \t\n",
      "\n",
      "Epoch 98 train_loss: 1.374 train_f1: 0.452 \t\n",
      "\n",
      "Validation 98 valid_acc: 0.584 best_acc: 0.607 \t\n",
      "\n",
      "Epoch 99 train_loss: 1.364 train_f1: 0.450 \t\n",
      "\n",
      "Validation 99 valid_acc: 0.597 best_acc: 0.607 \t\n",
      "\n",
      "Epoch 100 train_loss: 1.357 train_f1: 0.453 \t\n",
      "\n",
      "Validation 100 valid_acc: 0.599 best_acc: 0.607 \t\n",
      "\n",
      "Epoch 101 train_loss: 1.349 train_f1: 0.460 \t\n",
      "\n",
      "Validation 101 valid_acc: 0.611 best_acc: 0.611 \t\n",
      "\n",
      "Epoch 102 train_loss: 1.355 train_f1: 0.456 \t\n",
      "\n",
      "Validation 102 valid_acc: 0.600 best_acc: 0.611 \t\n",
      "\n",
      "Epoch 103 train_loss: 1.350 train_f1: 0.462 \t\n",
      "\n",
      "Validation 103 valid_acc: 0.600 best_acc: 0.611 \t\n",
      "\n",
      "Epoch 104 train_loss: 1.342 train_f1: 0.467 \t\n",
      "\n",
      "Validation 104 valid_acc: 0.593 best_acc: 0.611 \t\n",
      "\n",
      "Epoch 105 train_loss: 1.323 train_f1: 0.473 \t\n",
      "\n",
      "Validation 105 valid_acc: 0.603 best_acc: 0.611 \t\n",
      "\n",
      "Epoch 106 train_loss: 1.323 train_f1: 0.476 \t\n",
      "\n",
      "Validation 106 valid_acc: 0.601 best_acc: 0.611 \t\n",
      "\n",
      "Epoch 107 train_loss: 1.323 train_f1: 0.478 \t\n",
      "\n",
      "Validation 107 valid_acc: 0.618 best_acc: 0.618 \t\n",
      "\n",
      "Epoch 108 train_loss: 1.331 train_f1: 0.480 \t\n",
      "\n",
      "Validation 108 valid_acc: 0.602 best_acc: 0.618 \t\n",
      "\n",
      "Epoch 109 train_loss: 1.310 train_f1: 0.484 \t\n",
      "\n",
      "Validation 109 valid_acc: 0.599 best_acc: 0.618 \t\n",
      "\n",
      "Epoch 110 train_loss: 1.307 train_f1: 0.484 \t\n",
      "\n",
      "Validation 110 valid_acc: 0.623 best_acc: 0.623 \t\n",
      "\n",
      "Epoch 111 train_loss: 1.297 train_f1: 0.490 \t\n",
      "\n",
      "Validation 111 valid_acc: 0.608 best_acc: 0.623 \t\n",
      "\n",
      "Epoch 112 train_loss: 1.286 train_f1: 0.489 \t\n",
      "\n",
      "Validation 112 valid_acc: 0.615 best_acc: 0.623 \t\n",
      "\n",
      "Epoch 113 train_loss: 1.280 train_f1: 0.496 \t\n",
      "\n",
      "Validation 113 valid_acc: 0.611 best_acc: 0.623 \t\n",
      "\n",
      "Epoch 114 train_loss: 1.289 train_f1: 0.493 \t\n",
      "\n",
      "Validation 114 valid_acc: 0.618 best_acc: 0.623 \t\n",
      "\n",
      "Epoch 115 train_loss: 1.268 train_f1: 0.501 \t\n",
      "\n",
      "Validation 115 valid_acc: 0.623 best_acc: 0.623 \t\n",
      "\n",
      "Epoch 116 train_loss: 1.274 train_f1: 0.502 \t\n",
      "\n",
      "Validation 116 valid_acc: 0.621 best_acc: 0.623 \t\n",
      "\n",
      "Epoch 117 train_loss: 1.267 train_f1: 0.503 \t\n",
      "\n",
      "Validation 117 valid_acc: 0.631 best_acc: 0.631 \t\n",
      "\n",
      "Epoch 118 train_loss: 1.272 train_f1: 0.500 \t\n",
      "\n",
      "Validation 118 valid_acc: 0.636 best_acc: 0.636 \t\n",
      "\n",
      "Epoch 119 train_loss: 1.265 train_f1: 0.506 \t\n",
      "\n",
      "Validation 119 valid_acc: 0.636 best_acc: 0.636 \t\n",
      "\n",
      "Epoch 120 train_loss: 1.262 train_f1: 0.505 \t\n",
      "\n",
      "Validation 120 valid_acc: 0.620 best_acc: 0.636 \t\n",
      "\n",
      "Epoch 121 train_loss: 1.249 train_f1: 0.519 \t\n",
      "\n",
      "Validation 121 valid_acc: 0.637 best_acc: 0.637 \t\n",
      "\n",
      "Epoch 122 train_loss: 1.256 train_f1: 0.517 \t\n",
      "\n",
      "Validation 122 valid_acc: 0.637 best_acc: 0.637 \t\n",
      "\n",
      "Epoch 123 train_loss: 1.239 train_f1: 0.523 \t\n",
      "\n",
      "Validation 123 valid_acc: 0.626 best_acc: 0.637 \t\n",
      "\n",
      "Epoch 124 train_loss: 1.227 train_f1: 0.535 \t\n",
      "\n",
      "Validation 124 valid_acc: 0.630 best_acc: 0.637 \t\n",
      "\n",
      "Epoch 125 train_loss: 1.247 train_f1: 0.529 \t\n",
      "\n",
      "Validation 125 valid_acc: 0.625 best_acc: 0.637 \t\n",
      "\n",
      "Epoch 126 train_loss: 1.221 train_f1: 0.532 \t\n",
      "\n",
      "Validation 126 valid_acc: 0.632 best_acc: 0.637 \t\n",
      "\n",
      "Epoch 127 train_loss: 1.204 train_f1: 0.540 \t\n",
      "\n",
      "Validation 127 valid_acc: 0.621 best_acc: 0.637 \t\n",
      "\n",
      "Epoch 128 train_loss: 1.196 train_f1: 0.544 \t\n",
      "\n",
      "Validation 128 valid_acc: 0.640 best_acc: 0.640 \t\n",
      "\n",
      "Epoch 129 train_loss: 1.188 train_f1: 0.547 \t\n",
      "\n",
      "Validation 129 valid_acc: 0.618 best_acc: 0.640 \t\n",
      "\n",
      "Epoch 130 train_loss: 1.199 train_f1: 0.549 \t\n",
      "\n",
      "Validation 130 valid_acc: 0.643 best_acc: 0.643 \t\n",
      "\n",
      "Epoch 131 train_loss: 1.186 train_f1: 0.552 \t\n",
      "\n",
      "Validation 131 valid_acc: 0.639 best_acc: 0.643 \t\n",
      "\n",
      "Epoch 132 train_loss: 1.188 train_f1: 0.554 \t\n",
      "\n",
      "Validation 132 valid_acc: 0.658 best_acc: 0.658 \t\n",
      "\n",
      "Epoch 133 train_loss: 1.172 train_f1: 0.558 \t\n",
      "\n",
      "Validation 133 valid_acc: 0.651 best_acc: 0.658 \t\n",
      "\n",
      "Epoch 134 train_loss: 1.169 train_f1: 0.562 \t\n",
      "\n",
      "Validation 134 valid_acc: 0.647 best_acc: 0.658 \t\n",
      "\n",
      "Epoch 135 train_loss: 1.162 train_f1: 0.569 \t\n",
      "\n",
      "Validation 135 valid_acc: 0.644 best_acc: 0.658 \t\n",
      "\n",
      "Epoch 136 train_loss: 1.174 train_f1: 0.565 \t\n",
      "\n",
      "Validation 136 valid_acc: 0.642 best_acc: 0.658 \t\n",
      "\n",
      "Epoch 137 train_loss: 1.158 train_f1: 0.566 \t\n",
      "\n",
      "Validation 137 valid_acc: 0.661 best_acc: 0.661 \t\n",
      "\n",
      "Epoch 138 train_loss: 1.157 train_f1: 0.571 \t\n",
      "\n",
      "Validation 138 valid_acc: 0.663 best_acc: 0.663 \t\n",
      "\n",
      "Epoch 139 train_loss: 1.153 train_f1: 0.573 \t\n",
      "\n",
      "Validation 139 valid_acc: 0.671 best_acc: 0.671 \t\n",
      "\n",
      "Epoch 140 train_loss: 1.143 train_f1: 0.577 \t\n",
      "\n",
      "Validation 140 valid_acc: 0.666 best_acc: 0.671 \t\n",
      "\n",
      "Epoch 141 train_loss: 1.147 train_f1: 0.572 \t\n",
      "\n",
      "Validation 141 valid_acc: 0.654 best_acc: 0.671 \t\n",
      "\n",
      "Epoch 142 train_loss: 1.132 train_f1: 0.584 \t\n",
      "\n",
      "Validation 142 valid_acc: 0.669 best_acc: 0.671 \t\n",
      "\n",
      "Epoch 143 train_loss: 1.120 train_f1: 0.587 \t\n",
      "\n",
      "Validation 143 valid_acc: 0.654 best_acc: 0.671 \t\n",
      "\n",
      "Epoch 144 train_loss: 1.117 train_f1: 0.589 \t\n",
      "\n",
      "Validation 144 valid_acc: 0.661 best_acc: 0.671 \t\n",
      "\n",
      "Epoch 145 train_loss: 1.119 train_f1: 0.589 \t\n",
      "\n",
      "Validation 145 valid_acc: 0.668 best_acc: 0.671 \t\n",
      "\n",
      "Epoch 146 train_loss: 1.112 train_f1: 0.590 \t\n",
      "\n",
      "Validation 146 valid_acc: 0.669 best_acc: 0.671 \t\n",
      "\n",
      "Epoch 147 train_loss: 1.110 train_f1: 0.594 \t\n",
      "\n",
      "Validation 147 valid_acc: 0.672 best_acc: 0.672 \t\n",
      "\n",
      "Epoch 148 train_loss: 1.100 train_f1: 0.596 \t\n",
      "\n",
      "Validation 148 valid_acc: 0.656 best_acc: 0.672 \t\n",
      "\n",
      "Epoch 149 train_loss: 1.102 train_f1: 0.597 \t\n",
      "\n",
      "Validation 149 valid_acc: 0.672 best_acc: 0.672 \t\n",
      "\n",
      "Epoch 150 train_loss: 1.093 train_f1: 0.600 \t\n",
      "\n",
      "Validation 150 valid_acc: 0.682 best_acc: 0.682 \t\n",
      "\n",
      "Epoch 151 train_loss: 1.089 train_f1: 0.602 \t\n",
      "\n",
      "Validation 151 valid_acc: 0.681 best_acc: 0.682 \t\n",
      "\n",
      "Epoch 152 train_loss: 1.088 train_f1: 0.600 \t\n",
      "\n",
      "Validation 152 valid_acc: 0.672 best_acc: 0.682 \t\n",
      "\n",
      "Epoch 153 train_loss: 1.080 train_f1: 0.605 \t\n",
      "\n",
      "Validation 153 valid_acc: 0.675 best_acc: 0.682 \t\n",
      "\n",
      "Epoch 154 train_loss: 1.069 train_f1: 0.611 \t\n",
      "\n",
      "Validation 154 valid_acc: 0.667 best_acc: 0.682 \t\n",
      "\n",
      "Epoch 155 train_loss: 1.067 train_f1: 0.611 \t\n",
      "\n",
      "Validation 155 valid_acc: 0.689 best_acc: 0.689 \t\n",
      "\n",
      "Epoch 156 train_loss: 1.064 train_f1: 0.611 \t\n",
      "\n",
      "Validation 156 valid_acc: 0.691 best_acc: 0.691 \t\n",
      "\n",
      "Epoch 157 train_loss: 1.061 train_f1: 0.612 \t\n",
      "\n",
      "Validation 157 valid_acc: 0.686 best_acc: 0.691 \t\n",
      "\n",
      "Epoch 158 train_loss: 1.052 train_f1: 0.614 \t\n",
      "\n",
      "Validation 158 valid_acc: 0.688 best_acc: 0.691 \t\n",
      "\n",
      "Epoch 159 train_loss: 1.057 train_f1: 0.615 \t\n",
      "\n",
      "Validation 159 valid_acc: 0.672 best_acc: 0.691 \t\n",
      "\n",
      "Epoch 160 train_loss: 1.041 train_f1: 0.620 \t\n",
      "\n",
      "Validation 160 valid_acc: 0.678 best_acc: 0.691 \t\n",
      "\n",
      "Epoch 161 train_loss: 1.035 train_f1: 0.627 \t\n",
      "\n",
      "Validation 161 valid_acc: 0.690 best_acc: 0.691 \t\n",
      "\n",
      "Epoch 162 train_loss: 1.022 train_f1: 0.635 \t\n",
      "\n",
      "Validation 162 valid_acc: 0.690 best_acc: 0.691 \t\n",
      "\n",
      "Epoch 163 train_loss: 1.038 train_f1: 0.632 \t\n",
      "\n",
      "Validation 163 valid_acc: 0.693 best_acc: 0.693 \t\n",
      "\n",
      "Epoch 164 train_loss: 1.029 train_f1: 0.629 \t\n",
      "\n",
      "Validation 164 valid_acc: 0.689 best_acc: 0.693 \t\n",
      "\n",
      "Epoch 165 train_loss: 1.034 train_f1: 0.628 \t\n",
      "\n",
      "Validation 165 valid_acc: 0.686 best_acc: 0.693 \t\n",
      "\n",
      "Epoch 166 train_loss: 0.999 train_f1: 0.631 \t\n",
      "\n",
      "Validation 166 valid_acc: 0.684 best_acc: 0.693 \t\n",
      "\n",
      "Epoch 167 train_loss: 1.016 train_f1: 0.639 \t\n",
      "\n",
      "Validation 167 valid_acc: 0.703 best_acc: 0.703 \t\n",
      "\n",
      "Epoch 168 train_loss: 0.986 train_f1: 0.641 \t\n",
      "\n",
      "Validation 168 valid_acc: 0.692 best_acc: 0.703 \t\n",
      "\n",
      "Epoch 169 train_loss: 0.990 train_f1: 0.642 \t\n",
      "\n",
      "Validation 169 valid_acc: 0.694 best_acc: 0.703 \t\n",
      "\n",
      "Epoch 170 train_loss: 0.981 train_f1: 0.647 \t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation 170 valid_acc: 0.697 best_acc: 0.703 \t\n",
      "\n",
      "Epoch 171 train_loss: 1.000 train_f1: 0.646 \t\n",
      "\n",
      "Validation 171 valid_acc: 0.683 best_acc: 0.703 \t\n",
      "\n",
      "Epoch 172 train_loss: 0.986 train_f1: 0.646 \t\n",
      "\n",
      "Validation 172 valid_acc: 0.686 best_acc: 0.703 \t\n",
      "\n",
      "Epoch 173 train_loss: 0.975 train_f1: 0.645 \t\n",
      "\n",
      "Validation 173 valid_acc: 0.697 best_acc: 0.703 \t\n",
      "\n",
      "Epoch 174 train_loss: 0.975 train_f1: 0.655 \t\n",
      "\n",
      "Validation 174 valid_acc: 0.697 best_acc: 0.703 \t\n",
      "\n",
      "Epoch 175 train_loss: 0.951 train_f1: 0.661 \t\n",
      "\n",
      "Validation 175 valid_acc: 0.698 best_acc: 0.703 \t\n",
      "\n",
      "Epoch 176 train_loss: 0.952 train_f1: 0.658 \t\n",
      "\n",
      "Validation 176 valid_acc: 0.705 best_acc: 0.705 \t\n",
      "\n",
      "Epoch 177 train_loss: 0.957 train_f1: 0.658 \t\n",
      "\n",
      "Validation 177 valid_acc: 0.705 best_acc: 0.705 \t\n",
      "\n",
      "Epoch 178 train_loss: 0.958 train_f1: 0.657 \t\n",
      "\n",
      "Validation 178 valid_acc: 0.699 best_acc: 0.705 \t\n",
      "\n",
      "Epoch 179 train_loss: 0.936 train_f1: 0.668 \t\n",
      "\n",
      "Validation 179 valid_acc: 0.705 best_acc: 0.705 \t\n",
      "\n",
      "Epoch 180 train_loss: 0.948 train_f1: 0.665 \t\n",
      "\n",
      "Validation 180 valid_acc: 0.697 best_acc: 0.705 \t\n",
      "\n",
      "Epoch 181 train_loss: 0.947 train_f1: 0.669 \t\n",
      "\n",
      "Validation 181 valid_acc: 0.693 best_acc: 0.705 \t\n",
      "\n",
      "Epoch 182 train_loss: 0.932 train_f1: 0.674 \t\n",
      "\n",
      "Validation 182 valid_acc: 0.694 best_acc: 0.705 \t\n",
      "\n",
      "Epoch 183 train_loss: 0.934 train_f1: 0.671 \t\n",
      "\n",
      "Validation 183 valid_acc: 0.710 best_acc: 0.710 \t\n",
      "\n",
      "Epoch 184 train_loss: 0.924 train_f1: 0.670 \t\n",
      "\n",
      "Validation 184 valid_acc: 0.704 best_acc: 0.710 \t\n",
      "\n",
      "Epoch 185 train_loss: 0.920 train_f1: 0.679 \t\n",
      "\n",
      "Validation 185 valid_acc: 0.698 best_acc: 0.710 \t\n",
      "\n",
      "Epoch 186 train_loss: 0.914 train_f1: 0.681 \t\n",
      "\n",
      "Validation 186 valid_acc: 0.697 best_acc: 0.710 \t\n",
      "\n",
      "Epoch 187 train_loss: 0.913 train_f1: 0.682 \t\n",
      "\n",
      "Validation 187 valid_acc: 0.692 best_acc: 0.710 \t\n",
      "\n",
      "Epoch 188 train_loss: 0.920 train_f1: 0.679 \t\n",
      "\n",
      "Validation 188 valid_acc: 0.709 best_acc: 0.710 \t\n",
      "\n",
      "Epoch 189 train_loss: 0.907 train_f1: 0.687 \t\n",
      "\n",
      "Validation 189 valid_acc: 0.708 best_acc: 0.710 \t\n",
      "\n",
      "Epoch 190 train_loss: 0.904 train_f1: 0.685 \t\n",
      "\n",
      "Validation 190 valid_acc: 0.713 best_acc: 0.713 \t\n",
      "\n",
      "Epoch 191 train_loss: 0.883 train_f1: 0.696 \t\n",
      "\n",
      "Validation 191 valid_acc: 0.703 best_acc: 0.713 \t\n",
      "\n",
      "Epoch 192 train_loss: 0.895 train_f1: 0.692 \t\n",
      "\n",
      "Validation 192 valid_acc: 0.708 best_acc: 0.713 \t\n",
      "\n",
      "Epoch 193 train_loss: 0.878 train_f1: 0.699 \t\n",
      "\n",
      "Validation 193 valid_acc: 0.719 best_acc: 0.719 \t\n",
      "\n",
      "Epoch 194 train_loss: 0.883 train_f1: 0.698 \t\n",
      "\n",
      "Validation 194 valid_acc: 0.714 best_acc: 0.719 \t\n",
      "\n",
      "Epoch 195 train_loss: 0.871 train_f1: 0.701 \t\n",
      "\n",
      "Validation 195 valid_acc: 0.712 best_acc: 0.719 \t\n",
      "\n",
      "Epoch 196 train_loss: 0.871 train_f1: 0.703 \t\n",
      "\n",
      "Validation 196 valid_acc: 0.706 best_acc: 0.719 \t\n",
      "\n",
      "Epoch 197 train_loss: 0.858 train_f1: 0.709 \t\n",
      "\n",
      "Validation 197 valid_acc: 0.726 best_acc: 0.726 \t\n",
      "\n",
      "Epoch 198 train_loss: 0.861 train_f1: 0.709 \t\n",
      "\n",
      "Validation 198 valid_acc: 0.717 best_acc: 0.726 \t\n",
      "\n",
      "Epoch 199 train_loss: 0.855 train_f1: 0.715 \t\n",
      "\n",
      "Validation 199 valid_acc: 0.729 best_acc: 0.729 \t\n",
      "\n",
      "Epoch 200 train_loss: 0.856 train_f1: 0.711 \t\n",
      "\n",
      "Validation 200 valid_acc: 0.730 best_acc: 0.730 \t\n",
      "\n",
      "Epoch 201 train_loss: 0.850 train_f1: 0.713 \t\n",
      "\n",
      "Validation 201 valid_acc: 0.729 best_acc: 0.730 \t\n",
      "\n",
      "Epoch 202 train_loss: 0.852 train_f1: 0.708 \t\n",
      "\n",
      "Validation 202 valid_acc: 0.718 best_acc: 0.730 \t\n",
      "\n",
      "Epoch 203 train_loss: 0.845 train_f1: 0.713 \t\n",
      "\n",
      "Validation 203 valid_acc: 0.721 best_acc: 0.730 \t\n",
      "\n",
      "Epoch 204 train_loss: 0.849 train_f1: 0.708 \t\n",
      "\n",
      "Validation 204 valid_acc: 0.718 best_acc: 0.730 \t\n",
      "\n",
      "Epoch 205 train_loss: 0.827 train_f1: 0.718 \t\n",
      "\n",
      "Validation 205 valid_acc: 0.715 best_acc: 0.730 \t\n",
      "\n",
      "Epoch 206 train_loss: 0.825 train_f1: 0.720 \t\n",
      "\n",
      "Validation 206 valid_acc: 0.718 best_acc: 0.730 \t\n",
      "\n",
      "Epoch 207 train_loss: 0.825 train_f1: 0.722 \t\n",
      "\n",
      "Validation 207 valid_acc: 0.722 best_acc: 0.730 \t\n",
      "\n",
      "Epoch 208 train_loss: 0.823 train_f1: 0.725 \t\n",
      "\n",
      "Validation 208 valid_acc: 0.726 best_acc: 0.730 \t\n",
      "\n",
      "Epoch 209 train_loss: 0.808 train_f1: 0.727 \t\n",
      "\n",
      "Validation 209 valid_acc: 0.732 best_acc: 0.732 \t\n",
      "\n",
      "Epoch 210 train_loss: 0.815 train_f1: 0.727 \t\n",
      "\n",
      "Validation 210 valid_acc: 0.719 best_acc: 0.732 \t\n",
      "\n",
      "Epoch 211 train_loss: 0.814 train_f1: 0.724 \t\n",
      "\n",
      "Validation 211 valid_acc: 0.726 best_acc: 0.732 \t\n",
      "\n",
      "Epoch 212 train_loss: 0.807 train_f1: 0.720 \t\n",
      "\n",
      "Validation 212 valid_acc: 0.738 best_acc: 0.738 \t\n",
      "\n",
      "Epoch 213 train_loss: 0.816 train_f1: 0.725 \t\n",
      "\n",
      "Validation 213 valid_acc: 0.735 best_acc: 0.738 \t\n",
      "\n",
      "Epoch 214 train_loss: 0.787 train_f1: 0.735 \t\n",
      "\n",
      "Validation 214 valid_acc: 0.743 best_acc: 0.743 \t\n",
      "\n",
      "Epoch 215 train_loss: 0.791 train_f1: 0.732 \t\n",
      "\n",
      "Validation 215 valid_acc: 0.747 best_acc: 0.747 \t\n",
      "\n",
      "Epoch 216 train_loss: 0.783 train_f1: 0.736 \t\n",
      "\n",
      "Validation 216 valid_acc: 0.742 best_acc: 0.747 \t\n",
      "\n",
      "Epoch 217 train_loss: 0.788 train_f1: 0.730 \t\n",
      "\n",
      "Validation 217 valid_acc: 0.736 best_acc: 0.747 \t\n",
      "\n",
      "Epoch 218 train_loss: 0.780 train_f1: 0.736 \t\n",
      "\n",
      "Validation 218 valid_acc: 0.731 best_acc: 0.747 \t\n",
      "\n",
      "Epoch 219 train_loss: 0.787 train_f1: 0.732 \t\n",
      "\n",
      "Validation 219 valid_acc: 0.727 best_acc: 0.747 \t\n",
      "\n",
      "Epoch 220 train_loss: 0.783 train_f1: 0.739 \t\n",
      "\n",
      "Validation 220 valid_acc: 0.737 best_acc: 0.747 \t\n",
      "\n",
      "Epoch 221 train_loss: 0.768 train_f1: 0.739 \t\n",
      "\n",
      "Validation 221 valid_acc: 0.730 best_acc: 0.747 \t\n",
      "\n",
      "Epoch 222 train_loss: 0.773 train_f1: 0.738 \t\n",
      "\n",
      "Validation 222 valid_acc: 0.732 best_acc: 0.747 \t\n",
      "\n",
      "Epoch 223 train_loss: 0.766 train_f1: 0.744 \t\n",
      "\n",
      "Validation 223 valid_acc: 0.741 best_acc: 0.747 \t\n",
      "\n",
      "Epoch 224 train_loss: 0.754 train_f1: 0.746 \t\n",
      "\n",
      "Validation 224 valid_acc: 0.741 best_acc: 0.747 \t\n",
      "\n",
      "Epoch 225 train_loss: 0.778 train_f1: 0.737 \t\n",
      "\n",
      "Validation 225 valid_acc: 0.736 best_acc: 0.747 \t\n",
      "\n",
      "Epoch 226 train_loss: 0.771 train_f1: 0.743 \t\n",
      "\n",
      "Validation 226 valid_acc: 0.731 best_acc: 0.747 \t\n",
      "\n",
      "Epoch 227 train_loss: 0.764 train_f1: 0.746 \t\n",
      "\n",
      "Validation 227 valid_acc: 0.747 best_acc: 0.747 \t\n",
      "\n",
      "Epoch 228 train_loss: 0.762 train_f1: 0.742 \t\n",
      "\n",
      "Validation 228 valid_acc: 0.744 best_acc: 0.747 \t\n",
      "\n",
      "Epoch 229 train_loss: 0.758 train_f1: 0.744 \t\n",
      "\n",
      "Validation 229 valid_acc: 0.741 best_acc: 0.747 \t\n",
      "\n",
      "Epoch 230 train_loss: 0.752 train_f1: 0.749 \t\n",
      "\n",
      "Validation 230 valid_acc: 0.743 best_acc: 0.747 \t\n",
      "\n",
      "Epoch 231 train_loss: 0.725 train_f1: 0.754 \t\n",
      "\n",
      "Validation 231 valid_acc: 0.754 best_acc: 0.754 \t\n",
      "\n",
      "Epoch 232 train_loss: 0.743 train_f1: 0.749 \t\n",
      "\n",
      "Validation 232 valid_acc: 0.737 best_acc: 0.754 \t\n",
      "\n",
      "Epoch 233 train_loss: 0.732 train_f1: 0.756 \t\n",
      "\n",
      "Validation 233 valid_acc: 0.750 best_acc: 0.754 \t\n",
      "\n",
      "Epoch 234 train_loss: 0.752 train_f1: 0.748 \t\n",
      "\n",
      "Validation 234 valid_acc: 0.750 best_acc: 0.754 \t\n",
      "\n",
      "Epoch 235 train_loss: 0.750 train_f1: 0.749 \t\n",
      "\n",
      "Validation 235 valid_acc: 0.738 best_acc: 0.754 \t\n",
      "\n",
      "Epoch 236 train_loss: 0.736 train_f1: 0.750 \t\n",
      "\n",
      "Validation 236 valid_acc: 0.747 best_acc: 0.754 \t\n",
      "\n",
      "Epoch 237 train_loss: 0.731 train_f1: 0.753 \t\n",
      "\n",
      "Validation 237 valid_acc: 0.748 best_acc: 0.754 \t\n",
      "\n",
      "Epoch 238 train_loss: 0.714 train_f1: 0.759 \t\n",
      "\n",
      "Validation 238 valid_acc: 0.747 best_acc: 0.754 \t\n",
      "\n",
      "Epoch 239 train_loss: 0.724 train_f1: 0.747 \t\n",
      "\n",
      "Validation 239 valid_acc: 0.740 best_acc: 0.754 \t\n",
      "\n",
      "Epoch 240 train_loss: 0.711 train_f1: 0.762 \t\n",
      "\n",
      "Validation 240 valid_acc: 0.750 best_acc: 0.754 \t\n",
      "\n",
      "Epoch 241 train_loss: 0.717 train_f1: 0.756 \t\n",
      "\n",
      "Validation 241 valid_acc: 0.747 best_acc: 0.754 \t\n",
      "\n",
      "Epoch 242 train_loss: 0.697 train_f1: 0.762 \t\n",
      "\n",
      "Validation 242 valid_acc: 0.748 best_acc: 0.754 \t\n",
      "\n",
      "Epoch 243 train_loss: 0.702 train_f1: 0.764 \t\n",
      "\n",
      "Validation 243 valid_acc: 0.757 best_acc: 0.757 \t\n",
      "\n",
      "Epoch 244 train_loss: 0.682 train_f1: 0.768 \t\n",
      "\n",
      "Validation 244 valid_acc: 0.760 best_acc: 0.760 \t\n",
      "\n",
      "Epoch 245 train_loss: 0.705 train_f1: 0.761 \t\n",
      "\n",
      "Validation 245 valid_acc: 0.755 best_acc: 0.760 \t\n",
      "\n",
      "Epoch 246 train_loss: 0.714 train_f1: 0.764 \t\n",
      "\n",
      "Validation 246 valid_acc: 0.750 best_acc: 0.760 \t\n",
      "\n",
      "Epoch 247 train_loss: 0.701 train_f1: 0.765 \t\n",
      "\n",
      "Validation 247 valid_acc: 0.757 best_acc: 0.760 \t\n",
      "\n",
      "Epoch 248 train_loss: 0.682 train_f1: 0.764 \t\n",
      "\n",
      "Validation 248 valid_acc: 0.748 best_acc: 0.760 \t\n",
      "\n",
      "Epoch 249 train_loss: 0.685 train_f1: 0.767 \t\n",
      "\n",
      "Validation 249 valid_acc: 0.751 best_acc: 0.760 \t\n",
      "\n",
      "Epoch 250 train_loss: 0.691 train_f1: 0.766 \t\n",
      "\n",
      "Validation 250 valid_acc: 0.744 best_acc: 0.760 \t\n",
      "\n",
      "Epoch 251 train_loss: 0.665 train_f1: 0.775 \t\n",
      "\n",
      "Validation 251 valid_acc: 0.740 best_acc: 0.760 \t\n",
      "\n",
      "Epoch 252 train_loss: 0.679 train_f1: 0.771 \t\n",
      "\n",
      "Validation 252 valid_acc: 0.754 best_acc: 0.760 \t\n",
      "\n",
      "Epoch 253 train_loss: 0.683 train_f1: 0.771 \t\n",
      "\n",
      "Validation 253 valid_acc: 0.754 best_acc: 0.760 \t\n",
      "\n",
      "Epoch 254 train_loss: 0.670 train_f1: 0.777 \t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation 254 valid_acc: 0.745 best_acc: 0.760 \t\n",
      "\n",
      "Epoch 255 train_loss: 0.666 train_f1: 0.777 \t\n",
      "\n",
      "Validation 255 valid_acc: 0.762 best_acc: 0.762 \t\n",
      "\n",
      "Epoch 256 train_loss: 0.681 train_f1: 0.777 \t\n",
      "\n",
      "Validation 256 valid_acc: 0.751 best_acc: 0.762 \t\n",
      "\n",
      "Epoch 257 train_loss: 0.652 train_f1: 0.781 \t\n",
      "\n",
      "Validation 257 valid_acc: 0.753 best_acc: 0.762 \t\n",
      "\n",
      "Epoch 258 train_loss: 0.663 train_f1: 0.781 \t\n",
      "\n",
      "Validation 258 valid_acc: 0.762 best_acc: 0.762 \t\n",
      "\n",
      "Epoch 259 train_loss: 0.666 train_f1: 0.778 \t\n",
      "\n",
      "Validation 259 valid_acc: 0.760 best_acc: 0.762 \t\n",
      "\n",
      "Epoch 260 train_loss: 0.658 train_f1: 0.777 \t\n",
      "\n",
      "Validation 260 valid_acc: 0.765 best_acc: 0.765 \t\n",
      "\n",
      "Epoch 261 train_loss: 0.654 train_f1: 0.778 \t\n",
      "\n",
      "Validation 261 valid_acc: 0.765 best_acc: 0.765 \t\n",
      "\n",
      "Epoch 262 train_loss: 0.648 train_f1: 0.785 \t\n",
      "\n",
      "Validation 262 valid_acc: 0.768 best_acc: 0.768 \t\n",
      "\n",
      "Epoch 263 train_loss: 0.686 train_f1: 0.774 \t\n",
      "\n",
      "Validation 263 valid_acc: 0.769 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 264 train_loss: 0.654 train_f1: 0.779 \t\n",
      "\n",
      "Validation 264 valid_acc: 0.758 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 265 train_loss: 0.633 train_f1: 0.785 \t\n",
      "\n",
      "Validation 265 valid_acc: 0.763 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 266 train_loss: 0.638 train_f1: 0.786 \t\n",
      "\n",
      "Validation 266 valid_acc: 0.758 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 267 train_loss: 0.631 train_f1: 0.790 \t\n",
      "\n",
      "Validation 267 valid_acc: 0.742 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 268 train_loss: 0.643 train_f1: 0.781 \t\n",
      "\n",
      "Validation 268 valid_acc: 0.750 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 269 train_loss: 0.648 train_f1: 0.785 \t\n",
      "\n",
      "Validation 269 valid_acc: 0.760 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 270 train_loss: 0.618 train_f1: 0.794 \t\n",
      "\n",
      "Validation 270 valid_acc: 0.749 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 271 train_loss: 0.624 train_f1: 0.790 \t\n",
      "\n",
      "Validation 271 valid_acc: 0.758 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 272 train_loss: 0.616 train_f1: 0.792 \t\n",
      "\n",
      "Validation 272 valid_acc: 0.756 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 273 train_loss: 0.618 train_f1: 0.792 \t\n",
      "\n",
      "Validation 273 valid_acc: 0.756 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 274 train_loss: 0.626 train_f1: 0.791 \t\n",
      "\n",
      "Validation 274 valid_acc: 0.758 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 275 train_loss: 0.614 train_f1: 0.796 \t\n",
      "\n",
      "Validation 275 valid_acc: 0.762 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 276 train_loss: 0.617 train_f1: 0.793 \t\n",
      "\n",
      "Validation 276 valid_acc: 0.761 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 277 train_loss: 0.615 train_f1: 0.795 \t\n",
      "\n",
      "Validation 277 valid_acc: 0.750 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 278 train_loss: 0.614 train_f1: 0.801 \t\n",
      "\n",
      "Validation 278 valid_acc: 0.758 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 279 train_loss: 0.614 train_f1: 0.796 \t\n",
      "\n",
      "Validation 279 valid_acc: 0.771 best_acc: 0.771 \t\n",
      "\n",
      "Epoch 280 train_loss: 0.601 train_f1: 0.797 \t\n",
      "\n",
      "Validation 280 valid_acc: 0.770 best_acc: 0.771 \t\n",
      "\n",
      "Epoch 281 train_loss: 0.615 train_f1: 0.798 \t\n",
      "\n",
      "Validation 281 valid_acc: 0.755 best_acc: 0.771 \t\n",
      "\n",
      "Epoch 282 train_loss: 0.617 train_f1: 0.796 \t\n",
      "\n",
      "Validation 282 valid_acc: 0.766 best_acc: 0.771 \t\n",
      "\n",
      "Epoch 283 train_loss: 0.606 train_f1: 0.793 \t\n",
      "\n",
      "Validation 283 valid_acc: 0.761 best_acc: 0.771 \t\n",
      "\n",
      "Epoch 284 train_loss: 0.591 train_f1: 0.804 \t\n",
      "\n",
      "Validation 284 valid_acc: 0.762 best_acc: 0.771 \t\n",
      "\n",
      "Epoch 285 train_loss: 0.604 train_f1: 0.800 \t\n",
      "\n",
      "Validation 285 valid_acc: 0.751 best_acc: 0.771 \t\n",
      "\n",
      "Epoch 286 train_loss: 0.605 train_f1: 0.797 \t\n",
      "\n",
      "Validation 286 valid_acc: 0.756 best_acc: 0.771 \t\n",
      "\n",
      "Epoch 287 train_loss: 0.586 train_f1: 0.805 \t\n",
      "\n",
      "Validation 287 valid_acc: 0.764 best_acc: 0.771 \t\n",
      "\n",
      "Epoch 288 train_loss: 0.585 train_f1: 0.808 \t\n",
      "\n",
      "Validation 288 valid_acc: 0.759 best_acc: 0.771 \t\n",
      "\n",
      "Epoch 289 train_loss: 0.588 train_f1: 0.802 \t\n",
      "\n",
      "Validation 289 valid_acc: 0.768 best_acc: 0.771 \t\n",
      "\n",
      "Epoch 290 train_loss: 0.580 train_f1: 0.805 \t\n",
      "\n",
      "Validation 290 valid_acc: 0.769 best_acc: 0.771 \t\n",
      "\n",
      "Epoch 291 train_loss: 0.600 train_f1: 0.803 \t\n",
      "\n",
      "Validation 291 valid_acc: 0.763 best_acc: 0.771 \t\n",
      "\n",
      "Epoch 292 train_loss: 0.577 train_f1: 0.804 \t\n",
      "\n",
      "Validation 292 valid_acc: 0.762 best_acc: 0.771 \t\n",
      "\n",
      "Epoch 293 train_loss: 0.584 train_f1: 0.809 \t\n",
      "\n",
      "Validation 293 valid_acc: 0.762 best_acc: 0.771 \t\n",
      "\n",
      "Epoch 294 train_loss: 0.587 train_f1: 0.802 \t\n",
      "\n",
      "Validation 294 valid_acc: 0.762 best_acc: 0.771 \t\n",
      "\n",
      "Epoch 295 train_loss: 0.562 train_f1: 0.814 \t\n",
      "\n",
      "Validation 295 valid_acc: 0.764 best_acc: 0.771 \t\n",
      "\n",
      "Epoch 296 train_loss: 0.571 train_f1: 0.809 \t\n",
      "\n",
      "Validation 296 valid_acc: 0.755 best_acc: 0.771 \t\n",
      "\n",
      "Epoch 297 train_loss: 0.567 train_f1: 0.810 \t\n",
      "\n",
      "Validation 297 valid_acc: 0.769 best_acc: 0.771 \t\n",
      "\n",
      "Epoch 298 train_loss: 0.572 train_f1: 0.814 \t\n",
      "\n",
      "Validation 298 valid_acc: 0.764 best_acc: 0.771 \t\n",
      "\n",
      "Epoch 299 train_loss: 0.565 train_f1: 0.814 \t\n",
      "\n",
      "Validation 299 valid_acc: 0.763 best_acc: 0.771 \t\n",
      "\n",
      "Epoch 300 train_loss: 0.564 train_f1: 0.814 \t\n",
      "\n",
      "Validation 300 valid_acc: 0.771 best_acc: 0.771 \t\n",
      "\n",
      "Epoch 301 train_loss: 0.567 train_f1: 0.814 \t\n",
      "\n",
      "Validation 301 valid_acc: 0.775 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 302 train_loss: 0.559 train_f1: 0.816 \t\n",
      "\n",
      "Validation 302 valid_acc: 0.772 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 303 train_loss: 0.556 train_f1: 0.816 \t\n",
      "\n",
      "Validation 303 valid_acc: 0.768 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 304 train_loss: 0.554 train_f1: 0.820 \t\n",
      "\n",
      "Validation 304 valid_acc: 0.761 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 305 train_loss: 0.543 train_f1: 0.822 \t\n",
      "\n",
      "Validation 305 valid_acc: 0.760 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 306 train_loss: 0.553 train_f1: 0.814 \t\n",
      "\n",
      "Validation 306 valid_acc: 0.769 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 307 train_loss: 0.549 train_f1: 0.817 \t\n",
      "\n",
      "Validation 307 valid_acc: 0.769 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 308 train_loss: 0.530 train_f1: 0.824 \t\n",
      "\n",
      "Validation 308 valid_acc: 0.769 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 309 train_loss: 0.538 train_f1: 0.822 \t\n",
      "\n",
      "Validation 309 valid_acc: 0.758 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 310 train_loss: 0.543 train_f1: 0.818 \t\n",
      "\n",
      "Validation 310 valid_acc: 0.763 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 311 train_loss: 0.535 train_f1: 0.824 \t\n",
      "\n",
      "Validation 311 valid_acc: 0.764 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 312 train_loss: 0.512 train_f1: 0.831 \t\n",
      "\n",
      "Validation 312 valid_acc: 0.752 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 313 train_loss: 0.526 train_f1: 0.825 \t\n",
      "\n",
      "Validation 313 valid_acc: 0.760 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 314 train_loss: 0.525 train_f1: 0.822 \t\n",
      "\n",
      "Validation 314 valid_acc: 0.765 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 315 train_loss: 0.523 train_f1: 0.825 \t\n",
      "\n",
      "Validation 315 valid_acc: 0.763 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 316 train_loss: 0.522 train_f1: 0.829 \t\n",
      "\n",
      "Validation 316 valid_acc: 0.760 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 317 train_loss: 0.517 train_f1: 0.827 \t\n",
      "\n",
      "Validation 317 valid_acc: 0.767 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 318 train_loss: 0.532 train_f1: 0.822 \t\n",
      "\n",
      "Validation 318 valid_acc: 0.765 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 319 train_loss: 0.516 train_f1: 0.833 \t\n",
      "\n",
      "Validation 319 valid_acc: 0.764 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 320 train_loss: 0.535 train_f1: 0.823 \t\n",
      "\n",
      "Validation 320 valid_acc: 0.765 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 321 train_loss: 0.493 train_f1: 0.837 \t\n",
      "\n",
      "Validation 321 valid_acc: 0.770 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 322 train_loss: 0.511 train_f1: 0.830 \t\n",
      "\n",
      "Validation 322 valid_acc: 0.763 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 323 train_loss: 0.507 train_f1: 0.833 \t\n",
      "\n",
      "Validation 323 valid_acc: 0.766 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 324 train_loss: 0.514 train_f1: 0.827 \t\n",
      "\n",
      "Validation 324 valid_acc: 0.771 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 325 train_loss: 0.519 train_f1: 0.829 \t\n",
      "\n",
      "Validation 325 valid_acc: 0.758 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 326 train_loss: 0.513 train_f1: 0.834 \t\n",
      "\n",
      "Validation 326 valid_acc: 0.766 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 327 train_loss: 0.502 train_f1: 0.834 \t\n",
      "\n",
      "Validation 327 valid_acc: 0.766 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 328 train_loss: 0.510 train_f1: 0.828 \t\n",
      "\n",
      "Validation 328 valid_acc: 0.763 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 329 train_loss: 0.496 train_f1: 0.837 \t\n",
      "\n",
      "Validation 329 valid_acc: 0.765 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 330 train_loss: 0.509 train_f1: 0.829 \t\n",
      "\n",
      "Validation 330 valid_acc: 0.774 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 331 train_loss: 0.515 train_f1: 0.827 \t\n",
      "\n",
      "Validation 331 valid_acc: 0.763 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 332 train_loss: 0.494 train_f1: 0.834 \t\n",
      "\n",
      "Validation 332 valid_acc: 0.764 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 333 train_loss: 0.507 train_f1: 0.833 \t\n",
      "\n",
      "Validation 333 valid_acc: 0.770 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 334 train_loss: 0.499 train_f1: 0.834 \t\n",
      "\n",
      "Validation 334 valid_acc: 0.767 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 335 train_loss: 0.496 train_f1: 0.837 \t\n",
      "\n",
      "Validation 335 valid_acc: 0.758 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 336 train_loss: 0.487 train_f1: 0.839 \t\n",
      "\n",
      "Validation 336 valid_acc: 0.766 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 337 train_loss: 0.487 train_f1: 0.840 \t\n",
      "\n",
      "Validation 337 valid_acc: 0.758 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 338 train_loss: 0.469 train_f1: 0.842 \t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation 338 valid_acc: 0.774 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 339 train_loss: 0.468 train_f1: 0.844 \t\n",
      "\n",
      "Validation 339 valid_acc: 0.763 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 340 train_loss: 0.502 train_f1: 0.835 \t\n",
      "\n",
      "Validation 340 valid_acc: 0.764 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 341 train_loss: 0.465 train_f1: 0.847 \t\n",
      "\n",
      "Validation 341 valid_acc: 0.751 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 342 train_loss: 0.468 train_f1: 0.842 \t\n",
      "\n",
      "Validation 342 valid_acc: 0.772 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 343 train_loss: 0.477 train_f1: 0.842 \t\n",
      "\n",
      "Validation 343 valid_acc: 0.769 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 344 train_loss: 0.469 train_f1: 0.844 \t\n",
      "\n",
      "Validation 344 valid_acc: 0.766 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 345 train_loss: 0.477 train_f1: 0.845 \t\n",
      "\n",
      "Validation 345 valid_acc: 0.754 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 346 train_loss: 0.465 train_f1: 0.843 \t\n",
      "\n",
      "Validation 346 valid_acc: 0.764 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 347 train_loss: 0.457 train_f1: 0.851 \t\n",
      "\n",
      "Validation 347 valid_acc: 0.763 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 348 train_loss: 0.466 train_f1: 0.844 \t\n",
      "\n",
      "Validation 348 valid_acc: 0.769 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 349 train_loss: 0.474 train_f1: 0.842 \t\n",
      "\n",
      "Validation 349 valid_acc: 0.775 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 350 train_loss: 0.448 train_f1: 0.853 \t\n",
      "\n",
      "Validation 350 valid_acc: 0.761 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 351 train_loss: 0.448 train_f1: 0.849 \t\n",
      "\n",
      "Validation 351 valid_acc: 0.765 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 352 train_loss: 0.447 train_f1: 0.850 \t\n",
      "\n",
      "Validation 352 valid_acc: 0.767 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 353 train_loss: 0.445 train_f1: 0.851 \t\n",
      "\n",
      "Validation 353 valid_acc: 0.762 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 354 train_loss: 0.433 train_f1: 0.852 \t\n",
      "\n",
      "Validation 354 valid_acc: 0.770 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 355 train_loss: 0.429 train_f1: 0.854 \t\n",
      "\n",
      "Validation 355 valid_acc: 0.769 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 356 train_loss: 0.441 train_f1: 0.851 \t\n",
      "\n",
      "Validation 356 valid_acc: 0.773 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 357 train_loss: 0.447 train_f1: 0.850 \t\n",
      "\n",
      "Validation 357 valid_acc: 0.765 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 358 train_loss: 0.443 train_f1: 0.852 \t\n",
      "\n",
      "Validation 358 valid_acc: 0.763 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 359 train_loss: 0.442 train_f1: 0.856 \t\n",
      "\n",
      "Validation 359 valid_acc: 0.756 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 360 train_loss: 0.438 train_f1: 0.854 \t\n",
      "\n",
      "Validation 360 valid_acc: 0.769 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 361 train_loss: 0.456 train_f1: 0.850 \t\n",
      "\n",
      "Validation 361 valid_acc: 0.769 best_acc: 0.775 \t\n",
      "\n",
      "Epoch 362 train_loss: 0.430 train_f1: 0.854 \t\n",
      "\n",
      "Validation 362 valid_acc: 0.777 best_acc: 0.777 \t\n",
      "\n",
      "Epoch 363 train_loss: 0.426 train_f1: 0.856 \t\n",
      "\n",
      "Validation 363 valid_acc: 0.772 best_acc: 0.777 \t\n",
      "\n",
      "Epoch 364 train_loss: 0.439 train_f1: 0.851 \t\n",
      "\n",
      "Validation 364 valid_acc: 0.780 best_acc: 0.780 \t\n",
      "\n",
      "Epoch 365 train_loss: 0.428 train_f1: 0.857 \t\n",
      "\n",
      "Validation 365 valid_acc: 0.770 best_acc: 0.780 \t\n",
      "\n",
      "Epoch 366 train_loss: 0.424 train_f1: 0.858 \t\n",
      "\n",
      "Validation 366 valid_acc: 0.766 best_acc: 0.780 \t\n",
      "\n",
      "Epoch 367 train_loss: 0.420 train_f1: 0.859 \t\n",
      "\n",
      "Validation 367 valid_acc: 0.759 best_acc: 0.780 \t\n",
      "\n",
      "Epoch 368 train_loss: 0.425 train_f1: 0.855 \t\n",
      "\n",
      "Validation 368 valid_acc: 0.766 best_acc: 0.780 \t\n",
      "\n",
      "Epoch 369 train_loss: 0.423 train_f1: 0.856 \t\n",
      "\n",
      "Validation 369 valid_acc: 0.772 best_acc: 0.780 \t\n",
      "\n",
      "Epoch 370 train_loss: 0.418 train_f1: 0.859 \t\n",
      "\n",
      "Validation 370 valid_acc: 0.768 best_acc: 0.780 \t\n",
      "\n",
      "Epoch 371 train_loss: 0.407 train_f1: 0.867 \t\n",
      "\n",
      "Validation 371 valid_acc: 0.775 best_acc: 0.780 \t\n",
      "\n",
      "Epoch 372 train_loss: 0.416 train_f1: 0.861 \t\n",
      "\n",
      "Validation 372 valid_acc: 0.763 best_acc: 0.780 \t\n",
      "\n",
      "Epoch 373 train_loss: 0.407 train_f1: 0.868 \t\n",
      "\n",
      "Validation 373 valid_acc: 0.768 best_acc: 0.780 \t\n",
      "\n",
      "Epoch 374 train_loss: 0.410 train_f1: 0.865 \t\n",
      "\n",
      "Validation 374 valid_acc: 0.766 best_acc: 0.780 \t\n",
      "\n",
      "Epoch 375 train_loss: 0.412 train_f1: 0.862 \t\n",
      "\n",
      "Validation 375 valid_acc: 0.773 best_acc: 0.780 \t\n",
      "\n",
      "Epoch 376 train_loss: 0.407 train_f1: 0.862 \t\n",
      "\n",
      "Validation 376 valid_acc: 0.771 best_acc: 0.780 \t\n",
      "\n",
      "Epoch 377 train_loss: 0.426 train_f1: 0.861 \t\n",
      "\n",
      "Validation 377 valid_acc: 0.772 best_acc: 0.780 \t\n",
      "\n",
      "Epoch 378 train_loss: 0.432 train_f1: 0.856 \t\n",
      "\n",
      "Validation 378 valid_acc: 0.771 best_acc: 0.780 \t\n",
      "\n",
      "Epoch 379 train_loss: 0.412 train_f1: 0.859 \t\n",
      "\n",
      "Validation 379 valid_acc: 0.772 best_acc: 0.780 \t\n",
      "\n",
      "Epoch 380 train_loss: 0.418 train_f1: 0.861 \t\n",
      "\n",
      "Validation 380 valid_acc: 0.767 best_acc: 0.780 \t\n",
      "\n",
      "Epoch 381 train_loss: 0.391 train_f1: 0.870 \t\n",
      "\n",
      "Validation 381 valid_acc: 0.782 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 382 train_loss: 0.406 train_f1: 0.867 \t\n",
      "\n",
      "Validation 382 valid_acc: 0.767 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 383 train_loss: 0.391 train_f1: 0.870 \t\n",
      "\n",
      "Validation 383 valid_acc: 0.760 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 384 train_loss: 0.391 train_f1: 0.866 \t\n",
      "\n",
      "Validation 384 valid_acc: 0.754 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 385 train_loss: 0.409 train_f1: 0.866 \t\n",
      "\n",
      "Validation 385 valid_acc: 0.746 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 386 train_loss: 0.401 train_f1: 0.866 \t\n",
      "\n",
      "Validation 386 valid_acc: 0.773 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 387 train_loss: 0.387 train_f1: 0.870 \t\n",
      "\n",
      "Validation 387 valid_acc: 0.776 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 388 train_loss: 0.385 train_f1: 0.870 \t\n",
      "\n",
      "Validation 388 valid_acc: 0.772 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 389 train_loss: 0.379 train_f1: 0.872 \t\n",
      "\n",
      "Validation 389 valid_acc: 0.777 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 390 train_loss: 0.400 train_f1: 0.864 \t\n",
      "\n",
      "Validation 390 valid_acc: 0.769 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 391 train_loss: 0.385 train_f1: 0.870 \t\n",
      "\n",
      "Validation 391 valid_acc: 0.772 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 392 train_loss: 0.384 train_f1: 0.870 \t\n",
      "\n",
      "Validation 392 valid_acc: 0.767 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 393 train_loss: 0.402 train_f1: 0.864 \t\n",
      "\n",
      "Validation 393 valid_acc: 0.754 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 394 train_loss: 0.379 train_f1: 0.871 \t\n",
      "\n",
      "Validation 394 valid_acc: 0.751 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 395 train_loss: 0.376 train_f1: 0.873 \t\n",
      "\n",
      "Validation 395 valid_acc: 0.758 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 396 train_loss: 0.369 train_f1: 0.877 \t\n",
      "\n",
      "Validation 396 valid_acc: 0.774 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 397 train_loss: 0.369 train_f1: 0.878 \t\n",
      "\n",
      "Validation 397 valid_acc: 0.766 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 398 train_loss: 0.360 train_f1: 0.880 \t\n",
      "\n",
      "Validation 398 valid_acc: 0.756 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 399 train_loss: 0.372 train_f1: 0.874 \t\n",
      "\n",
      "Validation 399 valid_acc: 0.765 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 400 train_loss: 0.371 train_f1: 0.877 \t\n",
      "\n",
      "Validation 400 valid_acc: 0.767 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 401 train_loss: 0.356 train_f1: 0.880 \t\n",
      "\n",
      "Validation 401 valid_acc: 0.753 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 402 train_loss: 0.376 train_f1: 0.875 \t\n",
      "\n",
      "Validation 402 valid_acc: 0.765 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 403 train_loss: 0.351 train_f1: 0.884 \t\n",
      "\n",
      "Validation 403 valid_acc: 0.764 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 404 train_loss: 0.360 train_f1: 0.886 \t\n",
      "\n",
      "Validation 404 valid_acc: 0.766 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 405 train_loss: 0.376 train_f1: 0.878 \t\n",
      "\n",
      "Validation 405 valid_acc: 0.765 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 406 train_loss: 0.365 train_f1: 0.881 \t\n",
      "\n",
      "Validation 406 valid_acc: 0.776 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 407 train_loss: 0.349 train_f1: 0.884 \t\n",
      "\n",
      "Validation 407 valid_acc: 0.760 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 408 train_loss: 0.357 train_f1: 0.879 \t\n",
      "\n",
      "Validation 408 valid_acc: 0.775 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 409 train_loss: 0.363 train_f1: 0.880 \t\n",
      "\n",
      "Validation 409 valid_acc: 0.775 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 410 train_loss: 0.351 train_f1: 0.885 \t\n",
      "\n",
      "Validation 410 valid_acc: 0.758 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 411 train_loss: 0.344 train_f1: 0.887 \t\n",
      "\n",
      "Validation 411 valid_acc: 0.765 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 412 train_loss: 0.332 train_f1: 0.890 \t\n",
      "\n",
      "Validation 412 valid_acc: 0.771 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 413 train_loss: 0.338 train_f1: 0.887 \t\n",
      "\n",
      "Validation 413 valid_acc: 0.778 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 414 train_loss: 0.354 train_f1: 0.885 \t\n",
      "\n",
      "Validation 414 valid_acc: 0.767 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 415 train_loss: 0.344 train_f1: 0.886 \t\n",
      "\n",
      "Validation 415 valid_acc: 0.769 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 416 train_loss: 0.354 train_f1: 0.883 \t\n",
      "\n",
      "Validation 416 valid_acc: 0.766 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 417 train_loss: 0.343 train_f1: 0.888 \t\n",
      "\n",
      "Validation 417 valid_acc: 0.776 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 418 train_loss: 0.333 train_f1: 0.887 \t\n",
      "\n",
      "Validation 418 valid_acc: 0.773 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 419 train_loss: 0.328 train_f1: 0.891 \t\n",
      "\n",
      "Validation 419 valid_acc: 0.760 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 420 train_loss: 0.343 train_f1: 0.885 \t\n",
      "\n",
      "Validation 420 valid_acc: 0.756 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 421 train_loss: 0.335 train_f1: 0.889 \t\n",
      "\n",
      "Validation 421 valid_acc: 0.764 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 422 train_loss: 0.317 train_f1: 0.892 \t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation 422 valid_acc: 0.764 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 423 train_loss: 0.325 train_f1: 0.890 \t\n",
      "\n",
      "Validation 423 valid_acc: 0.775 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 424 train_loss: 0.328 train_f1: 0.893 \t\n",
      "\n",
      "Validation 424 valid_acc: 0.767 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 425 train_loss: 0.330 train_f1: 0.890 \t\n",
      "\n",
      "Validation 425 valid_acc: 0.773 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 426 train_loss: 0.341 train_f1: 0.886 \t\n",
      "\n",
      "Validation 426 valid_acc: 0.765 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 427 train_loss: 0.317 train_f1: 0.894 \t\n",
      "\n",
      "Validation 427 valid_acc: 0.758 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 428 train_loss: 0.323 train_f1: 0.892 \t\n",
      "\n",
      "Validation 428 valid_acc: 0.765 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 429 train_loss: 0.333 train_f1: 0.887 \t\n",
      "\n",
      "Validation 429 valid_acc: 0.768 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 430 train_loss: 0.303 train_f1: 0.899 \t\n",
      "\n",
      "Validation 430 valid_acc: 0.768 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 431 train_loss: 0.328 train_f1: 0.889 \t\n",
      "\n",
      "Validation 431 valid_acc: 0.776 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 432 train_loss: 0.323 train_f1: 0.892 \t\n",
      "\n",
      "Validation 432 valid_acc: 0.769 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 433 train_loss: 0.309 train_f1: 0.900 \t\n",
      "\n",
      "Validation 433 valid_acc: 0.765 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 434 train_loss: 0.313 train_f1: 0.895 \t\n",
      "\n",
      "Validation 434 valid_acc: 0.776 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 435 train_loss: 0.312 train_f1: 0.895 \t\n",
      "\n",
      "Validation 435 valid_acc: 0.764 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 436 train_loss: 0.317 train_f1: 0.895 \t\n",
      "\n",
      "Validation 436 valid_acc: 0.774 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 437 train_loss: 0.301 train_f1: 0.899 \t\n",
      "\n",
      "Validation 437 valid_acc: 0.761 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 438 train_loss: 0.322 train_f1: 0.895 \t\n",
      "\n",
      "Validation 438 valid_acc: 0.776 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 439 train_loss: 0.308 train_f1: 0.896 \t\n",
      "\n",
      "Validation 439 valid_acc: 0.765 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 440 train_loss: 0.310 train_f1: 0.897 \t\n",
      "\n",
      "Validation 440 valid_acc: 0.770 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 441 train_loss: 0.310 train_f1: 0.896 \t\n",
      "\n",
      "Validation 441 valid_acc: 0.765 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 442 train_loss: 0.320 train_f1: 0.890 \t\n",
      "\n",
      "Validation 442 valid_acc: 0.764 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 443 train_loss: 0.324 train_f1: 0.888 \t\n",
      "\n",
      "Validation 443 valid_acc: 0.771 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 444 train_loss: 0.311 train_f1: 0.896 \t\n",
      "\n",
      "Validation 444 valid_acc: 0.778 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 445 train_loss: 0.316 train_f1: 0.894 \t\n",
      "\n",
      "Validation 445 valid_acc: 0.754 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 446 train_loss: 0.303 train_f1: 0.902 \t\n",
      "\n",
      "Validation 446 valid_acc: 0.772 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 447 train_loss: 0.287 train_f1: 0.907 \t\n",
      "\n",
      "Validation 447 valid_acc: 0.769 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 448 train_loss: 0.302 train_f1: 0.900 \t\n",
      "\n",
      "Validation 448 valid_acc: 0.775 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 449 train_loss: 0.292 train_f1: 0.902 \t\n",
      "\n",
      "Validation 449 valid_acc: 0.762 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 450 train_loss: 0.299 train_f1: 0.900 \t\n",
      "\n",
      "Validation 450 valid_acc: 0.767 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 451 train_loss: 0.294 train_f1: 0.903 \t\n",
      "\n",
      "Validation 451 valid_acc: 0.764 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 452 train_loss: 0.296 train_f1: 0.902 \t\n",
      "\n",
      "Validation 452 valid_acc: 0.765 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 453 train_loss: 0.292 train_f1: 0.901 \t\n",
      "\n",
      "Validation 453 valid_acc: 0.758 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 454 train_loss: 0.296 train_f1: 0.903 \t\n",
      "\n",
      "Validation 454 valid_acc: 0.772 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 455 train_loss: 0.290 train_f1: 0.902 \t\n",
      "\n",
      "Validation 455 valid_acc: 0.764 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 456 train_loss: 0.287 train_f1: 0.904 \t\n",
      "\n",
      "Validation 456 valid_acc: 0.776 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 457 train_loss: 0.290 train_f1: 0.903 \t\n",
      "\n",
      "Validation 457 valid_acc: 0.772 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 458 train_loss: 0.289 train_f1: 0.901 \t\n",
      "\n",
      "Validation 458 valid_acc: 0.776 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 459 train_loss: 0.295 train_f1: 0.901 \t\n",
      "\n",
      "Validation 459 valid_acc: 0.772 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 460 train_loss: 0.299 train_f1: 0.901 \t\n",
      "\n",
      "Validation 460 valid_acc: 0.747 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 461 train_loss: 0.295 train_f1: 0.902 \t\n",
      "\n",
      "Validation 461 valid_acc: 0.772 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 462 train_loss: 0.276 train_f1: 0.907 \t\n",
      "\n",
      "Validation 462 valid_acc: 0.767 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 463 train_loss: 0.287 train_f1: 0.903 \t\n",
      "\n",
      "Validation 463 valid_acc: 0.770 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 464 train_loss: 0.280 train_f1: 0.909 \t\n",
      "\n",
      "Validation 464 valid_acc: 0.758 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 465 train_loss: 0.286 train_f1: 0.904 \t\n",
      "\n",
      "Validation 465 valid_acc: 0.774 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 466 train_loss: 0.272 train_f1: 0.910 \t\n",
      "\n",
      "Validation 466 valid_acc: 0.765 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 467 train_loss: 0.275 train_f1: 0.907 \t\n",
      "\n",
      "Validation 467 valid_acc: 0.764 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 468 train_loss: 0.264 train_f1: 0.912 \t\n",
      "\n",
      "Validation 468 valid_acc: 0.766 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 469 train_loss: 0.279 train_f1: 0.908 \t\n",
      "\n",
      "Validation 469 valid_acc: 0.762 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 470 train_loss: 0.276 train_f1: 0.907 \t\n",
      "\n",
      "Validation 470 valid_acc: 0.778 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 471 train_loss: 0.257 train_f1: 0.918 \t\n",
      "\n",
      "Validation 471 valid_acc: 0.777 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 472 train_loss: 0.273 train_f1: 0.906 \t\n",
      "\n",
      "Validation 472 valid_acc: 0.770 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 473 train_loss: 0.262 train_f1: 0.914 \t\n",
      "\n",
      "Validation 473 valid_acc: 0.756 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 474 train_loss: 0.277 train_f1: 0.907 \t\n",
      "\n",
      "Validation 474 valid_acc: 0.762 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 475 train_loss: 0.262 train_f1: 0.915 \t\n",
      "\n",
      "Validation 475 valid_acc: 0.772 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 476 train_loss: 0.259 train_f1: 0.913 \t\n",
      "\n",
      "Validation 476 valid_acc: 0.758 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 477 train_loss: 0.276 train_f1: 0.905 \t\n",
      "\n",
      "Validation 477 valid_acc: 0.775 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 478 train_loss: 0.258 train_f1: 0.914 \t\n",
      "\n",
      "Validation 478 valid_acc: 0.773 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 479 train_loss: 0.268 train_f1: 0.910 \t\n",
      "\n",
      "Validation 479 valid_acc: 0.778 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 480 train_loss: 0.244 train_f1: 0.920 \t\n",
      "\n",
      "Validation 480 valid_acc: 0.777 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 481 train_loss: 0.241 train_f1: 0.917 \t\n",
      "\n",
      "Validation 481 valid_acc: 0.759 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 482 train_loss: 0.241 train_f1: 0.919 \t\n",
      "\n",
      "Validation 482 valid_acc: 0.778 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 483 train_loss: 0.252 train_f1: 0.913 \t\n",
      "\n",
      "Validation 483 valid_acc: 0.770 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 484 train_loss: 0.260 train_f1: 0.912 \t\n",
      "\n",
      "Validation 484 valid_acc: 0.771 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 485 train_loss: 0.247 train_f1: 0.915 \t\n",
      "\n",
      "Validation 485 valid_acc: 0.761 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 486 train_loss: 0.256 train_f1: 0.915 \t\n",
      "\n",
      "Validation 486 valid_acc: 0.766 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 487 train_loss: 0.255 train_f1: 0.914 \t\n",
      "\n",
      "Validation 487 valid_acc: 0.774 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 488 train_loss: 0.256 train_f1: 0.914 \t\n",
      "\n",
      "Validation 488 valid_acc: 0.769 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 489 train_loss: 0.256 train_f1: 0.914 \t\n",
      "\n",
      "Validation 489 valid_acc: 0.768 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 490 train_loss: 0.234 train_f1: 0.924 \t\n",
      "\n",
      "Validation 490 valid_acc: 0.768 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 491 train_loss: 0.243 train_f1: 0.919 \t\n",
      "\n",
      "Validation 491 valid_acc: 0.761 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 492 train_loss: 0.250 train_f1: 0.917 \t\n",
      "\n",
      "Validation 492 valid_acc: 0.777 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 493 train_loss: 0.242 train_f1: 0.920 \t\n",
      "\n",
      "Validation 493 valid_acc: 0.762 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 494 train_loss: 0.232 train_f1: 0.924 \t\n",
      "\n",
      "Validation 494 valid_acc: 0.772 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 495 train_loss: 0.251 train_f1: 0.915 \t\n",
      "\n",
      "Validation 495 valid_acc: 0.758 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 496 train_loss: 0.251 train_f1: 0.919 \t\n",
      "\n",
      "Validation 496 valid_acc: 0.768 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 497 train_loss: 0.236 train_f1: 0.921 \t\n",
      "\n",
      "Validation 497 valid_acc: 0.767 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 498 train_loss: 0.233 train_f1: 0.922 \t\n",
      "\n",
      "Validation 498 valid_acc: 0.763 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 499 train_loss: 0.231 train_f1: 0.923 \t\n",
      "\n",
      "Validation 499 valid_acc: 0.765 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 500 train_loss: 0.244 train_f1: 0.920 \t\n",
      "\n",
      "Validation 500 valid_acc: 0.757 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 501 train_loss: 0.242 train_f1: 0.917 \t\n",
      "\n",
      "Validation 501 valid_acc: 0.769 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 502 train_loss: 0.224 train_f1: 0.927 \t\n",
      "\n",
      "Validation 502 valid_acc: 0.765 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 503 train_loss: 0.244 train_f1: 0.917 \t\n",
      "\n",
      "Validation 503 valid_acc: 0.771 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 504 train_loss: 0.254 train_f1: 0.914 \t\n",
      "\n",
      "Validation 504 valid_acc: 0.767 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 505 train_loss: 0.224 train_f1: 0.925 \t\n",
      "\n",
      "Validation 505 valid_acc: 0.767 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 506 train_loss: 0.241 train_f1: 0.920 \t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation 506 valid_acc: 0.772 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 507 train_loss: 0.224 train_f1: 0.926 \t\n",
      "\n",
      "Validation 507 valid_acc: 0.760 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 508 train_loss: 0.215 train_f1: 0.931 \t\n",
      "\n",
      "Validation 508 valid_acc: 0.763 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 509 train_loss: 0.232 train_f1: 0.922 \t\n",
      "\n",
      "Validation 509 valid_acc: 0.772 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 510 train_loss: 0.234 train_f1: 0.924 \t\n",
      "\n",
      "Validation 510 valid_acc: 0.747 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 511 train_loss: 0.210 train_f1: 0.931 \t\n",
      "\n",
      "Validation 511 valid_acc: 0.772 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 512 train_loss: 0.226 train_f1: 0.924 \t\n",
      "\n",
      "Validation 512 valid_acc: 0.768 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 513 train_loss: 0.229 train_f1: 0.923 \t\n",
      "\n",
      "Validation 513 valid_acc: 0.767 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 514 train_loss: 0.237 train_f1: 0.920 \t\n",
      "\n",
      "Validation 514 valid_acc: 0.762 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 515 train_loss: 0.212 train_f1: 0.928 \t\n",
      "\n",
      "Validation 515 valid_acc: 0.764 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 516 train_loss: 0.239 train_f1: 0.918 \t\n",
      "\n",
      "Validation 516 valid_acc: 0.762 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 517 train_loss: 0.229 train_f1: 0.923 \t\n",
      "\n",
      "Validation 517 valid_acc: 0.767 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 518 train_loss: 0.212 train_f1: 0.929 \t\n",
      "\n",
      "Validation 518 valid_acc: 0.762 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 519 train_loss: 0.214 train_f1: 0.929 \t\n",
      "\n",
      "Validation 519 valid_acc: 0.762 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 520 train_loss: 0.210 train_f1: 0.930 \t\n",
      "\n",
      "Validation 520 valid_acc: 0.761 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 521 train_loss: 0.208 train_f1: 0.929 \t\n",
      "\n",
      "Validation 521 valid_acc: 0.756 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 522 train_loss: 0.215 train_f1: 0.928 \t\n",
      "\n",
      "Validation 522 valid_acc: 0.762 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 523 train_loss: 0.216 train_f1: 0.928 \t\n",
      "\n",
      "Validation 523 valid_acc: 0.758 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 524 train_loss: 0.231 train_f1: 0.921 \t\n",
      "\n",
      "Validation 524 valid_acc: 0.765 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 525 train_loss: 0.209 train_f1: 0.931 \t\n",
      "\n",
      "Validation 525 valid_acc: 0.766 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 526 train_loss: 0.202 train_f1: 0.933 \t\n",
      "\n",
      "Validation 526 valid_acc: 0.748 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 527 train_loss: 0.207 train_f1: 0.931 \t\n",
      "\n",
      "Validation 527 valid_acc: 0.758 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 528 train_loss: 0.197 train_f1: 0.932 \t\n",
      "\n",
      "Validation 528 valid_acc: 0.765 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 529 train_loss: 0.200 train_f1: 0.933 \t\n",
      "\n",
      "Validation 529 valid_acc: 0.761 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 530 train_loss: 0.204 train_f1: 0.932 \t\n",
      "\n",
      "Validation 530 valid_acc: 0.745 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 531 train_loss: 0.203 train_f1: 0.934 \t\n",
      "\n",
      "Validation 531 valid_acc: 0.764 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 532 train_loss: 0.204 train_f1: 0.933 \t\n",
      "\n",
      "Validation 532 valid_acc: 0.750 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 533 train_loss: 0.200 train_f1: 0.933 \t\n",
      "\n",
      "Validation 533 valid_acc: 0.764 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 534 train_loss: 0.189 train_f1: 0.938 \t\n",
      "\n",
      "Validation 534 valid_acc: 0.761 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 535 train_loss: 0.203 train_f1: 0.931 \t\n",
      "\n",
      "Validation 535 valid_acc: 0.762 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 536 train_loss: 0.181 train_f1: 0.941 \t\n",
      "\n",
      "Validation 536 valid_acc: 0.762 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 537 train_loss: 0.196 train_f1: 0.935 \t\n",
      "\n",
      "Validation 537 valid_acc: 0.758 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 538 train_loss: 0.195 train_f1: 0.933 \t\n",
      "\n",
      "Validation 538 valid_acc: 0.757 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 539 train_loss: 0.193 train_f1: 0.937 \t\n",
      "\n",
      "Validation 539 valid_acc: 0.765 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 540 train_loss: 0.191 train_f1: 0.936 \t\n",
      "\n",
      "Validation 540 valid_acc: 0.760 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 541 train_loss: 0.196 train_f1: 0.933 \t\n",
      "\n",
      "Validation 541 valid_acc: 0.769 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 542 train_loss: 0.190 train_f1: 0.937 \t\n",
      "\n",
      "Validation 542 valid_acc: 0.754 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 543 train_loss: 0.206 train_f1: 0.931 \t\n",
      "\n",
      "Validation 543 valid_acc: 0.769 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 544 train_loss: 0.187 train_f1: 0.938 \t\n",
      "\n",
      "Validation 544 valid_acc: 0.735 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 545 train_loss: 0.180 train_f1: 0.940 \t\n",
      "\n",
      "Validation 545 valid_acc: 0.769 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 546 train_loss: 0.188 train_f1: 0.937 \t\n",
      "\n",
      "Validation 546 valid_acc: 0.769 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 547 train_loss: 0.187 train_f1: 0.939 \t\n",
      "\n",
      "Validation 547 valid_acc: 0.769 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 548 train_loss: 0.188 train_f1: 0.935 \t\n",
      "\n",
      "Validation 548 valid_acc: 0.759 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 549 train_loss: 0.190 train_f1: 0.938 \t\n",
      "\n",
      "Validation 549 valid_acc: 0.758 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 550 train_loss: 0.196 train_f1: 0.935 \t\n",
      "\n",
      "Validation 550 valid_acc: 0.750 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 551 train_loss: 0.183 train_f1: 0.939 \t\n",
      "\n",
      "Validation 551 valid_acc: 0.739 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 552 train_loss: 0.177 train_f1: 0.940 \t\n",
      "\n",
      "Validation 552 valid_acc: 0.762 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 553 train_loss: 0.185 train_f1: 0.937 \t\n",
      "\n",
      "Validation 553 valid_acc: 0.761 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 554 train_loss: 0.202 train_f1: 0.931 \t\n",
      "\n",
      "Validation 554 valid_acc: 0.764 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 555 train_loss: 0.181 train_f1: 0.941 \t\n",
      "\n",
      "Validation 555 valid_acc: 0.760 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 556 train_loss: 0.184 train_f1: 0.938 \t\n",
      "\n",
      "Validation 556 valid_acc: 0.767 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 557 train_loss: 0.184 train_f1: 0.939 \t\n",
      "\n",
      "Validation 557 valid_acc: 0.759 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 558 train_loss: 0.194 train_f1: 0.934 \t\n",
      "\n",
      "Validation 558 valid_acc: 0.754 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 559 train_loss: 0.174 train_f1: 0.943 \t\n",
      "\n",
      "Validation 559 valid_acc: 0.756 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 560 train_loss: 0.168 train_f1: 0.943 \t\n",
      "\n",
      "Validation 560 valid_acc: 0.763 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 561 train_loss: 0.176 train_f1: 0.942 \t\n",
      "\n",
      "Validation 561 valid_acc: 0.776 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 562 train_loss: 0.160 train_f1: 0.948 \t\n",
      "\n",
      "Validation 562 valid_acc: 0.740 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 563 train_loss: 0.177 train_f1: 0.938 \t\n",
      "\n",
      "Validation 563 valid_acc: 0.769 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 564 train_loss: 0.187 train_f1: 0.936 \t\n",
      "\n",
      "Validation 564 valid_acc: 0.758 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 565 train_loss: 0.190 train_f1: 0.938 \t\n",
      "\n",
      "Validation 565 valid_acc: 0.752 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 566 train_loss: 0.170 train_f1: 0.943 \t\n",
      "\n",
      "Validation 566 valid_acc: 0.771 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 567 train_loss: 0.168 train_f1: 0.945 \t\n",
      "\n",
      "Validation 567 valid_acc: 0.772 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 568 train_loss: 0.173 train_f1: 0.942 \t\n",
      "\n",
      "Validation 568 valid_acc: 0.751 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 569 train_loss: 0.179 train_f1: 0.939 \t\n",
      "\n",
      "Validation 569 valid_acc: 0.763 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 570 train_loss: 0.176 train_f1: 0.942 \t\n",
      "\n",
      "Validation 570 valid_acc: 0.754 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 571 train_loss: 0.167 train_f1: 0.946 \t\n",
      "\n",
      "Validation 571 valid_acc: 0.761 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 572 train_loss: 0.158 train_f1: 0.948 \t\n",
      "\n",
      "Validation 572 valid_acc: 0.762 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 573 train_loss: 0.166 train_f1: 0.946 \t\n",
      "\n",
      "Validation 573 valid_acc: 0.759 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 574 train_loss: 0.157 train_f1: 0.948 \t\n",
      "\n",
      "Validation 574 valid_acc: 0.761 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 575 train_loss: 0.162 train_f1: 0.945 \t\n",
      "\n",
      "Validation 575 valid_acc: 0.764 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 576 train_loss: 0.178 train_f1: 0.939 \t\n",
      "\n",
      "Validation 576 valid_acc: 0.760 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 577 train_loss: 0.154 train_f1: 0.947 \t\n",
      "\n",
      "Validation 577 valid_acc: 0.762 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 578 train_loss: 0.154 train_f1: 0.947 \t\n",
      "\n",
      "Validation 578 valid_acc: 0.762 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 579 train_loss: 0.162 train_f1: 0.946 \t\n",
      "\n",
      "Validation 579 valid_acc: 0.760 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 580 train_loss: 0.179 train_f1: 0.940 \t\n",
      "\n",
      "Validation 580 valid_acc: 0.753 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 581 train_loss: 0.155 train_f1: 0.949 \t\n",
      "\n",
      "Validation 581 valid_acc: 0.767 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 582 train_loss: 0.163 train_f1: 0.945 \t\n",
      "\n",
      "Validation 582 valid_acc: 0.767 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 583 train_loss: 0.153 train_f1: 0.947 \t\n",
      "\n",
      "Validation 583 valid_acc: 0.768 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 584 train_loss: 0.168 train_f1: 0.944 \t\n",
      "\n",
      "Validation 584 valid_acc: 0.759 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 585 train_loss: 0.159 train_f1: 0.947 \t\n",
      "\n",
      "Validation 585 valid_acc: 0.754 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 586 train_loss: 0.153 train_f1: 0.947 \t\n",
      "\n",
      "Validation 586 valid_acc: 0.763 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 587 train_loss: 0.156 train_f1: 0.947 \t\n",
      "\n",
      "Validation 587 valid_acc: 0.765 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 588 train_loss: 0.149 train_f1: 0.953 \t\n",
      "\n",
      "Validation 588 valid_acc: 0.764 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 589 train_loss: 0.157 train_f1: 0.948 \t\n",
      "\n",
      "Validation 589 valid_acc: 0.770 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 590 train_loss: 0.139 train_f1: 0.955 \t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation 590 valid_acc: 0.762 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 591 train_loss: 0.149 train_f1: 0.950 \t\n",
      "\n",
      "Validation 591 valid_acc: 0.765 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 592 train_loss: 0.150 train_f1: 0.952 \t\n",
      "\n",
      "Validation 592 valid_acc: 0.762 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 593 train_loss: 0.150 train_f1: 0.946 \t\n",
      "\n",
      "Validation 593 valid_acc: 0.769 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 594 train_loss: 0.164 train_f1: 0.946 \t\n",
      "\n",
      "Validation 594 valid_acc: 0.751 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 595 train_loss: 0.140 train_f1: 0.952 \t\n",
      "\n",
      "Validation 595 valid_acc: 0.762 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 596 train_loss: 0.143 train_f1: 0.952 \t\n",
      "\n",
      "Validation 596 valid_acc: 0.766 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 597 train_loss: 0.137 train_f1: 0.956 \t\n",
      "\n",
      "Validation 597 valid_acc: 0.742 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 598 train_loss: 0.151 train_f1: 0.948 \t\n",
      "\n",
      "Validation 598 valid_acc: 0.745 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 599 train_loss: 0.153 train_f1: 0.949 \t\n",
      "\n",
      "Validation 599 valid_acc: 0.754 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 600 train_loss: 0.143 train_f1: 0.952 \t\n",
      "\n",
      "Validation 600 valid_acc: 0.760 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 601 train_loss: 0.152 train_f1: 0.949 \t\n",
      "\n",
      "Validation 601 valid_acc: 0.758 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 602 train_loss: 0.147 train_f1: 0.954 \t\n",
      "\n",
      "Validation 602 valid_acc: 0.756 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 603 train_loss: 0.132 train_f1: 0.956 \t\n",
      "\n",
      "Validation 603 valid_acc: 0.758 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 604 train_loss: 0.155 train_f1: 0.946 \t\n",
      "\n",
      "Validation 604 valid_acc: 0.760 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 605 train_loss: 0.132 train_f1: 0.957 \t\n",
      "\n",
      "Validation 605 valid_acc: 0.763 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 606 train_loss: 0.142 train_f1: 0.954 \t\n",
      "\n",
      "Validation 606 valid_acc: 0.758 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 607 train_loss: 0.139 train_f1: 0.955 \t\n",
      "\n",
      "Validation 607 valid_acc: 0.767 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 608 train_loss: 0.134 train_f1: 0.957 \t\n",
      "\n",
      "Validation 608 valid_acc: 0.772 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 609 train_loss: 0.122 train_f1: 0.959 \t\n",
      "\n",
      "Validation 609 valid_acc: 0.768 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 610 train_loss: 0.156 train_f1: 0.948 \t\n",
      "\n",
      "Validation 610 valid_acc: 0.765 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 611 train_loss: 0.134 train_f1: 0.955 \t\n",
      "\n",
      "Validation 611 valid_acc: 0.740 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 612 train_loss: 0.138 train_f1: 0.954 \t\n",
      "\n",
      "Validation 612 valid_acc: 0.760 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 613 train_loss: 0.140 train_f1: 0.951 \t\n",
      "\n",
      "Validation 613 valid_acc: 0.756 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 614 train_loss: 0.139 train_f1: 0.953 \t\n",
      "\n",
      "Validation 614 valid_acc: 0.739 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 615 train_loss: 0.142 train_f1: 0.954 \t\n",
      "\n",
      "Validation 615 valid_acc: 0.760 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 616 train_loss: 0.135 train_f1: 0.954 \t\n",
      "\n",
      "Validation 616 valid_acc: 0.753 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 617 train_loss: 0.132 train_f1: 0.955 \t\n",
      "\n",
      "Validation 617 valid_acc: 0.757 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 618 train_loss: 0.130 train_f1: 0.957 \t\n",
      "\n",
      "Validation 618 valid_acc: 0.764 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 619 train_loss: 0.109 train_f1: 0.964 \t\n",
      "\n",
      "Validation 619 valid_acc: 0.754 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 620 train_loss: 0.126 train_f1: 0.959 \t\n",
      "\n",
      "Validation 620 valid_acc: 0.774 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 621 train_loss: 0.118 train_f1: 0.961 \t\n",
      "\n",
      "Validation 621 valid_acc: 0.762 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 622 train_loss: 0.128 train_f1: 0.958 \t\n",
      "\n",
      "Validation 622 valid_acc: 0.769 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 623 train_loss: 0.129 train_f1: 0.958 \t\n",
      "\n",
      "Validation 623 valid_acc: 0.755 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 624 train_loss: 0.115 train_f1: 0.962 \t\n",
      "\n",
      "Validation 624 valid_acc: 0.751 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 625 train_loss: 0.130 train_f1: 0.959 \t\n",
      "\n",
      "Validation 625 valid_acc: 0.762 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 626 train_loss: 0.134 train_f1: 0.956 \t\n",
      "\n",
      "Validation 626 valid_acc: 0.764 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 627 train_loss: 0.114 train_f1: 0.963 \t\n",
      "\n",
      "Validation 627 valid_acc: 0.750 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 628 train_loss: 0.124 train_f1: 0.960 \t\n",
      "\n",
      "Validation 628 valid_acc: 0.736 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 629 train_loss: 0.129 train_f1: 0.956 \t\n",
      "\n",
      "Validation 629 valid_acc: 0.740 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 630 train_loss: 0.122 train_f1: 0.959 \t\n",
      "\n",
      "Validation 630 valid_acc: 0.749 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 631 train_loss: 0.123 train_f1: 0.958 \t\n",
      "\n",
      "Validation 631 valid_acc: 0.751 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 632 train_loss: 0.117 train_f1: 0.962 \t\n",
      "\n",
      "Validation 632 valid_acc: 0.762 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 633 train_loss: 0.129 train_f1: 0.958 \t\n",
      "\n",
      "Validation 633 valid_acc: 0.755 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 634 train_loss: 0.117 train_f1: 0.962 \t\n",
      "\n",
      "Validation 634 valid_acc: 0.761 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 635 train_loss: 0.117 train_f1: 0.961 \t\n",
      "\n",
      "Validation 635 valid_acc: 0.760 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 636 train_loss: 0.119 train_f1: 0.960 \t\n",
      "\n",
      "Validation 636 valid_acc: 0.751 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 637 train_loss: 0.134 train_f1: 0.959 \t\n",
      "\n",
      "Validation 637 valid_acc: 0.763 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 638 train_loss: 0.127 train_f1: 0.957 \t\n",
      "\n",
      "Validation 638 valid_acc: 0.754 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 639 train_loss: 0.117 train_f1: 0.961 \t\n",
      "\n",
      "Validation 639 valid_acc: 0.756 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 640 train_loss: 0.134 train_f1: 0.957 \t\n",
      "\n",
      "Validation 640 valid_acc: 0.760 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 641 train_loss: 0.112 train_f1: 0.962 \t\n",
      "\n",
      "Validation 641 valid_acc: 0.759 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 642 train_loss: 0.116 train_f1: 0.962 \t\n",
      "\n",
      "Validation 642 valid_acc: 0.750 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 643 train_loss: 0.121 train_f1: 0.958 \t\n",
      "\n",
      "Validation 643 valid_acc: 0.753 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 644 train_loss: 0.119 train_f1: 0.959 \t\n",
      "\n",
      "Validation 644 valid_acc: 0.759 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 645 train_loss: 0.123 train_f1: 0.958 \t\n",
      "\n",
      "Validation 645 valid_acc: 0.766 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 646 train_loss: 0.112 train_f1: 0.963 \t\n",
      "\n",
      "Validation 646 valid_acc: 0.762 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 647 train_loss: 0.121 train_f1: 0.959 \t\n",
      "\n",
      "Validation 647 valid_acc: 0.763 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 648 train_loss: 0.112 train_f1: 0.962 \t\n",
      "\n",
      "Validation 648 valid_acc: 0.760 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 649 train_loss: 0.112 train_f1: 0.965 \t\n",
      "\n",
      "Validation 649 valid_acc: 0.745 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 650 train_loss: 0.115 train_f1: 0.963 \t\n",
      "\n",
      "Validation 650 valid_acc: 0.765 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 651 train_loss: 0.129 train_f1: 0.957 \t\n",
      "\n",
      "Validation 651 valid_acc: 0.750 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 652 train_loss: 0.103 train_f1: 0.965 \t\n",
      "\n",
      "Validation 652 valid_acc: 0.757 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 653 train_loss: 0.120 train_f1: 0.961 \t\n",
      "\n",
      "Validation 653 valid_acc: 0.746 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 654 train_loss: 0.110 train_f1: 0.963 \t\n",
      "\n",
      "Validation 654 valid_acc: 0.764 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 655 train_loss: 0.107 train_f1: 0.964 \t\n",
      "\n",
      "Validation 655 valid_acc: 0.760 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 656 train_loss: 0.106 train_f1: 0.964 \t\n",
      "\n",
      "Validation 656 valid_acc: 0.762 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 657 train_loss: 0.109 train_f1: 0.966 \t\n",
      "\n",
      "Validation 657 valid_acc: 0.761 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 658 train_loss: 0.106 train_f1: 0.967 \t\n",
      "\n",
      "Validation 658 valid_acc: 0.758 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 659 train_loss: 0.109 train_f1: 0.964 \t\n",
      "\n",
      "Validation 659 valid_acc: 0.762 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 660 train_loss: 0.097 train_f1: 0.968 \t\n",
      "\n",
      "Validation 660 valid_acc: 0.760 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 661 train_loss: 0.103 train_f1: 0.966 \t\n",
      "\n",
      "Validation 661 valid_acc: 0.755 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 662 train_loss: 0.100 train_f1: 0.967 \t\n",
      "\n",
      "Validation 662 valid_acc: 0.752 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 663 train_loss: 0.091 train_f1: 0.971 \t\n",
      "\n",
      "Validation 663 valid_acc: 0.754 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 664 train_loss: 0.098 train_f1: 0.969 \t\n",
      "\n",
      "Validation 664 valid_acc: 0.763 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 665 train_loss: 0.113 train_f1: 0.961 \t\n",
      "\n",
      "Validation 665 valid_acc: 0.754 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 666 train_loss: 0.107 train_f1: 0.966 \t\n",
      "\n",
      "Validation 666 valid_acc: 0.762 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 667 train_loss: 0.107 train_f1: 0.966 \t\n",
      "\n",
      "Validation 667 valid_acc: 0.744 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 668 train_loss: 0.112 train_f1: 0.963 \t\n",
      "\n",
      "Validation 668 valid_acc: 0.762 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 669 train_loss: 0.101 train_f1: 0.967 \t\n",
      "\n",
      "Validation 669 valid_acc: 0.756 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 670 train_loss: 0.100 train_f1: 0.967 \t\n",
      "\n",
      "Validation 670 valid_acc: 0.758 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 671 train_loss: 0.099 train_f1: 0.967 \t\n",
      "\n",
      "Validation 671 valid_acc: 0.751 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 672 train_loss: 0.093 train_f1: 0.970 \t\n",
      "\n",
      "Validation 672 valid_acc: 0.740 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 673 train_loss: 0.097 train_f1: 0.967 \t\n",
      "\n",
      "Validation 673 valid_acc: 0.740 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 674 train_loss: 0.106 train_f1: 0.966 \t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation 674 valid_acc: 0.740 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 675 train_loss: 0.084 train_f1: 0.974 \t\n",
      "\n",
      "Validation 675 valid_acc: 0.742 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 676 train_loss: 0.091 train_f1: 0.972 \t\n",
      "\n",
      "Validation 676 valid_acc: 0.759 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 677 train_loss: 0.095 train_f1: 0.970 \t\n",
      "\n",
      "Validation 677 valid_acc: 0.759 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 678 train_loss: 0.088 train_f1: 0.971 \t\n",
      "\n",
      "Validation 678 valid_acc: 0.764 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 679 train_loss: 0.112 train_f1: 0.965 \t\n",
      "\n",
      "Validation 679 valid_acc: 0.736 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 680 train_loss: 0.093 train_f1: 0.970 \t\n",
      "\n",
      "Validation 680 valid_acc: 0.750 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 681 train_loss: 0.108 train_f1: 0.966 \t\n",
      "\n",
      "Validation 681 valid_acc: 0.765 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 682 train_loss: 0.098 train_f1: 0.969 \t\n",
      "\n",
      "Validation 682 valid_acc: 0.751 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 683 train_loss: 0.107 train_f1: 0.963 \t\n",
      "\n",
      "Validation 683 valid_acc: 0.753 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 684 train_loss: 0.087 train_f1: 0.969 \t\n",
      "\n",
      "Validation 684 valid_acc: 0.749 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 685 train_loss: 0.098 train_f1: 0.968 \t\n",
      "\n",
      "Validation 685 valid_acc: 0.757 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 686 train_loss: 0.093 train_f1: 0.967 \t\n",
      "\n",
      "Validation 686 valid_acc: 0.750 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 687 train_loss: 0.083 train_f1: 0.974 \t\n",
      "\n",
      "Validation 687 valid_acc: 0.747 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 688 train_loss: 0.099 train_f1: 0.969 \t\n",
      "\n",
      "Validation 688 valid_acc: 0.758 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 689 train_loss: 0.103 train_f1: 0.966 \t\n",
      "\n",
      "Validation 689 valid_acc: 0.748 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 690 train_loss: 0.099 train_f1: 0.965 \t\n",
      "\n",
      "Validation 690 valid_acc: 0.761 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 691 train_loss: 0.093 train_f1: 0.970 \t\n",
      "\n",
      "Validation 691 valid_acc: 0.752 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 692 train_loss: 0.093 train_f1: 0.969 \t\n",
      "\n",
      "Validation 692 valid_acc: 0.758 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 693 train_loss: 0.101 train_f1: 0.967 \t\n",
      "\n",
      "Validation 693 valid_acc: 0.763 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 694 train_loss: 0.095 train_f1: 0.968 \t\n",
      "\n",
      "Validation 694 valid_acc: 0.755 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 695 train_loss: 0.099 train_f1: 0.967 \t\n",
      "\n",
      "Validation 695 valid_acc: 0.764 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 696 train_loss: 0.092 train_f1: 0.971 \t\n",
      "\n",
      "Validation 696 valid_acc: 0.759 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 697 train_loss: 0.092 train_f1: 0.971 \t\n",
      "\n",
      "Validation 697 valid_acc: 0.754 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 698 train_loss: 0.098 train_f1: 0.969 \t\n",
      "\n",
      "Validation 698 valid_acc: 0.763 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 699 train_loss: 0.086 train_f1: 0.972 \t\n",
      "\n",
      "Validation 699 valid_acc: 0.751 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 700 train_loss: 0.087 train_f1: 0.970 \t\n",
      "\n",
      "Validation 700 valid_acc: 0.745 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 701 train_loss: 0.088 train_f1: 0.971 \t\n",
      "\n",
      "Validation 701 valid_acc: 0.749 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 702 train_loss: 0.088 train_f1: 0.972 \t\n",
      "\n",
      "Validation 702 valid_acc: 0.746 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 703 train_loss: 0.075 train_f1: 0.977 \t\n",
      "\n",
      "Validation 703 valid_acc: 0.768 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 704 train_loss: 0.089 train_f1: 0.972 \t\n",
      "\n",
      "Validation 704 valid_acc: 0.750 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 705 train_loss: 0.089 train_f1: 0.969 \t\n",
      "\n",
      "Validation 705 valid_acc: 0.748 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 706 train_loss: 0.084 train_f1: 0.974 \t\n",
      "\n",
      "Validation 706 valid_acc: 0.765 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 707 train_loss: 0.079 train_f1: 0.974 \t\n",
      "\n",
      "Validation 707 valid_acc: 0.748 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 708 train_loss: 0.080 train_f1: 0.975 \t\n",
      "\n",
      "Validation 708 valid_acc: 0.741 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 709 train_loss: 0.082 train_f1: 0.973 \t\n",
      "\n",
      "Validation 709 valid_acc: 0.763 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 710 train_loss: 0.075 train_f1: 0.973 \t\n",
      "\n",
      "Validation 710 valid_acc: 0.763 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 711 train_loss: 0.087 train_f1: 0.972 \t\n",
      "\n",
      "Validation 711 valid_acc: 0.750 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 712 train_loss: 0.077 train_f1: 0.974 \t\n",
      "\n",
      "Validation 712 valid_acc: 0.766 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 713 train_loss: 0.079 train_f1: 0.973 \t\n",
      "\n",
      "Validation 713 valid_acc: 0.744 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 714 train_loss: 0.086 train_f1: 0.974 \t\n",
      "\n",
      "Validation 714 valid_acc: 0.744 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 715 train_loss: 0.081 train_f1: 0.974 \t\n",
      "\n",
      "Validation 715 valid_acc: 0.764 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 716 train_loss: 0.082 train_f1: 0.973 \t\n",
      "\n",
      "Validation 716 valid_acc: 0.772 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 717 train_loss: 0.101 train_f1: 0.967 \t\n",
      "\n",
      "Validation 717 valid_acc: 0.758 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 718 train_loss: 0.088 train_f1: 0.972 \t\n",
      "\n",
      "Validation 718 valid_acc: 0.751 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 719 train_loss: 0.099 train_f1: 0.968 \t\n",
      "\n",
      "Validation 719 valid_acc: 0.751 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 720 train_loss: 0.092 train_f1: 0.970 \t\n",
      "\n",
      "Validation 720 valid_acc: 0.745 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 721 train_loss: 0.082 train_f1: 0.974 \t\n",
      "\n",
      "Validation 721 valid_acc: 0.752 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 722 train_loss: 0.083 train_f1: 0.973 \t\n",
      "\n",
      "Validation 722 valid_acc: 0.743 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 723 train_loss: 0.080 train_f1: 0.972 \t\n",
      "\n",
      "Validation 723 valid_acc: 0.766 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 724 train_loss: 0.079 train_f1: 0.974 \t\n",
      "\n",
      "Validation 724 valid_acc: 0.756 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 725 train_loss: 0.081 train_f1: 0.973 \t\n",
      "\n",
      "Validation 725 valid_acc: 0.743 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 726 train_loss: 0.078 train_f1: 0.973 \t\n",
      "\n",
      "Validation 726 valid_acc: 0.747 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 727 train_loss: 0.082 train_f1: 0.972 \t\n",
      "\n",
      "Validation 727 valid_acc: 0.743 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 728 train_loss: 0.089 train_f1: 0.970 \t\n",
      "\n",
      "Validation 728 valid_acc: 0.736 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 729 train_loss: 0.083 train_f1: 0.973 \t\n",
      "\n",
      "Validation 729 valid_acc: 0.758 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 730 train_loss: 0.069 train_f1: 0.979 \t\n",
      "\n",
      "Validation 730 valid_acc: 0.759 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 731 train_loss: 0.079 train_f1: 0.974 \t\n",
      "\n",
      "Validation 731 valid_acc: 0.748 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 732 train_loss: 0.076 train_f1: 0.975 \t\n",
      "\n",
      "Validation 732 valid_acc: 0.740 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 733 train_loss: 0.066 train_f1: 0.979 \t\n",
      "\n",
      "Validation 733 valid_acc: 0.754 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 734 train_loss: 0.068 train_f1: 0.977 \t\n",
      "\n",
      "Validation 734 valid_acc: 0.759 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 735 train_loss: 0.079 train_f1: 0.974 \t\n",
      "\n",
      "Validation 735 valid_acc: 0.759 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 736 train_loss: 0.058 train_f1: 0.982 \t\n",
      "\n",
      "Validation 736 valid_acc: 0.748 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 737 train_loss: 0.071 train_f1: 0.977 \t\n",
      "\n",
      "Validation 737 valid_acc: 0.744 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 738 train_loss: 0.071 train_f1: 0.979 \t\n",
      "\n",
      "Validation 738 valid_acc: 0.728 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 739 train_loss: 0.074 train_f1: 0.975 \t\n",
      "\n",
      "Validation 739 valid_acc: 0.750 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 740 train_loss: 0.087 train_f1: 0.972 \t\n",
      "\n",
      "Validation 740 valid_acc: 0.754 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 741 train_loss: 0.071 train_f1: 0.979 \t\n",
      "\n",
      "Validation 741 valid_acc: 0.760 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 742 train_loss: 0.083 train_f1: 0.973 \t\n",
      "\n",
      "Validation 742 valid_acc: 0.759 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 743 train_loss: 0.064 train_f1: 0.979 \t\n",
      "\n",
      "Validation 743 valid_acc: 0.750 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 744 train_loss: 0.074 train_f1: 0.978 \t\n",
      "\n",
      "Validation 744 valid_acc: 0.747 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 745 train_loss: 0.085 train_f1: 0.971 \t\n",
      "\n",
      "Validation 745 valid_acc: 0.758 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 746 train_loss: 0.074 train_f1: 0.974 \t\n",
      "\n",
      "Validation 746 valid_acc: 0.740 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 747 train_loss: 0.069 train_f1: 0.978 \t\n",
      "\n",
      "Validation 747 valid_acc: 0.753 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 748 train_loss: 0.067 train_f1: 0.978 \t\n",
      "\n",
      "Validation 748 valid_acc: 0.760 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 749 train_loss: 0.075 train_f1: 0.974 \t\n",
      "\n",
      "Validation 749 valid_acc: 0.747 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 750 train_loss: 0.078 train_f1: 0.974 \t\n",
      "\n",
      "Validation 750 valid_acc: 0.750 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 751 train_loss: 0.079 train_f1: 0.974 \t\n",
      "\n",
      "Validation 751 valid_acc: 0.751 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 752 train_loss: 0.073 train_f1: 0.977 \t\n",
      "\n",
      "Validation 752 valid_acc: 0.749 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 753 train_loss: 0.078 train_f1: 0.974 \t\n",
      "\n",
      "Validation 753 valid_acc: 0.751 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 754 train_loss: 0.068 train_f1: 0.976 \t\n",
      "\n",
      "Validation 754 valid_acc: 0.753 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 755 train_loss: 0.071 train_f1: 0.978 \t\n",
      "\n",
      "Validation 755 valid_acc: 0.762 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 756 train_loss: 0.074 train_f1: 0.976 \t\n",
      "\n",
      "Validation 756 valid_acc: 0.766 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 757 train_loss: 0.072 train_f1: 0.976 \t\n",
      "\n",
      "Validation 757 valid_acc: 0.757 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 758 train_loss: 0.070 train_f1: 0.978 \t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation 758 valid_acc: 0.761 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 759 train_loss: 0.074 train_f1: 0.976 \t\n",
      "\n",
      "Validation 759 valid_acc: 0.754 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 760 train_loss: 0.078 train_f1: 0.974 \t\n",
      "\n",
      "Validation 760 valid_acc: 0.764 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 761 train_loss: 0.071 train_f1: 0.978 \t\n",
      "\n",
      "Validation 761 valid_acc: 0.747 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 762 train_loss: 0.075 train_f1: 0.975 \t\n",
      "\n",
      "Validation 762 valid_acc: 0.750 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 763 train_loss: 0.072 train_f1: 0.976 \t\n",
      "\n",
      "Validation 763 valid_acc: 0.762 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 764 train_loss: 0.059 train_f1: 0.982 \t\n",
      "\n",
      "Validation 764 valid_acc: 0.752 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 765 train_loss: 0.062 train_f1: 0.981 \t\n",
      "\n",
      "Validation 765 valid_acc: 0.757 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 766 train_loss: 0.074 train_f1: 0.976 \t\n",
      "\n",
      "Validation 766 valid_acc: 0.758 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 767 train_loss: 0.064 train_f1: 0.981 \t\n",
      "\n",
      "Validation 767 valid_acc: 0.746 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 768 train_loss: 0.075 train_f1: 0.977 \t\n",
      "\n",
      "Validation 768 valid_acc: 0.738 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 769 train_loss: 0.063 train_f1: 0.979 \t\n",
      "\n",
      "Validation 769 valid_acc: 0.760 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 770 train_loss: 0.078 train_f1: 0.974 \t\n",
      "\n",
      "Validation 770 valid_acc: 0.744 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 771 train_loss: 0.066 train_f1: 0.980 \t\n",
      "\n",
      "Validation 771 valid_acc: 0.763 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 772 train_loss: 0.062 train_f1: 0.980 \t\n",
      "\n",
      "Validation 772 valid_acc: 0.753 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 773 train_loss: 0.075 train_f1: 0.974 \t\n",
      "\n",
      "Validation 773 valid_acc: 0.741 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 774 train_loss: 0.067 train_f1: 0.977 \t\n",
      "\n",
      "Validation 774 valid_acc: 0.753 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 775 train_loss: 0.063 train_f1: 0.980 \t\n",
      "\n",
      "Validation 775 valid_acc: 0.758 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 776 train_loss: 0.063 train_f1: 0.979 \t\n",
      "\n",
      "Validation 776 valid_acc: 0.740 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 777 train_loss: 0.057 train_f1: 0.982 \t\n",
      "\n",
      "Validation 777 valid_acc: 0.769 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 778 train_loss: 0.057 train_f1: 0.981 \t\n",
      "\n",
      "Validation 778 valid_acc: 0.755 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 779 train_loss: 0.064 train_f1: 0.978 \t\n",
      "\n",
      "Validation 779 valid_acc: 0.753 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 780 train_loss: 0.064 train_f1: 0.979 \t\n",
      "\n",
      "Validation 780 valid_acc: 0.745 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 781 train_loss: 0.063 train_f1: 0.980 \t\n",
      "\n",
      "Validation 781 valid_acc: 0.752 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 782 train_loss: 0.057 train_f1: 0.982 \t\n",
      "\n",
      "Validation 782 valid_acc: 0.756 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 783 train_loss: 0.059 train_f1: 0.982 \t\n",
      "\n",
      "Validation 783 valid_acc: 0.749 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 784 train_loss: 0.074 train_f1: 0.974 \t\n",
      "\n",
      "Validation 784 valid_acc: 0.744 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 785 train_loss: 0.074 train_f1: 0.977 \t\n",
      "\n",
      "Validation 785 valid_acc: 0.760 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 786 train_loss: 0.073 train_f1: 0.977 \t\n",
      "\n",
      "Validation 786 valid_acc: 0.748 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 787 train_loss: 0.060 train_f1: 0.980 \t\n",
      "\n",
      "Validation 787 valid_acc: 0.762 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 788 train_loss: 0.064 train_f1: 0.979 \t\n",
      "\n",
      "Validation 788 valid_acc: 0.751 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 789 train_loss: 0.066 train_f1: 0.979 \t\n",
      "\n",
      "Validation 789 valid_acc: 0.755 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 790 train_loss: 0.058 train_f1: 0.981 \t\n",
      "\n",
      "Validation 790 valid_acc: 0.760 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 791 train_loss: 0.065 train_f1: 0.978 \t\n",
      "\n",
      "Validation 791 valid_acc: 0.748 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 792 train_loss: 0.065 train_f1: 0.979 \t\n",
      "\n",
      "Validation 792 valid_acc: 0.746 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 793 train_loss: 0.076 train_f1: 0.977 \t\n",
      "\n",
      "Validation 793 valid_acc: 0.756 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 794 train_loss: 0.067 train_f1: 0.977 \t\n",
      "\n",
      "Validation 794 valid_acc: 0.751 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 795 train_loss: 0.056 train_f1: 0.981 \t\n",
      "\n",
      "Validation 795 valid_acc: 0.739 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 796 train_loss: 0.061 train_f1: 0.980 \t\n",
      "\n",
      "Validation 796 valid_acc: 0.744 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 797 train_loss: 0.057 train_f1: 0.981 \t\n",
      "\n",
      "Validation 797 valid_acc: 0.752 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 798 train_loss: 0.064 train_f1: 0.979 \t\n",
      "\n",
      "Validation 798 valid_acc: 0.753 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 799 train_loss: 0.063 train_f1: 0.979 \t\n",
      "\n",
      "Validation 799 valid_acc: 0.727 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 800 train_loss: 0.063 train_f1: 0.979 \t\n",
      "\n",
      "Validation 800 valid_acc: 0.758 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 801 train_loss: 0.061 train_f1: 0.981 \t\n",
      "\n",
      "Validation 801 valid_acc: 0.747 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 802 train_loss: 0.059 train_f1: 0.979 \t\n",
      "\n",
      "Validation 802 valid_acc: 0.759 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 803 train_loss: 0.052 train_f1: 0.983 \t\n",
      "\n",
      "Validation 803 valid_acc: 0.749 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 804 train_loss: 0.059 train_f1: 0.981 \t\n",
      "\n",
      "Validation 804 valid_acc: 0.748 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 805 train_loss: 0.069 train_f1: 0.978 \t\n",
      "\n",
      "Validation 805 valid_acc: 0.760 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 806 train_loss: 0.060 train_f1: 0.980 \t\n",
      "\n",
      "Validation 806 valid_acc: 0.756 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 807 train_loss: 0.059 train_f1: 0.983 \t\n",
      "\n",
      "Validation 807 valid_acc: 0.754 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 808 train_loss: 0.057 train_f1: 0.984 \t\n",
      "\n",
      "Validation 808 valid_acc: 0.758 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 809 train_loss: 0.052 train_f1: 0.983 \t\n",
      "\n",
      "Validation 809 valid_acc: 0.760 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 810 train_loss: 0.053 train_f1: 0.983 \t\n",
      "\n",
      "Validation 810 valid_acc: 0.741 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 811 train_loss: 0.050 train_f1: 0.983 \t\n",
      "\n",
      "Validation 811 valid_acc: 0.757 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 812 train_loss: 0.049 train_f1: 0.985 \t\n",
      "\n",
      "Validation 812 valid_acc: 0.757 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 813 train_loss: 0.055 train_f1: 0.983 \t\n",
      "\n",
      "Validation 813 valid_acc: 0.745 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 814 train_loss: 0.066 train_f1: 0.977 \t\n",
      "\n",
      "Validation 814 valid_acc: 0.762 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 815 train_loss: 0.055 train_f1: 0.981 \t\n",
      "\n",
      "Validation 815 valid_acc: 0.760 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 816 train_loss: 0.055 train_f1: 0.981 \t\n",
      "\n",
      "Validation 816 valid_acc: 0.749 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 817 train_loss: 0.058 train_f1: 0.981 \t\n",
      "\n",
      "Validation 817 valid_acc: 0.762 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 818 train_loss: 0.059 train_f1: 0.981 \t\n",
      "\n",
      "Validation 818 valid_acc: 0.762 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 819 train_loss: 0.056 train_f1: 0.982 \t\n",
      "\n",
      "Validation 819 valid_acc: 0.751 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 820 train_loss: 0.058 train_f1: 0.979 \t\n",
      "\n",
      "Validation 820 valid_acc: 0.758 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 821 train_loss: 0.050 train_f1: 0.983 \t\n",
      "\n",
      "Validation 821 valid_acc: 0.750 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 822 train_loss: 0.062 train_f1: 0.981 \t\n",
      "\n",
      "Validation 822 valid_acc: 0.751 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 823 train_loss: 0.059 train_f1: 0.981 \t\n",
      "\n",
      "Validation 823 valid_acc: 0.760 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 824 train_loss: 0.057 train_f1: 0.982 \t\n",
      "\n",
      "Validation 824 valid_acc: 0.744 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 825 train_loss: 0.051 train_f1: 0.984 \t\n",
      "\n",
      "Validation 825 valid_acc: 0.760 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 826 train_loss: 0.064 train_f1: 0.980 \t\n",
      "\n",
      "Validation 826 valid_acc: 0.754 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 827 train_loss: 0.042 train_f1: 0.986 \t\n",
      "\n",
      "Validation 827 valid_acc: 0.760 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 828 train_loss: 0.056 train_f1: 0.982 \t\n",
      "\n",
      "Validation 828 valid_acc: 0.750 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 829 train_loss: 0.048 train_f1: 0.985 \t\n",
      "\n",
      "Validation 829 valid_acc: 0.754 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 830 train_loss: 0.061 train_f1: 0.980 \t\n",
      "\n",
      "Validation 830 valid_acc: 0.757 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 831 train_loss: 0.058 train_f1: 0.980 \t\n",
      "\n",
      "Validation 831 valid_acc: 0.753 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 832 train_loss: 0.054 train_f1: 0.984 \t\n",
      "\n",
      "Validation 832 valid_acc: 0.745 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 833 train_loss: 0.048 train_f1: 0.985 \t\n",
      "\n",
      "Validation 833 valid_acc: 0.749 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 834 train_loss: 0.059 train_f1: 0.982 \t\n",
      "\n",
      "Validation 834 valid_acc: 0.754 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 835 train_loss: 0.053 train_f1: 0.982 \t\n",
      "\n",
      "Validation 835 valid_acc: 0.759 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 836 train_loss: 0.061 train_f1: 0.982 \t\n",
      "\n",
      "Validation 836 valid_acc: 0.747 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 837 train_loss: 0.054 train_f1: 0.983 \t\n",
      "\n",
      "Validation 837 valid_acc: 0.750 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 838 train_loss: 0.045 train_f1: 0.987 \t\n",
      "\n",
      "Validation 838 valid_acc: 0.749 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 839 train_loss: 0.038 train_f1: 0.988 \t\n",
      "\n",
      "Validation 839 valid_acc: 0.758 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 840 train_loss: 0.052 train_f1: 0.982 \t\n",
      "\n",
      "Validation 840 valid_acc: 0.751 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 841 train_loss: 0.044 train_f1: 0.987 \t\n",
      "\n",
      "Validation 841 valid_acc: 0.751 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 842 train_loss: 0.057 train_f1: 0.980 \t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation 842 valid_acc: 0.744 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 843 train_loss: 0.048 train_f1: 0.984 \t\n",
      "\n",
      "Validation 843 valid_acc: 0.754 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 844 train_loss: 0.053 train_f1: 0.982 \t\n",
      "\n",
      "Validation 844 valid_acc: 0.750 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 845 train_loss: 0.051 train_f1: 0.984 \t\n",
      "\n",
      "Validation 845 valid_acc: 0.753 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 846 train_loss: 0.046 train_f1: 0.985 \t\n",
      "\n",
      "Validation 846 valid_acc: 0.754 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 847 train_loss: 0.039 train_f1: 0.987 \t\n",
      "\n",
      "Validation 847 valid_acc: 0.754 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 848 train_loss: 0.058 train_f1: 0.980 \t\n",
      "\n",
      "Validation 848 valid_acc: 0.746 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 849 train_loss: 0.052 train_f1: 0.981 \t\n",
      "\n",
      "Validation 849 valid_acc: 0.758 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 850 train_loss: 0.046 train_f1: 0.986 \t\n",
      "\n",
      "Validation 850 valid_acc: 0.762 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 851 train_loss: 0.055 train_f1: 0.983 \t\n",
      "\n",
      "Validation 851 valid_acc: 0.748 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 852 train_loss: 0.058 train_f1: 0.982 \t\n",
      "\n",
      "Validation 852 valid_acc: 0.755 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 853 train_loss: 0.056 train_f1: 0.981 \t\n",
      "\n",
      "Validation 853 valid_acc: 0.762 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 854 train_loss: 0.044 train_f1: 0.986 \t\n",
      "\n",
      "Validation 854 valid_acc: 0.754 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 855 train_loss: 0.050 train_f1: 0.984 \t\n",
      "\n",
      "Validation 855 valid_acc: 0.751 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 856 train_loss: 0.048 train_f1: 0.983 \t\n",
      "\n",
      "Validation 856 valid_acc: 0.762 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 857 train_loss: 0.049 train_f1: 0.984 \t\n",
      "\n",
      "Validation 857 valid_acc: 0.754 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 858 train_loss: 0.042 train_f1: 0.986 \t\n",
      "\n",
      "Validation 858 valid_acc: 0.753 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 859 train_loss: 0.052 train_f1: 0.984 \t\n",
      "\n",
      "Validation 859 valid_acc: 0.751 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 860 train_loss: 0.049 train_f1: 0.983 \t\n",
      "\n",
      "Validation 860 valid_acc: 0.747 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 861 train_loss: 0.042 train_f1: 0.987 \t\n",
      "\n",
      "Validation 861 valid_acc: 0.753 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 862 train_loss: 0.047 train_f1: 0.984 \t\n",
      "\n",
      "Validation 862 valid_acc: 0.760 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 863 train_loss: 0.049 train_f1: 0.984 \t\n",
      "\n",
      "Validation 863 valid_acc: 0.740 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 864 train_loss: 0.047 train_f1: 0.985 \t\n",
      "\n",
      "Validation 864 valid_acc: 0.740 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 865 train_loss: 0.052 train_f1: 0.984 \t\n",
      "\n",
      "Validation 865 valid_acc: 0.748 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 866 train_loss: 0.054 train_f1: 0.984 \t\n",
      "\n",
      "Validation 866 valid_acc: 0.751 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 867 train_loss: 0.051 train_f1: 0.984 \t\n",
      "\n",
      "Validation 867 valid_acc: 0.759 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 868 train_loss: 0.046 train_f1: 0.985 \t\n",
      "\n",
      "Validation 868 valid_acc: 0.751 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 869 train_loss: 0.064 train_f1: 0.980 \t\n",
      "\n",
      "Validation 869 valid_acc: 0.758 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 870 train_loss: 0.051 train_f1: 0.983 \t\n",
      "\n",
      "Validation 870 valid_acc: 0.765 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 871 train_loss: 0.049 train_f1: 0.984 \t\n",
      "\n",
      "Validation 871 valid_acc: 0.765 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 872 train_loss: 0.052 train_f1: 0.984 \t\n",
      "\n",
      "Validation 872 valid_acc: 0.747 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 873 train_loss: 0.053 train_f1: 0.982 \t\n",
      "\n",
      "Validation 873 valid_acc: 0.758 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 874 train_loss: 0.042 train_f1: 0.986 \t\n",
      "\n",
      "Validation 874 valid_acc: 0.754 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 875 train_loss: 0.040 train_f1: 0.988 \t\n",
      "\n",
      "Validation 875 valid_acc: 0.757 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 876 train_loss: 0.054 train_f1: 0.983 \t\n",
      "\n",
      "Validation 876 valid_acc: 0.733 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 877 train_loss: 0.047 train_f1: 0.986 \t\n",
      "\n",
      "Validation 877 valid_acc: 0.755 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 878 train_loss: 0.060 train_f1: 0.980 \t\n",
      "\n",
      "Validation 878 valid_acc: 0.765 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 879 train_loss: 0.040 train_f1: 0.986 \t\n",
      "\n",
      "Validation 879 valid_acc: 0.758 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 880 train_loss: 0.045 train_f1: 0.986 \t\n",
      "\n",
      "Validation 880 valid_acc: 0.754 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 881 train_loss: 0.043 train_f1: 0.986 \t\n",
      "\n",
      "Validation 881 valid_acc: 0.751 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 882 train_loss: 0.049 train_f1: 0.983 \t\n",
      "\n",
      "Validation 882 valid_acc: 0.731 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 883 train_loss: 0.055 train_f1: 0.982 \t\n",
      "\n",
      "Validation 883 valid_acc: 0.762 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 884 train_loss: 0.045 train_f1: 0.984 \t\n",
      "\n",
      "Validation 884 valid_acc: 0.750 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 885 train_loss: 0.049 train_f1: 0.985 \t\n",
      "\n",
      "Validation 885 valid_acc: 0.754 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 886 train_loss: 0.042 train_f1: 0.987 \t\n",
      "\n",
      "Validation 886 valid_acc: 0.759 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 887 train_loss: 0.049 train_f1: 0.983 \t\n",
      "\n",
      "Validation 887 valid_acc: 0.743 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 888 train_loss: 0.043 train_f1: 0.987 \t\n",
      "\n",
      "Validation 888 valid_acc: 0.750 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 889 train_loss: 0.052 train_f1: 0.984 \t\n",
      "\n",
      "Validation 889 valid_acc: 0.748 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 890 train_loss: 0.039 train_f1: 0.987 \t\n",
      "\n",
      "Validation 890 valid_acc: 0.733 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 891 train_loss: 0.041 train_f1: 0.987 \t\n",
      "\n",
      "Validation 891 valid_acc: 0.759 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 892 train_loss: 0.042 train_f1: 0.988 \t\n",
      "\n",
      "Validation 892 valid_acc: 0.758 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 893 train_loss: 0.049 train_f1: 0.984 \t\n",
      "\n",
      "Validation 893 valid_acc: 0.744 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 894 train_loss: 0.042 train_f1: 0.986 \t\n",
      "\n",
      "Validation 894 valid_acc: 0.743 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 895 train_loss: 0.042 train_f1: 0.986 \t\n",
      "\n",
      "Validation 895 valid_acc: 0.752 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 896 train_loss: 0.056 train_f1: 0.982 \t\n",
      "\n",
      "Validation 896 valid_acc: 0.747 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 897 train_loss: 0.044 train_f1: 0.987 \t\n",
      "\n",
      "Validation 897 valid_acc: 0.762 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 898 train_loss: 0.053 train_f1: 0.983 \t\n",
      "\n",
      "Validation 898 valid_acc: 0.759 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 899 train_loss: 0.041 train_f1: 0.987 \t\n",
      "\n",
      "Validation 899 valid_acc: 0.747 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 900 train_loss: 0.044 train_f1: 0.987 \t\n",
      "\n",
      "Validation 900 valid_acc: 0.751 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 901 train_loss: 0.029 train_f1: 0.991 \t\n",
      "\n",
      "Validation 901 valid_acc: 0.745 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 902 train_loss: 0.047 train_f1: 0.984 \t\n",
      "\n",
      "Validation 902 valid_acc: 0.752 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 903 train_loss: 0.046 train_f1: 0.985 \t\n",
      "\n",
      "Validation 903 valid_acc: 0.753 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 904 train_loss: 0.042 train_f1: 0.988 \t\n",
      "\n",
      "Validation 904 valid_acc: 0.758 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 905 train_loss: 0.044 train_f1: 0.985 \t\n",
      "\n",
      "Validation 905 valid_acc: 0.749 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 906 train_loss: 0.036 train_f1: 0.988 \t\n",
      "\n",
      "Validation 906 valid_acc: 0.760 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 907 train_loss: 0.042 train_f1: 0.988 \t\n",
      "\n",
      "Validation 907 valid_acc: 0.738 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 908 train_loss: 0.042 train_f1: 0.987 \t\n",
      "\n",
      "Validation 908 valid_acc: 0.759 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 909 train_loss: 0.040 train_f1: 0.987 \t\n",
      "\n",
      "Validation 909 valid_acc: 0.756 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 910 train_loss: 0.037 train_f1: 0.989 \t\n",
      "\n",
      "Validation 910 valid_acc: 0.741 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 911 train_loss: 0.046 train_f1: 0.985 \t\n",
      "\n",
      "Validation 911 valid_acc: 0.749 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 912 train_loss: 0.045 train_f1: 0.986 \t\n",
      "\n",
      "Validation 912 valid_acc: 0.754 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 913 train_loss: 0.043 train_f1: 0.988 \t\n",
      "\n",
      "Validation 913 valid_acc: 0.722 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 914 train_loss: 0.028 train_f1: 0.992 \t\n",
      "\n",
      "Validation 914 valid_acc: 0.749 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 915 train_loss: 0.035 train_f1: 0.989 \t\n",
      "\n",
      "Validation 915 valid_acc: 0.758 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 916 train_loss: 0.036 train_f1: 0.988 \t\n",
      "\n",
      "Validation 916 valid_acc: 0.746 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 917 train_loss: 0.039 train_f1: 0.989 \t\n",
      "\n",
      "Validation 917 valid_acc: 0.737 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 918 train_loss: 0.038 train_f1: 0.988 \t\n",
      "\n",
      "Validation 918 valid_acc: 0.757 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 919 train_loss: 0.045 train_f1: 0.986 \t\n",
      "\n",
      "Validation 919 valid_acc: 0.743 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 920 train_loss: 0.042 train_f1: 0.986 \t\n",
      "\n",
      "Validation 920 valid_acc: 0.749 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 921 train_loss: 0.036 train_f1: 0.988 \t\n",
      "\n",
      "Validation 921 valid_acc: 0.751 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 922 train_loss: 0.039 train_f1: 0.988 \t\n",
      "\n",
      "Validation 922 valid_acc: 0.757 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 923 train_loss: 0.048 train_f1: 0.984 \t\n",
      "\n",
      "Validation 923 valid_acc: 0.755 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 924 train_loss: 0.040 train_f1: 0.987 \t\n",
      "\n",
      "Validation 924 valid_acc: 0.745 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 925 train_loss: 0.039 train_f1: 0.987 \t\n",
      "\n",
      "Validation 925 valid_acc: 0.744 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 926 train_loss: 0.036 train_f1: 0.988 \t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation 926 valid_acc: 0.747 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 927 train_loss: 0.040 train_f1: 0.988 \t\n",
      "\n",
      "Validation 927 valid_acc: 0.743 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 928 train_loss: 0.041 train_f1: 0.987 \t\n",
      "\n",
      "Validation 928 valid_acc: 0.745 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 929 train_loss: 0.034 train_f1: 0.989 \t\n",
      "\n",
      "Validation 929 valid_acc: 0.751 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 930 train_loss: 0.042 train_f1: 0.985 \t\n",
      "\n",
      "Validation 930 valid_acc: 0.758 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 931 train_loss: 0.036 train_f1: 0.988 \t\n",
      "\n",
      "Validation 931 valid_acc: 0.754 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 932 train_loss: 0.037 train_f1: 0.987 \t\n",
      "\n",
      "Validation 932 valid_acc: 0.735 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 933 train_loss: 0.044 train_f1: 0.987 \t\n",
      "\n",
      "Validation 933 valid_acc: 0.749 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 934 train_loss: 0.036 train_f1: 0.988 \t\n",
      "\n",
      "Validation 934 valid_acc: 0.758 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 935 train_loss: 0.039 train_f1: 0.989 \t\n",
      "\n",
      "Validation 935 valid_acc: 0.746 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 936 train_loss: 0.045 train_f1: 0.984 \t\n",
      "\n",
      "Validation 936 valid_acc: 0.757 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 937 train_loss: 0.042 train_f1: 0.986 \t\n",
      "\n",
      "Validation 937 valid_acc: 0.750 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 938 train_loss: 0.039 train_f1: 0.988 \t\n",
      "\n",
      "Validation 938 valid_acc: 0.740 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 939 train_loss: 0.032 train_f1: 0.990 \t\n",
      "\n",
      "Validation 939 valid_acc: 0.747 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 940 train_loss: 0.044 train_f1: 0.986 \t\n",
      "\n",
      "Validation 940 valid_acc: 0.746 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 941 train_loss: 0.039 train_f1: 0.986 \t\n",
      "\n",
      "Validation 941 valid_acc: 0.752 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 942 train_loss: 0.035 train_f1: 0.988 \t\n",
      "\n",
      "Validation 942 valid_acc: 0.755 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 943 train_loss: 0.038 train_f1: 0.988 \t\n",
      "\n",
      "Validation 943 valid_acc: 0.739 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 944 train_loss: 0.039 train_f1: 0.986 \t\n",
      "\n",
      "Validation 944 valid_acc: 0.731 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 945 train_loss: 0.038 train_f1: 0.988 \t\n",
      "\n",
      "Validation 945 valid_acc: 0.752 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 946 train_loss: 0.034 train_f1: 0.989 \t\n",
      "\n",
      "Validation 946 valid_acc: 0.761 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 947 train_loss: 0.033 train_f1: 0.990 \t\n",
      "\n",
      "Validation 947 valid_acc: 0.754 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 948 train_loss: 0.048 train_f1: 0.985 \t\n",
      "\n",
      "Validation 948 valid_acc: 0.742 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 949 train_loss: 0.032 train_f1: 0.988 \t\n",
      "\n",
      "Validation 949 valid_acc: 0.743 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 950 train_loss: 0.036 train_f1: 0.990 \t\n",
      "\n",
      "Validation 950 valid_acc: 0.751 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 951 train_loss: 0.032 train_f1: 0.990 \t\n",
      "\n",
      "Validation 951 valid_acc: 0.751 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 952 train_loss: 0.042 train_f1: 0.986 \t\n",
      "\n",
      "Validation 952 valid_acc: 0.754 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 953 train_loss: 0.030 train_f1: 0.991 \t\n",
      "\n",
      "Validation 953 valid_acc: 0.763 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 954 train_loss: 0.030 train_f1: 0.991 \t\n",
      "\n",
      "Validation 954 valid_acc: 0.767 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 955 train_loss: 0.034 train_f1: 0.988 \t\n",
      "\n",
      "Validation 955 valid_acc: 0.746 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 956 train_loss: 0.035 train_f1: 0.989 \t\n",
      "\n",
      "Validation 956 valid_acc: 0.748 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 957 train_loss: 0.043 train_f1: 0.986 \t\n",
      "\n",
      "Validation 957 valid_acc: 0.752 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 958 train_loss: 0.033 train_f1: 0.990 \t\n",
      "\n",
      "Validation 958 valid_acc: 0.750 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 959 train_loss: 0.033 train_f1: 0.989 \t\n",
      "\n",
      "Validation 959 valid_acc: 0.752 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 960 train_loss: 0.037 train_f1: 0.989 \t\n",
      "\n",
      "Validation 960 valid_acc: 0.766 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 961 train_loss: 0.042 train_f1: 0.986 \t\n",
      "\n",
      "Validation 961 valid_acc: 0.762 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 962 train_loss: 0.042 train_f1: 0.986 \t\n",
      "\n",
      "Validation 962 valid_acc: 0.751 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 963 train_loss: 0.035 train_f1: 0.989 \t\n",
      "\n",
      "Validation 963 valid_acc: 0.762 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 964 train_loss: 0.036 train_f1: 0.988 \t\n",
      "\n",
      "Validation 964 valid_acc: 0.751 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 965 train_loss: 0.044 train_f1: 0.986 \t\n",
      "\n",
      "Validation 965 valid_acc: 0.750 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 966 train_loss: 0.026 train_f1: 0.992 \t\n",
      "\n",
      "Validation 966 valid_acc: 0.764 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 967 train_loss: 0.029 train_f1: 0.991 \t\n",
      "\n",
      "Validation 967 valid_acc: 0.747 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 968 train_loss: 0.038 train_f1: 0.988 \t\n",
      "\n",
      "Validation 968 valid_acc: 0.747 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 969 train_loss: 0.040 train_f1: 0.986 \t\n",
      "\n",
      "Validation 969 valid_acc: 0.733 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 970 train_loss: 0.032 train_f1: 0.990 \t\n",
      "\n",
      "Validation 970 valid_acc: 0.749 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 971 train_loss: 0.041 train_f1: 0.987 \t\n",
      "\n",
      "Validation 971 valid_acc: 0.740 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 972 train_loss: 0.034 train_f1: 0.989 \t\n",
      "\n",
      "Validation 972 valid_acc: 0.740 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 973 train_loss: 0.042 train_f1: 0.986 \t\n",
      "\n",
      "Validation 973 valid_acc: 0.735 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 974 train_loss: 0.038 train_f1: 0.988 \t\n",
      "\n",
      "Validation 974 valid_acc: 0.732 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 975 train_loss: 0.044 train_f1: 0.985 \t\n",
      "\n",
      "Validation 975 valid_acc: 0.744 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 976 train_loss: 0.048 train_f1: 0.986 \t\n",
      "\n",
      "Validation 976 valid_acc: 0.744 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 977 train_loss: 0.038 train_f1: 0.987 \t\n",
      "\n",
      "Validation 977 valid_acc: 0.744 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 978 train_loss: 0.031 train_f1: 0.989 \t\n",
      "\n",
      "Validation 978 valid_acc: 0.747 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 979 train_loss: 0.033 train_f1: 0.990 \t\n",
      "\n",
      "Validation 979 valid_acc: 0.754 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 980 train_loss: 0.033 train_f1: 0.989 \t\n",
      "\n",
      "Validation 980 valid_acc: 0.751 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 981 train_loss: 0.030 train_f1: 0.991 \t\n",
      "\n",
      "Validation 981 valid_acc: 0.748 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 982 train_loss: 0.031 train_f1: 0.991 \t\n",
      "\n",
      "Validation 982 valid_acc: 0.747 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 983 train_loss: 0.028 train_f1: 0.991 \t\n",
      "\n",
      "Validation 983 valid_acc: 0.740 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 984 train_loss: 0.035 train_f1: 0.989 \t\n",
      "\n",
      "Validation 984 valid_acc: 0.746 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 985 train_loss: 0.033 train_f1: 0.990 \t\n",
      "\n",
      "Validation 985 valid_acc: 0.750 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 986 train_loss: 0.035 train_f1: 0.989 \t\n",
      "\n",
      "Validation 986 valid_acc: 0.749 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 987 train_loss: 0.034 train_f1: 0.989 \t\n",
      "\n",
      "Validation 987 valid_acc: 0.751 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 988 train_loss: 0.029 train_f1: 0.991 \t\n",
      "\n",
      "Validation 988 valid_acc: 0.755 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 989 train_loss: 0.031 train_f1: 0.989 \t\n",
      "\n",
      "Validation 989 valid_acc: 0.747 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 990 train_loss: 0.033 train_f1: 0.990 \t\n",
      "\n",
      "Validation 990 valid_acc: 0.741 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 991 train_loss: 0.033 train_f1: 0.990 \t\n",
      "\n",
      "Validation 991 valid_acc: 0.747 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 992 train_loss: 0.036 train_f1: 0.989 \t\n",
      "\n",
      "Validation 992 valid_acc: 0.740 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 993 train_loss: 0.026 train_f1: 0.992 \t\n",
      "\n",
      "Validation 993 valid_acc: 0.744 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 994 train_loss: 0.022 train_f1: 0.995 \t\n",
      "\n",
      "Validation 994 valid_acc: 0.753 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 995 train_loss: 0.035 train_f1: 0.990 \t\n",
      "\n",
      "Validation 995 valid_acc: 0.766 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 996 train_loss: 0.039 train_f1: 0.988 \t\n",
      "\n",
      "Validation 996 valid_acc: 0.754 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 997 train_loss: 0.035 train_f1: 0.989 \t\n",
      "\n",
      "Validation 997 valid_acc: 0.744 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 998 train_loss: 0.033 train_f1: 0.989 \t\n",
      "\n",
      "Validation 998 valid_acc: 0.751 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 999 train_loss: 0.029 train_f1: 0.991 \t\n",
      "\n",
      "Validation 999 valid_acc: 0.751 best_acc: 0.782 \t\n",
      "\n",
      "Epoch 1000 train_loss: 0.040 train_f1: 0.990 \t\n",
      "\n",
      "Validation 1000 valid_acc: 0.748 best_acc: 0.782 \t\n",
      "49789.8383307457\n"
     ]
    }
   ],
   "source": [
    "# DISP DATETIME FOR CHECKING TIME\n",
    "start = time.time()\n",
    "val_acc_sum=[]\n",
    "train_loss_sum=[]\n",
    "train_acc_sum=[]\n",
    "val_loss_sum=[]\n",
    "val_acc_min = 0\n",
    "print(results_directory)\n",
    "\n",
    "for num_epoch in range(epochs):\n",
    "    random.shuffle(data_train)\n",
    "    train_loss, train_f1 = train(data_train, mel_directory, batch_size, class2index, minimum_len, x_mean_final, x_std_final)\n",
    "    print('\\nEpoch',num_epoch+1,'train_loss:',f'{train_loss:.3f}','train_f1:',f'{train_f1:.3f}',\"\\t\")\n",
    "    model_output = \"ECG_ABN_E%02dL%.2f\" % (num_epoch, train_loss)\n",
    "    save_name = os.path.join(results_directory, model_output)\n",
    "    \n",
    "    val_acc = test(data_val, mel_directory, input_directory, class2index, minimum_len, model, x_mean_final, x_std_final)\n",
    "\n",
    "    if val_acc > val_acc_min:\n",
    "        val_acc_min = val_acc\n",
    "        model.save(save_name)\n",
    "    print('\\nValidation', num_epoch+1, 'valid_acc:',f'{val_acc:.3f}', 'best_acc:',f'{val_acc_min:.3f}', \"\\t\")\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "395.881px",
    "left": "1487.43px",
    "right": "20px",
    "top": "128.94px",
    "width": "200.142px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
