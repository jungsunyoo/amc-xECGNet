{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0012702   0.00038759  0.00402317 -0.0029567   0.00051957  0.00116427\n",
      " -0.0008405  -0.00222516 -0.0019119  -0.00093502  0.00129789  0.00177598]\n",
      "(5225,) (276,) (1376,)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, 2880, 12)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)              (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_20 (Lambda)              (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)              (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)              (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_23 (Lambda)              (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_24 (Lambda)              (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_13 (GaussianNois (None, 2880, 1)      0           lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_14 (GaussianNois (None, 2880, 1)      0           lambda_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_15 (GaussianNois (None, 2880, 1)      0           lambda_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_16 (GaussianNois (None, 2880, 1)      0           lambda_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_17 (GaussianNois (None, 2880, 1)      0           lambda_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_18 (GaussianNois (None, 2880, 1)      0           lambda_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_19 (GaussianNois (None, 2880, 1)      0           lambda_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_20 (GaussianNois (None, 2880, 1)      0           lambda_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_21 (GaussianNois (None, 2880, 1)      0           lambda_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_22 (GaussianNois (None, 2880, 1)      0           lambda_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_23 (GaussianNois (None, 2880, 1)      0           lambda_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_24 (GaussianNois (None, 2880, 1)      0           lambda_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_109 (Conv1D)             (None, 2880, 32)     352         gaussian_noise_13[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_118 (Conv1D)             (None, 2880, 32)     352         gaussian_noise_14[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_127 (Conv1D)             (None, 2880, 32)     352         gaussian_noise_15[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_136 (Conv1D)             (None, 2880, 32)     352         gaussian_noise_16[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_145 (Conv1D)             (None, 2880, 32)     352         gaussian_noise_17[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_154 (Conv1D)             (None, 2880, 32)     352         gaussian_noise_18[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_163 (Conv1D)             (None, 2880, 32)     352         gaussian_noise_19[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_172 (Conv1D)             (None, 2880, 32)     352         gaussian_noise_20[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_181 (Conv1D)             (None, 2880, 32)     352         gaussian_noise_21[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_190 (Conv1D)             (None, 2880, 32)     352         gaussian_noise_22[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_199 (Conv1D)             (None, 2880, 32)     352         gaussian_noise_23[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_208 (Conv1D)             (None, 2880, 32)     352         gaussian_noise_24[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 2880, 32)     128         conv1d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 2880, 32)     128         conv1d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 2880, 32)     128         conv1d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 2880, 32)     128         conv1d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 2880, 32)     128         conv1d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 2880, 32)     128         conv1d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 2880, 32)     128         conv1d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 2880, 32)     128         conv1d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 2880, 32)     128         conv1d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 2880, 32)     128         conv1d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 2880, 32)     128         conv1d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 2880, 32)     128         conv1d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_97 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_105 (LeakyReLU)     (None, 2880, 32)     0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_113 (LeakyReLU)     (None, 2880, 32)     0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_121 (LeakyReLU)     (None, 2880, 32)     0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_129 (LeakyReLU)     (None, 2880, 32)     0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_137 (LeakyReLU)     (None, 2880, 32)     0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_145 (LeakyReLU)     (None, 2880, 32)     0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_153 (LeakyReLU)     (None, 2880, 32)     0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_161 (LeakyReLU)     (None, 2880, 32)     0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_169 (LeakyReLU)     (None, 2880, 32)     0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_177 (LeakyReLU)     (None, 2880, 32)     0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_185 (LeakyReLU)     (None, 2880, 32)     0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_110 (Conv1D)             (None, 2880, 32)     10272       leaky_re_lu_97[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_119 (Conv1D)             (None, 2880, 32)     10272       leaky_re_lu_105[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_128 (Conv1D)             (None, 2880, 32)     10272       leaky_re_lu_113[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_137 (Conv1D)             (None, 2880, 32)     10272       leaky_re_lu_121[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_146 (Conv1D)             (None, 2880, 32)     10272       leaky_re_lu_129[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_155 (Conv1D)             (None, 2880, 32)     10272       leaky_re_lu_137[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_164 (Conv1D)             (None, 2880, 32)     10272       leaky_re_lu_145[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_173 (Conv1D)             (None, 2880, 32)     10272       leaky_re_lu_153[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_182 (Conv1D)             (None, 2880, 32)     10272       leaky_re_lu_161[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_191 (Conv1D)             (None, 2880, 32)     10272       leaky_re_lu_169[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_200 (Conv1D)             (None, 2880, 32)     10272       leaky_re_lu_177[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_209 (Conv1D)             (None, 2880, 32)     10272       leaky_re_lu_185[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_37 (Add)                    (None, 2880, 32)     0           conv1d_110[0][0]                 \n",
      "                                                                 leaky_re_lu_97[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_40 (Add)                    (None, 2880, 32)     0           conv1d_119[0][0]                 \n",
      "                                                                 leaky_re_lu_105[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_43 (Add)                    (None, 2880, 32)     0           conv1d_128[0][0]                 \n",
      "                                                                 leaky_re_lu_113[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_46 (Add)                    (None, 2880, 32)     0           conv1d_137[0][0]                 \n",
      "                                                                 leaky_re_lu_121[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_49 (Add)                    (None, 2880, 32)     0           conv1d_146[0][0]                 \n",
      "                                                                 leaky_re_lu_129[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_52 (Add)                    (None, 2880, 32)     0           conv1d_155[0][0]                 \n",
      "                                                                 leaky_re_lu_137[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_55 (Add)                    (None, 2880, 32)     0           conv1d_164[0][0]                 \n",
      "                                                                 leaky_re_lu_145[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_58 (Add)                    (None, 2880, 32)     0           conv1d_173[0][0]                 \n",
      "                                                                 leaky_re_lu_153[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_61 (Add)                    (None, 2880, 32)     0           conv1d_182[0][0]                 \n",
      "                                                                 leaky_re_lu_161[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_64 (Add)                    (None, 2880, 32)     0           conv1d_191[0][0]                 \n",
      "                                                                 leaky_re_lu_169[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_67 (Add)                    (None, 2880, 32)     0           conv1d_200[0][0]                 \n",
      "                                                                 leaky_re_lu_177[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_70 (Add)                    (None, 2880, 32)     0           conv1d_209[0][0]                 \n",
      "                                                                 leaky_re_lu_185[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 2880, 32)     128         add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 2880, 32)     128         add_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 2880, 32)     128         add_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 2880, 32)     128         add_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 2880, 32)     128         add_49[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 2880, 32)     128         add_52[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 2880, 32)     128         add_55[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 2880, 32)     128         add_58[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 2880, 32)     128         add_61[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 2880, 32)     128         add_64[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 2880, 32)     128         add_67[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 2880, 32)     128         add_70[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_98 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_106 (LeakyReLU)     (None, 2880, 32)     0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_114 (LeakyReLU)     (None, 2880, 32)     0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_122 (LeakyReLU)     (None, 2880, 32)     0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_130 (LeakyReLU)     (None, 2880, 32)     0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_138 (LeakyReLU)     (None, 2880, 32)     0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_146 (LeakyReLU)     (None, 2880, 32)     0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_154 (LeakyReLU)     (None, 2880, 32)     0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_162 (LeakyReLU)     (None, 2880, 32)     0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_170 (LeakyReLU)     (None, 2880, 32)     0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_178 (LeakyReLU)     (None, 2880, 32)     0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_186 (LeakyReLU)     (None, 2880, 32)     0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_111 (Conv1D)             (None, 1440, 32)     20512       leaky_re_lu_98[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_120 (Conv1D)             (None, 1440, 32)     20512       leaky_re_lu_106[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_129 (Conv1D)             (None, 1440, 32)     20512       leaky_re_lu_114[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_138 (Conv1D)             (None, 1440, 32)     20512       leaky_re_lu_122[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_147 (Conv1D)             (None, 1440, 32)     20512       leaky_re_lu_130[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_156 (Conv1D)             (None, 1440, 32)     20512       leaky_re_lu_138[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_165 (Conv1D)             (None, 1440, 32)     20512       leaky_re_lu_146[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_174 (Conv1D)             (None, 1440, 32)     20512       leaky_re_lu_154[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_183 (Conv1D)             (None, 1440, 32)     20512       leaky_re_lu_162[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_192 (Conv1D)             (None, 1440, 32)     20512       leaky_re_lu_170[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_201 (Conv1D)             (None, 1440, 32)     20512       leaky_re_lu_178[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_210 (Conv1D)             (None, 1440, 32)     20512       leaky_re_lu_186[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_112 (Conv1D)             (None, 1440, 64)     20544       conv1d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_121 (Conv1D)             (None, 1440, 64)     20544       conv1d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_130 (Conv1D)             (None, 1440, 64)     20544       conv1d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_139 (Conv1D)             (None, 1440, 64)     20544       conv1d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_148 (Conv1D)             (None, 1440, 64)     20544       conv1d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_157 (Conv1D)             (None, 1440, 64)     20544       conv1d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_166 (Conv1D)             (None, 1440, 64)     20544       conv1d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_175 (Conv1D)             (None, 1440, 64)     20544       conv1d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_184 (Conv1D)             (None, 1440, 64)     20544       conv1d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_193 (Conv1D)             (None, 1440, 64)     20544       conv1d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_202 (Conv1D)             (None, 1440, 64)     20544       conv1d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_211 (Conv1D)             (None, 1440, 64)     20544       conv1d_210[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 1440, 64)     256         conv1d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 1440, 64)     256         conv1d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 1440, 64)     256         conv1d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 1440, 64)     256         conv1d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 1440, 64)     256         conv1d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 1440, 64)     256         conv1d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 1440, 64)     256         conv1d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 1440, 64)     256         conv1d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 1440, 64)     256         conv1d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 1440, 64)     256         conv1d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 1440, 64)     256         conv1d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 1440, 64)     256         conv1d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_99 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_107 (LeakyReLU)     (None, 1440, 64)     0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_115 (LeakyReLU)     (None, 1440, 64)     0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_123 (LeakyReLU)     (None, 1440, 64)     0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_131 (LeakyReLU)     (None, 1440, 64)     0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_139 (LeakyReLU)     (None, 1440, 64)     0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_147 (LeakyReLU)     (None, 1440, 64)     0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_155 (LeakyReLU)     (None, 1440, 64)     0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_163 (LeakyReLU)     (None, 1440, 64)     0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_171 (LeakyReLU)     (None, 1440, 64)     0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_179 (LeakyReLU)     (None, 1440, 64)     0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_187 (LeakyReLU)     (None, 1440, 64)     0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_113 (Conv1D)             (None, 1440, 64)     41024       leaky_re_lu_99[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_122 (Conv1D)             (None, 1440, 64)     41024       leaky_re_lu_107[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_131 (Conv1D)             (None, 1440, 64)     41024       leaky_re_lu_115[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_140 (Conv1D)             (None, 1440, 64)     41024       leaky_re_lu_123[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_149 (Conv1D)             (None, 1440, 64)     41024       leaky_re_lu_131[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_158 (Conv1D)             (None, 1440, 64)     41024       leaky_re_lu_139[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_167 (Conv1D)             (None, 1440, 64)     41024       leaky_re_lu_147[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_176 (Conv1D)             (None, 1440, 64)     41024       leaky_re_lu_155[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_185 (Conv1D)             (None, 1440, 64)     41024       leaky_re_lu_163[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_194 (Conv1D)             (None, 1440, 64)     41024       leaky_re_lu_171[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_203 (Conv1D)             (None, 1440, 64)     41024       leaky_re_lu_179[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_212 (Conv1D)             (None, 1440, 64)     41024       leaky_re_lu_187[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_38 (Add)                    (None, 1440, 64)     0           conv1d_113[0][0]                 \n",
      "                                                                 leaky_re_lu_99[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_41 (Add)                    (None, 1440, 64)     0           conv1d_122[0][0]                 \n",
      "                                                                 leaky_re_lu_107[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_44 (Add)                    (None, 1440, 64)     0           conv1d_131[0][0]                 \n",
      "                                                                 leaky_re_lu_115[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_47 (Add)                    (None, 1440, 64)     0           conv1d_140[0][0]                 \n",
      "                                                                 leaky_re_lu_123[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_50 (Add)                    (None, 1440, 64)     0           conv1d_149[0][0]                 \n",
      "                                                                 leaky_re_lu_131[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_53 (Add)                    (None, 1440, 64)     0           conv1d_158[0][0]                 \n",
      "                                                                 leaky_re_lu_139[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_56 (Add)                    (None, 1440, 64)     0           conv1d_167[0][0]                 \n",
      "                                                                 leaky_re_lu_147[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_59 (Add)                    (None, 1440, 64)     0           conv1d_176[0][0]                 \n",
      "                                                                 leaky_re_lu_155[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_62 (Add)                    (None, 1440, 64)     0           conv1d_185[0][0]                 \n",
      "                                                                 leaky_re_lu_163[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_65 (Add)                    (None, 1440, 64)     0           conv1d_194[0][0]                 \n",
      "                                                                 leaky_re_lu_171[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_68 (Add)                    (None, 1440, 64)     0           conv1d_203[0][0]                 \n",
      "                                                                 leaky_re_lu_179[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_71 (Add)                    (None, 1440, 64)     0           conv1d_212[0][0]                 \n",
      "                                                                 leaky_re_lu_187[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 1440, 64)     256         add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 1440, 64)     256         add_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 1440, 64)     256         add_44[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 1440, 64)     256         add_47[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 1440, 64)     256         add_50[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 1440, 64)     256         add_53[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 1440, 64)     256         add_56[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 1440, 64)     256         add_59[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 1440, 64)     256         add_62[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 1440, 64)     256         add_65[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 1440, 64)     256         add_68[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 1440, 64)     256         add_71[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_100 (LeakyReLU)     (None, 1440, 64)     0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_108 (LeakyReLU)     (None, 1440, 64)     0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_116 (LeakyReLU)     (None, 1440, 64)     0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_124 (LeakyReLU)     (None, 1440, 64)     0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_132 (LeakyReLU)     (None, 1440, 64)     0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_140 (LeakyReLU)     (None, 1440, 64)     0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_148 (LeakyReLU)     (None, 1440, 64)     0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_156 (LeakyReLU)     (None, 1440, 64)     0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_164 (LeakyReLU)     (None, 1440, 64)     0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_172 (LeakyReLU)     (None, 1440, 64)     0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_180 (LeakyReLU)     (None, 1440, 64)     0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_188 (LeakyReLU)     (None, 1440, 64)     0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_114 (Conv1D)             (None, 720, 32)      40992       leaky_re_lu_100[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_123 (Conv1D)             (None, 720, 32)      40992       leaky_re_lu_108[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_132 (Conv1D)             (None, 720, 32)      40992       leaky_re_lu_116[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_141 (Conv1D)             (None, 720, 32)      40992       leaky_re_lu_124[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_150 (Conv1D)             (None, 720, 32)      40992       leaky_re_lu_132[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_159 (Conv1D)             (None, 720, 32)      40992       leaky_re_lu_140[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_168 (Conv1D)             (None, 720, 32)      40992       leaky_re_lu_148[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_177 (Conv1D)             (None, 720, 32)      40992       leaky_re_lu_156[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_186 (Conv1D)             (None, 720, 32)      40992       leaky_re_lu_164[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_195 (Conv1D)             (None, 720, 32)      40992       leaky_re_lu_172[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_204 (Conv1D)             (None, 720, 32)      40992       leaky_re_lu_180[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_213 (Conv1D)             (None, 720, 32)      40992       leaky_re_lu_188[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_115 (Conv1D)             (None, 720, 128)     41088       conv1d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_124 (Conv1D)             (None, 720, 128)     41088       conv1d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_133 (Conv1D)             (None, 720, 128)     41088       conv1d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_142 (Conv1D)             (None, 720, 128)     41088       conv1d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_151 (Conv1D)             (None, 720, 128)     41088       conv1d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_160 (Conv1D)             (None, 720, 128)     41088       conv1d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_169 (Conv1D)             (None, 720, 128)     41088       conv1d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_178 (Conv1D)             (None, 720, 128)     41088       conv1d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_187 (Conv1D)             (None, 720, 128)     41088       conv1d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_196 (Conv1D)             (None, 720, 128)     41088       conv1d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_205 (Conv1D)             (None, 720, 128)     41088       conv1d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_214 (Conv1D)             (None, 720, 128)     41088       conv1d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 720, 128)     512         conv1d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 720, 128)     512         conv1d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 720, 128)     512         conv1d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 720, 128)     512         conv1d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 720, 128)     512         conv1d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 720, 128)     512         conv1d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 720, 128)     512         conv1d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 720, 128)     512         conv1d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 720, 128)     512         conv1d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 720, 128)     512         conv1d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 720, 128)     512         conv1d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 720, 128)     512         conv1d_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_101 (LeakyReLU)     (None, 720, 128)     0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_109 (LeakyReLU)     (None, 720, 128)     0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_117 (LeakyReLU)     (None, 720, 128)     0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_125 (LeakyReLU)     (None, 720, 128)     0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_133 (LeakyReLU)     (None, 720, 128)     0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_141 (LeakyReLU)     (None, 720, 128)     0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_149 (LeakyReLU)     (None, 720, 128)     0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_157 (LeakyReLU)     (None, 720, 128)     0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_165 (LeakyReLU)     (None, 720, 128)     0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_173 (LeakyReLU)     (None, 720, 128)     0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_181 (LeakyReLU)     (None, 720, 128)     0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_189 (LeakyReLU)     (None, 720, 128)     0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_116 (Conv1D)             (None, 720, 128)     163968      leaky_re_lu_101[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_125 (Conv1D)             (None, 720, 128)     163968      leaky_re_lu_109[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_134 (Conv1D)             (None, 720, 128)     163968      leaky_re_lu_117[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_143 (Conv1D)             (None, 720, 128)     163968      leaky_re_lu_125[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_152 (Conv1D)             (None, 720, 128)     163968      leaky_re_lu_133[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_161 (Conv1D)             (None, 720, 128)     163968      leaky_re_lu_141[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_170 (Conv1D)             (None, 720, 128)     163968      leaky_re_lu_149[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_179 (Conv1D)             (None, 720, 128)     163968      leaky_re_lu_157[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_188 (Conv1D)             (None, 720, 128)     163968      leaky_re_lu_165[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_197 (Conv1D)             (None, 720, 128)     163968      leaky_re_lu_173[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_206 (Conv1D)             (None, 720, 128)     163968      leaky_re_lu_181[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_215 (Conv1D)             (None, 720, 128)     163968      leaky_re_lu_189[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_39 (Add)                    (None, 720, 128)     0           conv1d_116[0][0]                 \n",
      "                                                                 leaky_re_lu_101[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_42 (Add)                    (None, 720, 128)     0           conv1d_125[0][0]                 \n",
      "                                                                 leaky_re_lu_109[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_45 (Add)                    (None, 720, 128)     0           conv1d_134[0][0]                 \n",
      "                                                                 leaky_re_lu_117[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_48 (Add)                    (None, 720, 128)     0           conv1d_143[0][0]                 \n",
      "                                                                 leaky_re_lu_125[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_51 (Add)                    (None, 720, 128)     0           conv1d_152[0][0]                 \n",
      "                                                                 leaky_re_lu_133[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_54 (Add)                    (None, 720, 128)     0           conv1d_161[0][0]                 \n",
      "                                                                 leaky_re_lu_141[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_57 (Add)                    (None, 720, 128)     0           conv1d_170[0][0]                 \n",
      "                                                                 leaky_re_lu_149[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_60 (Add)                    (None, 720, 128)     0           conv1d_179[0][0]                 \n",
      "                                                                 leaky_re_lu_157[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_63 (Add)                    (None, 720, 128)     0           conv1d_188[0][0]                 \n",
      "                                                                 leaky_re_lu_165[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_66 (Add)                    (None, 720, 128)     0           conv1d_197[0][0]                 \n",
      "                                                                 leaky_re_lu_173[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_69 (Add)                    (None, 720, 128)     0           conv1d_206[0][0]                 \n",
      "                                                                 leaky_re_lu_181[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_72 (Add)                    (None, 720, 128)     0           conv1d_215[0][0]                 \n",
      "                                                                 leaky_re_lu_189[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 720, 128)     512         add_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 720, 128)     512         add_42[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 720, 128)     512         add_45[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 720, 128)     512         add_48[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 720, 128)     512         add_51[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 720, 128)     512         add_54[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 720, 128)     512         add_57[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 720, 128)     512         add_60[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 720, 128)     512         add_63[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 720, 128)     512         add_66[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 720, 128)     512         add_69[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 720, 128)     512         add_72[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_102 (LeakyReLU)     (None, 720, 128)     0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_110 (LeakyReLU)     (None, 720, 128)     0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_118 (LeakyReLU)     (None, 720, 128)     0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_126 (LeakyReLU)     (None, 720, 128)     0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_134 (LeakyReLU)     (None, 720, 128)     0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_142 (LeakyReLU)     (None, 720, 128)     0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_150 (LeakyReLU)     (None, 720, 128)     0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_158 (LeakyReLU)     (None, 720, 128)     0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_166 (LeakyReLU)     (None, 720, 128)     0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_174 (LeakyReLU)     (None, 720, 128)     0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_182 (LeakyReLU)     (None, 720, 128)     0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_190 (LeakyReLU)     (None, 720, 128)     0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_117 (Conv1D)             (None, 360, 64)      163904      leaky_re_lu_102[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_126 (Conv1D)             (None, 360, 64)      163904      leaky_re_lu_110[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_135 (Conv1D)             (None, 360, 64)      163904      leaky_re_lu_118[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_144 (Conv1D)             (None, 360, 64)      163904      leaky_re_lu_126[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_153 (Conv1D)             (None, 360, 64)      163904      leaky_re_lu_134[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_162 (Conv1D)             (None, 360, 64)      163904      leaky_re_lu_142[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_171 (Conv1D)             (None, 360, 64)      163904      leaky_re_lu_150[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_180 (Conv1D)             (None, 360, 64)      163904      leaky_re_lu_158[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_189 (Conv1D)             (None, 360, 64)      163904      leaky_re_lu_166[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_198 (Conv1D)             (None, 360, 64)      163904      leaky_re_lu_174[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_207 (Conv1D)             (None, 360, 64)      163904      leaky_re_lu_182[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_216 (Conv1D)             (None, 360, 64)      163904      leaky_re_lu_190[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_13 (Bidirectional (None, 360, 256)     148992      conv1d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_14 (Bidirectional (None, 360, 256)     148992      conv1d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_15 (Bidirectional (None, 360, 256)     148992      conv1d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_16 (Bidirectional (None, 360, 256)     148992      conv1d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_17 (Bidirectional (None, 360, 256)     148992      conv1d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_18 (Bidirectional (None, 360, 256)     148992      conv1d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_19 (Bidirectional (None, 360, 256)     148992      conv1d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_20 (Bidirectional (None, 360, 256)     148992      conv1d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_21 (Bidirectional (None, 360, 256)     148992      conv1d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_22 (Bidirectional (None, 360, 256)     148992      conv1d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_23 (Bidirectional (None, 360, 256)     148992      conv1d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_24 (Bidirectional (None, 360, 256)     148992      conv1d_216[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_103 (LeakyReLU)     (None, 360, 256)     0           bidirectional_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_111 (LeakyReLU)     (None, 360, 256)     0           bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_119 (LeakyReLU)     (None, 360, 256)     0           bidirectional_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_127 (LeakyReLU)     (None, 360, 256)     0           bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_135 (LeakyReLU)     (None, 360, 256)     0           bidirectional_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_143 (LeakyReLU)     (None, 360, 256)     0           bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_151 (LeakyReLU)     (None, 360, 256)     0           bidirectional_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_159 (LeakyReLU)     (None, 360, 256)     0           bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_167 (LeakyReLU)     (None, 360, 256)     0           bidirectional_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_175 (LeakyReLU)     (None, 360, 256)     0           bidirectional_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_183 (LeakyReLU)     (None, 360, 256)     0           bidirectional_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_191 (LeakyReLU)     (None, 360, 256)     0           bidirectional_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_13 (Atte (None, 256)          66048       leaky_re_lu_103[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_14 (Atte (None, 256)          66048       leaky_re_lu_111[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_15 (Atte (None, 256)          66048       leaky_re_lu_119[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_16 (Atte (None, 256)          66048       leaky_re_lu_127[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_17 (Atte (None, 256)          66048       leaky_re_lu_135[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_18 (Atte (None, 256)          66048       leaky_re_lu_143[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_19 (Atte (None, 256)          66048       leaky_re_lu_151[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_20 (Atte (None, 256)          66048       leaky_re_lu_159[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_21 (Atte (None, 256)          66048       leaky_re_lu_167[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_22 (Atte (None, 256)          66048       leaky_re_lu_175[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_23 (Atte (None, 256)          66048       leaky_re_lu_183[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_24 (Atte (None, 256)          66048       leaky_re_lu_191[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 256)          1024        attention_with_context_13[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 256)          1024        attention_with_context_14[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 256)          1024        attention_with_context_15[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 256)          1024        attention_with_context_16[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 256)          1024        attention_with_context_17[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 256)          1024        attention_with_context_18[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 256)          1024        attention_with_context_19[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 256)          1024        attention_with_context_20[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 256)          1024        attention_with_context_21[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 256)          1024        attention_with_context_22[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 256)          1024        attention_with_context_23[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 256)          1024        attention_with_context_24[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_104 (LeakyReLU)     (None, 256)          0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_112 (LeakyReLU)     (None, 256)          0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_120 (LeakyReLU)     (None, 256)          0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_128 (LeakyReLU)     (None, 256)          0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_136 (LeakyReLU)     (None, 256)          0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_144 (LeakyReLU)     (None, 256)          0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_152 (LeakyReLU)     (None, 256)          0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_160 (LeakyReLU)     (None, 256)          0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_168 (LeakyReLU)     (None, 256)          0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_176 (LeakyReLU)     (None, 256)          0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_184 (LeakyReLU)     (None, 256)          0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_192 (LeakyReLU)     (None, 256)          0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 9)            2313        leaky_re_lu_104[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 9)            2313        leaky_re_lu_112[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 9)            2313        leaky_re_lu_120[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 9)            2313        leaky_re_lu_128[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 9)            2313        leaky_re_lu_136[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 9)            2313        leaky_re_lu_144[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 9)            2313        leaky_re_lu_152[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 9)            2313        leaky_re_lu_160[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 9)            2313        leaky_re_lu_168[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 9)            2313        leaky_re_lu_176[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 9)            2313        leaky_re_lu_184[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 9)            2313        leaky_re_lu_192[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 9)            0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 9)            0           dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 9)            0           dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 9)            0           dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 9)            0           dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 9)            0           dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 9)            0           dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 9)            0           dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 9)            0           dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 9)            0           dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 9)            0           dense_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 9)            0           dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "average_2 (Average)             (None, 9)            0           activation_13[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "                                                                 activation_20[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_22[0][0]              \n",
      "                                                                 activation_23[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 8,673,900\n",
      "Trainable params: 8,657,004\n",
      "Non-trainable params: 16,896\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 train_loss: 0.589 train_acc: 0.788 train_f1: 0.404 \t\n",
      "\n",
      "Validation 1 valid_acc: 0.284 best_acc: 0.284 \t\n",
      "\n",
      "Epoch 2 train_loss: 0.500 train_acc: 0.875 train_f1: 0.489 \t\n",
      "\n",
      "Validation 2 valid_acc: 0.298 best_acc: 0.298 \t\n",
      "\n",
      "Epoch 3 train_loss: 0.460 train_acc: 0.894 train_f1: 0.510 \t\n",
      "\n",
      "Validation 3 valid_acc: 0.276 best_acc: 0.298 \t\n",
      "\n",
      "Epoch 4 train_loss: 0.431 train_acc: 0.904 train_f1: 0.525 \t\n",
      "\n",
      "Validation 4 valid_acc: 0.291 best_acc: 0.298 \t\n",
      "\n",
      "Epoch 5 train_loss: 0.406 train_acc: 0.911 train_f1: 0.541 \t\n",
      "\n",
      "Validation 5 valid_acc: 0.320 best_acc: 0.320 \t\n",
      "\n",
      "Epoch 6 train_loss: 0.388 train_acc: 0.913 train_f1: 0.541 \t\n",
      "\n",
      "Validation 6 valid_acc: 0.302 best_acc: 0.320 \t\n",
      "\n",
      "Epoch 7 train_loss: 0.368 train_acc: 0.916 train_f1: 0.548 \t\n",
      "\n",
      "Validation 7 valid_acc: 0.335 best_acc: 0.335 \t\n",
      "\n",
      "Epoch 8 train_loss: 0.353 train_acc: 0.918 train_f1: 0.553 \t\n",
      "\n",
      "Validation 8 valid_acc: 0.335 best_acc: 0.335 \t\n",
      "\n",
      "Epoch 9 train_loss: 0.341 train_acc: 0.919 train_f1: 0.555 \t\n",
      "\n",
      "Validation 9 valid_acc: 0.349 best_acc: 0.349 \t\n",
      "\n",
      "Epoch 10 train_loss: 0.329 train_acc: 0.919 train_f1: 0.553 \t\n",
      "\n",
      "Validation 10 valid_acc: 0.320 best_acc: 0.349 \t\n",
      "\n",
      "Epoch 11 train_loss: 0.320 train_acc: 0.921 train_f1: 0.557 \t\n",
      "\n",
      "Validation 11 valid_acc: 0.316 best_acc: 0.349 \t\n",
      "\n",
      "Epoch 12 train_loss: 0.309 train_acc: 0.921 train_f1: 0.558 \t\n",
      "\n",
      "Validation 12 valid_acc: 0.331 best_acc: 0.349 \t\n",
      "\n",
      "Epoch 13 train_loss: 0.300 train_acc: 0.923 train_f1: 0.571 \t\n",
      "\n",
      "Validation 13 valid_acc: 0.342 best_acc: 0.349 \t\n",
      "\n",
      "Epoch 14 train_loss: 0.290 train_acc: 0.924 train_f1: 0.576 \t\n",
      "\n",
      "Validation 14 valid_acc: 0.360 best_acc: 0.360 \t\n",
      "\n",
      "Epoch 15 train_loss: 0.283 train_acc: 0.926 train_f1: 0.591 \t\n",
      "\n",
      "Validation 15 valid_acc: 0.393 best_acc: 0.393 \t\n",
      "\n",
      "Epoch 16 train_loss: 0.274 train_acc: 0.928 train_f1: 0.597 \t\n",
      "\n",
      "Validation 16 valid_acc: 0.396 best_acc: 0.396 \t\n",
      "\n",
      "Epoch 17 train_loss: 0.269 train_acc: 0.929 train_f1: 0.606 \t\n",
      "\n",
      "Validation 17 valid_acc: 0.396 best_acc: 0.396 \t\n",
      "\n",
      "Epoch 18 train_loss: 0.262 train_acc: 0.930 train_f1: 0.613 \t\n",
      "\n",
      "Validation 18 valid_acc: 0.404 best_acc: 0.404 \t\n",
      "\n",
      "Epoch 19 train_loss: 0.255 train_acc: 0.931 train_f1: 0.621 \t\n",
      "\n",
      "Validation 19 valid_acc: 0.433 best_acc: 0.433 \t\n",
      "\n",
      "Epoch 20 train_loss: 0.248 train_acc: 0.932 train_f1: 0.629 \t\n",
      "\n",
      "Validation 20 valid_acc: 0.429 best_acc: 0.433 \t\n",
      "\n",
      "Epoch 21 train_loss: 0.243 train_acc: 0.933 train_f1: 0.634 \t\n",
      "\n",
      "Validation 21 valid_acc: 0.447 best_acc: 0.447 \t\n",
      "\n",
      "Epoch 22 train_loss: 0.239 train_acc: 0.934 train_f1: 0.638 \t\n",
      "\n",
      "Validation 22 valid_acc: 0.455 best_acc: 0.455 \t\n",
      "\n",
      "Epoch 23 train_loss: 0.235 train_acc: 0.934 train_f1: 0.638 \t\n",
      "\n",
      "Validation 23 valid_acc: 0.433 best_acc: 0.455 \t\n",
      "\n",
      "Epoch 24 train_loss: 0.230 train_acc: 0.935 train_f1: 0.643 \t\n",
      "\n",
      "Validation 24 valid_acc: 0.473 best_acc: 0.473 \t\n",
      "\n",
      "Epoch 25 train_loss: 0.227 train_acc: 0.935 train_f1: 0.645 \t\n",
      "\n",
      "Validation 25 valid_acc: 0.473 best_acc: 0.473 \t\n",
      "\n",
      "Epoch 26 train_loss: 0.222 train_acc: 0.936 train_f1: 0.648 \t\n",
      "\n",
      "Validation 26 valid_acc: 0.498 best_acc: 0.498 \t\n",
      "\n",
      "Epoch 27 train_loss: 0.218 train_acc: 0.938 train_f1: 0.665 \t\n",
      "\n",
      "Validation 27 valid_acc: 0.502 best_acc: 0.502 \t\n",
      "\n",
      "Epoch 28 train_loss: 0.215 train_acc: 0.938 train_f1: 0.666 \t\n",
      "\n",
      "Validation 28 valid_acc: 0.498 best_acc: 0.502 \t\n",
      "\n",
      "Epoch 29 train_loss: 0.210 train_acc: 0.938 train_f1: 0.665 \t\n",
      "\n",
      "Validation 29 valid_acc: 0.527 best_acc: 0.527 \t\n",
      "\n",
      "Epoch 30 train_loss: 0.207 train_acc: 0.939 train_f1: 0.672 \t\n",
      "\n",
      "Validation 30 valid_acc: 0.520 best_acc: 0.527 \t\n",
      "\n",
      "Epoch 31 train_loss: 0.204 train_acc: 0.939 train_f1: 0.672 \t\n",
      "\n",
      "Validation 31 valid_acc: 0.524 best_acc: 0.527 \t\n",
      "\n",
      "Epoch 32 train_loss: 0.201 train_acc: 0.939 train_f1: 0.676 \t\n",
      "\n",
      "Validation 32 valid_acc: 0.505 best_acc: 0.527 \t\n",
      "\n",
      "Epoch 33 train_loss: 0.198 train_acc: 0.940 train_f1: 0.678 \t\n",
      "\n",
      "Validation 33 valid_acc: 0.513 best_acc: 0.527 \t\n",
      "\n",
      "Epoch 34 train_loss: 0.195 train_acc: 0.940 train_f1: 0.681 \t\n",
      "\n",
      "Validation 34 valid_acc: 0.513 best_acc: 0.527 \t\n",
      "\n",
      "Epoch 35 train_loss: 0.193 train_acc: 0.941 train_f1: 0.685 \t\n",
      "\n",
      "Validation 35 valid_acc: 0.509 best_acc: 0.527 \t\n",
      "\n",
      "Epoch 36 train_loss: 0.190 train_acc: 0.941 train_f1: 0.688 \t\n",
      "\n",
      "Validation 36 valid_acc: 0.520 best_acc: 0.527 \t\n",
      "\n",
      "Epoch 37 train_loss: 0.187 train_acc: 0.942 train_f1: 0.691 \t\n",
      "\n",
      "Validation 37 valid_acc: 0.524 best_acc: 0.527 \t\n",
      "\n",
      "Epoch 38 train_loss: 0.183 train_acc: 0.942 train_f1: 0.695 \t\n",
      "\n",
      "Validation 38 valid_acc: 0.538 best_acc: 0.538 \t\n",
      "\n",
      "Epoch 39 train_loss: 0.184 train_acc: 0.941 train_f1: 0.690 \t\n",
      "\n",
      "Validation 39 valid_acc: 0.520 best_acc: 0.538 \t\n",
      "\n",
      "Epoch 40 train_loss: 0.179 train_acc: 0.943 train_f1: 0.700 \t\n",
      "\n",
      "Validation 40 valid_acc: 0.538 best_acc: 0.538 \t\n",
      "\n",
      "Epoch 41 train_loss: 0.178 train_acc: 0.943 train_f1: 0.700 \t\n",
      "\n",
      "Validation 41 valid_acc: 0.531 best_acc: 0.538 \t\n",
      "\n",
      "Epoch 42 train_loss: 0.176 train_acc: 0.943 train_f1: 0.701 \t\n",
      "\n",
      "Validation 42 valid_acc: 0.535 best_acc: 0.538 \t\n",
      "\n",
      "Epoch 43 train_loss: 0.175 train_acc: 0.943 train_f1: 0.696 \t\n",
      "\n",
      "Validation 43 valid_acc: 0.553 best_acc: 0.553 \t\n",
      "\n",
      "Epoch 44 train_loss: 0.172 train_acc: 0.944 train_f1: 0.705 \t\n",
      "\n",
      "Validation 44 valid_acc: 0.549 best_acc: 0.553 \t\n",
      "\n",
      "Epoch 45 train_loss: 0.170 train_acc: 0.944 train_f1: 0.708 \t\n",
      "\n",
      "Validation 45 valid_acc: 0.578 best_acc: 0.578 \t\n",
      "\n",
      "Epoch 46 train_loss: 0.170 train_acc: 0.944 train_f1: 0.705 \t\n",
      "\n",
      "Validation 46 valid_acc: 0.578 best_acc: 0.578 \t\n",
      "\n",
      "Epoch 47 train_loss: 0.167 train_acc: 0.945 train_f1: 0.713 \t\n",
      "\n",
      "Validation 47 valid_acc: 0.564 best_acc: 0.578 \t\n",
      "\n",
      "Epoch 48 train_loss: 0.166 train_acc: 0.945 train_f1: 0.714 \t\n",
      "\n",
      "Validation 48 valid_acc: 0.560 best_acc: 0.578 \t\n",
      "\n",
      "Epoch 49 train_loss: 0.165 train_acc: 0.945 train_f1: 0.712 \t\n",
      "\n",
      "Validation 49 valid_acc: 0.556 best_acc: 0.578 \t\n",
      "\n",
      "Epoch 50 train_loss: 0.163 train_acc: 0.945 train_f1: 0.717 \t\n",
      "\n",
      "Validation 50 valid_acc: 0.567 best_acc: 0.578 \t\n",
      "\n",
      "Epoch 51 train_loss: 0.163 train_acc: 0.945 train_f1: 0.712 \t\n",
      "\n",
      "Validation 51 valid_acc: 0.578 best_acc: 0.578 \t\n",
      "\n",
      "Epoch 52 train_loss: 0.161 train_acc: 0.946 train_f1: 0.719 \t\n",
      "\n",
      "Validation 52 valid_acc: 0.571 best_acc: 0.578 \t\n",
      "\n",
      "Epoch 53 train_loss: 0.159 train_acc: 0.946 train_f1: 0.718 \t\n",
      "\n",
      "Validation 53 valid_acc: 0.575 best_acc: 0.578 \t\n",
      "\n",
      "Epoch 54 train_loss: 0.160 train_acc: 0.945 train_f1: 0.717 \t\n",
      "\n",
      "Validation 54 valid_acc: 0.567 best_acc: 0.578 \t\n",
      "\n",
      "Epoch 55 train_loss: 0.158 train_acc: 0.947 train_f1: 0.724 \t\n",
      "\n",
      "Validation 55 valid_acc: 0.571 best_acc: 0.578 \t\n",
      "\n",
      "Epoch 56 train_loss: 0.156 train_acc: 0.946 train_f1: 0.724 \t\n",
      "\n",
      "Validation 56 valid_acc: 0.571 best_acc: 0.578 \t\n",
      "\n",
      "Epoch 57 train_loss: 0.157 train_acc: 0.947 train_f1: 0.723 \t\n",
      "\n",
      "Validation 57 valid_acc: 0.564 best_acc: 0.578 \t\n",
      "\n",
      "Epoch 58 train_loss: 0.156 train_acc: 0.945 train_f1: 0.717 \t\n",
      "\n",
      "Validation 58 valid_acc: 0.564 best_acc: 0.578 \t\n",
      "\n",
      "Epoch 59 train_loss: 0.154 train_acc: 0.947 train_f1: 0.726 \t\n",
      "\n",
      "Validation 59 valid_acc: 0.582 best_acc: 0.582 \t\n",
      "\n",
      "Epoch 60 train_loss: 0.153 train_acc: 0.946 train_f1: 0.725 \t\n",
      "\n",
      "Validation 60 valid_acc: 0.542 best_acc: 0.582 \t\n",
      "\n",
      "Epoch 61 train_loss: 0.153 train_acc: 0.947 train_f1: 0.726 \t\n",
      "\n",
      "Validation 61 valid_acc: 0.582 best_acc: 0.582 \t\n",
      "\n",
      "Epoch 62 train_loss: 0.151 train_acc: 0.947 train_f1: 0.728 \t\n",
      "\n",
      "Validation 62 valid_acc: 0.549 best_acc: 0.582 \t\n",
      "\n",
      "Epoch 63 train_loss: 0.150 train_acc: 0.947 train_f1: 0.727 \t\n",
      "\n",
      "Validation 63 valid_acc: 0.560 best_acc: 0.582 \t\n",
      "\n",
      "Epoch 64 train_loss: 0.151 train_acc: 0.947 train_f1: 0.727 \t\n",
      "\n",
      "Validation 64 valid_acc: 0.553 best_acc: 0.582 \t\n",
      "\n",
      "Epoch 65 train_loss: 0.149 train_acc: 0.947 train_f1: 0.730 \t\n",
      "\n",
      "Validation 65 valid_acc: 0.575 best_acc: 0.582 \t\n",
      "\n",
      "Epoch 66 train_loss: 0.149 train_acc: 0.948 train_f1: 0.732 \t\n",
      "\n",
      "Validation 66 valid_acc: 0.575 best_acc: 0.582 \t\n",
      "\n",
      "Epoch 67 train_loss: 0.147 train_acc: 0.948 train_f1: 0.733 \t\n",
      "\n",
      "Validation 67 valid_acc: 0.582 best_acc: 0.582 \t\n",
      "\n",
      "Epoch 68 train_loss: 0.146 train_acc: 0.949 train_f1: 0.737 \t\n",
      "\n",
      "Validation 68 valid_acc: 0.593 best_acc: 0.593 \t\n",
      "\n",
      "Epoch 69 train_loss: 0.147 train_acc: 0.948 train_f1: 0.734 \t\n",
      "\n",
      "Validation 69 valid_acc: 0.571 best_acc: 0.593 \t\n",
      "\n",
      "Epoch 70 train_loss: 0.145 train_acc: 0.948 train_f1: 0.736 \t\n",
      "\n",
      "Validation 70 valid_acc: 0.585 best_acc: 0.593 \t\n",
      "\n",
      "Epoch 71 train_loss: 0.144 train_acc: 0.948 train_f1: 0.736 \t\n",
      "\n",
      "Validation 71 valid_acc: 0.578 best_acc: 0.593 \t\n",
      "\n",
      "Epoch 72 train_loss: 0.143 train_acc: 0.949 train_f1: 0.737 \t\n",
      "\n",
      "Validation 72 valid_acc: 0.585 best_acc: 0.593 \t\n",
      "\n",
      "Epoch 73 train_loss: 0.143 train_acc: 0.949 train_f1: 0.739 \t\n",
      "\n",
      "Validation 73 valid_acc: 0.578 best_acc: 0.593 \t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 74 train_loss: 0.142 train_acc: 0.949 train_f1: 0.739 \t\n",
      "\n",
      "Validation 74 valid_acc: 0.571 best_acc: 0.593 \t\n",
      "\n",
      "Epoch 75 train_loss: 0.142 train_acc: 0.949 train_f1: 0.741 \t\n",
      "\n",
      "Validation 75 valid_acc: 0.589 best_acc: 0.593 \t\n",
      "\n",
      "Epoch 76 train_loss: 0.141 train_acc: 0.949 train_f1: 0.742 \t\n",
      "\n",
      "Validation 76 valid_acc: 0.596 best_acc: 0.596 \t\n",
      "\n",
      "Epoch 77 train_loss: 0.140 train_acc: 0.949 train_f1: 0.738 \t\n",
      "\n",
      "Validation 77 valid_acc: 0.604 best_acc: 0.604 \t\n",
      "\n",
      "Epoch 78 train_loss: 0.140 train_acc: 0.949 train_f1: 0.742 \t\n",
      "\n",
      "Validation 78 valid_acc: 0.600 best_acc: 0.604 \t\n",
      "\n",
      "Epoch 79 train_loss: 0.139 train_acc: 0.950 train_f1: 0.744 \t\n",
      "\n",
      "Validation 79 valid_acc: 0.593 best_acc: 0.604 \t\n",
      "\n",
      "Epoch 80 train_loss: 0.138 train_acc: 0.950 train_f1: 0.745 \t\n",
      "\n",
      "Validation 80 valid_acc: 0.585 best_acc: 0.604 \t\n",
      "\n",
      "Epoch 81 train_loss: 0.137 train_acc: 0.950 train_f1: 0.746 \t\n",
      "\n",
      "Validation 81 valid_acc: 0.582 best_acc: 0.604 \t\n",
      "\n",
      "Epoch 82 train_loss: 0.138 train_acc: 0.949 train_f1: 0.744 \t\n",
      "\n",
      "Validation 82 valid_acc: 0.578 best_acc: 0.604 \t\n",
      "\n",
      "Epoch 83 train_loss: 0.137 train_acc: 0.951 train_f1: 0.749 \t\n",
      "\n",
      "Validation 83 valid_acc: 0.585 best_acc: 0.604 \t\n",
      "\n",
      "Epoch 84 train_loss: 0.136 train_acc: 0.951 train_f1: 0.749 \t\n",
      "\n",
      "Validation 84 valid_acc: 0.589 best_acc: 0.604 \t\n",
      "\n",
      "Epoch 85 train_loss: 0.136 train_acc: 0.950 train_f1: 0.748 \t\n",
      "\n",
      "Validation 85 valid_acc: 0.596 best_acc: 0.604 \t\n",
      "\n",
      "Epoch 86 train_loss: 0.135 train_acc: 0.950 train_f1: 0.745 \t\n",
      "\n",
      "Validation 86 valid_acc: 0.596 best_acc: 0.604 \t\n",
      "\n",
      "Epoch 87 train_loss: 0.135 train_acc: 0.951 train_f1: 0.750 \t\n",
      "\n",
      "Validation 87 valid_acc: 0.589 best_acc: 0.604 \t\n",
      "\n",
      "Epoch 88 train_loss: 0.134 train_acc: 0.950 train_f1: 0.749 \t\n",
      "\n",
      "Validation 88 valid_acc: 0.582 best_acc: 0.604 \t\n",
      "\n",
      "Epoch 89 train_loss: 0.135 train_acc: 0.950 train_f1: 0.749 \t\n",
      "\n",
      "Validation 89 valid_acc: 0.589 best_acc: 0.604 \t\n",
      "\n",
      "Epoch 90 train_loss: 0.134 train_acc: 0.950 train_f1: 0.747 \t\n",
      "\n",
      "Validation 90 valid_acc: 0.578 best_acc: 0.604 \t\n",
      "\n",
      "Epoch 91 train_loss: 0.133 train_acc: 0.950 train_f1: 0.747 \t\n",
      "\n",
      "Validation 91 valid_acc: 0.589 best_acc: 0.604 \t\n",
      "\n",
      "Epoch 92 train_loss: 0.133 train_acc: 0.952 train_f1: 0.755 \t\n",
      "\n",
      "Validation 92 valid_acc: 0.585 best_acc: 0.604 \t\n",
      "\n",
      "Epoch 93 train_loss: 0.133 train_acc: 0.950 train_f1: 0.749 \t\n",
      "\n",
      "Validation 93 valid_acc: 0.571 best_acc: 0.604 \t\n",
      "\n",
      "Epoch 94 train_loss: 0.132 train_acc: 0.952 train_f1: 0.754 \t\n",
      "\n",
      "Validation 94 valid_acc: 0.593 best_acc: 0.604 \t\n",
      "\n",
      "Epoch 95 train_loss: 0.132 train_acc: 0.952 train_f1: 0.755 \t\n",
      "\n",
      "Validation 95 valid_acc: 0.604 best_acc: 0.604 \t\n",
      "\n",
      "Epoch 96 train_loss: 0.130 train_acc: 0.952 train_f1: 0.759 \t\n",
      "\n",
      "Validation 96 valid_acc: 0.596 best_acc: 0.604 \t\n",
      "\n",
      "Epoch 97 train_loss: 0.130 train_acc: 0.952 train_f1: 0.756 \t\n",
      "\n",
      "Validation 97 valid_acc: 0.607 best_acc: 0.607 \t\n",
      "\n",
      "Epoch 98 train_loss: 0.130 train_acc: 0.952 train_f1: 0.756 \t\n",
      "\n",
      "Validation 98 valid_acc: 0.593 best_acc: 0.607 \t\n",
      "\n",
      "Epoch 99 train_loss: 0.129 train_acc: 0.952 train_f1: 0.758 \t\n",
      "\n",
      "Validation 99 valid_acc: 0.575 best_acc: 0.607 \t\n",
      "\n",
      "Epoch 100 train_loss: 0.128 train_acc: 0.953 train_f1: 0.761 \t\n",
      "\n",
      "Validation 100 valid_acc: 0.596 best_acc: 0.607 \t\n",
      "\n",
      "Epoch 101 train_loss: 0.128 train_acc: 0.952 train_f1: 0.760 \t\n",
      "\n",
      "Validation 101 valid_acc: 0.600 best_acc: 0.607 \t\n",
      "\n",
      "Epoch 102 train_loss: 0.127 train_acc: 0.953 train_f1: 0.762 \t\n",
      "\n",
      "Validation 102 valid_acc: 0.585 best_acc: 0.607 \t\n",
      "\n",
      "Epoch 103 train_loss: 0.128 train_acc: 0.952 train_f1: 0.757 \t\n",
      "\n",
      "Validation 103 valid_acc: 0.589 best_acc: 0.607 \t\n",
      "\n",
      "Epoch 104 train_loss: 0.128 train_acc: 0.952 train_f1: 0.757 \t\n",
      "\n",
      "Validation 104 valid_acc: 0.589 best_acc: 0.607 \t\n",
      "\n",
      "Epoch 105 train_loss: 0.126 train_acc: 0.953 train_f1: 0.761 \t\n",
      "\n",
      "Validation 105 valid_acc: 0.607 best_acc: 0.607 \t\n",
      "\n",
      "Epoch 106 train_loss: 0.127 train_acc: 0.952 train_f1: 0.760 \t\n",
      "\n",
      "Validation 106 valid_acc: 0.593 best_acc: 0.607 \t\n",
      "\n",
      "Epoch 107 train_loss: 0.126 train_acc: 0.952 train_f1: 0.758 \t\n",
      "\n",
      "Validation 107 valid_acc: 0.600 best_acc: 0.607 \t\n",
      "\n",
      "Epoch 108 train_loss: 0.126 train_acc: 0.953 train_f1: 0.764 \t\n",
      "\n",
      "Validation 108 valid_acc: 0.596 best_acc: 0.607 \t\n",
      "\n",
      "Epoch 109 train_loss: 0.126 train_acc: 0.952 train_f1: 0.758 \t\n",
      "\n",
      "Validation 109 valid_acc: 0.600 best_acc: 0.607 \t\n",
      "\n",
      "Epoch 110 train_loss: 0.125 train_acc: 0.953 train_f1: 0.764 \t\n",
      "\n",
      "Validation 110 valid_acc: 0.589 best_acc: 0.607 \t\n",
      "\n",
      "Epoch 111 train_loss: 0.124 train_acc: 0.953 train_f1: 0.766 \t\n",
      "\n",
      "Validation 111 valid_acc: 0.600 best_acc: 0.607 \t\n",
      "\n",
      "Epoch 112 train_loss: 0.125 train_acc: 0.952 train_f1: 0.760 \t\n",
      "\n",
      "Validation 112 valid_acc: 0.571 best_acc: 0.607 \t\n",
      "\n",
      "Epoch 113 train_loss: 0.125 train_acc: 0.953 train_f1: 0.762 \t\n",
      "\n",
      "Validation 113 valid_acc: 0.571 best_acc: 0.607 \t\n",
      "\n",
      "Epoch 114 train_loss: 0.124 train_acc: 0.953 train_f1: 0.765 \t\n",
      "\n",
      "Validation 114 valid_acc: 0.589 best_acc: 0.607 \t\n",
      "\n",
      "Epoch 115 train_loss: 0.123 train_acc: 0.954 train_f1: 0.769 \t\n",
      "\n",
      "Validation 115 valid_acc: 0.593 best_acc: 0.607 \t\n",
      "\n",
      "Epoch 116 train_loss: 0.122 train_acc: 0.954 train_f1: 0.769 \t\n",
      "\n",
      "Validation 116 valid_acc: 0.596 best_acc: 0.607 \t\n",
      "\n",
      "Epoch 117 train_loss: 0.122 train_acc: 0.954 train_f1: 0.769 \t\n",
      "\n",
      "Validation 117 valid_acc: 0.578 best_acc: 0.607 \t\n",
      "\n",
      "Epoch 118 train_loss: 0.123 train_acc: 0.954 train_f1: 0.768 \t\n",
      "\n",
      "Validation 118 valid_acc: 0.575 best_acc: 0.607 \t\n",
      "\n",
      "Epoch 119 train_loss: 0.121 train_acc: 0.954 train_f1: 0.769 \t\n",
      "\n",
      "Validation 119 valid_acc: 0.582 best_acc: 0.607 \t\n",
      "\n",
      "Epoch 120 train_loss: 0.121 train_acc: 0.953 train_f1: 0.767 \t\n",
      "\n",
      "Validation 120 valid_acc: 0.589 best_acc: 0.607 \t\n",
      "\n",
      "Epoch 121 train_loss: 0.121 train_acc: 0.954 train_f1: 0.771 \t\n",
      "\n",
      "Validation 121 valid_acc: 0.593 best_acc: 0.607 \t\n",
      "\n",
      "Epoch 122 train_loss: 0.121 train_acc: 0.954 train_f1: 0.766 \t\n",
      "\n",
      "Validation 122 valid_acc: 0.596 best_acc: 0.607 \t\n",
      "\n",
      "Epoch 123 train_loss: 0.120 train_acc: 0.954 train_f1: 0.771 \t\n",
      "\n",
      "Validation 123 valid_acc: 0.607 best_acc: 0.607 \t\n",
      "\n",
      "Epoch 124 train_loss: 0.120 train_acc: 0.954 train_f1: 0.768 \t\n",
      "\n",
      "Validation 124 valid_acc: 0.600 best_acc: 0.607 \t\n",
      "\n",
      "Epoch 125 train_loss: 0.120 train_acc: 0.954 train_f1: 0.769 \t\n",
      "\n",
      "Validation 125 valid_acc: 0.593 best_acc: 0.607 \t\n",
      "\n",
      "Epoch 126 train_loss: 0.120 train_acc: 0.954 train_f1: 0.769 \t\n",
      "\n",
      "Validation 126 valid_acc: 0.578 best_acc: 0.607 \t\n",
      "\n",
      "Epoch 127 train_loss: 0.119 train_acc: 0.954 train_f1: 0.773 \t\n",
      "\n",
      "Validation 127 valid_acc: 0.604 best_acc: 0.607 \t\n",
      "\n",
      "Epoch 128 train_loss: 0.118 train_acc: 0.954 train_f1: 0.772 \t\n",
      "\n",
      "Validation 128 valid_acc: 0.600 best_acc: 0.607 \t\n",
      "\n",
      "Epoch 129 train_loss: 0.119 train_acc: 0.955 train_f1: 0.775 \t\n",
      "\n",
      "Validation 129 valid_acc: 0.582 best_acc: 0.607 \t\n",
      "\n",
      "Epoch 130 train_loss: 0.119 train_acc: 0.954 train_f1: 0.771 \t\n",
      "\n",
      "Validation 130 valid_acc: 0.596 best_acc: 0.607 \t\n",
      "\n",
      "Epoch 131 train_loss: 0.118 train_acc: 0.955 train_f1: 0.774 \t\n",
      "\n",
      "Validation 131 valid_acc: 0.622 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 132 train_loss: 0.117 train_acc: 0.955 train_f1: 0.777 \t\n",
      "\n",
      "Validation 132 valid_acc: 0.589 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 133 train_loss: 0.118 train_acc: 0.955 train_f1: 0.773 \t\n",
      "\n",
      "Validation 133 valid_acc: 0.611 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 134 train_loss: 0.116 train_acc: 0.956 train_f1: 0.781 \t\n",
      "\n",
      "Validation 134 valid_acc: 0.596 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 135 train_loss: 0.116 train_acc: 0.955 train_f1: 0.774 \t\n",
      "\n",
      "Validation 135 valid_acc: 0.578 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 136 train_loss: 0.117 train_acc: 0.955 train_f1: 0.774 \t\n",
      "\n",
      "Validation 136 valid_acc: 0.596 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 137 train_loss: 0.116 train_acc: 0.955 train_f1: 0.775 \t\n",
      "\n",
      "Validation 137 valid_acc: 0.589 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 138 train_loss: 0.116 train_acc: 0.955 train_f1: 0.773 \t\n",
      "\n",
      "Validation 138 valid_acc: 0.593 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 139 train_loss: 0.115 train_acc: 0.955 train_f1: 0.775 \t\n",
      "\n",
      "Validation 139 valid_acc: 0.604 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 140 train_loss: 0.115 train_acc: 0.956 train_f1: 0.780 \t\n",
      "\n",
      "Validation 140 valid_acc: 0.600 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 141 train_loss: 0.114 train_acc: 0.956 train_f1: 0.784 \t\n",
      "\n",
      "Validation 141 valid_acc: 0.589 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 142 train_loss: 0.113 train_acc: 0.956 train_f1: 0.781 \t\n",
      "\n",
      "Validation 142 valid_acc: 0.600 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 143 train_loss: 0.115 train_acc: 0.955 train_f1: 0.779 \t\n",
      "\n",
      "Validation 143 valid_acc: 0.607 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 144 train_loss: 0.114 train_acc: 0.956 train_f1: 0.779 \t\n",
      "\n",
      "Validation 144 valid_acc: 0.567 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 145 train_loss: 0.114 train_acc: 0.956 train_f1: 0.780 \t\n",
      "\n",
      "Validation 145 valid_acc: 0.585 best_acc: 0.622 \t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 146 train_loss: 0.113 train_acc: 0.957 train_f1: 0.786 \t\n",
      "\n",
      "Validation 146 valid_acc: 0.615 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 147 train_loss: 0.113 train_acc: 0.956 train_f1: 0.781 \t\n",
      "\n",
      "Validation 147 valid_acc: 0.615 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 148 train_loss: 0.113 train_acc: 0.955 train_f1: 0.777 \t\n",
      "\n",
      "Validation 148 valid_acc: 0.611 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 149 train_loss: 0.113 train_acc: 0.956 train_f1: 0.780 \t\n",
      "\n",
      "Validation 149 valid_acc: 0.607 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 150 train_loss: 0.113 train_acc: 0.956 train_f1: 0.780 \t\n",
      "\n",
      "Validation 150 valid_acc: 0.585 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 151 train_loss: 0.112 train_acc: 0.956 train_f1: 0.783 \t\n",
      "\n",
      "Validation 151 valid_acc: 0.611 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 152 train_loss: 0.112 train_acc: 0.956 train_f1: 0.782 \t\n",
      "\n",
      "Validation 152 valid_acc: 0.593 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 153 train_loss: 0.111 train_acc: 0.957 train_f1: 0.786 \t\n",
      "\n",
      "Validation 153 valid_acc: 0.615 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 154 train_loss: 0.112 train_acc: 0.956 train_f1: 0.783 \t\n",
      "\n",
      "Validation 154 valid_acc: 0.593 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 155 train_loss: 0.111 train_acc: 0.957 train_f1: 0.787 \t\n",
      "\n",
      "Validation 155 valid_acc: 0.589 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 156 train_loss: 0.111 train_acc: 0.957 train_f1: 0.785 \t\n",
      "\n",
      "Validation 156 valid_acc: 0.593 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 157 train_loss: 0.112 train_acc: 0.956 train_f1: 0.782 \t\n",
      "\n",
      "Validation 157 valid_acc: 0.604 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 158 train_loss: 0.111 train_acc: 0.957 train_f1: 0.786 \t\n",
      "\n",
      "Validation 158 valid_acc: 0.600 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 159 train_loss: 0.110 train_acc: 0.957 train_f1: 0.786 \t\n",
      "\n",
      "Validation 159 valid_acc: 0.611 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 160 train_loss: 0.110 train_acc: 0.957 train_f1: 0.787 \t\n",
      "\n",
      "Validation 160 valid_acc: 0.600 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 161 train_loss: 0.109 train_acc: 0.958 train_f1: 0.790 \t\n",
      "\n",
      "Validation 161 valid_acc: 0.604 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 162 train_loss: 0.109 train_acc: 0.957 train_f1: 0.789 \t\n",
      "\n",
      "Validation 162 valid_acc: 0.589 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 163 train_loss: 0.110 train_acc: 0.957 train_f1: 0.787 \t\n",
      "\n",
      "Validation 163 valid_acc: 0.578 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 164 train_loss: 0.107 train_acc: 0.958 train_f1: 0.794 \t\n",
      "\n",
      "Validation 164 valid_acc: 0.615 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 165 train_loss: 0.109 train_acc: 0.957 train_f1: 0.788 \t\n",
      "\n",
      "Validation 165 valid_acc: 0.589 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 166 train_loss: 0.107 train_acc: 0.958 train_f1: 0.792 \t\n",
      "\n",
      "Validation 166 valid_acc: 0.589 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 167 train_loss: 0.108 train_acc: 0.957 train_f1: 0.789 \t\n",
      "\n",
      "Validation 167 valid_acc: 0.585 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 168 train_loss: 0.108 train_acc: 0.958 train_f1: 0.791 \t\n",
      "\n",
      "Validation 168 valid_acc: 0.593 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 169 train_loss: 0.108 train_acc: 0.958 train_f1: 0.791 \t\n",
      "\n",
      "Validation 169 valid_acc: 0.575 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 170 train_loss: 0.107 train_acc: 0.958 train_f1: 0.791 \t\n",
      "\n",
      "Validation 170 valid_acc: 0.600 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 171 train_loss: 0.107 train_acc: 0.957 train_f1: 0.789 \t\n",
      "\n",
      "Validation 171 valid_acc: 0.600 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 172 train_loss: 0.107 train_acc: 0.958 train_f1: 0.793 \t\n",
      "\n",
      "Validation 172 valid_acc: 0.593 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 173 train_loss: 0.107 train_acc: 0.957 train_f1: 0.785 \t\n",
      "\n",
      "Validation 173 valid_acc: 0.596 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 174 train_loss: 0.106 train_acc: 0.959 train_f1: 0.796 \t\n",
      "\n",
      "Validation 174 valid_acc: 0.607 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 175 train_loss: 0.106 train_acc: 0.958 train_f1: 0.794 \t\n",
      "\n",
      "Validation 175 valid_acc: 0.593 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 176 train_loss: 0.106 train_acc: 0.958 train_f1: 0.793 \t\n",
      "\n",
      "Validation 176 valid_acc: 0.600 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 177 train_loss: 0.106 train_acc: 0.958 train_f1: 0.793 \t\n",
      "\n",
      "Validation 177 valid_acc: 0.585 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 178 train_loss: 0.105 train_acc: 0.958 train_f1: 0.795 \t\n",
      "\n",
      "Validation 178 valid_acc: 0.582 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 179 train_loss: 0.105 train_acc: 0.958 train_f1: 0.795 \t\n",
      "\n",
      "Validation 179 valid_acc: 0.618 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 180 train_loss: 0.104 train_acc: 0.958 train_f1: 0.793 \t\n",
      "\n",
      "Validation 180 valid_acc: 0.600 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 181 train_loss: 0.104 train_acc: 0.959 train_f1: 0.798 \t\n",
      "\n",
      "Validation 181 valid_acc: 0.589 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 182 train_loss: 0.105 train_acc: 0.958 train_f1: 0.792 \t\n",
      "\n",
      "Validation 182 valid_acc: 0.618 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 183 train_loss: 0.104 train_acc: 0.958 train_f1: 0.793 \t\n",
      "\n",
      "Validation 183 valid_acc: 0.607 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 184 train_loss: 0.105 train_acc: 0.958 train_f1: 0.792 \t\n",
      "\n",
      "Validation 184 valid_acc: 0.604 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 185 train_loss: 0.104 train_acc: 0.959 train_f1: 0.795 \t\n",
      "\n",
      "Validation 185 valid_acc: 0.618 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 186 train_loss: 0.105 train_acc: 0.959 train_f1: 0.798 \t\n",
      "\n",
      "Validation 186 valid_acc: 0.560 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 187 train_loss: 0.104 train_acc: 0.959 train_f1: 0.797 \t\n",
      "\n",
      "Validation 187 valid_acc: 0.607 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 188 train_loss: 0.103 train_acc: 0.959 train_f1: 0.799 \t\n",
      "\n",
      "Validation 188 valid_acc: 0.607 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 189 train_loss: 0.103 train_acc: 0.960 train_f1: 0.802 \t\n",
      "\n",
      "Validation 189 valid_acc: 0.589 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 190 train_loss: 0.103 train_acc: 0.959 train_f1: 0.796 \t\n",
      "\n",
      "Validation 190 valid_acc: 0.585 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 191 train_loss: 0.102 train_acc: 0.960 train_f1: 0.801 \t\n",
      "\n",
      "Validation 191 valid_acc: 0.604 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 192 train_loss: 0.102 train_acc: 0.959 train_f1: 0.799 \t\n",
      "\n",
      "Validation 192 valid_acc: 0.604 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 193 train_loss: 0.102 train_acc: 0.959 train_f1: 0.800 \t\n",
      "\n",
      "Validation 193 valid_acc: 0.589 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 194 train_loss: 0.100 train_acc: 0.960 train_f1: 0.803 \t\n",
      "\n",
      "Validation 194 valid_acc: 0.600 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 195 train_loss: 0.101 train_acc: 0.960 train_f1: 0.805 \t\n",
      "\n",
      "Validation 195 valid_acc: 0.593 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 196 train_loss: 0.102 train_acc: 0.959 train_f1: 0.800 \t\n",
      "\n",
      "Validation 196 valid_acc: 0.600 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 197 train_loss: 0.102 train_acc: 0.960 train_f1: 0.803 \t\n",
      "\n",
      "Validation 197 valid_acc: 0.596 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 198 train_loss: 0.101 train_acc: 0.960 train_f1: 0.801 \t\n",
      "\n",
      "Validation 198 valid_acc: 0.611 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 199 train_loss: 0.102 train_acc: 0.959 train_f1: 0.798 \t\n",
      "\n",
      "Validation 199 valid_acc: 0.593 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 200 train_loss: 0.102 train_acc: 0.959 train_f1: 0.800 \t\n",
      "\n",
      "Validation 200 valid_acc: 0.582 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 201 train_loss: 0.099 train_acc: 0.961 train_f1: 0.807 \t\n",
      "\n",
      "Validation 201 valid_acc: 0.604 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 202 train_loss: 0.101 train_acc: 0.960 train_f1: 0.801 \t\n",
      "\n",
      "Validation 202 valid_acc: 0.585 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 203 train_loss: 0.100 train_acc: 0.961 train_f1: 0.807 \t\n",
      "\n",
      "Validation 203 valid_acc: 0.589 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 204 train_loss: 0.099 train_acc: 0.960 train_f1: 0.804 \t\n",
      "\n",
      "Validation 204 valid_acc: 0.585 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 205 train_loss: 0.100 train_acc: 0.960 train_f1: 0.801 \t\n",
      "\n",
      "Validation 205 valid_acc: 0.578 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 206 train_loss: 0.101 train_acc: 0.960 train_f1: 0.804 \t\n",
      "\n",
      "Validation 206 valid_acc: 0.585 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 207 train_loss: 0.099 train_acc: 0.960 train_f1: 0.804 \t\n",
      "\n",
      "Validation 207 valid_acc: 0.611 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 208 train_loss: 0.099 train_acc: 0.960 train_f1: 0.805 \t\n",
      "\n",
      "Validation 208 valid_acc: 0.600 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 209 train_loss: 0.098 train_acc: 0.960 train_f1: 0.806 \t\n",
      "\n",
      "Validation 209 valid_acc: 0.600 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 210 train_loss: 0.098 train_acc: 0.960 train_f1: 0.805 \t\n",
      "\n",
      "Validation 210 valid_acc: 0.607 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 211 train_loss: 0.099 train_acc: 0.961 train_f1: 0.810 \t\n",
      "\n",
      "Validation 211 valid_acc: 0.596 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 212 train_loss: 0.098 train_acc: 0.960 train_f1: 0.805 \t\n",
      "\n",
      "Validation 212 valid_acc: 0.607 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 213 train_loss: 0.098 train_acc: 0.961 train_f1: 0.810 \t\n",
      "\n",
      "Validation 213 valid_acc: 0.625 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 214 train_loss: 0.099 train_acc: 0.960 train_f1: 0.806 \t\n",
      "\n",
      "Validation 214 valid_acc: 0.607 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 215 train_loss: 0.098 train_acc: 0.960 train_f1: 0.803 \t\n",
      "\n",
      "Validation 215 valid_acc: 0.604 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 216 train_loss: 0.099 train_acc: 0.960 train_f1: 0.805 \t\n",
      "\n",
      "Validation 216 valid_acc: 0.611 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 217 train_loss: 0.097 train_acc: 0.962 train_f1: 0.812 \t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation 217 valid_acc: 0.585 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 218 train_loss: 0.097 train_acc: 0.961 train_f1: 0.811 \t\n",
      "\n",
      "Validation 218 valid_acc: 0.589 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 219 train_loss: 0.097 train_acc: 0.961 train_f1: 0.808 \t\n",
      "\n",
      "Validation 219 valid_acc: 0.607 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 220 train_loss: 0.096 train_acc: 0.962 train_f1: 0.812 \t\n",
      "\n",
      "Validation 220 valid_acc: 0.600 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 221 train_loss: 0.098 train_acc: 0.960 train_f1: 0.804 \t\n",
      "\n",
      "Validation 221 valid_acc: 0.604 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 222 train_loss: 0.096 train_acc: 0.961 train_f1: 0.808 \t\n",
      "\n",
      "Validation 222 valid_acc: 0.593 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 223 train_loss: 0.096 train_acc: 0.962 train_f1: 0.811 \t\n",
      "\n",
      "Validation 223 valid_acc: 0.582 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 224 train_loss: 0.097 train_acc: 0.961 train_f1: 0.810 \t\n",
      "\n",
      "Validation 224 valid_acc: 0.607 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 225 train_loss: 0.097 train_acc: 0.961 train_f1: 0.808 \t\n",
      "\n",
      "Validation 225 valid_acc: 0.596 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 226 train_loss: 0.096 train_acc: 0.961 train_f1: 0.809 \t\n",
      "\n",
      "Validation 226 valid_acc: 0.600 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 227 train_loss: 0.096 train_acc: 0.961 train_f1: 0.809 \t\n",
      "\n",
      "Validation 227 valid_acc: 0.582 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 228 train_loss: 0.097 train_acc: 0.961 train_f1: 0.809 \t\n",
      "\n",
      "Validation 228 valid_acc: 0.596 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 229 train_loss: 0.096 train_acc: 0.961 train_f1: 0.811 \t\n",
      "\n",
      "Validation 229 valid_acc: 0.615 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 230 train_loss: 0.094 train_acc: 0.962 train_f1: 0.814 \t\n",
      "\n",
      "Validation 230 valid_acc: 0.585 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 231 train_loss: 0.095 train_acc: 0.962 train_f1: 0.812 \t\n",
      "\n",
      "Validation 231 valid_acc: 0.582 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 232 train_loss: 0.095 train_acc: 0.962 train_f1: 0.813 \t\n",
      "\n",
      "Validation 232 valid_acc: 0.600 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 233 train_loss: 0.095 train_acc: 0.962 train_f1: 0.813 \t\n",
      "\n",
      "Validation 233 valid_acc: 0.604 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 234 train_loss: 0.094 train_acc: 0.962 train_f1: 0.817 \t\n",
      "\n",
      "Validation 234 valid_acc: 0.611 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 235 train_loss: 0.094 train_acc: 0.962 train_f1: 0.815 \t\n",
      "\n",
      "Validation 235 valid_acc: 0.615 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 236 train_loss: 0.094 train_acc: 0.962 train_f1: 0.816 \t\n",
      "\n",
      "Validation 236 valid_acc: 0.596 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 237 train_loss: 0.094 train_acc: 0.963 train_f1: 0.817 \t\n",
      "\n",
      "Validation 237 valid_acc: 0.585 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 238 train_loss: 0.094 train_acc: 0.963 train_f1: 0.817 \t\n",
      "\n",
      "Validation 238 valid_acc: 0.607 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 239 train_loss: 0.094 train_acc: 0.963 train_f1: 0.818 \t\n",
      "\n",
      "Validation 239 valid_acc: 0.575 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 240 train_loss: 0.096 train_acc: 0.962 train_f1: 0.815 \t\n",
      "\n",
      "Validation 240 valid_acc: 0.604 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 241 train_loss: 0.093 train_acc: 0.963 train_f1: 0.819 \t\n",
      "\n",
      "Validation 241 valid_acc: 0.593 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 242 train_loss: 0.092 train_acc: 0.963 train_f1: 0.818 \t\n",
      "\n",
      "Validation 242 valid_acc: 0.611 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 243 train_loss: 0.093 train_acc: 0.963 train_f1: 0.819 \t\n",
      "\n",
      "Validation 243 valid_acc: 0.604 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 244 train_loss: 0.093 train_acc: 0.963 train_f1: 0.822 \t\n",
      "\n",
      "Validation 244 valid_acc: 0.589 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 245 train_loss: 0.094 train_acc: 0.963 train_f1: 0.818 \t\n",
      "\n",
      "Validation 245 valid_acc: 0.611 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 246 train_loss: 0.092 train_acc: 0.963 train_f1: 0.818 \t\n",
      "\n",
      "Validation 246 valid_acc: 0.600 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 247 train_loss: 0.093 train_acc: 0.963 train_f1: 0.816 \t\n",
      "\n",
      "Validation 247 valid_acc: 0.593 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 248 train_loss: 0.092 train_acc: 0.963 train_f1: 0.820 \t\n",
      "\n",
      "Validation 248 valid_acc: 0.585 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 249 train_loss: 0.093 train_acc: 0.963 train_f1: 0.818 \t\n",
      "\n",
      "Validation 249 valid_acc: 0.607 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 250 train_loss: 0.092 train_acc: 0.963 train_f1: 0.821 \t\n",
      "\n",
      "Validation 250 valid_acc: 0.589 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 251 train_loss: 0.093 train_acc: 0.963 train_f1: 0.818 \t\n",
      "\n",
      "Validation 251 valid_acc: 0.604 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 252 train_loss: 0.091 train_acc: 0.963 train_f1: 0.821 \t\n",
      "\n",
      "Validation 252 valid_acc: 0.618 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 253 train_loss: 0.091 train_acc: 0.964 train_f1: 0.822 \t\n",
      "\n",
      "Validation 253 valid_acc: 0.589 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 254 train_loss: 0.091 train_acc: 0.964 train_f1: 0.822 \t\n",
      "\n",
      "Validation 254 valid_acc: 0.615 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 255 train_loss: 0.091 train_acc: 0.964 train_f1: 0.823 \t\n",
      "\n",
      "Validation 255 valid_acc: 0.607 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 256 train_loss: 0.091 train_acc: 0.963 train_f1: 0.819 \t\n",
      "\n",
      "Validation 256 valid_acc: 0.611 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 257 train_loss: 0.090 train_acc: 0.964 train_f1: 0.825 \t\n",
      "\n",
      "Validation 257 valid_acc: 0.615 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 258 train_loss: 0.091 train_acc: 0.964 train_f1: 0.823 \t\n",
      "\n",
      "Validation 258 valid_acc: 0.593 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 259 train_loss: 0.090 train_acc: 0.964 train_f1: 0.825 \t\n",
      "\n",
      "Validation 259 valid_acc: 0.600 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 260 train_loss: 0.091 train_acc: 0.963 train_f1: 0.822 \t\n",
      "\n",
      "Validation 260 valid_acc: 0.604 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 261 train_loss: 0.090 train_acc: 0.964 train_f1: 0.827 \t\n",
      "\n",
      "Validation 261 valid_acc: 0.622 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 262 train_loss: 0.090 train_acc: 0.964 train_f1: 0.824 \t\n",
      "\n",
      "Validation 262 valid_acc: 0.596 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 263 train_loss: 0.089 train_acc: 0.964 train_f1: 0.825 \t\n",
      "\n",
      "Validation 263 valid_acc: 0.607 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 264 train_loss: 0.090 train_acc: 0.964 train_f1: 0.825 \t\n",
      "\n",
      "Validation 264 valid_acc: 0.607 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 265 train_loss: 0.091 train_acc: 0.964 train_f1: 0.825 \t\n",
      "\n",
      "Validation 265 valid_acc: 0.622 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 266 train_loss: 0.089 train_acc: 0.964 train_f1: 0.824 \t\n",
      "\n",
      "Validation 266 valid_acc: 0.625 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 267 train_loss: 0.090 train_acc: 0.964 train_f1: 0.823 \t\n",
      "\n",
      "Validation 267 valid_acc: 0.618 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 268 train_loss: 0.091 train_acc: 0.963 train_f1: 0.821 \t\n",
      "\n",
      "Validation 268 valid_acc: 0.618 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 269 train_loss: 0.090 train_acc: 0.964 train_f1: 0.824 \t\n",
      "\n",
      "Validation 269 valid_acc: 0.607 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 270 train_loss: 0.089 train_acc: 0.964 train_f1: 0.828 \t\n",
      "\n",
      "Validation 270 valid_acc: 0.596 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 271 train_loss: 0.090 train_acc: 0.963 train_f1: 0.821 \t\n",
      "\n",
      "Validation 271 valid_acc: 0.625 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 272 train_loss: 0.089 train_acc: 0.964 train_f1: 0.827 \t\n",
      "\n",
      "Validation 272 valid_acc: 0.604 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 273 train_loss: 0.089 train_acc: 0.964 train_f1: 0.827 \t\n",
      "\n",
      "Validation 273 valid_acc: 0.600 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 274 train_loss: 0.087 train_acc: 0.965 train_f1: 0.828 \t\n",
      "\n",
      "Validation 274 valid_acc: 0.607 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 275 train_loss: 0.088 train_acc: 0.965 train_f1: 0.831 \t\n",
      "\n",
      "Validation 275 valid_acc: 0.611 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 276 train_loss: 0.089 train_acc: 0.964 train_f1: 0.827 \t\n",
      "\n",
      "Validation 276 valid_acc: 0.611 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 277 train_loss: 0.088 train_acc: 0.964 train_f1: 0.824 \t\n",
      "\n",
      "Validation 277 valid_acc: 0.604 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 278 train_loss: 0.088 train_acc: 0.965 train_f1: 0.828 \t\n",
      "\n",
      "Validation 278 valid_acc: 0.593 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 279 train_loss: 0.087 train_acc: 0.965 train_f1: 0.833 \t\n",
      "\n",
      "Validation 279 valid_acc: 0.589 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 280 train_loss: 0.088 train_acc: 0.965 train_f1: 0.830 \t\n",
      "\n",
      "Validation 280 valid_acc: 0.600 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 281 train_loss: 0.087 train_acc: 0.965 train_f1: 0.832 \t\n",
      "\n",
      "Validation 281 valid_acc: 0.582 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 282 train_loss: 0.088 train_acc: 0.965 train_f1: 0.828 \t\n",
      "\n",
      "Validation 282 valid_acc: 0.604 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 283 train_loss: 0.086 train_acc: 0.965 train_f1: 0.832 \t\n",
      "\n",
      "Validation 283 valid_acc: 0.600 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 284 train_loss: 0.087 train_acc: 0.965 train_f1: 0.832 \t\n",
      "\n",
      "Validation 284 valid_acc: 0.618 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 285 train_loss: 0.085 train_acc: 0.966 train_f1: 0.837 \t\n",
      "\n",
      "Validation 285 valid_acc: 0.611 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 286 train_loss: 0.087 train_acc: 0.966 train_f1: 0.833 \t\n",
      "\n",
      "Validation 286 valid_acc: 0.625 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 287 train_loss: 0.085 train_acc: 0.966 train_f1: 0.835 \t\n",
      "\n",
      "Validation 287 valid_acc: 0.589 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 288 train_loss: 0.085 train_acc: 0.966 train_f1: 0.835 \t\n",
      "\n",
      "Validation 288 valid_acc: 0.604 best_acc: 0.625 \t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 289 train_loss: 0.085 train_acc: 0.966 train_f1: 0.835 \t\n",
      "\n",
      "Validation 289 valid_acc: 0.585 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 290 train_loss: 0.086 train_acc: 0.965 train_f1: 0.831 \t\n",
      "\n",
      "Validation 290 valid_acc: 0.596 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 291 train_loss: 0.087 train_acc: 0.965 train_f1: 0.832 \t\n",
      "\n",
      "Validation 291 valid_acc: 0.596 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 292 train_loss: 0.085 train_acc: 0.966 train_f1: 0.837 \t\n",
      "\n",
      "Validation 292 valid_acc: 0.596 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 293 train_loss: 0.085 train_acc: 0.966 train_f1: 0.835 \t\n",
      "\n",
      "Validation 293 valid_acc: 0.593 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 294 train_loss: 0.085 train_acc: 0.965 train_f1: 0.832 \t\n",
      "\n",
      "Validation 294 valid_acc: 0.596 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 295 train_loss: 0.085 train_acc: 0.966 train_f1: 0.836 \t\n",
      "\n",
      "Validation 295 valid_acc: 0.596 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 296 train_loss: 0.086 train_acc: 0.965 train_f1: 0.833 \t\n",
      "\n",
      "Validation 296 valid_acc: 0.604 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 297 train_loss: 0.085 train_acc: 0.966 train_f1: 0.835 \t\n",
      "\n",
      "Validation 297 valid_acc: 0.596 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 298 train_loss: 0.085 train_acc: 0.966 train_f1: 0.836 \t\n",
      "\n",
      "Validation 298 valid_acc: 0.607 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 299 train_loss: 0.084 train_acc: 0.967 train_f1: 0.838 \t\n",
      "\n",
      "Validation 299 valid_acc: 0.618 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 300 train_loss: 0.084 train_acc: 0.966 train_f1: 0.836 \t\n",
      "\n",
      "Validation 300 valid_acc: 0.607 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 301 train_loss: 0.084 train_acc: 0.966 train_f1: 0.834 \t\n",
      "\n",
      "Validation 301 valid_acc: 0.596 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 302 train_loss: 0.085 train_acc: 0.966 train_f1: 0.835 \t\n",
      "\n",
      "Validation 302 valid_acc: 0.585 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 303 train_loss: 0.085 train_acc: 0.966 train_f1: 0.839 \t\n",
      "\n",
      "Validation 303 valid_acc: 0.618 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 304 train_loss: 0.084 train_acc: 0.967 train_f1: 0.841 \t\n",
      "\n",
      "Validation 304 valid_acc: 0.600 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 305 train_loss: 0.083 train_acc: 0.967 train_f1: 0.842 \t\n",
      "\n",
      "Validation 305 valid_acc: 0.607 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 306 train_loss: 0.084 train_acc: 0.966 train_f1: 0.838 \t\n",
      "\n",
      "Validation 306 valid_acc: 0.593 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 307 train_loss: 0.083 train_acc: 0.967 train_f1: 0.838 \t\n",
      "\n",
      "Validation 307 valid_acc: 0.604 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 308 train_loss: 0.083 train_acc: 0.966 train_f1: 0.837 \t\n",
      "\n",
      "Validation 308 valid_acc: 0.604 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 309 train_loss: 0.083 train_acc: 0.967 train_f1: 0.838 \t\n",
      "\n",
      "Validation 309 valid_acc: 0.600 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 310 train_loss: 0.083 train_acc: 0.966 train_f1: 0.837 \t\n",
      "\n",
      "Validation 310 valid_acc: 0.615 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 311 train_loss: 0.083 train_acc: 0.967 train_f1: 0.840 \t\n",
      "\n",
      "Validation 311 valid_acc: 0.604 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 312 train_loss: 0.083 train_acc: 0.967 train_f1: 0.840 \t\n",
      "\n",
      "Validation 312 valid_acc: 0.596 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 313 train_loss: 0.082 train_acc: 0.967 train_f1: 0.840 \t\n",
      "\n",
      "Validation 313 valid_acc: 0.611 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 314 train_loss: 0.083 train_acc: 0.966 train_f1: 0.836 \t\n",
      "\n",
      "Validation 314 valid_acc: 0.596 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 315 train_loss: 0.082 train_acc: 0.967 train_f1: 0.841 \t\n",
      "\n",
      "Validation 315 valid_acc: 0.582 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 316 train_loss: 0.081 train_acc: 0.967 train_f1: 0.843 \t\n",
      "\n",
      "Validation 316 valid_acc: 0.611 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 317 train_loss: 0.082 train_acc: 0.967 train_f1: 0.840 \t\n",
      "\n",
      "Validation 317 valid_acc: 0.600 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 318 train_loss: 0.082 train_acc: 0.968 train_f1: 0.843 \t\n",
      "\n",
      "Validation 318 valid_acc: 0.596 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 319 train_loss: 0.083 train_acc: 0.966 train_f1: 0.837 \t\n",
      "\n",
      "Validation 319 valid_acc: 0.600 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 320 train_loss: 0.082 train_acc: 0.967 train_f1: 0.842 \t\n",
      "\n",
      "Validation 320 valid_acc: 0.618 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 321 train_loss: 0.082 train_acc: 0.968 train_f1: 0.844 \t\n",
      "\n",
      "Validation 321 valid_acc: 0.611 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 322 train_loss: 0.082 train_acc: 0.967 train_f1: 0.842 \t\n",
      "\n",
      "Validation 322 valid_acc: 0.611 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 323 train_loss: 0.082 train_acc: 0.966 train_f1: 0.838 \t\n",
      "\n",
      "Validation 323 valid_acc: 0.607 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 324 train_loss: 0.082 train_acc: 0.967 train_f1: 0.841 \t\n",
      "\n",
      "Validation 324 valid_acc: 0.600 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 325 train_loss: 0.082 train_acc: 0.967 train_f1: 0.842 \t\n",
      "\n",
      "Validation 325 valid_acc: 0.600 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 326 train_loss: 0.082 train_acc: 0.967 train_f1: 0.842 \t\n",
      "\n",
      "Validation 326 valid_acc: 0.582 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 327 train_loss: 0.080 train_acc: 0.968 train_f1: 0.847 \t\n",
      "\n",
      "Validation 327 valid_acc: 0.615 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 328 train_loss: 0.081 train_acc: 0.967 train_f1: 0.843 \t\n",
      "\n",
      "Validation 328 valid_acc: 0.604 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 329 train_loss: 0.081 train_acc: 0.967 train_f1: 0.843 \t\n",
      "\n",
      "Validation 329 valid_acc: 0.611 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 330 train_loss: 0.081 train_acc: 0.967 train_f1: 0.842 \t\n",
      "\n",
      "Validation 330 valid_acc: 0.611 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 331 train_loss: 0.080 train_acc: 0.968 train_f1: 0.847 \t\n",
      "\n",
      "Validation 331 valid_acc: 0.596 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 332 train_loss: 0.080 train_acc: 0.968 train_f1: 0.845 \t\n",
      "\n",
      "Validation 332 valid_acc: 0.607 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 333 train_loss: 0.081 train_acc: 0.967 train_f1: 0.842 \t\n",
      "\n",
      "Validation 333 valid_acc: 0.607 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 334 train_loss: 0.080 train_acc: 0.968 train_f1: 0.846 \t\n",
      "\n",
      "Validation 334 valid_acc: 0.611 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 335 train_loss: 0.080 train_acc: 0.968 train_f1: 0.848 \t\n",
      "\n",
      "Validation 335 valid_acc: 0.615 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 336 train_loss: 0.080 train_acc: 0.968 train_f1: 0.845 \t\n",
      "\n",
      "Validation 336 valid_acc: 0.607 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 337 train_loss: 0.080 train_acc: 0.968 train_f1: 0.845 \t\n",
      "\n",
      "Validation 337 valid_acc: 0.611 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 338 train_loss: 0.079 train_acc: 0.968 train_f1: 0.849 \t\n",
      "\n",
      "Validation 338 valid_acc: 0.600 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 339 train_loss: 0.079 train_acc: 0.968 train_f1: 0.848 \t\n",
      "\n",
      "Validation 339 valid_acc: 0.618 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 340 train_loss: 0.079 train_acc: 0.968 train_f1: 0.848 \t\n",
      "\n",
      "Validation 340 valid_acc: 0.585 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 341 train_loss: 0.079 train_acc: 0.968 train_f1: 0.849 \t\n",
      "\n",
      "Validation 341 valid_acc: 0.611 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 342 train_loss: 0.079 train_acc: 0.969 train_f1: 0.850 \t\n",
      "\n",
      "Validation 342 valid_acc: 0.615 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 343 train_loss: 0.079 train_acc: 0.969 train_f1: 0.850 \t\n",
      "\n",
      "Validation 343 valid_acc: 0.596 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 344 train_loss: 0.078 train_acc: 0.969 train_f1: 0.852 \t\n",
      "\n",
      "Validation 344 valid_acc: 0.615 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 345 train_loss: 0.079 train_acc: 0.968 train_f1: 0.846 \t\n",
      "\n",
      "Validation 345 valid_acc: 0.593 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 346 train_loss: 0.079 train_acc: 0.969 train_f1: 0.849 \t\n",
      "\n",
      "Validation 346 valid_acc: 0.596 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 347 train_loss: 0.079 train_acc: 0.968 train_f1: 0.849 \t\n",
      "\n",
      "Validation 347 valid_acc: 0.618 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 348 train_loss: 0.079 train_acc: 0.969 train_f1: 0.849 \t\n",
      "\n",
      "Validation 348 valid_acc: 0.604 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 349 train_loss: 0.078 train_acc: 0.969 train_f1: 0.853 \t\n",
      "\n",
      "Validation 349 valid_acc: 0.604 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 350 train_loss: 0.078 train_acc: 0.969 train_f1: 0.852 \t\n",
      "\n",
      "Validation 350 valid_acc: 0.604 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 351 train_loss: 0.078 train_acc: 0.969 train_f1: 0.853 \t\n",
      "\n",
      "Validation 351 valid_acc: 0.615 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 352 train_loss: 0.077 train_acc: 0.969 train_f1: 0.851 \t\n",
      "\n",
      "Validation 352 valid_acc: 0.607 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 353 train_loss: 0.078 train_acc: 0.969 train_f1: 0.852 \t\n",
      "\n",
      "Validation 353 valid_acc: 0.604 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 354 train_loss: 0.078 train_acc: 0.969 train_f1: 0.852 \t\n",
      "\n",
      "Validation 354 valid_acc: 0.589 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 355 train_loss: 0.077 train_acc: 0.970 train_f1: 0.855 \t\n",
      "\n",
      "Validation 355 valid_acc: 0.611 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 356 train_loss: 0.077 train_acc: 0.969 train_f1: 0.854 \t\n",
      "\n",
      "Validation 356 valid_acc: 0.600 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 357 train_loss: 0.078 train_acc: 0.969 train_f1: 0.851 \t\n",
      "\n",
      "Validation 357 valid_acc: 0.596 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 358 train_loss: 0.077 train_acc: 0.969 train_f1: 0.851 \t\n",
      "\n",
      "Validation 358 valid_acc: 0.622 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 359 train_loss: 0.077 train_acc: 0.970 train_f1: 0.854 \t\n",
      "\n",
      "Validation 359 valid_acc: 0.600 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 360 train_loss: 0.077 train_acc: 0.969 train_f1: 0.851 \t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation 360 valid_acc: 0.615 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 361 train_loss: 0.077 train_acc: 0.969 train_f1: 0.853 \t\n",
      "\n",
      "Validation 361 valid_acc: 0.625 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 362 train_loss: 0.075 train_acc: 0.970 train_f1: 0.857 \t\n",
      "\n",
      "Validation 362 valid_acc: 0.604 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 363 train_loss: 0.077 train_acc: 0.969 train_f1: 0.853 \t\n",
      "\n",
      "Validation 363 valid_acc: 0.593 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 364 train_loss: 0.076 train_acc: 0.969 train_f1: 0.852 \t\n",
      "\n",
      "Validation 364 valid_acc: 0.611 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 365 train_loss: 0.078 train_acc: 0.969 train_f1: 0.851 \t\n",
      "\n",
      "Validation 365 valid_acc: 0.604 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 366 train_loss: 0.077 train_acc: 0.970 train_f1: 0.855 \t\n",
      "\n",
      "Validation 366 valid_acc: 0.596 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 367 train_loss: 0.075 train_acc: 0.970 train_f1: 0.858 \t\n",
      "\n",
      "Validation 367 valid_acc: 0.593 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 368 train_loss: 0.076 train_acc: 0.970 train_f1: 0.857 \t\n",
      "\n",
      "Validation 368 valid_acc: 0.582 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 369 train_loss: 0.076 train_acc: 0.970 train_f1: 0.858 \t\n",
      "\n",
      "Validation 369 valid_acc: 0.600 best_acc: 0.625 \t\n",
      "\n",
      "Epoch 370 train_loss: 0.076 train_acc: 0.970 train_f1: 0.856 \t\n",
      "\n",
      "Validation 370 valid_acc: 0.596 best_acc: 0.625 \t\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-59e6f6f64624>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnum_epoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmel_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass2index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminimum_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_mean_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_std_final\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nEpoch'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'train_loss:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf'{train_loss:.3f}'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'train_acc:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf'{train_acc:.3f}'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'train_f1:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf'{train_f1:.3f}'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0mmodel_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ecg_mel_E%02dL%.2f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-59e6f6f64624>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(data_train, mel_directory, batch_size, class2index, minimum_len, x_mean_final, x_std_final)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mbatch_mels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_mels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mbatch_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtrain_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_mels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_tmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0macc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_tmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import keras\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras.applications.densenet import DenseNet121, DenseNet169\n",
    "#from keras.applications.nasnet import NASNetLarge\n",
    "# from keras_efficientnets import EfficientNetB7\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras import initializers, regularizers, constraints\n",
    "from keras.layers.normalization import BatchNormalization \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from keras import backend as K\n",
    "\n",
    "tf.set_random_seed(1234)\n",
    "random.seed(100)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "\n",
    "def score_f1(y_true, y_pred): #taken from old keras source code\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val\n",
    "\n",
    "def dot_product(x, kernel):\n",
    "    if K.backend() == 'tensorflow':\n",
    "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
    "    else:\n",
    "        return K.dot(x, kernel)\n",
    "    \n",
    "class AttentionWithContext(Layer):\n",
    "    def __init__(self,\n",
    "                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, u_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.u_regularizer = regularizers.get(u_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.u_constraint = constraints.get(u_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "        self.bias = bias\n",
    "        super(AttentionWithContext, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "        self.W = self.add_weight((input_shape[-1], input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight((input_shape[-1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "            self.u = self.add_weight((input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_u'.format(self.name),\n",
    "                                 regularizer=self.u_regularizer,\n",
    "                                 constraint=self.u_constraint)\n",
    "        super(AttentionWithContext, self).build(input_shape)\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        uit = dot_product(x, self.W)\n",
    "        if self.bias:\n",
    "            uit += self.b\n",
    "        uit = K.tanh(uit)\n",
    "        ait = dot_product(uit, self.u)\n",
    "        a = K.exp(ait)\n",
    "        if mask is not None:\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], input_shape[-1]\n",
    "\n",
    "    \n",
    "def cce_f1_loss(y_true, y_pred):\n",
    "    return 1 + 0.1*keras.losses.categorical_crossentropy(y_true, y_pred) - keras.metrics.categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "# Find unique number of classes  \n",
    "def get_unique_classes(input_directory,files):\n",
    "\n",
    "    unique_classes=set()\n",
    "    for f in files:\n",
    "        g = f.replace('.mat','.hea')\n",
    "        input_file = os.path.join(input_directory,g)\n",
    "        with open(input_file,'r') as f:\n",
    "            for lines in f:\n",
    "                if lines.startswith('#Dx'):\n",
    "                    tmp = lines.split(': ')[1].split(',')\n",
    "                    for c in tmp:\n",
    "                        unique_classes.add(c.strip())\n",
    "    return sorted(unique_classes)\n",
    "\n",
    "def one_hot_encoding(one_hot_vector,y, class2index):\n",
    "    ind=class2index[y]\n",
    "    one_hot_vector[ind]=1\n",
    "    return one_hot_vector\n",
    "\n",
    "# Search for multi-label subjects\n",
    "def searching_overlap(input_directory,class2index, input_file_names):\n",
    "    multiclasses=[]\n",
    "    multisubjects=[]\n",
    "    number = []\n",
    "    for file in input_file_names:\n",
    "        f=file\n",
    "        g = f.replace('.mat','.hea')\n",
    "        input_file = os.path.join(input_directory,g)\n",
    "        with open(input_file,'r') as f:\n",
    "            for lines in f:\n",
    "                if lines.startswith('#Dx'):\n",
    "                    tmp = lines.split(': ')[1].split(',')\n",
    "                    if len(tmp)>1:\n",
    "                        one_hot_vector = [0]*(len(class2index))\n",
    "                        for c in tmp:\n",
    "                            one_hot_vector = one_hot_encoding(one_hot_vector, c.strip(), class2index)\n",
    "                        multiclasses.append(one_hot_vector)\n",
    "                        multisubjects.append(g)\n",
    "                        number.append(len(tmp))\n",
    "    return multisubjects, multiclasses, number\n",
    "\n",
    "def block_feature(sequence_en, minimum_len): \n",
    "    new_en = []\n",
    "    if len(sequence_en) > minimum_len:  # 길이가 minimum보다 긴 경우\n",
    "        start = random.randint(0,len(sequence_en)-minimum_len)\n",
    "        #print(start)\n",
    "        new_en = sequence_en[start:start+minimum_len]\n",
    "    elif len(sequence_en) == minimum_len: # 길이가 minimum\n",
    "        new_en = sequence_en\n",
    "    else: \n",
    "        assert len(sequence_en) <= minimum_len\n",
    "    return new_en\n",
    "\n",
    "def exploratory_look(input_directory,file, class2index):\n",
    "    classes = []\n",
    "    f = file\n",
    "    g = f.replace('.mat','.hea')\n",
    "    input_file = os.path.join(input_directory,g)\n",
    "    with open(input_file,'r') as f:\n",
    "        for lines in f:\n",
    "            if lines.startswith('#Dx'):\n",
    "                tmp = lines.split(': ')[1].split(',')\n",
    "                print(tmp, len(tmp))\n",
    "    return tmp     \n",
    "\n",
    "# Get classes of sorted file names\n",
    "def get_labels(input_directory,file, class2index):\n",
    "    f = file\n",
    "    g = f.replace('.mat','.hea')\n",
    "    input_file = os.path.join(input_directory,g)\n",
    "    with open(input_file,'r') as f:\n",
    "        for lines in f:\n",
    "            if lines.startswith('#Dx'):\n",
    "                tmp = lines.split(': ')[1].split(',')\n",
    "                one_hot_vector = [0]*(len(class2index))\n",
    "                for c in tmp:\n",
    "                    one_hot_vector = one_hot_encoding(one_hot_vector, c.strip(), class2index)\n",
    "                \n",
    "    return one_hot_vector\n",
    "\n",
    "def randextract_mels(curr_step, batch_size, data, mel_directory, class2index, minimum_len, x_mean_final, x_std_final):\n",
    "    mel_files = []\n",
    "    classes = []\n",
    "    start = batch_size*curr_step\n",
    "    end = batch_size*(curr_step+1)\n",
    "    curr_file_indices = data[start:end]\n",
    "    for file in curr_file_indices:\n",
    "        tmp_file = np.load(mel_directory + '/' + file.replace('.mat', '.npy'))\n",
    "        clip_file = block_feature(tmp_file, minimum_len)\n",
    "        #print(clip_file.shape)\n",
    "        #clip_file = tmp_file[:minimum_len]\n",
    "        clip_file -= x_mean_final\n",
    "        clip_file /= x_std_final\n",
    "        mel_files.append(clip_file)\n",
    "        label = get_labels(input_directory, file, class2index)\n",
    "        classes.append(label)\n",
    "    concat = list(zip(mel_files, classes))\n",
    "    random.shuffle(concat)\n",
    "    mel_files, classes = zip(*concat)\n",
    "    return mel_files, classes\n",
    "\n",
    "def train(data_train, mel_directory, batch_size, class2index, minimum_len, x_mean_final, x_std_final): \n",
    "    loss=[]\n",
    "    acc = []\n",
    "    f1 = []\n",
    "\n",
    "    total_steps = int(np.ceil(len(data_train)/batch_size))\n",
    "    for curr_step in range(total_steps):\n",
    "        batch_mels, batch_labels = randextract_mels(curr_step, batch_size, data_train, mel_directory, class2index, minimum_len, x_mean_final, x_std_final)\n",
    "        batch_mels = np.asarray(batch_mels)\n",
    "        batch_labels = np.asarray(np.squeeze(batch_labels))\n",
    "        train_tmp = model.train_on_batch(batch_mels, batch_labels)\n",
    "        loss.append(train_tmp[0])\n",
    "        acc.append(train_tmp[1])\n",
    "        f1.append(train_tmp[2])\n",
    "\n",
    "    loss = np.mean(np.array(loss))\n",
    "    acc = np.mean(np.array(acc))\n",
    "    f1 = np.mean(np.array(f1))\n",
    "    return loss, acc, f1\n",
    "\n",
    "def test(data, mel_directory, input_directory, class2index, minimum_len, model, x_mean_final, x_std_final):\n",
    "    scores = []\n",
    "    predicted_labels=[]\n",
    "    accuracy=np.zeros(len(data))\n",
    "    #total_loss=[]\n",
    "    total_acc = 0\n",
    "    total_f1 = 0\n",
    "    \n",
    "    mel_files = []\n",
    "    classes = []\n",
    "    for i, file in enumerate(data):\n",
    "        tmp_file = np.load(mel_directory + '/' + file.replace('.mat', '.npy'))\n",
    "        steps = int(np.floor(tmp_file.shape[0]/minimum_len))\n",
    "        mel_files = []\n",
    "        for block in range(steps): # 128개씩 쪼갠 블럭 단위로 predict\n",
    "            start = block*minimum_len\n",
    "            end = (block+1)*minimum_len\n",
    "            clip_file = tmp_file[start:end]\n",
    "            clip_file -= x_mean_final\n",
    "            clip_file /= x_std_final\n",
    "            mel_files.append(clip_file)\n",
    "        mel_files = np.asarray(mel_files)\n",
    "        logit = model.predict(mel_files)\n",
    "        logit = np.mean(logit, axis=0)\n",
    "        \n",
    "        \n",
    "        \n",
    "        pred = np.zeros(len(logit))\n",
    "        for ii, label in enumerate(logit):\n",
    "            if label >= 0.5:\n",
    "                pred[ii] = 1\n",
    "            else:\n",
    "                pred[ii] = 0\n",
    "        pred = pred.tolist()\n",
    "        label = get_labels(input_directory,file,class2index)\n",
    "\n",
    "        \n",
    "        if pred == label:\n",
    "            acc = 1\n",
    "        else:\n",
    "            acc = 0\n",
    "        total_acc += acc\n",
    "        #total_f1 += f1\n",
    "    final_acc = total_acc / i\n",
    "    #final_f1 = total_f1 / i\n",
    "    return final_acc#, final_f1\n",
    "\n",
    "batch_size = 32\n",
    "minimum_len = 2880\n",
    "epochs = 1000\n",
    "loss_function = 'binary_crossentropy'\n",
    "# activation_function = 'softmax'\n",
    "rootdir = '../'\n",
    "date = datetime.today().strftime(\"%Y%m%d\")\n",
    "input_directory = os.path.join(rootdir, 'Training_WFDB')\n",
    "mel_name = 'Raw_data_20200424' \n",
    "mel_directory = os.path.join(rootdir, mel_name)\n",
    "results_directory = os.path.join(rootdir, 'results_'+date+'_0')\n",
    "if not os.path.isdir(input_directory):\n",
    "    os.mkdir(input_directory)\n",
    "if not os.path.isdir(mel_directory):\n",
    "    os.mkdir(mel_directory)\n",
    "# if not os.path.isdir(results_directory):\n",
    "#     os.mkdir(results_directory)\n",
    "        \n",
    "input_files = []\n",
    "for f in os.listdir(input_directory):\n",
    "    if os.path.isfile(os.path.join(input_directory, f)) and not f.lower().startswith('.') and f.lower().endswith('mat'):\n",
    "        input_files.append(f)\n",
    "input_file_names = sorted(input_files)\n",
    "\n",
    "unique_classes = get_unique_classes(input_directory, input_files)\n",
    "class2index = {}\n",
    "for a, b in enumerate(unique_classes):\n",
    "    class2index[b] = a\n",
    "    \n",
    "# classes_orig= [x.replace('.mat', '.hea') for x in input_file_names] # total subjects\n",
    "# classes_multi, _, _ = searching_overlap(input_directory,class2index, input_file_names)\n",
    "# classes_single = [x for x in classes_orig if x not in classes_multi]\n",
    "# classes_single = [x.replace('.hea', '.mat') for x in classes_single]\n",
    "\n",
    "# double-checking if classes_single have single-label\n",
    "# a, b, c  = searching_overlap(input_directory,class2index,classes_single)\n",
    "\n",
    "# we can safely use classes_single as input_file_names\n",
    "# input_file_names = classes_single\n",
    "random.shuffle(input_file_names)\n",
    "np.shape(input_file_names)\n",
    "\n",
    "x_mean_all = []\n",
    "x_std_all = []\n",
    "for file in input_file_names:\n",
    "    x = np.load(mel_directory + '/' + file.replace('.mat', '.npy'))\n",
    "    x_mean = [np.mean(x[:,0]), np.mean(x[:,1]), np.mean(x[:,2]), np.mean(x[:,3]), np.mean(x[:,4]), np.mean(x[:,5]),\n",
    "             np.mean(x[:,6]), np.mean(x[:,7]), np.mean(x[:,8]), np.mean(x[:,9]), np.mean(x[:,10]), np.mean(x[:,11])]\n",
    "    \n",
    "    x_std = [np.std(x[:,0]), np.std(x[:,1]), np.std(x[:,2]), np.std(x[:,3]), np.std(x[:,4]), np.std(x[:,5]),\n",
    "             np.std(x[:,6]), np.std(x[:,7]), np.std(x[:,8]), np.std(x[:,9]), np.std(x[:,10]), np.std(x[:,11])]\n",
    "    #print(x_mean)\n",
    "    x_mean_all.append(x_mean)\n",
    "    x_std_all.append(x_std)\n",
    "x_mean_final = np.mean(x_mean_all, axis=0)\n",
    "x_std_final = np.mean(x_std_all, axis=0)\n",
    "print(x_mean_final)\n",
    "\n",
    "data, data_test = train_test_split(input_file_names, test_size = 0.2, train_size = 0.8, shuffle=True)\n",
    "# data_train, data_val = train_test_split(data, test_size = 0.25, train_size = 0.75, shuffle=True)\n",
    "data_train, data_val = train_test_split(data, test_size = 0.05, train_size = 0.95, shuffle=True)\n",
    "print(np.shape(data_train), np.shape(data_val), np.shape(data_test))\n",
    "\n",
    "main_input = Input(shape=(minimum_len,12), dtype='float32', name='main_input')\n",
    "\n",
    "branch_pred = []\n",
    "for i in range(12):\n",
    "    # Slicing the ith channel:\n",
    "    input_sl = Lambda(lambda x: x[:, :, i:i+1])(main_input)\n",
    "    #print(input_sl)\n",
    "    x1 = GaussianNoise(0.01 ,input_shape=(minimum_len, 1))(input_sl)\n",
    "    x1 = Conv1D(32, 10, dilation_rate=3, padding='same')(x1)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = LeakyReLU(alpha=0.3)(x1)\n",
    "    x2 = Conv1D(32, 10, dilation_rate=3, padding='same')(x1)\n",
    "    x2 = add([x2, x1])\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = LeakyReLU(alpha=0.3)(x2)\n",
    "    #x2 = MaxPooling1D(pool_size=2)(x2)\n",
    "    x2 = Convolution1D(32, 20, strides = 2, padding='same')(x2)\n",
    "    #x2 = Dropout(0.25)(x2)\n",
    "\n",
    "    x3 = Conv1D(64, 10, dilation_rate=2, padding='same')(x2)\n",
    "    x3 = BatchNormalization()(x3)\n",
    "    x3 = LeakyReLU(alpha=0.3)(x3)\n",
    "    x4 = Conv1D(64, 10, dilation_rate=2, padding='same')(x3)\n",
    "    x4 = add([x4, x3])\n",
    "    x4 = BatchNormalization()(x4)\n",
    "    x4 = LeakyReLU(alpha=0.3)(x4)\n",
    "    #x4 = MaxPooling1D(pool_size=2)(x4)\n",
    "    x4 = Convolution1D(32, 20, strides = 2, padding='same')(x4)\n",
    "    #x4 = Dropout(0.25)(x4)\n",
    "\n",
    "    x5 = Conv1D(128, 10, dilation_rate=1, padding='same')(x4)\n",
    "    x5 = BatchNormalization()(x5)\n",
    "    x5 = LeakyReLU(alpha=0.3)(x5)\n",
    "    x6 = Conv1D(128, 10, dilation_rate=1, padding='same')(x5)\n",
    "    x6 = add([x6, x5])\n",
    "    x6 = BatchNormalization()(x6)\n",
    "    x6 = LeakyReLU(alpha=0.3)(x6)\n",
    "    #x6 = MaxPooling1D(pool_size=2)(x6)\n",
    "    x6 = Convolution1D(64, 20, strides = 2, padding='same')(x6)\n",
    "    #x6 = Dropout(0.25)(x6)\n",
    "    '''\n",
    "    x7 = Conv1D(64, 10, dilation_rate=1, padding='same')(x6)\n",
    "    x7 = BatchNormalization()(x7)\n",
    "    x7 = LeakyReLU(alpha=0.3)(x7)\n",
    "    x8 = Conv1D(64, 10, dilation_rate=1, padding='same')(x7)\n",
    "    x8 = add([x8, x7])\n",
    "    x8 = BatchNormalization()(x8)\n",
    "    x8 = LeakyReLU(alpha=0.3)(x8)\n",
    "    #x8 = MaxPooling1D(pool_size=2)(x8)\n",
    "    x8 = Convolution1D(64, 20, strides = 2, padding='same')(x8)\n",
    "    #cnnout = GlobalAveragePooling1D()(x8)\n",
    "    #x8 = Dropout(0.25)(x8)\n",
    "    '''\n",
    "    x = Bidirectional(CuDNNGRU(128, input_shape=(360,128),return_sequences=True,return_state=False))(x6)\n",
    "    x = LeakyReLU(alpha=0.3)(x)\n",
    "    x = AttentionWithContext()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.3)(x)\n",
    "    \n",
    "    #x = GlobalAveragePooling1D()(x8)\n",
    "    #x = Flatten()(x8)\n",
    "    #x = Dense(512)(x)\n",
    "    #x = BatchNormalization()(x)\n",
    "    #x = Activation('relu')(x)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    x = Dense(9)(x)\n",
    "#     pred  = Activation('softmax')(x)\n",
    "    pred  = Activation('sigmoid')(x)\n",
    "    branch_pred.append(pred)\n",
    "    \n",
    "out = Average()(branch_pred)\n",
    "#print(out)\n",
    "\n",
    "model = Model(inputs=main_input, outputs=out)\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=loss_function,\n",
    "              optimizer=optimizers.Adam(lr=1e-5),\n",
    "              metrics=['acc', score_f1])\n",
    "\n",
    "val_acc_sum=[]\n",
    "train_loss_sum=[]\n",
    "train_acc_sum=[]\n",
    "val_loss_sum=[]\n",
    "val_acc_min = 0\n",
    "for num_epoch in range(epochs):\n",
    "    random.shuffle(data_train)\n",
    "    train_loss, train_acc, train_f1 = train(data_train, mel_directory, batch_size, class2index, minimum_len, x_mean_final, x_std_final)\n",
    "    print('\\nEpoch',num_epoch+1,'train_loss:',f'{train_loss:.3f}','train_acc:',f'{train_acc:.3f}','train_f1:',f'{train_f1:.3f}',\"\\t\")\n",
    "    model_output = \"ecg_mel_E%02dL%.2f\" % (num_epoch, train_loss)\n",
    "    save_name = os.path.join(results_directory, model_output)\n",
    "    val_acc = test(data_val, mel_directory, input_directory, class2index, minimum_len, model, x_mean_final, x_std_final)\n",
    "    if val_acc > val_acc_min:\n",
    "        val_acc_min = val_acc\n",
    "#         model.save(save_name)\n",
    "    print('\\nValidation', num_epoch+1, 'valid_acc:',f'{val_acc:.3f}', 'best_acc:',f'{val_acc_min:.3f}', \"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
