{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/numba/errors.py:137: UserWarning: Insufficiently recent colorama version found. Numba requires colorama >= 0.3.9\n",
      "  warnings.warn(msg)\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.24290386e-03 -4.58280585e-05  4.31697309e-03 -3.00174693e-03\n",
      " -2.36609229e-04  1.28997408e-03  2.17347589e-04 -7.99152384e-04\n",
      " -3.42993744e-03 -1.69711686e-03  1.27138164e-03  1.94670545e-03]\n",
      "(4864,) (256,) (1281,)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, 2880, 12)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_1 (GaussianNoise (None, 2880, 1)      0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_2 (GaussianNoise (None, 2880, 1)      0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_3 (GaussianNoise (None, 2880, 1)      0           lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_4 (GaussianNoise (None, 2880, 1)      0           lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_5 (GaussianNoise (None, 2880, 1)      0           lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_6 (GaussianNoise (None, 2880, 1)      0           lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_7 (GaussianNoise (None, 2880, 1)      0           lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_8 (GaussianNoise (None, 2880, 1)      0           lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_9 (GaussianNoise (None, 2880, 1)      0           lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_10 (GaussianNois (None, 2880, 1)      0           lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_11 (GaussianNois (None, 2880, 1)      0           lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_12 (GaussianNois (None, 2880, 1)      0           lambda_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 2880, 32)     352         gaussian_noise_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 2880, 32)     352         gaussian_noise_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 2880, 32)     352         gaussian_noise_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 2880, 32)     352         gaussian_noise_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 2880, 32)     352         gaussian_noise_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_46 (Conv1D)              (None, 2880, 32)     352         gaussian_noise_6[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_55 (Conv1D)              (None, 2880, 32)     352         gaussian_noise_7[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_64 (Conv1D)              (None, 2880, 32)     352         gaussian_noise_8[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_73 (Conv1D)              (None, 2880, 32)     352         gaussian_noise_9[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_82 (Conv1D)              (None, 2880, 32)     352         gaussian_noise_10[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_91 (Conv1D)              (None, 2880, 32)     352         gaussian_noise_11[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_100 (Conv1D)             (None, 2880, 32)     352         gaussian_noise_12[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 2880, 32)     128         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 2880, 32)     128         conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 2880, 32)     128         conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 2880, 32)     128         conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 2880, 32)     128         conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 2880, 32)     128         conv1d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 2880, 32)     128         conv1d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 2880, 32)     128         conv1d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 2880, 32)     128         conv1d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 2880, 32)     128         conv1d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 2880, 32)     128         conv1d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 2880, 32)     128         conv1d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 2880, 32)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 2880, 32)     0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_33 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_41 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_49 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_57 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_65 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_73 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_81 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_89 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 2880, 32)     10272       leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 2880, 32)     10272       leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 2880, 32)     10272       leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 2880, 32)     10272       leaky_re_lu_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, 2880, 32)     10272       leaky_re_lu_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_47 (Conv1D)              (None, 2880, 32)     10272       leaky_re_lu_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_56 (Conv1D)              (None, 2880, 32)     10272       leaky_re_lu_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_65 (Conv1D)              (None, 2880, 32)     10272       leaky_re_lu_57[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_74 (Conv1D)              (None, 2880, 32)     10272       leaky_re_lu_65[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_83 (Conv1D)              (None, 2880, 32)     10272       leaky_re_lu_73[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_92 (Conv1D)              (None, 2880, 32)     10272       leaky_re_lu_81[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_101 (Conv1D)             (None, 2880, 32)     10272       leaky_re_lu_89[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 2880, 32)     0           conv1d_2[0][0]                   \n",
      "                                                                 leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 2880, 32)     0           conv1d_11[0][0]                  \n",
      "                                                                 leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 2880, 32)     0           conv1d_20[0][0]                  \n",
      "                                                                 leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 2880, 32)     0           conv1d_29[0][0]                  \n",
      "                                                                 leaky_re_lu_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 2880, 32)     0           conv1d_38[0][0]                  \n",
      "                                                                 leaky_re_lu_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 2880, 32)     0           conv1d_47[0][0]                  \n",
      "                                                                 leaky_re_lu_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 2880, 32)     0           conv1d_56[0][0]                  \n",
      "                                                                 leaky_re_lu_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 2880, 32)     0           conv1d_65[0][0]                  \n",
      "                                                                 leaky_re_lu_57[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 2880, 32)     0           conv1d_74[0][0]                  \n",
      "                                                                 leaky_re_lu_65[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 2880, 32)     0           conv1d_83[0][0]                  \n",
      "                                                                 leaky_re_lu_73[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 2880, 32)     0           conv1d_92[0][0]                  \n",
      "                                                                 leaky_re_lu_81[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_34 (Add)                    (None, 2880, 32)     0           conv1d_101[0][0]                 \n",
      "                                                                 leaky_re_lu_89[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 2880, 32)     128         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 2880, 32)     128         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 2880, 32)     128         add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 2880, 32)     128         add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 2880, 32)     128         add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 2880, 32)     128         add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 2880, 32)     128         add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 2880, 32)     128         add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 2880, 32)     128         add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 2880, 32)     128         add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 2880, 32)     128         add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 2880, 32)     128         add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 2880, 32)     0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_26 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_34 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_42 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_50 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_58 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_66 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_74 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_82 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_90 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 1440, 32)     20512       leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 1440, 32)     20512       leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 1440, 32)     20512       leaky_re_lu_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 1440, 32)     20512       leaky_re_lu_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_39 (Conv1D)              (None, 1440, 32)     20512       leaky_re_lu_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_48 (Conv1D)              (None, 1440, 32)     20512       leaky_re_lu_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_57 (Conv1D)              (None, 1440, 32)     20512       leaky_re_lu_50[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_66 (Conv1D)              (None, 1440, 32)     20512       leaky_re_lu_58[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_75 (Conv1D)              (None, 1440, 32)     20512       leaky_re_lu_66[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_84 (Conv1D)              (None, 1440, 32)     20512       leaky_re_lu_74[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_93 (Conv1D)              (None, 1440, 32)     20512       leaky_re_lu_82[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_102 (Conv1D)             (None, 1440, 32)     20512       leaky_re_lu_90[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 1440, 64)     20544       conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 1440, 64)     20544       conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 1440, 64)     20544       conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, 1440, 64)     20544       conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_40 (Conv1D)              (None, 1440, 64)     20544       conv1d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_49 (Conv1D)              (None, 1440, 64)     20544       conv1d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_58 (Conv1D)              (None, 1440, 64)     20544       conv1d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_67 (Conv1D)              (None, 1440, 64)     20544       conv1d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_76 (Conv1D)              (None, 1440, 64)     20544       conv1d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_85 (Conv1D)              (None, 1440, 64)     20544       conv1d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_94 (Conv1D)              (None, 1440, 64)     20544       conv1d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_103 (Conv1D)             (None, 1440, 64)     20544       conv1d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1440, 64)     256         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 1440, 64)     256         conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 1440, 64)     256         conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 1440, 64)     256         conv1d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 1440, 64)     256         conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 1440, 64)     256         conv1d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 1440, 64)     256         conv1d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 1440, 64)     256         conv1d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 1440, 64)     256         conv1d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 1440, 64)     256         conv1d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 1440, 64)     256         conv1d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 1440, 64)     256         conv1d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 1440, 64)     0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_27 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_35 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_43 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_51 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_59 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_67 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_75 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_83 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_91 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 1440, 64)     41024       leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 1440, 64)     41024       leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 1440, 64)     41024       leaky_re_lu_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 1440, 64)     41024       leaky_re_lu_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_41 (Conv1D)              (None, 1440, 64)     41024       leaky_re_lu_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_50 (Conv1D)              (None, 1440, 64)     41024       leaky_re_lu_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_59 (Conv1D)              (None, 1440, 64)     41024       leaky_re_lu_51[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_68 (Conv1D)              (None, 1440, 64)     41024       leaky_re_lu_59[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_77 (Conv1D)              (None, 1440, 64)     41024       leaky_re_lu_67[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_86 (Conv1D)              (None, 1440, 64)     41024       leaky_re_lu_75[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_95 (Conv1D)              (None, 1440, 64)     41024       leaky_re_lu_83[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_104 (Conv1D)             (None, 1440, 64)     41024       leaky_re_lu_91[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 1440, 64)     0           conv1d_5[0][0]                   \n",
      "                                                                 leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 1440, 64)     0           conv1d_14[0][0]                  \n",
      "                                                                 leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 1440, 64)     0           conv1d_23[0][0]                  \n",
      "                                                                 leaky_re_lu_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 1440, 64)     0           conv1d_32[0][0]                  \n",
      "                                                                 leaky_re_lu_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 1440, 64)     0           conv1d_41[0][0]                  \n",
      "                                                                 leaky_re_lu_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 1440, 64)     0           conv1d_50[0][0]                  \n",
      "                                                                 leaky_re_lu_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 1440, 64)     0           conv1d_59[0][0]                  \n",
      "                                                                 leaky_re_lu_51[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 1440, 64)     0           conv1d_68[0][0]                  \n",
      "                                                                 leaky_re_lu_59[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 1440, 64)     0           conv1d_77[0][0]                  \n",
      "                                                                 leaky_re_lu_67[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 1440, 64)     0           conv1d_86[0][0]                  \n",
      "                                                                 leaky_re_lu_75[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 1440, 64)     0           conv1d_95[0][0]                  \n",
      "                                                                 leaky_re_lu_83[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_35 (Add)                    (None, 1440, 64)     0           conv1d_104[0][0]                 \n",
      "                                                                 leaky_re_lu_91[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 1440, 64)     256         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 1440, 64)     256         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 1440, 64)     256         add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 1440, 64)     256         add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 1440, 64)     256         add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 1440, 64)     256         add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 1440, 64)     256         add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 1440, 64)     256         add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 1440, 64)     256         add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 1440, 64)     256         add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 1440, 64)     256         add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 1440, 64)     256         add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 1440, 64)     0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_28 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_36 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_44 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_52 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_60 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_68 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_76 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_84 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_92 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 720, 32)      40992       leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 720, 32)      40992       leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 720, 32)      40992       leaky_re_lu_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 720, 32)      40992       leaky_re_lu_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_42 (Conv1D)              (None, 720, 32)      40992       leaky_re_lu_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_51 (Conv1D)              (None, 720, 32)      40992       leaky_re_lu_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_60 (Conv1D)              (None, 720, 32)      40992       leaky_re_lu_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_69 (Conv1D)              (None, 720, 32)      40992       leaky_re_lu_60[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_78 (Conv1D)              (None, 720, 32)      40992       leaky_re_lu_68[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_87 (Conv1D)              (None, 720, 32)      40992       leaky_re_lu_76[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_96 (Conv1D)              (None, 720, 32)      40992       leaky_re_lu_84[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_105 (Conv1D)             (None, 720, 32)      40992       leaky_re_lu_92[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 720, 128)     41088       conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 720, 128)     41088       conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 720, 128)     41088       conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 720, 128)     41088       conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_43 (Conv1D)              (None, 720, 128)     41088       conv1d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_52 (Conv1D)              (None, 720, 128)     41088       conv1d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_61 (Conv1D)              (None, 720, 128)     41088       conv1d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_70 (Conv1D)              (None, 720, 128)     41088       conv1d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_79 (Conv1D)              (None, 720, 128)     41088       conv1d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_88 (Conv1D)              (None, 720, 128)     41088       conv1d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_97 (Conv1D)              (None, 720, 128)     41088       conv1d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_106 (Conv1D)             (None, 720, 128)     41088       conv1d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 720, 128)     512         conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 720, 128)     512         conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 720, 128)     512         conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 720, 128)     512         conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 720, 128)     512         conv1d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 720, 128)     512         conv1d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 720, 128)     512         conv1d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 720, 128)     512         conv1d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 720, 128)     512         conv1d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 720, 128)     512         conv1d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 720, 128)     512         conv1d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 720, 128)     512         conv1d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 720, 128)     0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_29 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_37 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_45 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_53 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_61 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_69 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_77 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_85 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_93 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 720, 128)     163968      leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 720, 128)     163968      leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 720, 128)     163968      leaky_re_lu_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 720, 128)     163968      leaky_re_lu_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_44 (Conv1D)              (None, 720, 128)     163968      leaky_re_lu_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_53 (Conv1D)              (None, 720, 128)     163968      leaky_re_lu_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_62 (Conv1D)              (None, 720, 128)     163968      leaky_re_lu_53[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_71 (Conv1D)              (None, 720, 128)     163968      leaky_re_lu_61[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_80 (Conv1D)              (None, 720, 128)     163968      leaky_re_lu_69[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_89 (Conv1D)              (None, 720, 128)     163968      leaky_re_lu_77[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_98 (Conv1D)              (None, 720, 128)     163968      leaky_re_lu_85[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_107 (Conv1D)             (None, 720, 128)     163968      leaky_re_lu_93[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 720, 128)     0           conv1d_8[0][0]                   \n",
      "                                                                 leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 720, 128)     0           conv1d_17[0][0]                  \n",
      "                                                                 leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 720, 128)     0           conv1d_26[0][0]                  \n",
      "                                                                 leaky_re_lu_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 720, 128)     0           conv1d_35[0][0]                  \n",
      "                                                                 leaky_re_lu_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 720, 128)     0           conv1d_44[0][0]                  \n",
      "                                                                 leaky_re_lu_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 720, 128)     0           conv1d_53[0][0]                  \n",
      "                                                                 leaky_re_lu_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 720, 128)     0           conv1d_62[0][0]                  \n",
      "                                                                 leaky_re_lu_53[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 720, 128)     0           conv1d_71[0][0]                  \n",
      "                                                                 leaky_re_lu_61[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 720, 128)     0           conv1d_80[0][0]                  \n",
      "                                                                 leaky_re_lu_69[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 720, 128)     0           conv1d_89[0][0]                  \n",
      "                                                                 leaky_re_lu_77[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_33 (Add)                    (None, 720, 128)     0           conv1d_98[0][0]                  \n",
      "                                                                 leaky_re_lu_85[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_36 (Add)                    (None, 720, 128)     0           conv1d_107[0][0]                 \n",
      "                                                                 leaky_re_lu_93[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 720, 128)     512         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 720, 128)     512         add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 720, 128)     512         add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 720, 128)     512         add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 720, 128)     512         add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 720, 128)     512         add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 720, 128)     512         add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 720, 128)     512         add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 720, 128)     512         add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 720, 128)     512         add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 720, 128)     512         add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 720, 128)     512         add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 720, 128)     0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_30 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_38 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_46 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_54 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_62 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_70 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_78 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_86 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_94 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 360, 64)      163904      leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 360, 64)      163904      leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 360, 64)      163904      leaky_re_lu_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, 360, 64)      163904      leaky_re_lu_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_45 (Conv1D)              (None, 360, 64)      163904      leaky_re_lu_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_54 (Conv1D)              (None, 360, 64)      163904      leaky_re_lu_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_63 (Conv1D)              (None, 360, 64)      163904      leaky_re_lu_54[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_72 (Conv1D)              (None, 360, 64)      163904      leaky_re_lu_62[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_81 (Conv1D)              (None, 360, 64)      163904      leaky_re_lu_70[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_90 (Conv1D)              (None, 360, 64)      163904      leaky_re_lu_78[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_99 (Conv1D)              (None, 360, 64)      163904      leaky_re_lu_86[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_108 (Conv1D)             (None, 360, 64)      163904      leaky_re_lu_94[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 360, 256)     148992      conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 360, 256)     148992      conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 360, 256)     148992      conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 360, 256)     148992      conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 360, 256)     148992      conv1d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, 360, 256)     148992      conv1d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, 360, 256)     148992      conv1d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, 360, 256)     148992      conv1d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, 360, 256)     148992      conv1d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, 360, 256)     148992      conv1d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional (None, 360, 256)     148992      conv1d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional (None, 360, 256)     148992      conv1d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 360, 256)     0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, 360, 256)     0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)      (None, 360, 256)     0           bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_31 (LeakyReLU)      (None, 360, 256)     0           bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_39 (LeakyReLU)      (None, 360, 256)     0           bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_47 (LeakyReLU)      (None, 360, 256)     0           bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_55 (LeakyReLU)      (None, 360, 256)     0           bidirectional_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_63 (LeakyReLU)      (None, 360, 256)     0           bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_71 (LeakyReLU)      (None, 360, 256)     0           bidirectional_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_79 (LeakyReLU)      (None, 360, 256)     0           bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_87 (LeakyReLU)      (None, 360, 256)     0           bidirectional_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_95 (LeakyReLU)      (None, 360, 256)     0           bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_1 (Atten (None, 256)          66048       leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_2 (Atten (None, 256)          66048       leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_3 (Atten (None, 256)          66048       leaky_re_lu_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_4 (Atten (None, 256)          66048       leaky_re_lu_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_5 (Atten (None, 256)          66048       leaky_re_lu_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_6 (Atten (None, 256)          66048       leaky_re_lu_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_7 (Atten (None, 256)          66048       leaky_re_lu_55[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_8 (Atten (None, 256)          66048       leaky_re_lu_63[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_9 (Atten (None, 256)          66048       leaky_re_lu_71[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_10 (Atte (None, 256)          66048       leaky_re_lu_79[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_11 (Atte (None, 256)          66048       leaky_re_lu_87[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_12 (Atte (None, 256)          66048       leaky_re_lu_95[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 256)          1024        attention_with_context_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 256)          1024        attention_with_context_2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 256)          1024        attention_with_context_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 256)          1024        attention_with_context_4[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 256)          1024        attention_with_context_5[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 256)          1024        attention_with_context_6[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 256)          1024        attention_with_context_7[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 256)          1024        attention_with_context_8[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 256)          1024        attention_with_context_9[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 256)          1024        attention_with_context_10[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 256)          1024        attention_with_context_11[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 256)          1024        attention_with_context_12[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 256)          0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, 256)          0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)      (None, 256)          0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_32 (LeakyReLU)      (None, 256)          0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_40 (LeakyReLU)      (None, 256)          0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_48 (LeakyReLU)      (None, 256)          0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_56 (LeakyReLU)      (None, 256)          0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_64 (LeakyReLU)      (None, 256)          0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_72 (LeakyReLU)      (None, 256)          0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_80 (LeakyReLU)      (None, 256)          0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_88 (LeakyReLU)      (None, 256)          0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_96 (LeakyReLU)      (None, 256)          0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 9)            2313        leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 9)            2313        leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 9)            2313        leaky_re_lu_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 9)            2313        leaky_re_lu_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 9)            2313        leaky_re_lu_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 9)            2313        leaky_re_lu_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 9)            2313        leaky_re_lu_56[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 9)            2313        leaky_re_lu_64[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 9)            2313        leaky_re_lu_72[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 9)            2313        leaky_re_lu_80[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 9)            2313        leaky_re_lu_88[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 9)            2313        leaky_re_lu_96[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 9)            0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 9)            0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 9)            0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 9)            0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 9)            0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 9)            0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 9)            0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 9)            0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 9)            0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 9)            0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 9)            0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 9)            0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "average_1 (Average)             (None, 9)            0           activation_1[0][0]               \n",
      "                                                                 activation_2[0][0]               \n",
      "                                                                 activation_3[0][0]               \n",
      "                                                                 activation_4[0][0]               \n",
      "                                                                 activation_5[0][0]               \n",
      "                                                                 activation_6[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_9[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 8,673,900\n",
      "Trainable params: 8,657,004\n",
      "Non-trainable params: 16,896\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "\n",
      "Epoch 1 train_loss: 1.762 train_acc: 0.466 train_f1: 0.063 \t\n",
      "\n",
      "Validation 1 valid_acc: 0.553 best_acc: 0.553 \t\n",
      "\n",
      "Epoch 2 train_loss: 1.482 train_acc: 0.579 train_f1: 0.207 \t\n",
      "\n",
      "Validation 2 valid_acc: 0.596 best_acc: 0.596 \t\n",
      "\n",
      "Epoch 3 train_loss: 1.353 train_acc: 0.625 train_f1: 0.304 \t\n",
      "\n",
      "Validation 3 valid_acc: 0.616 best_acc: 0.616 \t\n",
      "\n",
      "Epoch 4 train_loss: 1.290 train_acc: 0.645 train_f1: 0.341 \t\n",
      "\n",
      "Validation 4 valid_acc: 0.647 best_acc: 0.647 \t\n",
      "\n",
      "Epoch 5 train_loss: 1.238 train_acc: 0.659 train_f1: 0.368 \t\n",
      "\n",
      "Validation 5 valid_acc: 0.627 best_acc: 0.647 \t\n",
      "\n",
      "Epoch 6 train_loss: 1.201 train_acc: 0.675 train_f1: 0.403 \t\n",
      "\n",
      "Validation 6 valid_acc: 0.647 best_acc: 0.647 \t\n",
      "\n",
      "Epoch 7 train_loss: 1.159 train_acc: 0.688 train_f1: 0.438 \t\n",
      "\n",
      "Validation 7 valid_acc: 0.659 best_acc: 0.659 \t\n",
      "\n",
      "Epoch 8 train_loss: 1.135 train_acc: 0.694 train_f1: 0.458 \t\n",
      "\n",
      "Validation 8 valid_acc: 0.686 best_acc: 0.686 \t\n",
      "\n",
      "Epoch 9 train_loss: 1.106 train_acc: 0.708 train_f1: 0.477 \t\n",
      "\n",
      "Validation 9 valid_acc: 0.686 best_acc: 0.686 \t\n",
      "\n",
      "Epoch 10 train_loss: 1.077 train_acc: 0.709 train_f1: 0.499 \t\n",
      "\n",
      "Validation 10 valid_acc: 0.698 best_acc: 0.698 \t\n",
      "\n",
      "Epoch 11 train_loss: 1.047 train_acc: 0.728 train_f1: 0.519 \t\n",
      "\n",
      "Validation 11 valid_acc: 0.718 best_acc: 0.718 \t\n",
      "\n",
      "Epoch 12 train_loss: 1.029 train_acc: 0.733 train_f1: 0.539 \t\n",
      "\n",
      "Validation 12 valid_acc: 0.729 best_acc: 0.729 \t\n",
      "\n",
      "Epoch 13 train_loss: 1.014 train_acc: 0.735 train_f1: 0.543 \t\n",
      "\n",
      "Validation 13 valid_acc: 0.710 best_acc: 0.729 \t\n",
      "\n",
      "Epoch 14 train_loss: 1.006 train_acc: 0.735 train_f1: 0.543 \t\n",
      "\n",
      "Validation 14 valid_acc: 0.706 best_acc: 0.729 \t\n",
      "\n",
      "Epoch 15 train_loss: 1.000 train_acc: 0.742 train_f1: 0.562 \t\n",
      "\n",
      "Validation 15 valid_acc: 0.725 best_acc: 0.729 \t\n",
      "\n",
      "Epoch 16 train_loss: 0.971 train_acc: 0.749 train_f1: 0.573 \t\n",
      "\n",
      "Validation 16 valid_acc: 0.725 best_acc: 0.729 \t\n",
      "\n",
      "Epoch 17 train_loss: 0.955 train_acc: 0.754 train_f1: 0.594 \t\n",
      "\n",
      "Validation 17 valid_acc: 0.737 best_acc: 0.737 \t\n",
      "\n",
      "Epoch 18 train_loss: 0.946 train_acc: 0.752 train_f1: 0.593 \t\n",
      "\n",
      "Validation 18 valid_acc: 0.729 best_acc: 0.737 \t\n",
      "\n",
      "Epoch 19 train_loss: 0.928 train_acc: 0.756 train_f1: 0.611 \t\n",
      "\n",
      "Validation 19 valid_acc: 0.714 best_acc: 0.737 \t\n",
      "\n",
      "Epoch 20 train_loss: 0.929 train_acc: 0.755 train_f1: 0.610 \t\n",
      "\n",
      "Validation 20 valid_acc: 0.741 best_acc: 0.741 \t\n",
      "\n",
      "Epoch 21 train_loss: 0.919 train_acc: 0.755 train_f1: 0.617 \t\n",
      "\n",
      "Validation 21 valid_acc: 0.725 best_acc: 0.741 \t\n",
      "\n",
      "Epoch 22 train_loss: 0.904 train_acc: 0.762 train_f1: 0.623 \t\n",
      "\n",
      "Validation 22 valid_acc: 0.737 best_acc: 0.741 \t\n",
      "\n",
      "Epoch 23 train_loss: 0.899 train_acc: 0.760 train_f1: 0.630 \t\n",
      "\n",
      "Validation 23 valid_acc: 0.737 best_acc: 0.741 \t\n",
      "\n",
      "Epoch 24 train_loss: 0.886 train_acc: 0.764 train_f1: 0.637 \t\n",
      "\n",
      "Validation 24 valid_acc: 0.729 best_acc: 0.741 \t\n",
      "\n",
      "Epoch 25 train_loss: 0.877 train_acc: 0.766 train_f1: 0.645 \t\n",
      "\n",
      "Validation 25 valid_acc: 0.733 best_acc: 0.741 \t\n",
      "\n",
      "Epoch 26 train_loss: 0.877 train_acc: 0.763 train_f1: 0.650 \t\n",
      "\n",
      "Validation 26 valid_acc: 0.741 best_acc: 0.741 \t\n",
      "\n",
      "Epoch 27 train_loss: 0.862 train_acc: 0.767 train_f1: 0.657 \t\n",
      "\n",
      "Validation 27 valid_acc: 0.733 best_acc: 0.741 \t\n",
      "\n",
      "Epoch 28 train_loss: 0.854 train_acc: 0.770 train_f1: 0.663 \t\n",
      "\n",
      "Validation 28 valid_acc: 0.757 best_acc: 0.757 \t\n",
      "\n",
      "Epoch 29 train_loss: 0.842 train_acc: 0.775 train_f1: 0.667 \t\n",
      "\n",
      "Validation 29 valid_acc: 0.741 best_acc: 0.757 \t\n",
      "\n",
      "Epoch 30 train_loss: 0.832 train_acc: 0.772 train_f1: 0.676 \t\n",
      "\n",
      "Validation 30 valid_acc: 0.753 best_acc: 0.757 \t\n",
      "\n",
      "Epoch 31 train_loss: 0.826 train_acc: 0.775 train_f1: 0.685 \t\n",
      "\n",
      "Validation 31 valid_acc: 0.769 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 32 train_loss: 0.826 train_acc: 0.774 train_f1: 0.686 \t\n",
      "\n",
      "Validation 32 valid_acc: 0.745 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 33 train_loss: 0.819 train_acc: 0.779 train_f1: 0.687 \t\n",
      "\n",
      "Validation 33 valid_acc: 0.733 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 34 train_loss: 0.807 train_acc: 0.780 train_f1: 0.695 \t\n",
      "\n",
      "Validation 34 valid_acc: 0.722 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 35 train_loss: 0.804 train_acc: 0.779 train_f1: 0.698 \t\n",
      "\n",
      "Validation 35 valid_acc: 0.733 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 36 train_loss: 0.804 train_acc: 0.778 train_f1: 0.700 \t\n",
      "\n",
      "Validation 36 valid_acc: 0.761 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 37 train_loss: 0.799 train_acc: 0.781 train_f1: 0.698 \t\n",
      "\n",
      "Validation 37 valid_acc: 0.745 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 38 train_loss: 0.789 train_acc: 0.781 train_f1: 0.706 \t\n",
      "\n",
      "Validation 38 valid_acc: 0.761 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 39 train_loss: 0.781 train_acc: 0.783 train_f1: 0.710 \t\n",
      "\n",
      "Validation 39 valid_acc: 0.749 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 40 train_loss: 0.782 train_acc: 0.787 train_f1: 0.706 \t\n",
      "\n",
      "Validation 40 valid_acc: 0.761 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 41 train_loss: 0.778 train_acc: 0.786 train_f1: 0.710 \t\n",
      "\n",
      "Validation 41 valid_acc: 0.753 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 42 train_loss: 0.772 train_acc: 0.785 train_f1: 0.710 \t\n",
      "\n",
      "Validation 42 valid_acc: 0.737 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 43 train_loss: 0.764 train_acc: 0.790 train_f1: 0.714 \t\n",
      "\n",
      "Validation 43 valid_acc: 0.753 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 44 train_loss: 0.765 train_acc: 0.788 train_f1: 0.717 \t\n",
      "\n",
      "Validation 44 valid_acc: 0.745 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 45 train_loss: 0.746 train_acc: 0.797 train_f1: 0.726 \t\n",
      "\n",
      "Validation 45 valid_acc: 0.745 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 46 train_loss: 0.750 train_acc: 0.793 train_f1: 0.725 \t\n",
      "\n",
      "Validation 46 valid_acc: 0.741 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 47 train_loss: 0.754 train_acc: 0.791 train_f1: 0.721 \t\n",
      "\n",
      "Validation 47 valid_acc: 0.765 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 48 train_loss: 0.739 train_acc: 0.797 train_f1: 0.730 \t\n",
      "\n",
      "Validation 48 valid_acc: 0.745 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 49 train_loss: 0.743 train_acc: 0.788 train_f1: 0.726 \t\n",
      "\n",
      "Validation 49 valid_acc: 0.753 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 50 train_loss: 0.733 train_acc: 0.795 train_f1: 0.735 \t\n",
      "\n",
      "Validation 50 valid_acc: 0.749 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 51 train_loss: 0.732 train_acc: 0.798 train_f1: 0.735 \t\n",
      "\n",
      "Validation 51 valid_acc: 0.757 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 52 train_loss: 0.739 train_acc: 0.797 train_f1: 0.726 \t\n",
      "\n",
      "Validation 52 valid_acc: 0.757 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 53 train_loss: 0.723 train_acc: 0.798 train_f1: 0.734 \t\n",
      "\n",
      "Validation 53 valid_acc: 0.765 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 54 train_loss: 0.727 train_acc: 0.797 train_f1: 0.736 \t\n",
      "\n",
      "Validation 54 valid_acc: 0.729 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 55 train_loss: 0.715 train_acc: 0.796 train_f1: 0.740 \t\n",
      "\n",
      "Validation 55 valid_acc: 0.761 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 56 train_loss: 0.718 train_acc: 0.794 train_f1: 0.735 \t\n",
      "\n",
      "Validation 56 valid_acc: 0.761 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 57 train_loss: 0.715 train_acc: 0.800 train_f1: 0.738 \t\n",
      "\n",
      "Validation 57 valid_acc: 0.757 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 58 train_loss: 0.715 train_acc: 0.795 train_f1: 0.737 \t\n",
      "\n",
      "Validation 58 valid_acc: 0.769 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 59 train_loss: 0.707 train_acc: 0.800 train_f1: 0.744 \t\n",
      "\n",
      "Validation 59 valid_acc: 0.749 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 60 train_loss: 0.705 train_acc: 0.807 train_f1: 0.747 \t\n",
      "\n",
      "Validation 60 valid_acc: 0.749 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 61 train_loss: 0.699 train_acc: 0.805 train_f1: 0.742 \t\n",
      "\n",
      "Validation 61 valid_acc: 0.769 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 62 train_loss: 0.702 train_acc: 0.803 train_f1: 0.738 \t\n",
      "\n",
      "Validation 62 valid_acc: 0.753 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 63 train_loss: 0.698 train_acc: 0.802 train_f1: 0.748 \t\n",
      "\n",
      "Validation 63 valid_acc: 0.769 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 64 train_loss: 0.697 train_acc: 0.809 train_f1: 0.746 \t\n",
      "\n",
      "Validation 64 valid_acc: 0.761 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 65 train_loss: 0.697 train_acc: 0.801 train_f1: 0.747 \t\n",
      "\n",
      "Validation 65 valid_acc: 0.741 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 66 train_loss: 0.693 train_acc: 0.801 train_f1: 0.744 \t\n",
      "\n",
      "Validation 66 valid_acc: 0.757 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 67 train_loss: 0.682 train_acc: 0.806 train_f1: 0.746 \t\n",
      "\n",
      "Validation 67 valid_acc: 0.765 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 68 train_loss: 0.680 train_acc: 0.803 train_f1: 0.756 \t\n",
      "\n",
      "Validation 68 valid_acc: 0.749 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 69 train_loss: 0.677 train_acc: 0.812 train_f1: 0.755 \t\n",
      "\n",
      "Validation 69 valid_acc: 0.761 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 70 train_loss: 0.681 train_acc: 0.804 train_f1: 0.748 \t\n",
      "\n",
      "Validation 70 valid_acc: 0.757 best_acc: 0.769 \t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 71 train_loss: 0.676 train_acc: 0.807 train_f1: 0.751 \t\n",
      "\n",
      "Validation 71 valid_acc: 0.757 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 72 train_loss: 0.678 train_acc: 0.805 train_f1: 0.748 \t\n",
      "\n",
      "Validation 72 valid_acc: 0.757 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 73 train_loss: 0.667 train_acc: 0.811 train_f1: 0.758 \t\n",
      "\n",
      "Validation 73 valid_acc: 0.757 best_acc: 0.769 \t\n",
      "\n",
      "Epoch 74 train_loss: 0.667 train_acc: 0.814 train_f1: 0.753 \t\n",
      "\n",
      "Validation 74 valid_acc: 0.773 best_acc: 0.773 \t\n",
      "\n",
      "Epoch 75 train_loss: 0.671 train_acc: 0.806 train_f1: 0.755 \t\n",
      "\n",
      "Validation 75 valid_acc: 0.753 best_acc: 0.773 \t\n",
      "\n",
      "Epoch 76 train_loss: 0.662 train_acc: 0.814 train_f1: 0.755 \t\n",
      "\n",
      "Validation 76 valid_acc: 0.765 best_acc: 0.773 \t\n",
      "\n",
      "Epoch 77 train_loss: 0.664 train_acc: 0.808 train_f1: 0.758 \t\n",
      "\n",
      "Validation 77 valid_acc: 0.749 best_acc: 0.773 \t\n",
      "\n",
      "Epoch 78 train_loss: 0.654 train_acc: 0.812 train_f1: 0.764 \t\n",
      "\n",
      "Validation 78 valid_acc: 0.769 best_acc: 0.773 \t\n",
      "\n",
      "Epoch 79 train_loss: 0.656 train_acc: 0.816 train_f1: 0.762 \t\n",
      "\n",
      "Validation 79 valid_acc: 0.773 best_acc: 0.773 \t\n",
      "\n",
      "Epoch 80 train_loss: 0.648 train_acc: 0.816 train_f1: 0.768 \t\n",
      "\n",
      "Validation 80 valid_acc: 0.761 best_acc: 0.773 \t\n",
      "\n",
      "Epoch 81 train_loss: 0.650 train_acc: 0.819 train_f1: 0.764 \t\n",
      "\n",
      "Validation 81 valid_acc: 0.765 best_acc: 0.773 \t\n",
      "\n",
      "Epoch 82 train_loss: 0.653 train_acc: 0.813 train_f1: 0.764 \t\n",
      "\n",
      "Validation 82 valid_acc: 0.773 best_acc: 0.773 \t\n",
      "\n",
      "Epoch 83 train_loss: 0.647 train_acc: 0.811 train_f1: 0.764 \t\n",
      "\n",
      "Validation 83 valid_acc: 0.761 best_acc: 0.773 \t\n",
      "\n",
      "Epoch 84 train_loss: 0.638 train_acc: 0.817 train_f1: 0.766 \t\n",
      "\n",
      "Validation 84 valid_acc: 0.773 best_acc: 0.773 \t\n",
      "\n",
      "Epoch 85 train_loss: 0.639 train_acc: 0.819 train_f1: 0.768 \t\n",
      "\n",
      "Validation 85 valid_acc: 0.761 best_acc: 0.773 \t\n",
      "\n",
      "Epoch 86 train_loss: 0.636 train_acc: 0.821 train_f1: 0.769 \t\n",
      "\n",
      "Validation 86 valid_acc: 0.753 best_acc: 0.773 \t\n",
      "\n",
      "Epoch 87 train_loss: 0.634 train_acc: 0.822 train_f1: 0.770 \t\n",
      "\n",
      "Validation 87 valid_acc: 0.757 best_acc: 0.773 \t\n",
      "\n",
      "Epoch 88 train_loss: 0.637 train_acc: 0.816 train_f1: 0.770 \t\n",
      "\n",
      "Validation 88 valid_acc: 0.769 best_acc: 0.773 \t\n",
      "\n",
      "Epoch 89 train_loss: 0.629 train_acc: 0.824 train_f1: 0.774 \t\n",
      "\n",
      "Validation 89 valid_acc: 0.773 best_acc: 0.773 \t\n",
      "\n",
      "Epoch 90 train_loss: 0.641 train_acc: 0.815 train_f1: 0.765 \t\n",
      "\n",
      "Validation 90 valid_acc: 0.769 best_acc: 0.773 \t\n",
      "\n",
      "Epoch 91 train_loss: 0.628 train_acc: 0.826 train_f1: 0.772 \t\n",
      "\n",
      "Validation 91 valid_acc: 0.765 best_acc: 0.773 \t\n",
      "\n",
      "Epoch 92 train_loss: 0.614 train_acc: 0.831 train_f1: 0.775 \t\n",
      "\n",
      "Validation 92 valid_acc: 0.780 best_acc: 0.780 \t\n",
      "\n",
      "Epoch 93 train_loss: 0.625 train_acc: 0.825 train_f1: 0.772 \t\n",
      "\n",
      "Validation 93 valid_acc: 0.765 best_acc: 0.780 \t\n",
      "\n",
      "Epoch 94 train_loss: 0.618 train_acc: 0.828 train_f1: 0.775 \t\n",
      "\n",
      "Validation 94 valid_acc: 0.757 best_acc: 0.780 \t\n",
      "\n",
      "Epoch 95 train_loss: 0.624 train_acc: 0.819 train_f1: 0.772 \t\n",
      "\n",
      "Validation 95 valid_acc: 0.765 best_acc: 0.780 \t\n",
      "\n",
      "Epoch 96 train_loss: 0.623 train_acc: 0.820 train_f1: 0.769 \t\n",
      "\n",
      "Validation 96 valid_acc: 0.753 best_acc: 0.780 \t\n",
      "\n",
      "Epoch 97 train_loss: 0.617 train_acc: 0.825 train_f1: 0.776 \t\n",
      "\n",
      "Validation 97 valid_acc: 0.769 best_acc: 0.780 \t\n",
      "\n",
      "Epoch 98 train_loss: 0.617 train_acc: 0.822 train_f1: 0.776 \t\n",
      "\n",
      "Validation 98 valid_acc: 0.761 best_acc: 0.780 \t\n",
      "\n",
      "Epoch 99 train_loss: 0.611 train_acc: 0.823 train_f1: 0.776 \t\n",
      "\n",
      "Validation 99 valid_acc: 0.769 best_acc: 0.780 \t\n",
      "\n",
      "Epoch 100 train_loss: 0.609 train_acc: 0.829 train_f1: 0.781 \t\n",
      "\n",
      "Validation 100 valid_acc: 0.761 best_acc: 0.780 \t\n",
      "\n",
      "Epoch 101 train_loss: 0.611 train_acc: 0.828 train_f1: 0.775 \t\n",
      "\n",
      "Validation 101 valid_acc: 0.765 best_acc: 0.780 \t\n",
      "\n",
      "Epoch 102 train_loss: 0.613 train_acc: 0.823 train_f1: 0.777 \t\n",
      "\n",
      "Validation 102 valid_acc: 0.773 best_acc: 0.780 \t\n",
      "\n",
      "Epoch 103 train_loss: 0.599 train_acc: 0.830 train_f1: 0.779 \t\n",
      "\n",
      "Validation 103 valid_acc: 0.773 best_acc: 0.780 \t\n",
      "\n",
      "Epoch 104 train_loss: 0.601 train_acc: 0.830 train_f1: 0.782 \t\n",
      "\n",
      "Validation 104 valid_acc: 0.769 best_acc: 0.780 \t\n",
      "\n",
      "Epoch 105 train_loss: 0.596 train_acc: 0.830 train_f1: 0.783 \t\n",
      "\n",
      "Validation 105 valid_acc: 0.765 best_acc: 0.780 \t\n",
      "\n",
      "Epoch 106 train_loss: 0.601 train_acc: 0.829 train_f1: 0.780 \t\n",
      "\n",
      "Validation 106 valid_acc: 0.753 best_acc: 0.780 \t\n",
      "\n",
      "Epoch 107 train_loss: 0.597 train_acc: 0.833 train_f1: 0.784 \t\n",
      "\n",
      "Validation 107 valid_acc: 0.757 best_acc: 0.780 \t\n",
      "\n",
      "Epoch 108 train_loss: 0.598 train_acc: 0.829 train_f1: 0.784 \t\n",
      "\n",
      "Validation 108 valid_acc: 0.784 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 109 train_loss: 0.589 train_acc: 0.837 train_f1: 0.785 \t\n",
      "\n",
      "Validation 109 valid_acc: 0.776 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 110 train_loss: 0.599 train_acc: 0.828 train_f1: 0.782 \t\n",
      "\n",
      "Validation 110 valid_acc: 0.780 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 111 train_loss: 0.599 train_acc: 0.826 train_f1: 0.784 \t\n",
      "\n",
      "Validation 111 valid_acc: 0.761 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 112 train_loss: 0.589 train_acc: 0.831 train_f1: 0.787 \t\n",
      "\n",
      "Validation 112 valid_acc: 0.769 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 113 train_loss: 0.589 train_acc: 0.833 train_f1: 0.783 \t\n",
      "\n",
      "Validation 113 valid_acc: 0.776 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 114 train_loss: 0.583 train_acc: 0.835 train_f1: 0.787 \t\n",
      "\n",
      "Validation 114 valid_acc: 0.776 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 115 train_loss: 0.590 train_acc: 0.835 train_f1: 0.783 \t\n",
      "\n",
      "Validation 115 valid_acc: 0.769 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 116 train_loss: 0.585 train_acc: 0.836 train_f1: 0.785 \t\n",
      "\n",
      "Validation 116 valid_acc: 0.773 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 117 train_loss: 0.582 train_acc: 0.832 train_f1: 0.786 \t\n",
      "\n",
      "Validation 117 valid_acc: 0.773 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 118 train_loss: 0.579 train_acc: 0.842 train_f1: 0.788 \t\n",
      "\n",
      "Validation 118 valid_acc: 0.780 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 119 train_loss: 0.580 train_acc: 0.834 train_f1: 0.788 \t\n",
      "\n",
      "Validation 119 valid_acc: 0.784 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 120 train_loss: 0.579 train_acc: 0.835 train_f1: 0.790 \t\n",
      "\n",
      "Validation 120 valid_acc: 0.765 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 121 train_loss: 0.576 train_acc: 0.837 train_f1: 0.788 \t\n",
      "\n",
      "Validation 121 valid_acc: 0.773 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 122 train_loss: 0.568 train_acc: 0.839 train_f1: 0.791 \t\n",
      "\n",
      "Validation 122 valid_acc: 0.776 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 123 train_loss: 0.575 train_acc: 0.839 train_f1: 0.788 \t\n",
      "\n",
      "Validation 123 valid_acc: 0.761 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 124 train_loss: 0.571 train_acc: 0.833 train_f1: 0.793 \t\n",
      "\n",
      "Validation 124 valid_acc: 0.765 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 125 train_loss: 0.571 train_acc: 0.835 train_f1: 0.789 \t\n",
      "\n",
      "Validation 125 valid_acc: 0.776 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 126 train_loss: 0.571 train_acc: 0.835 train_f1: 0.790 \t\n",
      "\n",
      "Validation 126 valid_acc: 0.741 best_acc: 0.784 \t\n",
      "\n",
      "Epoch 127 train_loss: 0.565 train_acc: 0.838 train_f1: 0.792 \t\n",
      "\n",
      "Validation 127 valid_acc: 0.788 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 128 train_loss: 0.562 train_acc: 0.841 train_f1: 0.794 \t\n",
      "\n",
      "Validation 128 valid_acc: 0.769 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 129 train_loss: 0.565 train_acc: 0.841 train_f1: 0.792 \t\n",
      "\n",
      "Validation 129 valid_acc: 0.761 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 130 train_loss: 0.565 train_acc: 0.836 train_f1: 0.789 \t\n",
      "\n",
      "Validation 130 valid_acc: 0.769 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 131 train_loss: 0.564 train_acc: 0.839 train_f1: 0.796 \t\n",
      "\n",
      "Validation 131 valid_acc: 0.769 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 132 train_loss: 0.553 train_acc: 0.844 train_f1: 0.800 \t\n",
      "\n",
      "Validation 132 valid_acc: 0.773 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 133 train_loss: 0.551 train_acc: 0.844 train_f1: 0.797 \t\n",
      "\n",
      "Validation 133 valid_acc: 0.780 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 134 train_loss: 0.551 train_acc: 0.844 train_f1: 0.801 \t\n",
      "\n",
      "Validation 134 valid_acc: 0.773 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 135 train_loss: 0.548 train_acc: 0.846 train_f1: 0.805 \t\n",
      "\n",
      "Validation 135 valid_acc: 0.765 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 136 train_loss: 0.546 train_acc: 0.848 train_f1: 0.800 \t\n",
      "\n",
      "Validation 136 valid_acc: 0.776 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 137 train_loss: 0.554 train_acc: 0.845 train_f1: 0.799 \t\n",
      "\n",
      "Validation 137 valid_acc: 0.780 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 138 train_loss: 0.543 train_acc: 0.846 train_f1: 0.796 \t\n",
      "\n",
      "Validation 138 valid_acc: 0.784 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 139 train_loss: 0.539 train_acc: 0.850 train_f1: 0.803 \t\n",
      "\n",
      "Validation 139 valid_acc: 0.761 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 140 train_loss: 0.542 train_acc: 0.847 train_f1: 0.803 \t\n",
      "\n",
      "Validation 140 valid_acc: 0.773 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 141 train_loss: 0.544 train_acc: 0.849 train_f1: 0.799 \t\n",
      "\n",
      "Validation 141 valid_acc: 0.776 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 142 train_loss: 0.545 train_acc: 0.849 train_f1: 0.800 \t\n",
      "\n",
      "Validation 142 valid_acc: 0.776 best_acc: 0.788 \t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 143 train_loss: 0.537 train_acc: 0.845 train_f1: 0.806 \t\n",
      "\n",
      "Validation 143 valid_acc: 0.776 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 144 train_loss: 0.543 train_acc: 0.850 train_f1: 0.798 \t\n",
      "\n",
      "Validation 144 valid_acc: 0.776 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 145 train_loss: 0.542 train_acc: 0.846 train_f1: 0.799 \t\n",
      "\n",
      "Validation 145 valid_acc: 0.773 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 146 train_loss: 0.536 train_acc: 0.852 train_f1: 0.802 \t\n",
      "\n",
      "Validation 146 valid_acc: 0.780 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 147 train_loss: 0.536 train_acc: 0.845 train_f1: 0.802 \t\n",
      "\n",
      "Validation 147 valid_acc: 0.769 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 148 train_loss: 0.535 train_acc: 0.848 train_f1: 0.804 \t\n",
      "\n",
      "Validation 148 valid_acc: 0.780 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 149 train_loss: 0.533 train_acc: 0.846 train_f1: 0.802 \t\n",
      "\n",
      "Validation 149 valid_acc: 0.776 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 150 train_loss: 0.532 train_acc: 0.850 train_f1: 0.803 \t\n",
      "\n",
      "Validation 150 valid_acc: 0.773 best_acc: 0.788 \t\n",
      "\n",
      "Epoch 151 train_loss: 0.534 train_acc: 0.849 train_f1: 0.801 \t\n",
      "\n",
      "Validation 151 valid_acc: 0.780 best_acc: 0.788 \t\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import keras\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras.applications.densenet import DenseNet121, DenseNet169\n",
    "#from keras.applications.nasnet import NASNetLarge\n",
    "# from keras_efficientnets import EfficientNetB7\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras import initializers, regularizers, constraints\n",
    "from keras.layers.normalization import BatchNormalization \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from keras import backend as K\n",
    "\n",
    "tf.set_random_seed(1234)\n",
    "random.seed(100)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "\n",
    "def score_f1(y_true, y_pred): #taken from old keras source code\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val\n",
    "\n",
    "def dot_product(x, kernel):\n",
    "    if K.backend() == 'tensorflow':\n",
    "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
    "    else:\n",
    "        return K.dot(x, kernel)\n",
    "    \n",
    "class AttentionWithContext(Layer):\n",
    "    def __init__(self,\n",
    "                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, u_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.u_regularizer = regularizers.get(u_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.u_constraint = constraints.get(u_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "        self.bias = bias\n",
    "        super(AttentionWithContext, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "        self.W = self.add_weight((input_shape[-1], input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight((input_shape[-1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "            self.u = self.add_weight((input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_u'.format(self.name),\n",
    "                                 regularizer=self.u_regularizer,\n",
    "                                 constraint=self.u_constraint)\n",
    "        super(AttentionWithContext, self).build(input_shape)\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        uit = dot_product(x, self.W)\n",
    "        if self.bias:\n",
    "            uit += self.b\n",
    "        uit = K.tanh(uit)\n",
    "        ait = dot_product(uit, self.u)\n",
    "        a = K.exp(ait)\n",
    "        if mask is not None:\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], input_shape[-1]\n",
    "\n",
    "    \n",
    "def cce_f1_loss(y_true, y_pred):\n",
    "    return 1 + 0.1*keras.losses.categorical_crossentropy(y_true, y_pred) - keras.metrics.categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "# Find unique number of classes  \n",
    "def get_unique_classes(input_directory,files):\n",
    "\n",
    "    unique_classes=set()\n",
    "    for f in files:\n",
    "        g = f.replace('.mat','.hea')\n",
    "        input_file = os.path.join(input_directory,g)\n",
    "        with open(input_file,'r') as f:\n",
    "            for lines in f:\n",
    "                if lines.startswith('#Dx'):\n",
    "                    tmp = lines.split(': ')[1].split(',')\n",
    "                    for c in tmp:\n",
    "                        unique_classes.add(c.strip())\n",
    "    return sorted(unique_classes)\n",
    "\n",
    "def one_hot_encoding(one_hot_vector,y, class2index):\n",
    "    ind=class2index[y]\n",
    "    one_hot_vector[ind]=1\n",
    "    return one_hot_vector\n",
    "\n",
    "# Search for multi-label subjects\n",
    "def searching_overlap(input_directory,class2index, input_file_names):\n",
    "    multiclasses=[]\n",
    "    multisubjects=[]\n",
    "    number = []\n",
    "    for file in input_file_names:\n",
    "        f=file\n",
    "        g = f.replace('.mat','.hea')\n",
    "        input_file = os.path.join(input_directory,g)\n",
    "        with open(input_file,'r') as f:\n",
    "            for lines in f:\n",
    "                if lines.startswith('#Dx'):\n",
    "                    tmp = lines.split(': ')[1].split(',')\n",
    "                    if len(tmp)>1:\n",
    "                        one_hot_vector = [0]*(len(class2index))\n",
    "                        for c in tmp:\n",
    "                            one_hot_vector = one_hot_encoding(one_hot_vector, c.strip(), class2index)\n",
    "                        multiclasses.append(one_hot_vector)\n",
    "                        multisubjects.append(g)\n",
    "                        number.append(len(tmp))\n",
    "    return multisubjects, multiclasses, number\n",
    "\n",
    "def block_feature(sequence_en, minimum_len): \n",
    "    new_en = []\n",
    "    if len(sequence_en) > minimum_len:  # 길이가 minimum보다 긴 경우\n",
    "        start = random.randint(0,len(sequence_en)-minimum_len)\n",
    "        #print(start)\n",
    "        new_en = sequence_en[start:start+minimum_len]\n",
    "    elif len(sequence_en) == minimum_len: # 길이가 minimum\n",
    "        new_en = sequence_en\n",
    "    else: \n",
    "        assert len(sequence_en) <= minimum_len\n",
    "    return new_en\n",
    "\n",
    "def exploratory_look(input_directory,file, class2index):\n",
    "    classes = []\n",
    "    f = file\n",
    "    g = f.replace('.mat','.hea')\n",
    "    input_file = os.path.join(input_directory,g)\n",
    "    with open(input_file,'r') as f:\n",
    "        for lines in f:\n",
    "            if lines.startswith('#Dx'):\n",
    "                tmp = lines.split(': ')[1].split(',')\n",
    "                print(tmp, len(tmp))\n",
    "    return tmp     \n",
    "\n",
    "# Get classes of sorted file names\n",
    "def get_labels(input_directory,file, class2index):\n",
    "    f = file\n",
    "    g = f.replace('.mat','.hea')\n",
    "    input_file = os.path.join(input_directory,g)\n",
    "    with open(input_file,'r') as f:\n",
    "        for lines in f:\n",
    "            if lines.startswith('#Dx'):\n",
    "                tmp = lines.split(': ')[1].split(',')\n",
    "                one_hot_vector = [0]*(len(class2index))\n",
    "                for c in tmp:\n",
    "                    one_hot_vector = one_hot_encoding(one_hot_vector, c.strip(), class2index)\n",
    "                \n",
    "    return one_hot_vector\n",
    "\n",
    "def randextract_mels(curr_step, batch_size, data, mel_directory, class2index, minimum_len, x_mean_final, x_std_final):\n",
    "    mel_files = []\n",
    "    classes = []\n",
    "    start = batch_size*curr_step\n",
    "    end = batch_size*(curr_step+1)\n",
    "    curr_file_indices = data[start:end]\n",
    "    for file in curr_file_indices:\n",
    "        tmp_file = np.load(mel_directory + '/' + file.replace('.mat', '.npy'))\n",
    "        clip_file = block_feature(tmp_file, minimum_len)\n",
    "        #print(clip_file.shape)\n",
    "        #clip_file = tmp_file[:minimum_len]\n",
    "        clip_file -= x_mean_final\n",
    "        clip_file /= x_std_final\n",
    "        mel_files.append(clip_file)\n",
    "        label = get_labels(input_directory, file, class2index)\n",
    "        classes.append(label)\n",
    "    concat = list(zip(mel_files, classes))\n",
    "    random.shuffle(concat)\n",
    "    mel_files, classes = zip(*concat)\n",
    "    return mel_files, classes\n",
    "\n",
    "def train(data_train, mel_directory, batch_size, class2index, minimum_len, x_mean_final, x_std_final): \n",
    "    loss=[]\n",
    "    acc = []\n",
    "    f1 = []\n",
    "\n",
    "    total_steps = int(np.ceil(len(data_train)/batch_size))\n",
    "    for curr_step in range(total_steps):\n",
    "        batch_mels, batch_labels = randextract_mels(curr_step, batch_size, data_train, mel_directory, class2index, minimum_len, x_mean_final, x_std_final)\n",
    "        batch_mels = np.asarray(batch_mels)\n",
    "        batch_labels = np.asarray(np.squeeze(batch_labels))\n",
    "        train_tmp = model.train_on_batch(batch_mels, batch_labels)\n",
    "        loss.append(train_tmp[0])\n",
    "        acc.append(train_tmp[1])\n",
    "        f1.append(train_tmp[2])\n",
    "\n",
    "    loss = np.mean(np.array(loss))\n",
    "    acc = np.mean(np.array(acc))\n",
    "    f1 = np.mean(np.array(f1))\n",
    "    return loss, acc, f1\n",
    "\n",
    "def test(data, mel_directory, input_directory, class2index, minimum_len, model, x_mean_final, x_std_final):\n",
    "    scores = []\n",
    "    predicted_labels=[]\n",
    "    accuracy=np.zeros(len(data))\n",
    "    #total_loss=[]\n",
    "    total_acc = 0\n",
    "    total_f1 = 0\n",
    "    \n",
    "    mel_files = []\n",
    "    classes = []\n",
    "    for i, file in enumerate(data):\n",
    "        tmp_file = np.load(mel_directory + '/' + file.replace('.mat', '.npy'))\n",
    "        steps = int(np.floor(tmp_file.shape[0]/minimum_len))\n",
    "        mel_files = []\n",
    "        for block in range(steps): # 128개씩 쪼갠 블럭 단위로 predict\n",
    "            start = block*minimum_len\n",
    "            end = (block+1)*minimum_len\n",
    "            clip_file = tmp_file[start:end]\n",
    "            clip_file -= x_mean_final\n",
    "            clip_file /= x_std_final\n",
    "            mel_files.append(clip_file)\n",
    "        mel_files = np.asarray(mel_files)\n",
    "        logit = model.predict(mel_files)\n",
    "        logit = np.mean(logit, axis=0)\n",
    "        pred = np.argmax(logit)\n",
    "        label = np.argmax(get_labels(input_directory, file, class2index))\n",
    "        #f1 = f1_score(label, logit)\n",
    "        #print(pred, label)\n",
    "        if pred == label:\n",
    "            acc = 1\n",
    "        else:\n",
    "            acc = 0\n",
    "        total_acc += acc\n",
    "        #total_f1 += f1\n",
    "    final_acc = total_acc / i\n",
    "    #final_f1 = total_f1 / i\n",
    "    return final_acc#, final_f1\n",
    "\n",
    "batch_size = 32\n",
    "minimum_len = 2880\n",
    "epochs = 1000\n",
    "loss_function = 'categorical_crossentropy'\n",
    "activation_function = 'softmax'\n",
    "rootdir = '../'\n",
    "date = datetime.today().strftime(\"%Y%m%d\")\n",
    "input_directory = os.path.join(rootdir, 'Training_WFDB')\n",
    "mel_name = 'Raw_data_20200424' \n",
    "mel_directory = os.path.join(rootdir, mel_name)\n",
    "results_directory = os.path.join(rootdir, 'results_'+date+'_0')\n",
    "if not os.path.isdir(input_directory):\n",
    "    os.mkdir(input_directory)\n",
    "if not os.path.isdir(mel_directory):\n",
    "    os.mkdir(mel_directory)\n",
    "if not os.path.isdir(results_directory):\n",
    "    os.mkdir(results_directory)\n",
    "        \n",
    "input_files = []\n",
    "for f in os.listdir(input_directory):\n",
    "    if os.path.isfile(os.path.join(input_directory, f)) and not f.lower().startswith('.') and f.lower().endswith('mat'):\n",
    "        input_files.append(f)\n",
    "input_file_names = sorted(input_files)\n",
    "\n",
    "unique_classes = get_unique_classes(input_directory, input_files)\n",
    "class2index = {}\n",
    "for a, b in enumerate(unique_classes):\n",
    "    class2index[b] = a\n",
    "    \n",
    "# classes_orig= [x.replace('.mat', '.hea') for x in input_file_names] # total subjects\n",
    "# classes_multi, _, _ = searching_overlap(input_directory,class2index, input_file_names)\n",
    "# classes_single = [x for x in classes_orig if x not in classes_multi]\n",
    "# classes_single = [x.replace('.hea', '.mat') for x in classes_single]\n",
    "\n",
    "# double-checking if classes_single have single-label\n",
    "# a, b, c  = searching_overlap(input_directory,class2index,classes_single)\n",
    "\n",
    "# we can safely use classes_single as input_file_names\n",
    "# input_file_names = classes_single\n",
    "random.shuffle(input_file_names)\n",
    "np.shape(input_file_names)\n",
    "\n",
    "x_mean_all = []\n",
    "x_std_all = []\n",
    "for file in input_file_names:\n",
    "    x = np.load(mel_directory + '/' + file.replace('.mat', '.npy'))\n",
    "    x_mean = [np.mean(x[:,0]), np.mean(x[:,1]), np.mean(x[:,2]), np.mean(x[:,3]), np.mean(x[:,4]), np.mean(x[:,5]),\n",
    "             np.mean(x[:,6]), np.mean(x[:,7]), np.mean(x[:,8]), np.mean(x[:,9]), np.mean(x[:,10]), np.mean(x[:,11])]\n",
    "    \n",
    "    x_std = [np.std(x[:,0]), np.std(x[:,1]), np.std(x[:,2]), np.std(x[:,3]), np.std(x[:,4]), np.std(x[:,5]),\n",
    "             np.std(x[:,6]), np.std(x[:,7]), np.std(x[:,8]), np.std(x[:,9]), np.std(x[:,10]), np.std(x[:,11])]\n",
    "    #print(x_mean)\n",
    "    x_mean_all.append(x_mean)\n",
    "    x_std_all.append(x_std)\n",
    "x_mean_final = np.mean(x_mean_all, axis=0)\n",
    "x_std_final = np.mean(x_std_all, axis=0)\n",
    "print(x_mean_final)\n",
    "\n",
    "data, data_test = train_test_split(input_file_names, test_size = 0.2, train_size = 0.8, shuffle=True)\n",
    "# data_train, data_val = train_test_split(data, test_size = 0.25, train_size = 0.75, shuffle=True)\n",
    "data_train, data_val = train_test_split(data, test_size = 0.05, train_size = 0.95, shuffle=True)\n",
    "print(np.shape(data_train), np.shape(data_val), np.shape(data_test))\n",
    "\n",
    "main_input = Input(shape=(minimum_len,12), dtype='float32', name='main_input')\n",
    "\n",
    "branch_pred = []\n",
    "for i in range(12):\n",
    "    # Slicing the ith channel:\n",
    "    input_sl = Lambda(lambda x: x[:, :, i:i+1])(main_input)\n",
    "    #print(input_sl)\n",
    "    x1 = GaussianNoise(0.01 ,input_shape=(minimum_len, 1))(input_sl)\n",
    "    x1 = Conv1D(32, 10, dilation_rate=3, padding='same')(x1)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = LeakyReLU(alpha=0.3)(x1)\n",
    "    x2 = Conv1D(32, 10, dilation_rate=3, padding='same')(x1)\n",
    "    x2 = add([x2, x1])\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = LeakyReLU(alpha=0.3)(x2)\n",
    "    #x2 = MaxPooling1D(pool_size=2)(x2)\n",
    "    x2 = Convolution1D(32, 20, strides = 2, padding='same')(x2)\n",
    "    #x2 = Dropout(0.25)(x2)\n",
    "\n",
    "    x3 = Conv1D(64, 10, dilation_rate=2, padding='same')(x2)\n",
    "    x3 = BatchNormalization()(x3)\n",
    "    x3 = LeakyReLU(alpha=0.3)(x3)\n",
    "    x4 = Conv1D(64, 10, dilation_rate=2, padding='same')(x3)\n",
    "    x4 = add([x4, x3])\n",
    "    x4 = BatchNormalization()(x4)\n",
    "    x4 = LeakyReLU(alpha=0.3)(x4)\n",
    "    #x4 = MaxPooling1D(pool_size=2)(x4)\n",
    "    x4 = Convolution1D(32, 20, strides = 2, padding='same')(x4)\n",
    "    #x4 = Dropout(0.25)(x4)\n",
    "\n",
    "    x5 = Conv1D(128, 10, dilation_rate=1, padding='same')(x4)\n",
    "    x5 = BatchNormalization()(x5)\n",
    "    x5 = LeakyReLU(alpha=0.3)(x5)\n",
    "    x6 = Conv1D(128, 10, dilation_rate=1, padding='same')(x5)\n",
    "    x6 = add([x6, x5])\n",
    "    x6 = BatchNormalization()(x6)\n",
    "    x6 = LeakyReLU(alpha=0.3)(x6)\n",
    "    #x6 = MaxPooling1D(pool_size=2)(x6)\n",
    "    x6 = Convolution1D(64, 20, strides = 2, padding='same')(x6)\n",
    "    #x6 = Dropout(0.25)(x6)\n",
    "    '''\n",
    "    x7 = Conv1D(64, 10, dilation_rate=1, padding='same')(x6)\n",
    "    x7 = BatchNormalization()(x7)\n",
    "    x7 = LeakyReLU(alpha=0.3)(x7)\n",
    "    x8 = Conv1D(64, 10, dilation_rate=1, padding='same')(x7)\n",
    "    x8 = add([x8, x7])\n",
    "    x8 = BatchNormalization()(x8)\n",
    "    x8 = LeakyReLU(alpha=0.3)(x8)\n",
    "    #x8 = MaxPooling1D(pool_size=2)(x8)\n",
    "    x8 = Convolution1D(64, 20, strides = 2, padding='same')(x8)\n",
    "    #cnnout = GlobalAveragePooling1D()(x8)\n",
    "    #x8 = Dropout(0.25)(x8)\n",
    "    '''\n",
    "    x = Bidirectional(CuDNNGRU(128, input_shape=(360,128),return_sequences=True,return_state=False))(x6)\n",
    "    x = LeakyReLU(alpha=0.3)(x)\n",
    "    x = AttentionWithContext()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.3)(x)\n",
    "    \n",
    "    #x = GlobalAveragePooling1D()(x8)\n",
    "    #x = Flatten()(x8)\n",
    "    #x = Dense(512)(x)\n",
    "    #x = BatchNormalization()(x)\n",
    "    #x = Activation('relu')(x)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    x = Dense(9)(x)\n",
    "    pred  = Activation('softmax')(x)\n",
    "    branch_pred.append(pred)\n",
    "    \n",
    "out = Average()(branch_pred)\n",
    "#print(out)\n",
    "\n",
    "model = Model(inputs=main_input, outputs=out)\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=loss_function,\n",
    "              optimizer=optimizers.Adam(lr=1e-5),\n",
    "              metrics=['acc', score_f1])\n",
    "\n",
    "val_acc_sum=[]\n",
    "train_loss_sum=[]\n",
    "train_acc_sum=[]\n",
    "val_loss_sum=[]\n",
    "val_acc_min = 0\n",
    "for num_epoch in range(epochs):\n",
    "    random.shuffle(data_train)\n",
    "    train_loss, train_acc, train_f1 = train(data_train, mel_directory, batch_size, class2index, minimum_len, x_mean_final, x_std_final)\n",
    "    print('\\nEpoch',num_epoch+1,'train_loss:',f'{train_loss:.3f}','train_acc:',f'{train_acc:.3f}','train_f1:',f'{train_f1:.3f}',\"\\t\")\n",
    "    model_output = \"ecg_mel_E%02dL%.2f\" % (num_epoch, train_loss)\n",
    "    save_name = os.path.join(results_directory, model_output)\n",
    "    #val_acc, val_f1 = test(data_val, mel_directory, input_directory, class2index, minimum_len, model, x_mean_final, x_std_final)\n",
    "    val_acc = test(data_val, mel_directory, input_directory, class2index, minimum_len, model, x_mean_final, x_std_final)\n",
    "    #print('\\nValidation', num_epoch+1,'valid_loss:',f'{val_loss:.3f}','valid_acc:',f'{val_acc:.3f}',\"\\t\", dt.datetime.now())\n",
    "    if val_acc > val_acc_min:\n",
    "        val_acc_min = val_acc\n",
    "        model.save(save_name)\n",
    "        #print(\"Validation loss is improved\")\n",
    "    #print('\\nValidation', num_epoch+1, 'valid_acc:',f'{val_acc:.3f}', 'valid_f1:',f'{valid_f1:.3f}', 'best_f1:',f'{val_f1_min:.3f}', \"\\t\")\n",
    "    print('\\nValidation', num_epoch+1, 'valid_acc:',f'{val_acc:.3f}', 'best_acc:',f'{val_acc_min:.3f}', \"\\t\")\n",
    "    #val_acc_sum.append(val_acc)\n",
    "    #val_loss_sum.append(val_loss)\n",
    "    #train_loss_sum.append(train_loss)\n",
    "    #train_acc_sum.append(train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
