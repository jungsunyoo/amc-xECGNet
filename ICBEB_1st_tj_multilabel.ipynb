{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/numba/errors.py:137: UserWarning: Insufficiently recent colorama version found. Numba requires colorama >= 0.3.9\n",
      "  warnings.warn(msg)\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0012702   0.00038759  0.00402317 -0.0029567   0.00051957  0.00116427\n",
      " -0.0008405  -0.00222516 -0.0019119  -0.00093502  0.00129789  0.00177598]\n",
      "(5225,) (276,) (1376,)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, 2880, 12)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 2880, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_1 (GaussianNoise (None, 2880, 1)      0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_2 (GaussianNoise (None, 2880, 1)      0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_3 (GaussianNoise (None, 2880, 1)      0           lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_4 (GaussianNoise (None, 2880, 1)      0           lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_5 (GaussianNoise (None, 2880, 1)      0           lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_6 (GaussianNoise (None, 2880, 1)      0           lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_7 (GaussianNoise (None, 2880, 1)      0           lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_8 (GaussianNoise (None, 2880, 1)      0           lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_9 (GaussianNoise (None, 2880, 1)      0           lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_10 (GaussianNois (None, 2880, 1)      0           lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_11 (GaussianNois (None, 2880, 1)      0           lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_12 (GaussianNois (None, 2880, 1)      0           lambda_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 2880, 32)     352         gaussian_noise_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 2880, 32)     352         gaussian_noise_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 2880, 32)     352         gaussian_noise_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 2880, 32)     352         gaussian_noise_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 2880, 32)     352         gaussian_noise_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_46 (Conv1D)              (None, 2880, 32)     352         gaussian_noise_6[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_55 (Conv1D)              (None, 2880, 32)     352         gaussian_noise_7[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_64 (Conv1D)              (None, 2880, 32)     352         gaussian_noise_8[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_73 (Conv1D)              (None, 2880, 32)     352         gaussian_noise_9[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_82 (Conv1D)              (None, 2880, 32)     352         gaussian_noise_10[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_91 (Conv1D)              (None, 2880, 32)     352         gaussian_noise_11[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_100 (Conv1D)             (None, 2880, 32)     352         gaussian_noise_12[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 2880, 32)     128         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 2880, 32)     128         conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 2880, 32)     128         conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 2880, 32)     128         conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 2880, 32)     128         conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 2880, 32)     128         conv1d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 2880, 32)     128         conv1d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 2880, 32)     128         conv1d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 2880, 32)     128         conv1d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 2880, 32)     128         conv1d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 2880, 32)     128         conv1d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 2880, 32)     128         conv1d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 2880, 32)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 2880, 32)     0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_33 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_41 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_49 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_57 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_65 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_73 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_81 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_89 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 2880, 32)     10272       leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 2880, 32)     10272       leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 2880, 32)     10272       leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 2880, 32)     10272       leaky_re_lu_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, 2880, 32)     10272       leaky_re_lu_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_47 (Conv1D)              (None, 2880, 32)     10272       leaky_re_lu_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_56 (Conv1D)              (None, 2880, 32)     10272       leaky_re_lu_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_65 (Conv1D)              (None, 2880, 32)     10272       leaky_re_lu_57[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_74 (Conv1D)              (None, 2880, 32)     10272       leaky_re_lu_65[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_83 (Conv1D)              (None, 2880, 32)     10272       leaky_re_lu_73[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_92 (Conv1D)              (None, 2880, 32)     10272       leaky_re_lu_81[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_101 (Conv1D)             (None, 2880, 32)     10272       leaky_re_lu_89[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 2880, 32)     0           conv1d_2[0][0]                   \n",
      "                                                                 leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 2880, 32)     0           conv1d_11[0][0]                  \n",
      "                                                                 leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 2880, 32)     0           conv1d_20[0][0]                  \n",
      "                                                                 leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 2880, 32)     0           conv1d_29[0][0]                  \n",
      "                                                                 leaky_re_lu_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 2880, 32)     0           conv1d_38[0][0]                  \n",
      "                                                                 leaky_re_lu_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 2880, 32)     0           conv1d_47[0][0]                  \n",
      "                                                                 leaky_re_lu_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 2880, 32)     0           conv1d_56[0][0]                  \n",
      "                                                                 leaky_re_lu_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 2880, 32)     0           conv1d_65[0][0]                  \n",
      "                                                                 leaky_re_lu_57[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 2880, 32)     0           conv1d_74[0][0]                  \n",
      "                                                                 leaky_re_lu_65[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 2880, 32)     0           conv1d_83[0][0]                  \n",
      "                                                                 leaky_re_lu_73[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 2880, 32)     0           conv1d_92[0][0]                  \n",
      "                                                                 leaky_re_lu_81[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_34 (Add)                    (None, 2880, 32)     0           conv1d_101[0][0]                 \n",
      "                                                                 leaky_re_lu_89[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 2880, 32)     128         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 2880, 32)     128         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 2880, 32)     128         add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 2880, 32)     128         add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 2880, 32)     128         add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 2880, 32)     128         add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 2880, 32)     128         add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 2880, 32)     128         add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 2880, 32)     128         add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 2880, 32)     128         add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 2880, 32)     128         add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 2880, 32)     128         add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 2880, 32)     0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_26 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_34 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_42 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_50 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_58 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_66 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_74 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_82 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_90 (LeakyReLU)      (None, 2880, 32)     0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 1440, 32)     20512       leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 1440, 32)     20512       leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 1440, 32)     20512       leaky_re_lu_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 1440, 32)     20512       leaky_re_lu_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_39 (Conv1D)              (None, 1440, 32)     20512       leaky_re_lu_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_48 (Conv1D)              (None, 1440, 32)     20512       leaky_re_lu_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_57 (Conv1D)              (None, 1440, 32)     20512       leaky_re_lu_50[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_66 (Conv1D)              (None, 1440, 32)     20512       leaky_re_lu_58[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_75 (Conv1D)              (None, 1440, 32)     20512       leaky_re_lu_66[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_84 (Conv1D)              (None, 1440, 32)     20512       leaky_re_lu_74[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_93 (Conv1D)              (None, 1440, 32)     20512       leaky_re_lu_82[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_102 (Conv1D)             (None, 1440, 32)     20512       leaky_re_lu_90[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 1440, 64)     20544       conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 1440, 64)     20544       conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 1440, 64)     20544       conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, 1440, 64)     20544       conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_40 (Conv1D)              (None, 1440, 64)     20544       conv1d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_49 (Conv1D)              (None, 1440, 64)     20544       conv1d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_58 (Conv1D)              (None, 1440, 64)     20544       conv1d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_67 (Conv1D)              (None, 1440, 64)     20544       conv1d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_76 (Conv1D)              (None, 1440, 64)     20544       conv1d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_85 (Conv1D)              (None, 1440, 64)     20544       conv1d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_94 (Conv1D)              (None, 1440, 64)     20544       conv1d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_103 (Conv1D)             (None, 1440, 64)     20544       conv1d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1440, 64)     256         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 1440, 64)     256         conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 1440, 64)     256         conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 1440, 64)     256         conv1d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 1440, 64)     256         conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 1440, 64)     256         conv1d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 1440, 64)     256         conv1d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 1440, 64)     256         conv1d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 1440, 64)     256         conv1d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 1440, 64)     256         conv1d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 1440, 64)     256         conv1d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 1440, 64)     256         conv1d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 1440, 64)     0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_27 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_35 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_43 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_51 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_59 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_67 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_75 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_83 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_91 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 1440, 64)     41024       leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 1440, 64)     41024       leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 1440, 64)     41024       leaky_re_lu_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 1440, 64)     41024       leaky_re_lu_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_41 (Conv1D)              (None, 1440, 64)     41024       leaky_re_lu_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_50 (Conv1D)              (None, 1440, 64)     41024       leaky_re_lu_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_59 (Conv1D)              (None, 1440, 64)     41024       leaky_re_lu_51[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_68 (Conv1D)              (None, 1440, 64)     41024       leaky_re_lu_59[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_77 (Conv1D)              (None, 1440, 64)     41024       leaky_re_lu_67[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_86 (Conv1D)              (None, 1440, 64)     41024       leaky_re_lu_75[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_95 (Conv1D)              (None, 1440, 64)     41024       leaky_re_lu_83[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_104 (Conv1D)             (None, 1440, 64)     41024       leaky_re_lu_91[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 1440, 64)     0           conv1d_5[0][0]                   \n",
      "                                                                 leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 1440, 64)     0           conv1d_14[0][0]                  \n",
      "                                                                 leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 1440, 64)     0           conv1d_23[0][0]                  \n",
      "                                                                 leaky_re_lu_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 1440, 64)     0           conv1d_32[0][0]                  \n",
      "                                                                 leaky_re_lu_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 1440, 64)     0           conv1d_41[0][0]                  \n",
      "                                                                 leaky_re_lu_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 1440, 64)     0           conv1d_50[0][0]                  \n",
      "                                                                 leaky_re_lu_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 1440, 64)     0           conv1d_59[0][0]                  \n",
      "                                                                 leaky_re_lu_51[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 1440, 64)     0           conv1d_68[0][0]                  \n",
      "                                                                 leaky_re_lu_59[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 1440, 64)     0           conv1d_77[0][0]                  \n",
      "                                                                 leaky_re_lu_67[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 1440, 64)     0           conv1d_86[0][0]                  \n",
      "                                                                 leaky_re_lu_75[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 1440, 64)     0           conv1d_95[0][0]                  \n",
      "                                                                 leaky_re_lu_83[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_35 (Add)                    (None, 1440, 64)     0           conv1d_104[0][0]                 \n",
      "                                                                 leaky_re_lu_91[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 1440, 64)     256         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 1440, 64)     256         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 1440, 64)     256         add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 1440, 64)     256         add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 1440, 64)     256         add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 1440, 64)     256         add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 1440, 64)     256         add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 1440, 64)     256         add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 1440, 64)     256         add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 1440, 64)     256         add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 1440, 64)     256         add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 1440, 64)     256         add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 1440, 64)     0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_28 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_36 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_44 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_52 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_60 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_68 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_76 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_84 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_92 (LeakyReLU)      (None, 1440, 64)     0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 720, 32)      40992       leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 720, 32)      40992       leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 720, 32)      40992       leaky_re_lu_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 720, 32)      40992       leaky_re_lu_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_42 (Conv1D)              (None, 720, 32)      40992       leaky_re_lu_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_51 (Conv1D)              (None, 720, 32)      40992       leaky_re_lu_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_60 (Conv1D)              (None, 720, 32)      40992       leaky_re_lu_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_69 (Conv1D)              (None, 720, 32)      40992       leaky_re_lu_60[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_78 (Conv1D)              (None, 720, 32)      40992       leaky_re_lu_68[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_87 (Conv1D)              (None, 720, 32)      40992       leaky_re_lu_76[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_96 (Conv1D)              (None, 720, 32)      40992       leaky_re_lu_84[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_105 (Conv1D)             (None, 720, 32)      40992       leaky_re_lu_92[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 720, 128)     41088       conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 720, 128)     41088       conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 720, 128)     41088       conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 720, 128)     41088       conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_43 (Conv1D)              (None, 720, 128)     41088       conv1d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_52 (Conv1D)              (None, 720, 128)     41088       conv1d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_61 (Conv1D)              (None, 720, 128)     41088       conv1d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_70 (Conv1D)              (None, 720, 128)     41088       conv1d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_79 (Conv1D)              (None, 720, 128)     41088       conv1d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_88 (Conv1D)              (None, 720, 128)     41088       conv1d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_97 (Conv1D)              (None, 720, 128)     41088       conv1d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_106 (Conv1D)             (None, 720, 128)     41088       conv1d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 720, 128)     512         conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 720, 128)     512         conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 720, 128)     512         conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 720, 128)     512         conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 720, 128)     512         conv1d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 720, 128)     512         conv1d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 720, 128)     512         conv1d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 720, 128)     512         conv1d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 720, 128)     512         conv1d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 720, 128)     512         conv1d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 720, 128)     512         conv1d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 720, 128)     512         conv1d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 720, 128)     0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_29 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_37 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_45 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_53 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_61 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_69 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_77 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_85 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_93 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 720, 128)     163968      leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 720, 128)     163968      leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 720, 128)     163968      leaky_re_lu_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 720, 128)     163968      leaky_re_lu_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_44 (Conv1D)              (None, 720, 128)     163968      leaky_re_lu_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_53 (Conv1D)              (None, 720, 128)     163968      leaky_re_lu_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_62 (Conv1D)              (None, 720, 128)     163968      leaky_re_lu_53[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_71 (Conv1D)              (None, 720, 128)     163968      leaky_re_lu_61[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_80 (Conv1D)              (None, 720, 128)     163968      leaky_re_lu_69[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_89 (Conv1D)              (None, 720, 128)     163968      leaky_re_lu_77[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_98 (Conv1D)              (None, 720, 128)     163968      leaky_re_lu_85[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_107 (Conv1D)             (None, 720, 128)     163968      leaky_re_lu_93[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 720, 128)     0           conv1d_8[0][0]                   \n",
      "                                                                 leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 720, 128)     0           conv1d_17[0][0]                  \n",
      "                                                                 leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 720, 128)     0           conv1d_26[0][0]                  \n",
      "                                                                 leaky_re_lu_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 720, 128)     0           conv1d_35[0][0]                  \n",
      "                                                                 leaky_re_lu_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 720, 128)     0           conv1d_44[0][0]                  \n",
      "                                                                 leaky_re_lu_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 720, 128)     0           conv1d_53[0][0]                  \n",
      "                                                                 leaky_re_lu_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 720, 128)     0           conv1d_62[0][0]                  \n",
      "                                                                 leaky_re_lu_53[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 720, 128)     0           conv1d_71[0][0]                  \n",
      "                                                                 leaky_re_lu_61[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 720, 128)     0           conv1d_80[0][0]                  \n",
      "                                                                 leaky_re_lu_69[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 720, 128)     0           conv1d_89[0][0]                  \n",
      "                                                                 leaky_re_lu_77[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_33 (Add)                    (None, 720, 128)     0           conv1d_98[0][0]                  \n",
      "                                                                 leaky_re_lu_85[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_36 (Add)                    (None, 720, 128)     0           conv1d_107[0][0]                 \n",
      "                                                                 leaky_re_lu_93[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 720, 128)     512         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 720, 128)     512         add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 720, 128)     512         add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 720, 128)     512         add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 720, 128)     512         add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 720, 128)     512         add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 720, 128)     512         add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 720, 128)     512         add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 720, 128)     512         add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 720, 128)     512         add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 720, 128)     512         add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 720, 128)     512         add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 720, 128)     0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_30 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_38 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_46 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_54 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_62 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_70 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_78 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_86 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_94 (LeakyReLU)      (None, 720, 128)     0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 360, 64)      163904      leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 360, 64)      163904      leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 360, 64)      163904      leaky_re_lu_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, 360, 64)      163904      leaky_re_lu_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_45 (Conv1D)              (None, 360, 64)      163904      leaky_re_lu_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_54 (Conv1D)              (None, 360, 64)      163904      leaky_re_lu_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_63 (Conv1D)              (None, 360, 64)      163904      leaky_re_lu_54[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_72 (Conv1D)              (None, 360, 64)      163904      leaky_re_lu_62[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_81 (Conv1D)              (None, 360, 64)      163904      leaky_re_lu_70[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_90 (Conv1D)              (None, 360, 64)      163904      leaky_re_lu_78[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_99 (Conv1D)              (None, 360, 64)      163904      leaky_re_lu_86[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_108 (Conv1D)             (None, 360, 64)      163904      leaky_re_lu_94[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 360, 256)     148992      conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 360, 256)     148992      conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 360, 256)     148992      conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 360, 256)     148992      conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 360, 256)     148992      conv1d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, 360, 256)     148992      conv1d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, 360, 256)     148992      conv1d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, 360, 256)     148992      conv1d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, 360, 256)     148992      conv1d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, 360, 256)     148992      conv1d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional (None, 360, 256)     148992      conv1d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional (None, 360, 256)     148992      conv1d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 360, 256)     0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, 360, 256)     0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)      (None, 360, 256)     0           bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_31 (LeakyReLU)      (None, 360, 256)     0           bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_39 (LeakyReLU)      (None, 360, 256)     0           bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_47 (LeakyReLU)      (None, 360, 256)     0           bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_55 (LeakyReLU)      (None, 360, 256)     0           bidirectional_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_63 (LeakyReLU)      (None, 360, 256)     0           bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_71 (LeakyReLU)      (None, 360, 256)     0           bidirectional_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_79 (LeakyReLU)      (None, 360, 256)     0           bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_87 (LeakyReLU)      (None, 360, 256)     0           bidirectional_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_95 (LeakyReLU)      (None, 360, 256)     0           bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_1 (Atten (None, 256)          66048       leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_2 (Atten (None, 256)          66048       leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_3 (Atten (None, 256)          66048       leaky_re_lu_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_4 (Atten (None, 256)          66048       leaky_re_lu_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_5 (Atten (None, 256)          66048       leaky_re_lu_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_6 (Atten (None, 256)          66048       leaky_re_lu_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_7 (Atten (None, 256)          66048       leaky_re_lu_55[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_8 (Atten (None, 256)          66048       leaky_re_lu_63[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_9 (Atten (None, 256)          66048       leaky_re_lu_71[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_10 (Atte (None, 256)          66048       leaky_re_lu_79[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_11 (Atte (None, 256)          66048       leaky_re_lu_87[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_12 (Atte (None, 256)          66048       leaky_re_lu_95[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 256)          1024        attention_with_context_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 256)          1024        attention_with_context_2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 256)          1024        attention_with_context_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 256)          1024        attention_with_context_4[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 256)          1024        attention_with_context_5[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 256)          1024        attention_with_context_6[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 256)          1024        attention_with_context_7[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 256)          1024        attention_with_context_8[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 256)          1024        attention_with_context_9[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 256)          1024        attention_with_context_10[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 256)          1024        attention_with_context_11[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 256)          1024        attention_with_context_12[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 256)          0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, 256)          0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)      (None, 256)          0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_32 (LeakyReLU)      (None, 256)          0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_40 (LeakyReLU)      (None, 256)          0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_48 (LeakyReLU)      (None, 256)          0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_56 (LeakyReLU)      (None, 256)          0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_64 (LeakyReLU)      (None, 256)          0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_72 (LeakyReLU)      (None, 256)          0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_80 (LeakyReLU)      (None, 256)          0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_88 (LeakyReLU)      (None, 256)          0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_96 (LeakyReLU)      (None, 256)          0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 9)            2313        leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 9)            2313        leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 9)            2313        leaky_re_lu_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 9)            2313        leaky_re_lu_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 9)            2313        leaky_re_lu_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 9)            2313        leaky_re_lu_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 9)            2313        leaky_re_lu_56[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 9)            2313        leaky_re_lu_64[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 9)            2313        leaky_re_lu_72[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 9)            2313        leaky_re_lu_80[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 9)            2313        leaky_re_lu_88[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 9)            2313        leaky_re_lu_96[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 9)            0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 9)            0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 9)            0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 9)            0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 9)            0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 9)            0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 9)            0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 9)            0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 9)            0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 9)            0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 9)            0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 9)            0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "average_1 (Average)             (None, 9)            0           activation_1[0][0]               \n",
      "                                                                 activation_2[0][0]               \n",
      "                                                                 activation_3[0][0]               \n",
      "                                                                 activation_4[0][0]               \n",
      "                                                                 activation_5[0][0]               \n",
      "                                                                 activation_6[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_9[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 8,673,900\n",
      "Trainable params: 8,657,004\n",
      "Non-trainable params: 16,896\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "\n",
      "Epoch 1 train_loss: 2.133 train_acc: 0.481 train_f1: 0.341 \t\n",
      "\n",
      "Validation 1 valid_acc: 0.116 best_acc: 0.116 \t\n",
      "\n",
      "Epoch 2 train_loss: 1.981 train_acc: 0.566 train_f1: 0.388 \t\n",
      "\n",
      "Validation 2 valid_acc: 0.138 best_acc: 0.138 \t\n",
      "\n",
      "Epoch 3 train_loss: 1.903 train_acc: 0.602 train_f1: 0.410 \t\n",
      "\n",
      "Validation 3 valid_acc: 0.153 best_acc: 0.153 \t\n",
      "\n",
      "Epoch 4 train_loss: 1.852 train_acc: 0.618 train_f1: 0.424 \t\n",
      "\n",
      "Validation 4 valid_acc: 0.160 best_acc: 0.160 \t\n",
      "\n",
      "Epoch 5 train_loss: 1.805 train_acc: 0.631 train_f1: 0.439 \t\n",
      "\n",
      "Validation 5 valid_acc: 0.171 best_acc: 0.171 \t\n",
      "\n",
      "Epoch 6 train_loss: 1.766 train_acc: 0.646 train_f1: 0.450 \t\n",
      "\n",
      "Validation 6 valid_acc: 0.185 best_acc: 0.185 \t\n",
      "\n",
      "Epoch 7 train_loss: 1.730 train_acc: 0.653 train_f1: 0.467 \t\n",
      "\n",
      "Validation 7 valid_acc: 0.182 best_acc: 0.185 \t\n",
      "\n",
      "Epoch 8 train_loss: 1.698 train_acc: 0.656 train_f1: 0.481 \t\n",
      "\n",
      "Validation 8 valid_acc: 0.189 best_acc: 0.189 \t\n",
      "\n",
      "Epoch 9 train_loss: 1.670 train_acc: 0.666 train_f1: 0.496 \t\n",
      "\n",
      "Validation 9 valid_acc: 0.211 best_acc: 0.211 \t\n",
      "\n",
      "Epoch 10 train_loss: 1.642 train_acc: 0.675 train_f1: 0.510 \t\n",
      "\n",
      "Validation 10 valid_acc: 0.215 best_acc: 0.215 \t\n",
      "\n",
      "Epoch 11 train_loss: 1.604 train_acc: 0.679 train_f1: 0.529 \t\n",
      "\n",
      "Validation 11 valid_acc: 0.225 best_acc: 0.225 \t\n",
      "\n",
      "Epoch 12 train_loss: 1.583 train_acc: 0.681 train_f1: 0.543 \t\n",
      "\n",
      "Validation 12 valid_acc: 0.247 best_acc: 0.247 \t\n",
      "\n",
      "Epoch 13 train_loss: 1.559 train_acc: 0.675 train_f1: 0.554 \t\n",
      "\n",
      "Validation 13 valid_acc: 0.244 best_acc: 0.247 \t\n",
      "\n",
      "Epoch 14 train_loss: 1.539 train_acc: 0.686 train_f1: 0.566 \t\n",
      "\n",
      "Validation 14 valid_acc: 0.262 best_acc: 0.262 \t\n",
      "\n",
      "Epoch 15 train_loss: 1.514 train_acc: 0.687 train_f1: 0.571 \t\n",
      "\n",
      "Validation 15 valid_acc: 0.302 best_acc: 0.302 \t\n",
      "\n",
      "Epoch 16 train_loss: 1.494 train_acc: 0.692 train_f1: 0.582 \t\n",
      "\n",
      "Validation 16 valid_acc: 0.302 best_acc: 0.302 \t\n",
      "\n",
      "Epoch 17 train_loss: 1.476 train_acc: 0.694 train_f1: 0.588 \t\n",
      "\n",
      "Validation 17 valid_acc: 0.338 best_acc: 0.338 \t\n",
      "\n",
      "Epoch 18 train_loss: 1.457 train_acc: 0.691 train_f1: 0.596 \t\n",
      "\n",
      "Validation 18 valid_acc: 0.360 best_acc: 0.360 \t\n",
      "\n",
      "Epoch 19 train_loss: 1.437 train_acc: 0.697 train_f1: 0.601 \t\n",
      "\n",
      "Validation 19 valid_acc: 0.385 best_acc: 0.385 \t\n",
      "\n",
      "Epoch 20 train_loss: 1.415 train_acc: 0.694 train_f1: 0.609 \t\n",
      "\n",
      "Validation 20 valid_acc: 0.396 best_acc: 0.396 \t\n",
      "\n",
      "Epoch 21 train_loss: 1.399 train_acc: 0.693 train_f1: 0.619 \t\n",
      "\n",
      "Validation 21 valid_acc: 0.400 best_acc: 0.400 \t\n",
      "\n",
      "Epoch 22 train_loss: 1.376 train_acc: 0.700 train_f1: 0.632 \t\n",
      "\n",
      "Validation 22 valid_acc: 0.400 best_acc: 0.400 \t\n",
      "\n",
      "Epoch 23 train_loss: 1.364 train_acc: 0.702 train_f1: 0.641 \t\n",
      "\n",
      "Validation 23 valid_acc: 0.415 best_acc: 0.415 \t\n",
      "\n",
      "Epoch 24 train_loss: 1.346 train_acc: 0.706 train_f1: 0.645 \t\n",
      "\n",
      "Validation 24 valid_acc: 0.429 best_acc: 0.429 \t\n",
      "\n",
      "Epoch 25 train_loss: 1.330 train_acc: 0.703 train_f1: 0.652 \t\n",
      "\n",
      "Validation 25 valid_acc: 0.451 best_acc: 0.451 \t\n",
      "\n",
      "Epoch 26 train_loss: 1.318 train_acc: 0.708 train_f1: 0.661 \t\n",
      "\n",
      "Validation 26 valid_acc: 0.418 best_acc: 0.451 \t\n",
      "\n",
      "Epoch 27 train_loss: 1.303 train_acc: 0.705 train_f1: 0.666 \t\n",
      "\n",
      "Validation 27 valid_acc: 0.473 best_acc: 0.473 \t\n",
      "\n",
      "Epoch 28 train_loss: 1.282 train_acc: 0.710 train_f1: 0.677 \t\n",
      "\n",
      "Validation 28 valid_acc: 0.495 best_acc: 0.495 \t\n",
      "\n",
      "Epoch 29 train_loss: 1.270 train_acc: 0.710 train_f1: 0.683 \t\n",
      "\n",
      "Validation 29 valid_acc: 0.495 best_acc: 0.495 \t\n",
      "\n",
      "Epoch 30 train_loss: 1.254 train_acc: 0.711 train_f1: 0.692 \t\n",
      "\n",
      "Validation 30 valid_acc: 0.513 best_acc: 0.513 \t\n",
      "\n",
      "Epoch 31 train_loss: 1.236 train_acc: 0.713 train_f1: 0.697 \t\n",
      "\n",
      "Validation 31 valid_acc: 0.498 best_acc: 0.513 \t\n",
      "\n",
      "Epoch 32 train_loss: 1.227 train_acc: 0.721 train_f1: 0.702 \t\n",
      "\n",
      "Validation 32 valid_acc: 0.509 best_acc: 0.513 \t\n",
      "\n",
      "Epoch 33 train_loss: 1.213 train_acc: 0.716 train_f1: 0.705 \t\n",
      "\n",
      "Validation 33 valid_acc: 0.538 best_acc: 0.538 \t\n",
      "\n",
      "Epoch 34 train_loss: 1.199 train_acc: 0.719 train_f1: 0.708 \t\n",
      "\n",
      "Validation 34 valid_acc: 0.575 best_acc: 0.575 \t\n",
      "\n",
      "Epoch 35 train_loss: 1.181 train_acc: 0.725 train_f1: 0.719 \t\n",
      "\n",
      "Validation 35 valid_acc: 0.585 best_acc: 0.585 \t\n",
      "\n",
      "Epoch 36 train_loss: 1.173 train_acc: 0.721 train_f1: 0.718 \t\n",
      "\n",
      "Validation 36 valid_acc: 0.582 best_acc: 0.585 \t\n",
      "\n",
      "Epoch 37 train_loss: 1.155 train_acc: 0.725 train_f1: 0.729 \t\n",
      "\n",
      "Validation 37 valid_acc: 0.585 best_acc: 0.585 \t\n",
      "\n",
      "Epoch 38 train_loss: 1.149 train_acc: 0.726 train_f1: 0.731 \t\n",
      "\n",
      "Validation 38 valid_acc: 0.618 best_acc: 0.618 \t\n",
      "\n",
      "Epoch 39 train_loss: 1.133 train_acc: 0.727 train_f1: 0.730 \t\n",
      "\n",
      "Validation 39 valid_acc: 0.622 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 40 train_loss: 1.123 train_acc: 0.729 train_f1: 0.732 \t\n",
      "\n",
      "Validation 40 valid_acc: 0.618 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 41 train_loss: 1.112 train_acc: 0.730 train_f1: 0.736 \t\n",
      "\n",
      "Validation 41 valid_acc: 0.622 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 42 train_loss: 1.093 train_acc: 0.731 train_f1: 0.742 \t\n",
      "\n",
      "Validation 42 valid_acc: 0.596 best_acc: 0.622 \t\n",
      "\n",
      "Epoch 43 train_loss: 1.090 train_acc: 0.732 train_f1: 0.737 \t\n",
      "\n",
      "Validation 43 valid_acc: 0.629 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 44 train_loss: 1.082 train_acc: 0.735 train_f1: 0.739 \t\n",
      "\n",
      "Validation 44 valid_acc: 0.615 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 45 train_loss: 1.065 train_acc: 0.736 train_f1: 0.743 \t\n",
      "\n",
      "Validation 45 valid_acc: 0.607 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 46 train_loss: 1.055 train_acc: 0.740 train_f1: 0.743 \t\n",
      "\n",
      "Validation 46 valid_acc: 0.607 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 47 train_loss: 1.038 train_acc: 0.744 train_f1: 0.748 \t\n",
      "\n",
      "Validation 47 valid_acc: 0.600 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 48 train_loss: 1.032 train_acc: 0.737 train_f1: 0.745 \t\n",
      "\n",
      "Validation 48 valid_acc: 0.607 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 49 train_loss: 1.019 train_acc: 0.743 train_f1: 0.742 \t\n",
      "\n",
      "Validation 49 valid_acc: 0.600 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 50 train_loss: 1.010 train_acc: 0.741 train_f1: 0.746 \t\n",
      "\n",
      "Validation 50 valid_acc: 0.611 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 51 train_loss: 1.004 train_acc: 0.738 train_f1: 0.740 \t\n",
      "\n",
      "Validation 51 valid_acc: 0.611 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 52 train_loss: 0.989 train_acc: 0.746 train_f1: 0.746 \t\n",
      "\n",
      "Validation 52 valid_acc: 0.607 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 53 train_loss: 0.981 train_acc: 0.750 train_f1: 0.742 \t\n",
      "\n",
      "Validation 53 valid_acc: 0.582 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 54 train_loss: 0.970 train_acc: 0.748 train_f1: 0.741 \t\n",
      "\n",
      "Validation 54 valid_acc: 0.585 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 55 train_loss: 0.957 train_acc: 0.747 train_f1: 0.741 \t\n",
      "\n",
      "Validation 55 valid_acc: 0.585 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 56 train_loss: 0.952 train_acc: 0.746 train_f1: 0.738 \t\n",
      "\n",
      "Validation 56 valid_acc: 0.560 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 57 train_loss: 0.940 train_acc: 0.748 train_f1: 0.735 \t\n",
      "\n",
      "Validation 57 valid_acc: 0.538 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 58 train_loss: 0.925 train_acc: 0.756 train_f1: 0.734 \t\n",
      "\n",
      "Validation 58 valid_acc: 0.545 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 59 train_loss: 0.922 train_acc: 0.753 train_f1: 0.730 \t\n",
      "\n",
      "Validation 59 valid_acc: 0.545 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 60 train_loss: 0.908 train_acc: 0.762 train_f1: 0.727 \t\n",
      "\n",
      "Validation 60 valid_acc: 0.542 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 61 train_loss: 0.901 train_acc: 0.761 train_f1: 0.721 \t\n",
      "\n",
      "Validation 61 valid_acc: 0.535 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 62 train_loss: 0.893 train_acc: 0.764 train_f1: 0.719 \t\n",
      "\n",
      "Validation 62 valid_acc: 0.538 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 63 train_loss: 0.883 train_acc: 0.757 train_f1: 0.713 \t\n",
      "\n",
      "Validation 63 valid_acc: 0.498 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 64 train_loss: 0.874 train_acc: 0.763 train_f1: 0.709 \t\n",
      "\n",
      "Validation 64 valid_acc: 0.516 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 65 train_loss: 0.860 train_acc: 0.766 train_f1: 0.708 \t\n",
      "\n",
      "Validation 65 valid_acc: 0.524 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 66 train_loss: 0.858 train_acc: 0.765 train_f1: 0.706 \t\n",
      "\n",
      "Validation 66 valid_acc: 0.498 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 67 train_loss: 0.851 train_acc: 0.767 train_f1: 0.696 \t\n",
      "\n",
      "Validation 67 valid_acc: 0.502 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 68 train_loss: 0.846 train_acc: 0.766 train_f1: 0.689 \t\n",
      "\n",
      "Validation 68 valid_acc: 0.495 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 69 train_loss: 0.830 train_acc: 0.776 train_f1: 0.678 \t\n",
      "\n",
      "Validation 69 valid_acc: 0.495 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 70 train_loss: 0.827 train_acc: 0.771 train_f1: 0.680 \t\n",
      "\n",
      "Validation 70 valid_acc: 0.469 best_acc: 0.629 \t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 71 train_loss: 0.822 train_acc: 0.776 train_f1: 0.666 \t\n",
      "\n",
      "Validation 71 valid_acc: 0.447 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 72 train_loss: 0.811 train_acc: 0.775 train_f1: 0.672 \t\n",
      "\n",
      "Validation 72 valid_acc: 0.480 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 73 train_loss: 0.813 train_acc: 0.776 train_f1: 0.658 \t\n",
      "\n",
      "Validation 73 valid_acc: 0.425 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 74 train_loss: 0.792 train_acc: 0.785 train_f1: 0.658 \t\n",
      "\n",
      "Validation 74 valid_acc: 0.411 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 75 train_loss: 0.793 train_acc: 0.782 train_f1: 0.648 \t\n",
      "\n",
      "Validation 75 valid_acc: 0.425 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 76 train_loss: 0.785 train_acc: 0.780 train_f1: 0.640 \t\n",
      "\n",
      "Validation 76 valid_acc: 0.396 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 77 train_loss: 0.775 train_acc: 0.784 train_f1: 0.629 \t\n",
      "\n",
      "Validation 77 valid_acc: 0.378 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 78 train_loss: 0.766 train_acc: 0.786 train_f1: 0.621 \t\n",
      "\n",
      "Validation 78 valid_acc: 0.393 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 79 train_loss: 0.768 train_acc: 0.786 train_f1: 0.609 \t\n",
      "\n",
      "Validation 79 valid_acc: 0.415 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 80 train_loss: 0.760 train_acc: 0.790 train_f1: 0.603 \t\n",
      "\n",
      "Validation 80 valid_acc: 0.382 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 81 train_loss: 0.749 train_acc: 0.790 train_f1: 0.600 \t\n",
      "\n",
      "Validation 81 valid_acc: 0.371 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 82 train_loss: 0.747 train_acc: 0.789 train_f1: 0.586 \t\n",
      "\n",
      "Validation 82 valid_acc: 0.364 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 83 train_loss: 0.741 train_acc: 0.793 train_f1: 0.578 \t\n",
      "\n",
      "Validation 83 valid_acc: 0.338 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 84 train_loss: 0.729 train_acc: 0.795 train_f1: 0.576 \t\n",
      "\n",
      "Validation 84 valid_acc: 0.349 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 85 train_loss: 0.730 train_acc: 0.794 train_f1: 0.567 \t\n",
      "\n",
      "Validation 85 valid_acc: 0.335 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 86 train_loss: 0.723 train_acc: 0.798 train_f1: 0.554 \t\n",
      "\n",
      "Validation 86 valid_acc: 0.327 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 87 train_loss: 0.717 train_acc: 0.801 train_f1: 0.540 \t\n",
      "\n",
      "Validation 87 valid_acc: 0.316 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 88 train_loss: 0.710 train_acc: 0.799 train_f1: 0.536 \t\n",
      "\n",
      "Validation 88 valid_acc: 0.338 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 89 train_loss: 0.705 train_acc: 0.801 train_f1: 0.530 \t\n",
      "\n",
      "Validation 89 valid_acc: 0.324 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 90 train_loss: 0.695 train_acc: 0.800 train_f1: 0.526 \t\n",
      "\n",
      "Validation 90 valid_acc: 0.313 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 91 train_loss: 0.687 train_acc: 0.811 train_f1: 0.511 \t\n",
      "\n",
      "Validation 91 valid_acc: 0.316 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 92 train_loss: 0.690 train_acc: 0.807 train_f1: 0.513 \t\n",
      "\n",
      "Validation 92 valid_acc: 0.291 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 93 train_loss: 0.677 train_acc: 0.814 train_f1: 0.500 \t\n",
      "\n",
      "Validation 93 valid_acc: 0.313 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 94 train_loss: 0.677 train_acc: 0.809 train_f1: 0.495 \t\n",
      "\n",
      "Validation 94 valid_acc: 0.298 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 95 train_loss: 0.670 train_acc: 0.810 train_f1: 0.486 \t\n",
      "\n",
      "Validation 95 valid_acc: 0.276 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 96 train_loss: 0.667 train_acc: 0.811 train_f1: 0.484 \t\n",
      "\n",
      "Validation 96 valid_acc: 0.280 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 97 train_loss: 0.660 train_acc: 0.811 train_f1: 0.478 \t\n",
      "\n",
      "Validation 97 valid_acc: 0.291 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 98 train_loss: 0.657 train_acc: 0.812 train_f1: 0.467 \t\n",
      "\n",
      "Validation 98 valid_acc: 0.295 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 99 train_loss: 0.651 train_acc: 0.817 train_f1: 0.458 \t\n",
      "\n",
      "Validation 99 valid_acc: 0.265 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 100 train_loss: 0.649 train_acc: 0.817 train_f1: 0.452 \t\n",
      "\n",
      "Validation 100 valid_acc: 0.265 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 101 train_loss: 0.647 train_acc: 0.823 train_f1: 0.437 \t\n",
      "\n",
      "Validation 101 valid_acc: 0.265 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 102 train_loss: 0.634 train_acc: 0.829 train_f1: 0.437 \t\n",
      "\n",
      "Validation 102 valid_acc: 0.233 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 103 train_loss: 0.633 train_acc: 0.821 train_f1: 0.429 \t\n",
      "\n",
      "Validation 103 valid_acc: 0.258 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 104 train_loss: 0.627 train_acc: 0.826 train_f1: 0.431 \t\n",
      "\n",
      "Validation 104 valid_acc: 0.247 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 105 train_loss: 0.625 train_acc: 0.825 train_f1: 0.424 \t\n",
      "\n",
      "Validation 105 valid_acc: 0.225 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 106 train_loss: 0.616 train_acc: 0.826 train_f1: 0.423 \t\n",
      "\n",
      "Validation 106 valid_acc: 0.258 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 107 train_loss: 0.606 train_acc: 0.835 train_f1: 0.418 \t\n",
      "\n",
      "Validation 107 valid_acc: 0.236 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 108 train_loss: 0.613 train_acc: 0.829 train_f1: 0.409 \t\n",
      "\n",
      "Validation 108 valid_acc: 0.211 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 109 train_loss: 0.603 train_acc: 0.831 train_f1: 0.403 \t\n",
      "\n",
      "Validation 109 valid_acc: 0.215 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 110 train_loss: 0.594 train_acc: 0.833 train_f1: 0.403 \t\n",
      "\n",
      "Validation 110 valid_acc: 0.244 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 111 train_loss: 0.588 train_acc: 0.833 train_f1: 0.397 \t\n",
      "\n",
      "Validation 111 valid_acc: 0.218 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 112 train_loss: 0.586 train_acc: 0.837 train_f1: 0.395 \t\n",
      "\n",
      "Validation 112 valid_acc: 0.207 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 113 train_loss: 0.583 train_acc: 0.838 train_f1: 0.385 \t\n",
      "\n",
      "Validation 113 valid_acc: 0.215 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 114 train_loss: 0.579 train_acc: 0.842 train_f1: 0.371 \t\n",
      "\n",
      "Validation 114 valid_acc: 0.211 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 115 train_loss: 0.577 train_acc: 0.841 train_f1: 0.378 \t\n",
      "\n",
      "Validation 115 valid_acc: 0.189 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 116 train_loss: 0.570 train_acc: 0.845 train_f1: 0.368 \t\n",
      "\n",
      "Validation 116 valid_acc: 0.207 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 117 train_loss: 0.564 train_acc: 0.850 train_f1: 0.363 \t\n",
      "\n",
      "Validation 117 valid_acc: 0.193 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 118 train_loss: 0.563 train_acc: 0.843 train_f1: 0.360 \t\n",
      "\n",
      "Validation 118 valid_acc: 0.185 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 119 train_loss: 0.555 train_acc: 0.850 train_f1: 0.358 \t\n",
      "\n",
      "Validation 119 valid_acc: 0.204 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 120 train_loss: 0.552 train_acc: 0.848 train_f1: 0.350 \t\n",
      "\n",
      "Validation 120 valid_acc: 0.185 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 121 train_loss: 0.547 train_acc: 0.851 train_f1: 0.353 \t\n",
      "\n",
      "Validation 121 valid_acc: 0.178 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 122 train_loss: 0.538 train_acc: 0.852 train_f1: 0.343 \t\n",
      "\n",
      "Validation 122 valid_acc: 0.189 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 123 train_loss: 0.538 train_acc: 0.851 train_f1: 0.347 \t\n",
      "\n",
      "Validation 123 valid_acc: 0.189 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 124 train_loss: 0.536 train_acc: 0.853 train_f1: 0.332 \t\n",
      "\n",
      "Validation 124 valid_acc: 0.171 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 125 train_loss: 0.533 train_acc: 0.857 train_f1: 0.333 \t\n",
      "\n",
      "Validation 125 valid_acc: 0.160 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 126 train_loss: 0.525 train_acc: 0.852 train_f1: 0.327 \t\n",
      "\n",
      "Validation 126 valid_acc: 0.160 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 127 train_loss: 0.522 train_acc: 0.855 train_f1: 0.326 \t\n",
      "\n",
      "Validation 127 valid_acc: 0.171 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 128 train_loss: 0.509 train_acc: 0.864 train_f1: 0.329 \t\n",
      "\n",
      "Validation 128 valid_acc: 0.156 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 129 train_loss: 0.520 train_acc: 0.858 train_f1: 0.321 \t\n",
      "\n",
      "Validation 129 valid_acc: 0.167 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 130 train_loss: 0.513 train_acc: 0.864 train_f1: 0.315 \t\n",
      "\n",
      "Validation 130 valid_acc: 0.175 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 131 train_loss: 0.515 train_acc: 0.859 train_f1: 0.313 \t\n",
      "\n",
      "Validation 131 valid_acc: 0.149 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 132 train_loss: 0.503 train_acc: 0.865 train_f1: 0.306 \t\n",
      "\n",
      "Validation 132 valid_acc: 0.153 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 133 train_loss: 0.493 train_acc: 0.865 train_f1: 0.300 \t\n",
      "\n",
      "Validation 133 valid_acc: 0.153 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 134 train_loss: 0.489 train_acc: 0.869 train_f1: 0.295 \t\n",
      "\n",
      "Validation 134 valid_acc: 0.153 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 135 train_loss: 0.491 train_acc: 0.863 train_f1: 0.297 \t\n",
      "\n",
      "Validation 135 valid_acc: 0.149 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 136 train_loss: 0.488 train_acc: 0.868 train_f1: 0.291 \t\n",
      "\n",
      "Validation 136 valid_acc: 0.145 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 137 train_loss: 0.487 train_acc: 0.870 train_f1: 0.290 \t\n",
      "\n",
      "Validation 137 valid_acc: 0.131 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 138 train_loss: 0.480 train_acc: 0.868 train_f1: 0.288 \t\n",
      "\n",
      "Validation 138 valid_acc: 0.153 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 139 train_loss: 0.471 train_acc: 0.872 train_f1: 0.287 \t\n",
      "\n",
      "Validation 139 valid_acc: 0.138 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 140 train_loss: 0.474 train_acc: 0.871 train_f1: 0.285 \t\n",
      "\n",
      "Validation 140 valid_acc: 0.149 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 141 train_loss: 0.474 train_acc: 0.871 train_f1: 0.277 \t\n",
      "\n",
      "Validation 141 valid_acc: 0.153 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 142 train_loss: 0.472 train_acc: 0.873 train_f1: 0.277 \t\n",
      "\n",
      "Validation 142 valid_acc: 0.138 best_acc: 0.629 \t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 143 train_loss: 0.457 train_acc: 0.878 train_f1: 0.277 \t\n",
      "\n",
      "Validation 143 valid_acc: 0.142 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 144 train_loss: 0.467 train_acc: 0.876 train_f1: 0.267 \t\n",
      "\n",
      "Validation 144 valid_acc: 0.120 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 145 train_loss: 0.456 train_acc: 0.873 train_f1: 0.263 \t\n",
      "\n",
      "Validation 145 valid_acc: 0.124 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 146 train_loss: 0.456 train_acc: 0.875 train_f1: 0.268 \t\n",
      "\n",
      "Validation 146 valid_acc: 0.127 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 147 train_loss: 0.460 train_acc: 0.874 train_f1: 0.269 \t\n",
      "\n",
      "Validation 147 valid_acc: 0.120 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 148 train_loss: 0.448 train_acc: 0.880 train_f1: 0.262 \t\n",
      "\n",
      "Validation 148 valid_acc: 0.124 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 149 train_loss: 0.448 train_acc: 0.875 train_f1: 0.265 \t\n",
      "\n",
      "Validation 149 valid_acc: 0.124 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 150 train_loss: 0.441 train_acc: 0.877 train_f1: 0.260 \t\n",
      "\n",
      "Validation 150 valid_acc: 0.124 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 151 train_loss: 0.441 train_acc: 0.884 train_f1: 0.256 \t\n",
      "\n",
      "Validation 151 valid_acc: 0.113 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 152 train_loss: 0.428 train_acc: 0.884 train_f1: 0.266 \t\n",
      "\n",
      "Validation 152 valid_acc: 0.131 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 153 train_loss: 0.420 train_acc: 0.889 train_f1: 0.259 \t\n",
      "\n",
      "Validation 153 valid_acc: 0.124 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 154 train_loss: 0.435 train_acc: 0.879 train_f1: 0.257 \t\n",
      "\n",
      "Validation 154 valid_acc: 0.116 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 155 train_loss: 0.428 train_acc: 0.886 train_f1: 0.247 \t\n",
      "\n",
      "Validation 155 valid_acc: 0.120 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 156 train_loss: 0.420 train_acc: 0.885 train_f1: 0.245 \t\n",
      "\n",
      "Validation 156 valid_acc: 0.116 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 157 train_loss: 0.419 train_acc: 0.889 train_f1: 0.244 \t\n",
      "\n",
      "Validation 157 valid_acc: 0.124 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 158 train_loss: 0.417 train_acc: 0.885 train_f1: 0.246 \t\n",
      "\n",
      "Validation 158 valid_acc: 0.116 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 159 train_loss: 0.410 train_acc: 0.891 train_f1: 0.246 \t\n",
      "\n",
      "Validation 159 valid_acc: 0.120 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 160 train_loss: 0.418 train_acc: 0.888 train_f1: 0.237 \t\n",
      "\n",
      "Validation 160 valid_acc: 0.113 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 161 train_loss: 0.404 train_acc: 0.894 train_f1: 0.237 \t\n",
      "\n",
      "Validation 161 valid_acc: 0.109 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 162 train_loss: 0.399 train_acc: 0.893 train_f1: 0.234 \t\n",
      "\n",
      "Validation 162 valid_acc: 0.124 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 163 train_loss: 0.407 train_acc: 0.890 train_f1: 0.232 \t\n",
      "\n",
      "Validation 163 valid_acc: 0.113 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 164 train_loss: 0.405 train_acc: 0.892 train_f1: 0.237 \t\n",
      "\n",
      "Validation 164 valid_acc: 0.102 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 165 train_loss: 0.399 train_acc: 0.892 train_f1: 0.231 \t\n",
      "\n",
      "Validation 165 valid_acc: 0.113 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 166 train_loss: 0.392 train_acc: 0.897 train_f1: 0.227 \t\n",
      "\n",
      "Validation 166 valid_acc: 0.113 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 167 train_loss: 0.391 train_acc: 0.895 train_f1: 0.230 \t\n",
      "\n",
      "Validation 167 valid_acc: 0.109 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 168 train_loss: 0.394 train_acc: 0.892 train_f1: 0.230 \t\n",
      "\n",
      "Validation 168 valid_acc: 0.116 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 169 train_loss: 0.387 train_acc: 0.900 train_f1: 0.218 \t\n",
      "\n",
      "Validation 169 valid_acc: 0.105 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 170 train_loss: 0.383 train_acc: 0.896 train_f1: 0.221 \t\n",
      "\n",
      "Validation 170 valid_acc: 0.105 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 171 train_loss: 0.383 train_acc: 0.894 train_f1: 0.220 \t\n",
      "\n",
      "Validation 171 valid_acc: 0.113 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 172 train_loss: 0.388 train_acc: 0.893 train_f1: 0.219 \t\n",
      "\n",
      "Validation 172 valid_acc: 0.109 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 173 train_loss: 0.378 train_acc: 0.897 train_f1: 0.218 \t\n",
      "\n",
      "Validation 173 valid_acc: 0.102 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 174 train_loss: 0.377 train_acc: 0.903 train_f1: 0.210 \t\n",
      "\n",
      "Validation 174 valid_acc: 0.105 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 175 train_loss: 0.373 train_acc: 0.902 train_f1: 0.215 \t\n",
      "\n",
      "Validation 175 valid_acc: 0.098 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 176 train_loss: 0.362 train_acc: 0.903 train_f1: 0.213 \t\n",
      "\n",
      "Validation 176 valid_acc: 0.098 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 177 train_loss: 0.362 train_acc: 0.903 train_f1: 0.209 \t\n",
      "\n",
      "Validation 177 valid_acc: 0.098 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 178 train_loss: 0.367 train_acc: 0.903 train_f1: 0.211 \t\n",
      "\n",
      "Validation 178 valid_acc: 0.102 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 179 train_loss: 0.362 train_acc: 0.901 train_f1: 0.208 \t\n",
      "\n",
      "Validation 179 valid_acc: 0.105 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 180 train_loss: 0.357 train_acc: 0.907 train_f1: 0.204 \t\n",
      "\n",
      "Validation 180 valid_acc: 0.102 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 181 train_loss: 0.356 train_acc: 0.910 train_f1: 0.202 \t\n",
      "\n",
      "Validation 181 valid_acc: 0.102 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 182 train_loss: 0.361 train_acc: 0.901 train_f1: 0.206 \t\n",
      "\n",
      "Validation 182 valid_acc: 0.102 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 183 train_loss: 0.354 train_acc: 0.907 train_f1: 0.201 \t\n",
      "\n",
      "Validation 183 valid_acc: 0.098 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 184 train_loss: 0.360 train_acc: 0.901 train_f1: 0.198 \t\n",
      "\n",
      "Validation 184 valid_acc: 0.087 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 185 train_loss: 0.344 train_acc: 0.914 train_f1: 0.203 \t\n",
      "\n",
      "Validation 185 valid_acc: 0.102 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 186 train_loss: 0.348 train_acc: 0.906 train_f1: 0.190 \t\n",
      "\n",
      "Validation 186 valid_acc: 0.102 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 187 train_loss: 0.343 train_acc: 0.908 train_f1: 0.192 \t\n",
      "\n",
      "Validation 187 valid_acc: 0.098 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 188 train_loss: 0.340 train_acc: 0.906 train_f1: 0.196 \t\n",
      "\n",
      "Validation 188 valid_acc: 0.102 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 189 train_loss: 0.338 train_acc: 0.911 train_f1: 0.197 \t\n",
      "\n",
      "Validation 189 valid_acc: 0.098 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 190 train_loss: 0.336 train_acc: 0.914 train_f1: 0.190 \t\n",
      "\n",
      "Validation 190 valid_acc: 0.087 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 191 train_loss: 0.345 train_acc: 0.908 train_f1: 0.185 \t\n",
      "\n",
      "Validation 191 valid_acc: 0.080 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 192 train_loss: 0.332 train_acc: 0.915 train_f1: 0.191 \t\n",
      "\n",
      "Validation 192 valid_acc: 0.091 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 193 train_loss: 0.338 train_acc: 0.910 train_f1: 0.178 \t\n",
      "\n",
      "Validation 193 valid_acc: 0.098 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 194 train_loss: 0.335 train_acc: 0.908 train_f1: 0.180 \t\n",
      "\n",
      "Validation 194 valid_acc: 0.087 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 195 train_loss: 0.337 train_acc: 0.909 train_f1: 0.180 \t\n",
      "\n",
      "Validation 195 valid_acc: 0.091 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 196 train_loss: 0.319 train_acc: 0.920 train_f1: 0.179 \t\n",
      "\n",
      "Validation 196 valid_acc: 0.080 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 197 train_loss: 0.326 train_acc: 0.911 train_f1: 0.175 \t\n",
      "\n",
      "Validation 197 valid_acc: 0.091 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 198 train_loss: 0.323 train_acc: 0.915 train_f1: 0.177 \t\n",
      "\n",
      "Validation 198 valid_acc: 0.069 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 199 train_loss: 0.320 train_acc: 0.918 train_f1: 0.170 \t\n",
      "\n",
      "Validation 199 valid_acc: 0.076 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 200 train_loss: 0.323 train_acc: 0.915 train_f1: 0.174 \t\n",
      "\n",
      "Validation 200 valid_acc: 0.069 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 201 train_loss: 0.319 train_acc: 0.916 train_f1: 0.170 \t\n",
      "\n",
      "Validation 201 valid_acc: 0.080 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 202 train_loss: 0.315 train_acc: 0.918 train_f1: 0.172 \t\n",
      "\n",
      "Validation 202 valid_acc: 0.087 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 203 train_loss: 0.314 train_acc: 0.919 train_f1: 0.162 \t\n",
      "\n",
      "Validation 203 valid_acc: 0.069 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 204 train_loss: 0.311 train_acc: 0.919 train_f1: 0.164 \t\n",
      "\n",
      "Validation 204 valid_acc: 0.065 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 205 train_loss: 0.309 train_acc: 0.919 train_f1: 0.161 \t\n",
      "\n",
      "Validation 205 valid_acc: 0.087 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 206 train_loss: 0.306 train_acc: 0.919 train_f1: 0.161 \t\n",
      "\n",
      "Validation 206 valid_acc: 0.069 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 207 train_loss: 0.302 train_acc: 0.921 train_f1: 0.160 \t\n",
      "\n",
      "Validation 207 valid_acc: 0.069 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 208 train_loss: 0.300 train_acc: 0.926 train_f1: 0.156 \t\n",
      "\n",
      "Validation 208 valid_acc: 0.069 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 209 train_loss: 0.309 train_acc: 0.919 train_f1: 0.161 \t\n",
      "\n",
      "Validation 209 valid_acc: 0.065 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 210 train_loss: 0.298 train_acc: 0.923 train_f1: 0.153 \t\n",
      "\n",
      "Validation 210 valid_acc: 0.065 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 211 train_loss: 0.295 train_acc: 0.925 train_f1: 0.159 \t\n",
      "\n",
      "Validation 211 valid_acc: 0.062 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 212 train_loss: 0.301 train_acc: 0.920 train_f1: 0.158 \t\n",
      "\n",
      "Validation 212 valid_acc: 0.069 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 213 train_loss: 0.297 train_acc: 0.927 train_f1: 0.149 \t\n",
      "\n",
      "Validation 213 valid_acc: 0.069 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 214 train_loss: 0.299 train_acc: 0.921 train_f1: 0.147 \t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation 214 valid_acc: 0.062 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 215 train_loss: 0.287 train_acc: 0.928 train_f1: 0.150 \t\n",
      "\n",
      "Validation 215 valid_acc: 0.062 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 216 train_loss: 0.305 train_acc: 0.916 train_f1: 0.138 \t\n",
      "\n",
      "Validation 216 valid_acc: 0.058 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 217 train_loss: 0.295 train_acc: 0.921 train_f1: 0.149 \t\n",
      "\n",
      "Validation 217 valid_acc: 0.069 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 218 train_loss: 0.289 train_acc: 0.923 train_f1: 0.150 \t\n",
      "\n",
      "Validation 218 valid_acc: 0.062 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 219 train_loss: 0.284 train_acc: 0.926 train_f1: 0.149 \t\n",
      "\n",
      "Validation 219 valid_acc: 0.069 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 220 train_loss: 0.290 train_acc: 0.922 train_f1: 0.142 \t\n",
      "\n",
      "Validation 220 valid_acc: 0.069 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 221 train_loss: 0.282 train_acc: 0.929 train_f1: 0.141 \t\n",
      "\n",
      "Validation 221 valid_acc: 0.055 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 222 train_loss: 0.278 train_acc: 0.930 train_f1: 0.130 \t\n",
      "\n",
      "Validation 222 valid_acc: 0.062 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 223 train_loss: 0.272 train_acc: 0.932 train_f1: 0.130 \t\n",
      "\n",
      "Validation 223 valid_acc: 0.062 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 224 train_loss: 0.280 train_acc: 0.925 train_f1: 0.135 \t\n",
      "\n",
      "Validation 224 valid_acc: 0.058 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 225 train_loss: 0.280 train_acc: 0.923 train_f1: 0.142 \t\n",
      "\n",
      "Validation 225 valid_acc: 0.058 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 226 train_loss: 0.283 train_acc: 0.928 train_f1: 0.133 \t\n",
      "\n",
      "Validation 226 valid_acc: 0.062 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 227 train_loss: 0.271 train_acc: 0.930 train_f1: 0.137 \t\n",
      "\n",
      "Validation 227 valid_acc: 0.062 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 228 train_loss: 0.280 train_acc: 0.924 train_f1: 0.139 \t\n",
      "\n",
      "Validation 228 valid_acc: 0.055 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 229 train_loss: 0.268 train_acc: 0.929 train_f1: 0.125 \t\n",
      "\n",
      "Validation 229 valid_acc: 0.058 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 230 train_loss: 0.278 train_acc: 0.926 train_f1: 0.131 \t\n",
      "\n",
      "Validation 230 valid_acc: 0.065 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 231 train_loss: 0.276 train_acc: 0.931 train_f1: 0.122 \t\n",
      "\n",
      "Validation 231 valid_acc: 0.055 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 232 train_loss: 0.264 train_acc: 0.933 train_f1: 0.124 \t\n",
      "\n",
      "Validation 232 valid_acc: 0.062 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 233 train_loss: 0.260 train_acc: 0.931 train_f1: 0.127 \t\n",
      "\n",
      "Validation 233 valid_acc: 0.055 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 234 train_loss: 0.262 train_acc: 0.929 train_f1: 0.121 \t\n",
      "\n",
      "Validation 234 valid_acc: 0.055 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 235 train_loss: 0.254 train_acc: 0.934 train_f1: 0.113 \t\n",
      "\n",
      "Validation 235 valid_acc: 0.055 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 236 train_loss: 0.268 train_acc: 0.926 train_f1: 0.123 \t\n",
      "\n",
      "Validation 236 valid_acc: 0.047 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 237 train_loss: 0.251 train_acc: 0.936 train_f1: 0.113 \t\n",
      "\n",
      "Validation 237 valid_acc: 0.051 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 238 train_loss: 0.274 train_acc: 0.927 train_f1: 0.109 \t\n",
      "\n",
      "Validation 238 valid_acc: 0.058 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 239 train_loss: 0.261 train_acc: 0.933 train_f1: 0.118 \t\n",
      "\n",
      "Validation 239 valid_acc: 0.058 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 240 train_loss: 0.260 train_acc: 0.934 train_f1: 0.114 \t\n",
      "\n",
      "Validation 240 valid_acc: 0.058 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 241 train_loss: 0.256 train_acc: 0.936 train_f1: 0.112 \t\n",
      "\n",
      "Validation 241 valid_acc: 0.055 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 242 train_loss: 0.258 train_acc: 0.932 train_f1: 0.110 \t\n",
      "\n",
      "Validation 242 valid_acc: 0.051 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 243 train_loss: 0.254 train_acc: 0.927 train_f1: 0.117 \t\n",
      "\n",
      "Validation 243 valid_acc: 0.055 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 244 train_loss: 0.252 train_acc: 0.934 train_f1: 0.121 \t\n",
      "\n",
      "Validation 244 valid_acc: 0.036 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 245 train_loss: 0.259 train_acc: 0.932 train_f1: 0.105 \t\n",
      "\n",
      "Validation 245 valid_acc: 0.040 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 246 train_loss: 0.258 train_acc: 0.935 train_f1: 0.111 \t\n",
      "\n",
      "Validation 246 valid_acc: 0.047 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 247 train_loss: 0.256 train_acc: 0.933 train_f1: 0.110 \t\n",
      "\n",
      "Validation 247 valid_acc: 0.051 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 248 train_loss: 0.249 train_acc: 0.934 train_f1: 0.107 \t\n",
      "\n",
      "Validation 248 valid_acc: 0.044 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 249 train_loss: 0.248 train_acc: 0.935 train_f1: 0.100 \t\n",
      "\n",
      "Validation 249 valid_acc: 0.047 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 250 train_loss: 0.240 train_acc: 0.934 train_f1: 0.105 \t\n",
      "\n",
      "Validation 250 valid_acc: 0.040 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 251 train_loss: 0.246 train_acc: 0.939 train_f1: 0.097 \t\n",
      "\n",
      "Validation 251 valid_acc: 0.047 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 252 train_loss: 0.250 train_acc: 0.932 train_f1: 0.109 \t\n",
      "\n",
      "Validation 252 valid_acc: 0.055 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 253 train_loss: 0.249 train_acc: 0.936 train_f1: 0.094 \t\n",
      "\n",
      "Validation 253 valid_acc: 0.036 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 254 train_loss: 0.235 train_acc: 0.938 train_f1: 0.099 \t\n",
      "\n",
      "Validation 254 valid_acc: 0.044 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 255 train_loss: 0.241 train_acc: 0.940 train_f1: 0.091 \t\n",
      "\n",
      "Validation 255 valid_acc: 0.047 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 256 train_loss: 0.236 train_acc: 0.938 train_f1: 0.093 \t\n",
      "\n",
      "Validation 256 valid_acc: 0.033 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 257 train_loss: 0.232 train_acc: 0.938 train_f1: 0.090 \t\n",
      "\n",
      "Validation 257 valid_acc: 0.029 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 258 train_loss: 0.238 train_acc: 0.940 train_f1: 0.086 \t\n",
      "\n",
      "Validation 258 valid_acc: 0.044 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 259 train_loss: 0.241 train_acc: 0.934 train_f1: 0.085 \t\n",
      "\n",
      "Validation 259 valid_acc: 0.029 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 260 train_loss: 0.238 train_acc: 0.940 train_f1: 0.075 \t\n",
      "\n",
      "Validation 260 valid_acc: 0.036 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 261 train_loss: 0.229 train_acc: 0.941 train_f1: 0.087 \t\n",
      "\n",
      "Validation 261 valid_acc: 0.033 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 262 train_loss: 0.234 train_acc: 0.942 train_f1: 0.081 \t\n",
      "\n",
      "Validation 262 valid_acc: 0.022 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 263 train_loss: 0.245 train_acc: 0.937 train_f1: 0.084 \t\n",
      "\n",
      "Validation 263 valid_acc: 0.029 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 264 train_loss: 0.242 train_acc: 0.935 train_f1: 0.082 \t\n",
      "\n",
      "Validation 264 valid_acc: 0.033 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 265 train_loss: 0.227 train_acc: 0.941 train_f1: 0.078 \t\n",
      "\n",
      "Validation 265 valid_acc: 0.025 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 266 train_loss: 0.229 train_acc: 0.943 train_f1: 0.084 \t\n",
      "\n",
      "Validation 266 valid_acc: 0.040 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 267 train_loss: 0.226 train_acc: 0.941 train_f1: 0.077 \t\n",
      "\n",
      "Validation 267 valid_acc: 0.036 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 268 train_loss: 0.225 train_acc: 0.942 train_f1: 0.081 \t\n",
      "\n",
      "Validation 268 valid_acc: 0.025 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 269 train_loss: 0.221 train_acc: 0.942 train_f1: 0.071 \t\n",
      "\n",
      "Validation 269 valid_acc: 0.018 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 270 train_loss: 0.222 train_acc: 0.945 train_f1: 0.060 \t\n",
      "\n",
      "Validation 270 valid_acc: 0.036 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 271 train_loss: 0.215 train_acc: 0.946 train_f1: 0.068 \t\n",
      "\n",
      "Validation 271 valid_acc: 0.018 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 272 train_loss: 0.221 train_acc: 0.943 train_f1: 0.072 \t\n",
      "\n",
      "Validation 272 valid_acc: 0.015 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 273 train_loss: 0.232 train_acc: 0.940 train_f1: 0.060 \t\n",
      "\n",
      "Validation 273 valid_acc: 0.015 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 274 train_loss: 0.236 train_acc: 0.940 train_f1: 0.064 \t\n",
      "\n",
      "Validation 274 valid_acc: 0.015 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 275 train_loss: 0.223 train_acc: 0.942 train_f1: 0.066 \t\n",
      "\n",
      "Validation 275 valid_acc: 0.025 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 276 train_loss: 0.218 train_acc: 0.942 train_f1: 0.062 \t\n",
      "\n",
      "Validation 276 valid_acc: 0.015 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 277 train_loss: 0.221 train_acc: 0.944 train_f1: 0.062 \t\n",
      "\n",
      "Validation 277 valid_acc: 0.018 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 278 train_loss: 0.218 train_acc: 0.943 train_f1: 0.059 \t\n",
      "\n",
      "Validation 278 valid_acc: 0.025 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 279 train_loss: 0.216 train_acc: 0.946 train_f1: 0.068 \t\n",
      "\n",
      "Validation 279 valid_acc: 0.018 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 280 train_loss: 0.219 train_acc: 0.942 train_f1: 0.057 \t\n",
      "\n",
      "Validation 280 valid_acc: 0.011 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 281 train_loss: 0.223 train_acc: 0.942 train_f1: 0.050 \t\n",
      "\n",
      "Validation 281 valid_acc: 0.011 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 282 train_loss: 0.222 train_acc: 0.942 train_f1: 0.053 \t\n",
      "\n",
      "Validation 282 valid_acc: 0.015 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 283 train_loss: 0.214 train_acc: 0.944 train_f1: 0.057 \t\n",
      "\n",
      "Validation 283 valid_acc: 0.018 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 284 train_loss: 0.219 train_acc: 0.942 train_f1: 0.051 \t\n",
      "\n",
      "Validation 284 valid_acc: 0.011 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 285 train_loss: 0.211 train_acc: 0.946 train_f1: 0.046 \t\n",
      "\n",
      "Validation 285 valid_acc: 0.018 best_acc: 0.629 \t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 286 train_loss: 0.208 train_acc: 0.943 train_f1: 0.050 \t\n",
      "\n",
      "Validation 286 valid_acc: 0.011 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 287 train_loss: 0.220 train_acc: 0.940 train_f1: 0.046 \t\n",
      "\n",
      "Validation 287 valid_acc: 0.007 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 288 train_loss: 0.207 train_acc: 0.947 train_f1: 0.038 \t\n",
      "\n",
      "Validation 288 valid_acc: 0.011 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 289 train_loss: 0.204 train_acc: 0.947 train_f1: 0.045 \t\n",
      "\n",
      "Validation 289 valid_acc: 0.015 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 290 train_loss: 0.213 train_acc: 0.945 train_f1: 0.047 \t\n",
      "\n",
      "Validation 290 valid_acc: 0.007 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 291 train_loss: 0.214 train_acc: 0.940 train_f1: 0.043 \t\n",
      "\n",
      "Validation 291 valid_acc: 0.018 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 292 train_loss: 0.220 train_acc: 0.941 train_f1: 0.048 \t\n",
      "\n",
      "Validation 292 valid_acc: 0.015 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 293 train_loss: 0.216 train_acc: 0.940 train_f1: 0.042 \t\n",
      "\n",
      "Validation 293 valid_acc: 0.018 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 294 train_loss: 0.204 train_acc: 0.943 train_f1: 0.039 \t\n",
      "\n",
      "Validation 294 valid_acc: 0.018 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 295 train_loss: 0.209 train_acc: 0.939 train_f1: 0.042 \t\n",
      "\n",
      "Validation 295 valid_acc: 0.011 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 296 train_loss: 0.221 train_acc: 0.943 train_f1: 0.046 \t\n",
      "\n",
      "Validation 296 valid_acc: 0.011 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 297 train_loss: 0.210 train_acc: 0.945 train_f1: 0.045 \t\n",
      "\n",
      "Validation 297 valid_acc: 0.015 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 298 train_loss: 0.208 train_acc: 0.949 train_f1: 0.039 \t\n",
      "\n",
      "Validation 298 valid_acc: 0.011 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 299 train_loss: 0.216 train_acc: 0.944 train_f1: 0.039 \t\n",
      "\n",
      "Validation 299 valid_acc: 0.015 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 300 train_loss: 0.196 train_acc: 0.951 train_f1: 0.030 \t\n",
      "\n",
      "Validation 300 valid_acc: 0.007 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 301 train_loss: 0.206 train_acc: 0.944 train_f1: 0.031 \t\n",
      "\n",
      "Validation 301 valid_acc: 0.007 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 302 train_loss: 0.205 train_acc: 0.948 train_f1: 0.032 \t\n",
      "\n",
      "Validation 302 valid_acc: 0.007 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 303 train_loss: 0.207 train_acc: 0.945 train_f1: 0.023 \t\n",
      "\n",
      "Validation 303 valid_acc: 0.007 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 304 train_loss: 0.201 train_acc: 0.948 train_f1: 0.024 \t\n",
      "\n",
      "Validation 304 valid_acc: 0.011 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 305 train_loss: 0.201 train_acc: 0.947 train_f1: 0.023 \t\n",
      "\n",
      "Validation 305 valid_acc: 0.007 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 306 train_loss: 0.199 train_acc: 0.948 train_f1: 0.021 \t\n",
      "\n",
      "Validation 306 valid_acc: 0.007 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 307 train_loss: 0.201 train_acc: 0.948 train_f1: 0.022 \t\n",
      "\n",
      "Validation 307 valid_acc: 0.011 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 308 train_loss: 0.191 train_acc: 0.948 train_f1: 0.028 \t\n",
      "\n",
      "Validation 308 valid_acc: 0.007 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 309 train_loss: 0.202 train_acc: 0.944 train_f1: 0.020 \t\n",
      "\n",
      "Validation 309 valid_acc: 0.007 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 310 train_loss: 0.198 train_acc: 0.947 train_f1: 0.015 \t\n",
      "\n",
      "Validation 310 valid_acc: 0.007 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 311 train_loss: 0.196 train_acc: 0.946 train_f1: 0.015 \t\n",
      "\n",
      "Validation 311 valid_acc: 0.007 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 312 train_loss: 0.196 train_acc: 0.949 train_f1: 0.016 \t\n",
      "\n",
      "Validation 312 valid_acc: 0.007 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 313 train_loss: 0.193 train_acc: 0.948 train_f1: 0.024 \t\n",
      "\n",
      "Validation 313 valid_acc: 0.007 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 314 train_loss: 0.195 train_acc: 0.949 train_f1: 0.022 \t\n",
      "\n",
      "Validation 314 valid_acc: 0.007 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 315 train_loss: 0.202 train_acc: 0.944 train_f1: 0.020 \t\n",
      "\n",
      "Validation 315 valid_acc: 0.007 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 316 train_loss: 0.192 train_acc: 0.950 train_f1: 0.021 \t\n",
      "\n",
      "Validation 316 valid_acc: 0.007 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 317 train_loss: 0.182 train_acc: 0.953 train_f1: 0.020 \t\n",
      "\n",
      "Validation 317 valid_acc: 0.007 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 318 train_loss: 0.191 train_acc: 0.950 train_f1: 0.013 \t\n",
      "\n",
      "Validation 318 valid_acc: 0.007 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 319 train_loss: 0.198 train_acc: 0.946 train_f1: 0.014 \t\n",
      "\n",
      "Validation 319 valid_acc: 0.007 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 320 train_loss: 0.210 train_acc: 0.943 train_f1: 0.019 \t\n",
      "\n",
      "Validation 320 valid_acc: 0.007 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 321 train_loss: 0.192 train_acc: 0.950 train_f1: 0.016 \t\n",
      "\n",
      "Validation 321 valid_acc: 0.007 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 322 train_loss: 0.197 train_acc: 0.946 train_f1: 0.012 \t\n",
      "\n",
      "Validation 322 valid_acc: 0.007 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 323 train_loss: 0.187 train_acc: 0.954 train_f1: 0.010 \t\n",
      "\n",
      "Validation 323 valid_acc: 0.007 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 324 train_loss: 0.185 train_acc: 0.950 train_f1: 0.012 \t\n",
      "\n",
      "Validation 324 valid_acc: 0.007 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 325 train_loss: 0.181 train_acc: 0.949 train_f1: 0.012 \t\n",
      "\n",
      "Validation 325 valid_acc: 0.007 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 326 train_loss: 0.187 train_acc: 0.948 train_f1: 0.013 \t\n",
      "\n",
      "Validation 326 valid_acc: 0.011 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 327 train_loss: 0.183 train_acc: 0.950 train_f1: 0.007 \t\n",
      "\n",
      "Validation 327 valid_acc: 0.007 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 328 train_loss: 0.184 train_acc: 0.948 train_f1: 0.011 \t\n",
      "\n",
      "Validation 328 valid_acc: 0.007 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 329 train_loss: 0.183 train_acc: 0.954 train_f1: 0.010 \t\n",
      "\n",
      "Validation 329 valid_acc: 0.007 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 330 train_loss: 0.183 train_acc: 0.950 train_f1: 0.011 \t\n",
      "\n",
      "Validation 330 valid_acc: 0.007 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 331 train_loss: 0.178 train_acc: 0.953 train_f1: 0.008 \t\n",
      "\n",
      "Validation 331 valid_acc: 0.007 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 332 train_loss: 0.183 train_acc: 0.953 train_f1: 0.010 \t\n",
      "\n",
      "Validation 332 valid_acc: 0.007 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 333 train_loss: 0.186 train_acc: 0.950 train_f1: 0.007 \t\n",
      "\n",
      "Validation 333 valid_acc: 0.007 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 334 train_loss: 0.180 train_acc: 0.951 train_f1: 0.007 \t\n",
      "\n",
      "Validation 334 valid_acc: 0.007 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 335 train_loss: 0.184 train_acc: 0.950 train_f1: 0.005 \t\n",
      "\n",
      "Validation 335 valid_acc: 0.004 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 336 train_loss: 0.187 train_acc: 0.949 train_f1: 0.006 \t\n",
      "\n",
      "Validation 336 valid_acc: 0.007 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 337 train_loss: 0.184 train_acc: 0.950 train_f1: 0.006 \t\n",
      "\n",
      "Validation 337 valid_acc: 0.007 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 338 train_loss: 0.177 train_acc: 0.950 train_f1: 0.006 \t\n",
      "\n",
      "Validation 338 valid_acc: 0.007 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 339 train_loss: 0.187 train_acc: 0.949 train_f1: 0.003 \t\n",
      "\n",
      "Validation 339 valid_acc: 0.004 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 340 train_loss: 0.184 train_acc: 0.949 train_f1: 0.005 \t\n",
      "\n",
      "Validation 340 valid_acc: 0.007 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 341 train_loss: 0.184 train_acc: 0.951 train_f1: 0.006 \t\n",
      "\n",
      "Validation 341 valid_acc: 0.007 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 342 train_loss: 0.184 train_acc: 0.948 train_f1: 0.006 \t\n",
      "\n",
      "Validation 342 valid_acc: 0.007 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 343 train_loss: 0.179 train_acc: 0.951 train_f1: 0.007 \t\n",
      "\n",
      "Validation 343 valid_acc: 0.007 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 344 train_loss: 0.174 train_acc: 0.955 train_f1: 0.009 \t\n",
      "\n",
      "Validation 344 valid_acc: 0.007 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 345 train_loss: 0.184 train_acc: 0.949 train_f1: 0.006 \t\n",
      "\n",
      "Validation 345 valid_acc: 0.007 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 346 train_loss: 0.180 train_acc: 0.950 train_f1: 0.005 \t\n",
      "\n",
      "Validation 346 valid_acc: 0.007 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 347 train_loss: 0.190 train_acc: 0.948 train_f1: 0.006 \t\n",
      "\n",
      "Validation 347 valid_acc: 0.004 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 348 train_loss: 0.171 train_acc: 0.955 train_f1: 0.006 \t\n",
      "\n",
      "Validation 348 valid_acc: 0.007 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 349 train_loss: 0.172 train_acc: 0.951 train_f1: 0.006 \t\n",
      "\n",
      "Validation 349 valid_acc: 0.007 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 350 train_loss: 0.200 train_acc: 0.942 train_f1: 0.004 \t\n",
      "\n",
      "Validation 350 valid_acc: 0.000 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 351 train_loss: 0.183 train_acc: 0.950 train_f1: 0.004 \t\n",
      "\n",
      "Validation 351 valid_acc: 0.007 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 352 train_loss: 0.172 train_acc: 0.953 train_f1: 0.003 \t\n",
      "\n",
      "Validation 352 valid_acc: 0.007 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 353 train_loss: 0.179 train_acc: 0.953 train_f1: 0.004 \t\n",
      "\n",
      "Validation 353 valid_acc: 0.007 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 354 train_loss: 0.174 train_acc: 0.951 train_f1: 0.002 \t\n",
      "\n",
      "Validation 354 valid_acc: 0.004 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 355 train_loss: 0.187 train_acc: 0.950 train_f1: 0.004 \t\n",
      "\n",
      "Validation 355 valid_acc: 0.007 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 356 train_loss: 0.173 train_acc: 0.954 train_f1: 0.003 \t\n",
      "\n",
      "Validation 356 valid_acc: 0.004 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 357 train_loss: 0.172 train_acc: 0.952 train_f1: 0.002 \t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation 357 valid_acc: 0.000 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 358 train_loss: 0.170 train_acc: 0.956 train_f1: 0.004 \t\n",
      "\n",
      "Validation 358 valid_acc: 0.004 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 359 train_loss: 0.168 train_acc: 0.952 train_f1: 0.004 \t\n",
      "\n",
      "Validation 359 valid_acc: 0.004 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 360 train_loss: 0.172 train_acc: 0.954 train_f1: 0.004 \t\n",
      "\n",
      "Validation 360 valid_acc: 0.004 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 361 train_loss: 0.167 train_acc: 0.952 train_f1: 0.002 \t\n",
      "\n",
      "Validation 361 valid_acc: 0.004 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 362 train_loss: 0.164 train_acc: 0.955 train_f1: 0.002 \t\n",
      "\n",
      "Validation 362 valid_acc: 0.000 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 363 train_loss: 0.172 train_acc: 0.952 train_f1: 0.003 \t\n",
      "\n",
      "Validation 363 valid_acc: 0.000 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 364 train_loss: 0.172 train_acc: 0.949 train_f1: 0.001 \t\n",
      "\n",
      "Validation 364 valid_acc: 0.007 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 365 train_loss: 0.170 train_acc: 0.956 train_f1: 0.002 \t\n",
      "\n",
      "Validation 365 valid_acc: 0.004 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 366 train_loss: 0.171 train_acc: 0.951 train_f1: 0.002 \t\n",
      "\n",
      "Validation 366 valid_acc: 0.007 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 367 train_loss: 0.177 train_acc: 0.950 train_f1: 0.003 \t\n",
      "\n",
      "Validation 367 valid_acc: 0.004 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 368 train_loss: 0.175 train_acc: 0.951 train_f1: 0.002 \t\n",
      "\n",
      "Validation 368 valid_acc: 0.004 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 369 train_loss: 0.165 train_acc: 0.954 train_f1: 0.001 \t\n",
      "\n",
      "Validation 369 valid_acc: 0.004 best_acc: 0.629 \t\n",
      "\n",
      "Epoch 370 train_loss: 0.160 train_acc: 0.956 train_f1: 0.003 \t\n",
      "\n",
      "Validation 370 valid_acc: 0.004 best_acc: 0.629 \t\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-da9b0b7f92c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnum_epoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmel_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass2index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminimum_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_mean_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_std_final\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nEpoch'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'train_loss:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf'{train_loss:.3f}'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'train_acc:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf'{train_acc:.3f}'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'train_f1:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf'{train_f1:.3f}'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0mmodel_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ecg_mel_E%02dL%.2f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-da9b0b7f92c2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(data_train, mel_directory, batch_size, class2index, minimum_len, x_mean_final, x_std_final)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mbatch_mels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_mels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mbatch_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtrain_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_mels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_tmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0macc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_tmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import keras\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras.applications.densenet import DenseNet121, DenseNet169\n",
    "#from keras.applications.nasnet import NASNetLarge\n",
    "# from keras_efficientnets import EfficientNetB7\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras import initializers, regularizers, constraints\n",
    "from keras.layers.normalization import BatchNormalization \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from keras import backend as K\n",
    "\n",
    "tf.set_random_seed(1234)\n",
    "random.seed(100)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "\n",
    "def score_f1(y_true, y_pred): #taken from old keras source code\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val\n",
    "\n",
    "def dot_product(x, kernel):\n",
    "    if K.backend() == 'tensorflow':\n",
    "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
    "    else:\n",
    "        return K.dot(x, kernel)\n",
    "    \n",
    "class AttentionWithContext(Layer):\n",
    "    def __init__(self,\n",
    "                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, u_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.u_regularizer = regularizers.get(u_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.u_constraint = constraints.get(u_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "        self.bias = bias\n",
    "        super(AttentionWithContext, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "        self.W = self.add_weight((input_shape[-1], input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight((input_shape[-1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "            self.u = self.add_weight((input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_u'.format(self.name),\n",
    "                                 regularizer=self.u_regularizer,\n",
    "                                 constraint=self.u_constraint)\n",
    "        super(AttentionWithContext, self).build(input_shape)\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        uit = dot_product(x, self.W)\n",
    "        if self.bias:\n",
    "            uit += self.b\n",
    "        uit = K.tanh(uit)\n",
    "        ait = dot_product(uit, self.u)\n",
    "        a = K.exp(ait)\n",
    "        if mask is not None:\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], input_shape[-1]\n",
    "\n",
    "    \n",
    "def cce_f1_loss(y_true, y_pred):\n",
    "    return 1 + 0.1*keras.losses.categorical_crossentropy(y_true, y_pred) - keras.metrics.categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "# Find unique number of classes  \n",
    "def get_unique_classes(input_directory,files):\n",
    "\n",
    "    unique_classes=set()\n",
    "    for f in files:\n",
    "        g = f.replace('.mat','.hea')\n",
    "        input_file = os.path.join(input_directory,g)\n",
    "        with open(input_file,'r') as f:\n",
    "            for lines in f:\n",
    "                if lines.startswith('#Dx'):\n",
    "                    tmp = lines.split(': ')[1].split(',')\n",
    "                    for c in tmp:\n",
    "                        unique_classes.add(c.strip())\n",
    "    return sorted(unique_classes)\n",
    "\n",
    "def one_hot_encoding(one_hot_vector,y, class2index):\n",
    "    ind=class2index[y]\n",
    "    one_hot_vector[ind]=1\n",
    "    return one_hot_vector\n",
    "\n",
    "# Search for multi-label subjects\n",
    "def searching_overlap(input_directory,class2index, input_file_names):\n",
    "    multiclasses=[]\n",
    "    multisubjects=[]\n",
    "    number = []\n",
    "    for file in input_file_names:\n",
    "        f=file\n",
    "        g = f.replace('.mat','.hea')\n",
    "        input_file = os.path.join(input_directory,g)\n",
    "        with open(input_file,'r') as f:\n",
    "            for lines in f:\n",
    "                if lines.startswith('#Dx'):\n",
    "                    tmp = lines.split(': ')[1].split(',')\n",
    "                    if len(tmp)>1:\n",
    "                        one_hot_vector = [0]*(len(class2index))\n",
    "                        for c in tmp:\n",
    "                            one_hot_vector = one_hot_encoding(one_hot_vector, c.strip(), class2index)\n",
    "                        multiclasses.append(one_hot_vector)\n",
    "                        multisubjects.append(g)\n",
    "                        number.append(len(tmp))\n",
    "    return multisubjects, multiclasses, number\n",
    "\n",
    "def block_feature(sequence_en, minimum_len): \n",
    "    new_en = []\n",
    "    if len(sequence_en) > minimum_len:  #  minimum  \n",
    "        start = random.randint(0,len(sequence_en)-minimum_len)\n",
    "        #print(start)\n",
    "        new_en = sequence_en[start:start+minimum_len]\n",
    "    elif len(sequence_en) == minimum_len: #  minimum\n",
    "        new_en = sequence_en\n",
    "    else: \n",
    "        assert len(sequence_en) <= minimum_len\n",
    "    return new_en\n",
    "\n",
    "def exploratory_look(input_directory,file, class2index):\n",
    "    classes = []\n",
    "    f = file\n",
    "    g = f.replace('.mat','.hea')\n",
    "    input_file = os.path.join(input_directory,g)\n",
    "    with open(input_file,'r') as f:\n",
    "        for lines in f:\n",
    "            if lines.startswith('#Dx'):\n",
    "                tmp = lines.split(': ')[1].split(',')\n",
    "                print(tmp, len(tmp))\n",
    "    return tmp     \n",
    "\n",
    "# Get classes of sorted file names\n",
    "def get_labels(input_directory,file, class2index):\n",
    "    f = file\n",
    "    g = f.replace('.mat','.hea')\n",
    "    input_file = os.path.join(input_directory,g)\n",
    "    with open(input_file,'r') as f:\n",
    "        for lines in f:\n",
    "            if lines.startswith('#Dx'):\n",
    "                tmp = lines.split(': ')[1].split(',')\n",
    "                one_hot_vector = [0]*(len(class2index))\n",
    "                for c in tmp:\n",
    "                    one_hot_vector = one_hot_encoding(one_hot_vector, c.strip(), class2index)\n",
    "                \n",
    "    return one_hot_vector\n",
    "\n",
    "def randextract_mels(curr_step, batch_size, data, mel_directory, class2index, minimum_len, x_mean_final, x_std_final):\n",
    "    mel_files = []\n",
    "    classes = []\n",
    "    start = batch_size*curr_step\n",
    "    end = batch_size*(curr_step+1)\n",
    "    curr_file_indices = data[start:end]\n",
    "    for file in curr_file_indices:\n",
    "        tmp_file = np.load(mel_directory + '/' + file.replace('.mat', '.npy'))\n",
    "        clip_file = block_feature(tmp_file, minimum_len)\n",
    "        #print(clip_file.shape)\n",
    "        #clip_file = tmp_file[:minimum_len]\n",
    "        clip_file -= x_mean_final\n",
    "        clip_file /= x_std_final\n",
    "        mel_files.append(clip_file)\n",
    "        label = get_labels(input_directory, file, class2index)\n",
    "        classes.append(label)\n",
    "    concat = list(zip(mel_files, classes))\n",
    "    random.shuffle(concat)\n",
    "    mel_files, classes = zip(*concat)\n",
    "    return mel_files, classes\n",
    "\n",
    "def train(data_train, mel_directory, batch_size, class2index, minimum_len, x_mean_final, x_std_final): \n",
    "    loss=[]\n",
    "    acc = []\n",
    "    f1 = []\n",
    "\n",
    "    total_steps = int(np.ceil(len(data_train)/batch_size))\n",
    "    for curr_step in range(total_steps):\n",
    "        batch_mels, batch_labels = randextract_mels(curr_step, batch_size, data_train, mel_directory, class2index, minimum_len, x_mean_final, x_std_final)\n",
    "        batch_mels = np.asarray(batch_mels)\n",
    "        batch_labels = np.asarray(np.squeeze(batch_labels))\n",
    "        train_tmp = model.train_on_batch(batch_mels, batch_labels)\n",
    "        loss.append(train_tmp[0])\n",
    "        acc.append(train_tmp[1])\n",
    "        f1.append(train_tmp[2])\n",
    "\n",
    "    loss = np.mean(np.array(loss))\n",
    "    acc = np.mean(np.array(acc))\n",
    "    f1 = np.mean(np.array(f1))\n",
    "    return loss, acc, f1\n",
    "\n",
    "def test(data, mel_directory, input_directory, class2index, minimum_len, model, x_mean_final, x_std_final):\n",
    "    scores = []\n",
    "    predicted_labels=[]\n",
    "    accuracy=np.zeros(len(data))\n",
    "    #total_loss=[]\n",
    "    total_acc = 0\n",
    "    total_f1 = 0\n",
    "    \n",
    "    mel_files = []\n",
    "    classes = []\n",
    "    for i, file in enumerate(data):\n",
    "        tmp_file = np.load(mel_directory + '/' + file.replace('.mat', '.npy'))\n",
    "        steps = int(np.floor(tmp_file.shape[0]/minimum_len))\n",
    "        mel_files = []\n",
    "        for block in range(steps): # 128    predict\n",
    "            start = block*minimum_len\n",
    "            end = (block+1)*minimum_len\n",
    "            clip_file = tmp_file[start:end]\n",
    "            clip_file -= x_mean_final\n",
    "            clip_file /= x_std_final\n",
    "            mel_files.append(clip_file)\n",
    "        mel_files = np.asarray(mel_files)\n",
    "        logit = model.predict(mel_files)\n",
    "        logit = np.mean(logit, axis=0)\n",
    "        \n",
    "        \n",
    "        \n",
    "        pred = np.zeros(len(logit))\n",
    "        for ii, label in enumerate(logit):\n",
    "            if label >= 0.5:\n",
    "                pred[ii] = 1\n",
    "            else:\n",
    "                pred[ii] = 0\n",
    "        pred = pred.tolist()\n",
    "        label = get_labels(input_directory,file,class2index)\n",
    "\n",
    "        \n",
    "        if pred == label:\n",
    "            acc = 1\n",
    "        else:\n",
    "            acc = 0\n",
    "        total_acc += acc\n",
    "        #total_f1 += f1\n",
    "    final_acc = total_acc / i\n",
    "    #final_f1 = total_f1 / i\n",
    "    return final_acc#, final_f1\n",
    "\n",
    "batch_size = 32\n",
    "minimum_len = 2880\n",
    "epochs = 1000\n",
    "loss_function = 'categorical_crossentropy'\n",
    "activation_function = 'softmax'\n",
    "rootdir = '../'\n",
    "date = datetime.today().strftime(\"%Y%m%d\")\n",
    "input_directory = os.path.join(rootdir, 'Training_WFDB')\n",
    "mel_name = 'Raw_data_20200424' \n",
    "mel_directory = os.path.join(rootdir, mel_name)\n",
    "results_directory = os.path.join(rootdir, 'results_'+date+'_0')\n",
    "if not os.path.isdir(input_directory):\n",
    "    os.mkdir(input_directory)\n",
    "if not os.path.isdir(mel_directory):\n",
    "    os.mkdir(mel_directory)\n",
    "# if not os.path.isdir(results_directory):\n",
    "#     os.mkdir(results_directory)\n",
    "        \n",
    "input_files = []\n",
    "for f in os.listdir(input_directory):\n",
    "    if os.path.isfile(os.path.join(input_directory, f)) and not f.lower().startswith('.') and f.lower().endswith('mat'):\n",
    "        input_files.append(f)\n",
    "input_file_names = sorted(input_files)\n",
    "\n",
    "unique_classes = get_unique_classes(input_directory, input_files)\n",
    "class2index = {}\n",
    "for a, b in enumerate(unique_classes):\n",
    "    class2index[b] = a\n",
    "    \n",
    "# classes_orig= [x.replace('.mat', '.hea') for x in input_file_names] # total subjects\n",
    "# classes_multi, _, _ = searching_overlap(input_directory,class2index, input_file_names)\n",
    "# classes_single = [x for x in classes_orig if x not in classes_multi]\n",
    "# classes_single = [x.replace('.hea', '.mat') for x in classes_single]\n",
    "\n",
    "# double-checking if classes_single have single-label\n",
    "# a, b, c  = searching_overlap(input_directory,class2index,classes_single)\n",
    "\n",
    "# we can safely use classes_single as input_file_names\n",
    "# input_file_names = classes_single\n",
    "random.shuffle(input_file_names)\n",
    "np.shape(input_file_names)\n",
    "\n",
    "x_mean_all = []\n",
    "x_std_all = []\n",
    "for file in input_file_names:\n",
    "    x = np.load(mel_directory + '/' + file.replace('.mat', '.npy'))\n",
    "    x_mean = [np.mean(x[:,0]), np.mean(x[:,1]), np.mean(x[:,2]), np.mean(x[:,3]), np.mean(x[:,4]), np.mean(x[:,5]),\n",
    "             np.mean(x[:,6]), np.mean(x[:,7]), np.mean(x[:,8]), np.mean(x[:,9]), np.mean(x[:,10]), np.mean(x[:,11])]\n",
    "    \n",
    "    x_std = [np.std(x[:,0]), np.std(x[:,1]), np.std(x[:,2]), np.std(x[:,3]), np.std(x[:,4]), np.std(x[:,5]),\n",
    "             np.std(x[:,6]), np.std(x[:,7]), np.std(x[:,8]), np.std(x[:,9]), np.std(x[:,10]), np.std(x[:,11])]\n",
    "    #print(x_mean)\n",
    "    x_mean_all.append(x_mean)\n",
    "    x_std_all.append(x_std)\n",
    "x_mean_final = np.mean(x_mean_all, axis=0)\n",
    "x_std_final = np.mean(x_std_all, axis=0)\n",
    "print(x_mean_final)\n",
    "\n",
    "data, data_test = train_test_split(input_file_names, test_size = 0.2, train_size = 0.8, shuffle=True)\n",
    "# data_train, data_val = train_test_split(data, test_size = 0.25, train_size = 0.75, shuffle=True)\n",
    "data_train, data_val = train_test_split(data, test_size = 0.05, train_size = 0.95, shuffle=True)\n",
    "print(np.shape(data_train), np.shape(data_val), np.shape(data_test))\n",
    "\n",
    "main_input = Input(shape=(minimum_len,12), dtype='float32', name='main_input')\n",
    "\n",
    "branch_pred = []\n",
    "for i in range(12):\n",
    "    # Slicing the ith channel:\n",
    "    input_sl = Lambda(lambda x: x[:, :, i:i+1])(main_input)\n",
    "    #print(input_sl)\n",
    "    x1 = GaussianNoise(0.01 ,input_shape=(minimum_len, 1))(input_sl)\n",
    "    x1 = Conv1D(32, 10, dilation_rate=3, padding='same')(x1)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = LeakyReLU(alpha=0.3)(x1)\n",
    "    x2 = Conv1D(32, 10, dilation_rate=3, padding='same')(x1)\n",
    "    x2 = add([x2, x1])\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = LeakyReLU(alpha=0.3)(x2)\n",
    "    #x2 = MaxPooling1D(pool_size=2)(x2)\n",
    "    x2 = Convolution1D(32, 20, strides = 2, padding='same')(x2)\n",
    "    #x2 = Dropout(0.25)(x2)\n",
    "\n",
    "    x3 = Conv1D(64, 10, dilation_rate=2, padding='same')(x2)\n",
    "    x3 = BatchNormalization()(x3)\n",
    "    x3 = LeakyReLU(alpha=0.3)(x3)\n",
    "    x4 = Conv1D(64, 10, dilation_rate=2, padding='same')(x3)\n",
    "    x4 = add([x4, x3])\n",
    "    x4 = BatchNormalization()(x4)\n",
    "    x4 = LeakyReLU(alpha=0.3)(x4)\n",
    "    #x4 = MaxPooling1D(pool_size=2)(x4)\n",
    "    x4 = Convolution1D(32, 20, strides = 2, padding='same')(x4)\n",
    "    #x4 = Dropout(0.25)(x4)\n",
    "\n",
    "    x5 = Conv1D(128, 10, dilation_rate=1, padding='same')(x4)\n",
    "    x5 = BatchNormalization()(x5)\n",
    "    x5 = LeakyReLU(alpha=0.3)(x5)\n",
    "    x6 = Conv1D(128, 10, dilation_rate=1, padding='same')(x5)\n",
    "    x6 = add([x6, x5])\n",
    "    x6 = BatchNormalization()(x6)\n",
    "    x6 = LeakyReLU(alpha=0.3)(x6)\n",
    "    #x6 = MaxPooling1D(pool_size=2)(x6)\n",
    "    x6 = Convolution1D(64, 20, strides = 2, padding='same')(x6)\n",
    "    #x6 = Dropout(0.25)(x6)\n",
    "    '''\n",
    "    x7 = Conv1D(64, 10, dilation_rate=1, padding='same')(x6)\n",
    "    x7 = BatchNormalization()(x7)\n",
    "    x7 = LeakyReLU(alpha=0.3)(x7)\n",
    "    x8 = Conv1D(64, 10, dilation_rate=1, padding='same')(x7)\n",
    "    x8 = add([x8, x7])\n",
    "    x8 = BatchNormalization()(x8)\n",
    "    x8 = LeakyReLU(alpha=0.3)(x8)\n",
    "    #x8 = MaxPooling1D(pool_size=2)(x8)\n",
    "    x8 = Convolution1D(64, 20, strides = 2, padding='same')(x8)\n",
    "    #cnnout = GlobalAveragePooling1D()(x8)\n",
    "    #x8 = Dropout(0.25)(x8)\n",
    "    '''\n",
    "    x = Bidirectional(CuDNNGRU(128, input_shape=(360,128),return_sequences=True,return_state=False))(x6)\n",
    "    x = LeakyReLU(alpha=0.3)(x)\n",
    "    x = AttentionWithContext()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.3)(x)\n",
    "    \n",
    "    #x = GlobalAveragePooling1D()(x8)\n",
    "    #x = Flatten()(x8)\n",
    "    #x = Dense(512)(x)\n",
    "    #x = BatchNormalization()(x)\n",
    "    #x = Activation('relu')(x)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    x = Dense(9)(x)\n",
    "#     pred  = Activation('softmax')(x)\n",
    "    pred  = Activation('sigmoid')(x)\n",
    "    branch_pred.append(pred)\n",
    "    \n",
    "out = Average()(branch_pred)\n",
    "#print(out)\n",
    "\n",
    "model = Model(inputs=main_input, outputs=out)\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=loss_function,\n",
    "              optimizer=optimizers.Adam(lr=1e-5),\n",
    "              metrics=['acc', score_f1])\n",
    "\n",
    "val_acc_sum=[]\n",
    "train_loss_sum=[]\n",
    "train_acc_sum=[]\n",
    "val_loss_sum=[]\n",
    "val_acc_min = 0\n",
    "for num_epoch in range(epochs):\n",
    "    random.shuffle(data_train)\n",
    "    train_loss, train_acc, train_f1 = train(data_train, mel_directory, batch_size, class2index, minimum_len, x_mean_final, x_std_final)\n",
    "    print('\\nEpoch',num_epoch+1,'train_loss:',f'{train_loss:.3f}','train_acc:',f'{train_acc:.3f}','train_f1:',f'{train_f1:.3f}',\"\\t\")\n",
    "    model_output = \"ecg_mel_E%02dL%.2f\" % (num_epoch, train_loss)\n",
    "    save_name = os.path.join(results_directory, model_output)\n",
    "    val_acc = test(data_val, mel_directory, input_directory, class2index, minimum_len, model, x_mean_final, x_std_final)\n",
    "    if val_acc > val_acc_min:\n",
    "        val_acc_min = val_acc\n",
    "#         model.save(save_name)\n",
    "    print('\\nValidation', num_epoch+1, 'valid_acc:',f'{val_acc:.3f}', 'best_acc:',f'{val_acc_min:.3f}', \"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
